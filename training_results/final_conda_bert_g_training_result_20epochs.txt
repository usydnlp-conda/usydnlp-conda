 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
10/09/2021 11:08:25 - INFO - data_loader -   *** Example ***
10/09/2021 11:08:25 - INFO - data_loader -   guid: train-4
10/09/2021 11:08:25 - INFO - data_loader -   tokens: [CLS] w ##tf [SEP]
10/09/2021 11:08:25 - INFO - data_loader -   input_ids: 101 1059 24475 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 11:08:25 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 11:08:25 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 11:08:25 - INFO - data_loader -   intent_label: 4 (id = 4)
10/09/2021 11:08:25 - INFO - data_loader -   slot_labels: 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 11:08:25 - INFO - data_loader -   ner_embeds: [-0.05268421 -0.3358649   0.27530029 -0.07744435 -0.07584086 -0.02695106
 -0.26804128  0.02627846 -0.10347202  0.2013707  -0.01272027  0.16158915
 -0.03340857  0.17287622 -0.18740179  0.26615396  0.09241544 -0.11608424
 -0.27987984 -0.28424925 -0.18137644 -0.22812925  0.0249024   0.30128998
  0.13045995  0.03118261  0.16935138 -0.06230416  0.17561074  0.00367108
 -0.07402565  0.04037194 -0.07837126 -0.1561325   0.20836185  0.14040159
  0.11099035  0.17083055 -0.35949063  0.03112581 -0.18540204  0.04089637
 -0.29396915  0.49076098 -0.05263726 -0.16885227  0.11559261  0.25719538
 -0.1559715  -0.06362429 -0.12877826  0.06794425 -0.01322358  0.26562798
  0.08987913  0.29401389 -0.37333494 -0.01440139  0.30768135 -0.37712052
 -0.108851    0.07931803  0.17231582 -0.44193396  0.03251904  0.0195513
 -0.03582918 -0.13726601 -0.28466982 -0.33915862 -0.0583167   0.01170416
  0.32957253  0.08330661  0.28316665  0.00079225  0.41026247  0.02413866
 -0.45413318 -0.1344302  -0.09248621  0.51263183 -0.13745138 -0.11134322
 -0.20985258  0.39278489 -0.1011213   0.18303782 -0.12043855  0.26268336
 -0.0461308   0.30422714  0.07902091 -0.15427054  0.18763816 -0.00932948
  0.02431204  0.30051631 -0.24693149  0.11975729 -0.0125444   0.13902089
 -0.25323379 -0.1082405   0.42633086  0.19724542 -0.07689937 -0.1337288
  0.27917713 -0.0091875   0.25963399 -0.14592938 -0.05517824  0.0350663
  0.20550938  0.11277337 -0.2699483   0.01591763 -0.00071367  0.07296164
  0.02445946  0.14451511 -0.04559916 -0.17699969 -0.42008832  0.10587756
  0.09828436  0.28259453 -0.0146672  -0.11086253 -0.35100189  0.04879292
 -0.0834544   0.16815855 -0.13103473 -0.02294332  0.36864796  0.14379583
  0.44768068 -0.23370998  0.152519    0.04665052 -0.17252302  0.31976756
 -0.16741526 -0.25466728 -0.26076594  0.00063117 -0.05335071  0.15843306
 -0.26611817  0.05734076 -0.08238135  0.18893163 -0.20564257 -0.16225532
 -0.20887086  0.08916163 -0.01871778  0.12805638  0.26127747 -0.0709104
 -0.27082589 -0.1627634   0.13914403  0.12214889 -0.1563787  -0.24772033
 -0.06986653  0.2272698  -0.05595371 -0.00991442 -0.20372061  0.04004419
 -0.04990653  0.43829471  0.11963772 -0.12598085  0.24185398 -0.04867083
 -0.08653479 -0.26793903  0.13082959 -0.43375427 -0.13357146  0.19298363
 -0.22029646  0.38383847 -0.07818928 -0.0058459  -0.32991308 -0.08181709
  0.14099021  0.09491039  0.21827479 -0.00399596 -0.08103576  0.13853465
  0.01428204  0.44172066  0.10182345  0.14742956 -0.14591892  0.33454806
  0.04376031  0.32970932  0.15365525 -0.22210287 -0.16479632 -0.28103629
  0.00301148  0.01037944  0.20718177 -0.2371673   0.33999005 -0.13203178
 -0.26044402 -0.22456646 -0.09428472  0.12473079 -0.10682054  0.08118179
  0.18629588 -0.10320079  0.10400119 -0.36503249  0.0367523  -0.26162294
 -0.13888274 -0.00607623  0.1842383  -0.33304039  0.17386849 -0.0694743
  0.03439113  0.08467512  0.23954627  0.3646954  -0.02856011 -0.21535675
  0.18716544  0.25370413 -0.18916315  0.1572178  -0.06640452  0.13099778
  0.01409951 -0.31194866 -0.14290154 -0.1712914  -0.32875261 -0.09570646
  0.28620249 -0.23103324  0.22911115  0.02136808 -0.04183525  0.2437249
 -0.1248548  -0.05797715  0.476778   -0.21734898  0.23745687  0.26735842
  0.27674222  0.07875728 -0.16760489 -0.46723711 -0.08130792  0.09524607
 -0.19139667  0.13001987  0.25027886 -0.01569632  0.08894423 -0.10037478
  0.12834264 -0.4296048   0.41507876  0.2195386  -0.00381741 -0.146727
  0.23849073  0.10347191  0.17253159 -0.4031671   0.19611832  0.17422171
  0.3443523  -0.18065456  0.04004083  0.10621159 -0.19717942  0.25161341
 -0.0291713   0.11438692  0.13997085  0.00901562 -0.24855603 -0.01550403] [-0.47509575  0.19322996  0.09058284  0.12235206  0.20578794 -0.3794229
 -0.25328559 -0.20086733 -0.50696862  0.17097612 -0.05185251 -0.27098504
  0.1505567   0.00882347 -0.03236378  0.18745057  0.28245705 -0.11977331
 -0.09746733 -0.25681302 -0.22011192  0.14133778 -0.09037875  0.1428376
  0.05336268  0.2458068   0.14467685  0.12476639  0.20338061 -0.17834681
 -0.11976382 -0.18027107  0.26472208 -0.14300209  0.48964411  0.43201447
 -0.0071297   0.16748212  0.09454816 -0.22697915  0.08857109  0.23078236
 -0.06169993  0.28164837 -0.58418095  0.06461781  0.44695544 -0.02666998
  0.37402087  0.14639162 -0.17126805  0.09270799  0.11221284  0.05032074
  0.3808358  -0.29725406 -0.36730972 -0.14402159 -0.18254577  0.12402073
  0.09387682 -0.22651145 -0.10609733 -0.0136183   0.28536072  0.45290929
 -0.53860331 -0.3619462   0.26005948  0.09354918  0.08874993 -0.46099499
 -0.08624528  0.38800418 -0.0744816  -0.35217977  0.06698658 -0.37457588
  0.02266525 -0.17537478  0.32514113  0.05738147 -0.29305115 -0.31626078
  0.2652005   0.40359458  0.18133615  0.16825841  0.30778497  0.29977912
  0.11703255  0.15107699 -0.38094392 -0.00905125 -0.05924525  0.09739665
  0.22405544 -0.32275772 -0.15189651  0.08419188 -0.0125859   0.38530457
 -0.17455772 -0.19452548  0.12359562 -0.3390587  -0.05763136 -0.4432961
 -0.24677284 -0.36757258  0.57128966 -0.0280515   0.20388041  0.11885364
  0.06200645 -0.13207953  0.27703524 -0.44224432 -0.35678315 -0.41083971
  0.33576921  0.05482301 -0.06200571 -0.29987481  0.34921369  0.18924208
  0.06739873 -0.05239455  0.16044503 -0.03043925  0.16585945  0.1198721
 -0.15038754 -0.16760361 -0.1431416  -0.28948554 -0.26585883 -0.28681776
  0.12636618  0.19202395 -0.51696157 -0.15527061 -0.18057446 -0.04664311
 -0.10404671 -0.17699049 -0.13566346 -0.01460888 -0.108468    0.58548939
 -0.04487317  0.09950307 -0.51150364  0.28937268  0.29389998 -0.20538421
  0.09857183  0.36885765 -0.06212871 -0.34556243  0.12134673 -0.50290102
  0.26917115 -0.37880948  0.10994862 -0.45533454 -0.07806785 -0.1991418
 -0.21206231 -0.12996316 -0.04361296  0.19771098 -0.20996234 -0.02332311
 -0.15923461 -0.20150936  0.00474958  0.54112434 -0.04599045  0.00825694
  0.14641407 -0.53599721 -0.29431322 -0.15927984 -0.09643052  0.06591419
  0.00714104 -0.06892661 -0.1570337  -0.34614766  0.10732599  0.12330206
  0.62872142  0.00976194 -0.09972356  0.55251229  0.26639217  0.22162615
 -0.2339406   0.08052832  0.09413529  0.26647547  0.09899525  0.29793075
  0.15887377 -0.22486597  0.11529019 -0.08634094  0.40688595  0.00185034
  0.15372594  0.12731063 -0.00240551 -0.12942466  0.55968392 -0.17018704
 -0.51134002 -0.04594962  0.01274681 -0.09691153 -0.3937768   0.32149416
  0.25365001 -0.23030996  0.15108523  0.5116173   0.51437283 -0.05148496
  0.29056045  0.06482575 -0.39005435  0.26417333 -0.07566784  0.16243994
 -0.29432714 -0.17263365 -0.06322131 -0.40219173  0.03552081  0.43699551
 -0.19939171 -0.03125809  0.03694878 -0.57863271  0.1433669  -0.18857792
  0.03392582 -0.21754131 -0.25005811  0.06765123  0.19634166  0.25541183
 -0.15626983  0.01426008 -0.18259156 -0.02416558  0.08734059 -0.28485525
  0.15933627 -0.11470606 -0.1866634   0.21417831  0.47832984 -0.37654257
 -0.19679652 -0.33287853 -0.38257587 -0.11773556 -0.17417422  0.13042571
 -0.33089721 -0.27325413  0.07948069  0.03535396 -0.19736187  0.44519433
 -0.38347244 -0.28470078 -0.04555248 -0.00672489  0.16680367 -0.46688628
  0.2609579  -0.24713737  0.15496723 -0.1301744  -0.24742807 -0.32724041
 -0.03993053  0.31702393 -0.12842414  0.25210178  0.15610629 -0.26908815
 -0.51959801  0.32177866  0.30455482  0.46877158  0.07606479  0.12330614] [-0.9501915   0.38645992  0.18116568  0.24470413  0.41157588 -0.75884581
 -0.50657117 -0.40173465 -1.01393723  0.34195223 -0.10370502 -0.54197007
  0.3011134   0.01764694 -0.06472756  0.37490115  0.56491411 -0.23954663
 -0.19493465 -0.51362604 -0.44022384  0.28267556 -0.18075751  0.2856752
  0.10672535  0.4916136   0.2893537   0.24953279  0.40676123 -0.35669363
 -0.23952764 -0.36054215  0.52944416 -0.28600419  0.97928822  0.86402893
 -0.0142594   0.33496425  0.18909632 -0.4539583   0.17714217  0.46156472
 -0.12339986  0.56329674 -1.1683619   0.12923563  0.89391088 -0.05333996
  0.74804175  0.29278323 -0.34253609  0.18541598  0.22442567  0.10064148
  0.7616716  -0.59450811 -0.73461944 -0.28804317 -0.36509153  0.24804147
  0.18775363 -0.4530229  -0.21219467 -0.0272366   0.57072145  0.90581858
 -1.07720661 -0.72389239  0.52011895  0.18709837  0.17749986 -0.92198998
 -0.17249057  0.77600837 -0.1489632  -0.70435953  0.13397315 -0.74915177
  0.0453305  -0.35074955  0.65028226  0.11476294 -0.58610231 -0.63252157
  0.53040099  0.80718917  0.3626723   0.33651683  0.61556995  0.59955823
  0.2340651   0.30215397 -0.76188785 -0.0181025  -0.11849051  0.1947933
  0.44811088 -0.64551544 -0.30379301  0.16838376 -0.02517181  0.77060914
 -0.34911543 -0.38905096  0.24719124 -0.67811739 -0.11526272 -0.88659221
 -0.49354568 -0.73514515  1.14257932 -0.056103    0.40776083  0.23770727
  0.12401291 -0.26415905  0.55407047 -0.88448864 -0.7135663  -0.82167941
  0.67153841  0.10964603 -0.12401143 -0.59974962  0.69842738  0.37848416
  0.13479747 -0.1047891   0.32089007 -0.0608785   0.33171889  0.2397442
 -0.30077508 -0.33520722 -0.2862832  -0.57897109 -0.53171766 -0.57363552
  0.25273237  0.3840479  -1.03392315 -0.31054121 -0.36114892 -0.09328622
 -0.20809342 -0.35398099 -0.27132693 -0.02921776 -0.21693599  1.17097878
 -0.08974633  0.19900614 -1.02300727  0.57874537  0.58779997 -0.41076842
  0.19714366  0.7377153  -0.12425742 -0.69112486  0.24269347 -1.00580204
  0.5383423  -0.75761896  0.21989724 -0.91066909 -0.15613569 -0.3982836
 -0.42412463 -0.25992632 -0.08722592  0.39542195 -0.41992468 -0.04664622
 -0.31846923 -0.40301871  0.00949917  1.08224869 -0.0919809   0.01651389
  0.29282814 -1.07199442 -0.58862644 -0.31855968 -0.19286104  0.13182838
  0.01428208 -0.13785322 -0.31406739 -0.69229531  0.21465197  0.24660411
  1.25744283  0.01952389 -0.19944711  1.10502458  0.53278434  0.4432523
 -0.4678812   0.16105664  0.18827058  0.53295094  0.19799049  0.59586149
  0.31774753 -0.44973195  0.23058039 -0.17268188  0.8137719   0.00370069
  0.30745187  0.25462127 -0.00481102 -0.25884932  1.11936784 -0.34037408
 -1.02268004 -0.09189923  0.02549363 -0.19382305 -0.78755361  0.64298832
  0.50730002 -0.46061993  0.30217046  1.02323461  1.02874565 -0.10296992
  0.58112091  0.1296515  -0.78010869  0.52834666 -0.15133567  0.32487988
 -0.58865428 -0.3452673  -0.12644263 -0.80438346  0.07104162  0.87399101
 -0.39878342 -0.06251618  0.07389756 -1.15726542  0.28673381 -0.37715584
  0.06785164 -0.43508261 -0.50011623  0.13530245  0.39268333  0.51082367
 -0.31253967  0.02852016 -0.36518312 -0.04833116  0.17468119 -0.56971049
  0.31867254 -0.22941212 -0.37332681  0.42835662  0.95665967 -0.75308514
 -0.39359304 -0.66575706 -0.76515174 -0.23547111 -0.34834844  0.26085141
 -0.66179442 -0.54650825  0.15896139  0.07070792 -0.39472374  0.89038867
 -0.76694489 -0.56940156 -0.09110496 -0.01344978  0.33360735 -0.93377256
  0.52191579 -0.49427474  0.30993447 -0.2603488  -0.49485615 -0.65448081
 -0.07986105  0.63404787 -0.25684828  0.50420356  0.31221259 -0.5381763
 -1.03919601  0.64355731  0.60910964  0.93754315  0.15212958  0.24661228] [ 3.23701560e-01  1.23859271e-01  3.17038149e-01 -1.99837953e-01
  1.45933881e-01  1.97479472e-01  1.11766860e-01 -2.97712028e-01
  2.12801516e-01 -8.30430072e-03 -1.36353567e-01  5.88244051e-02
 -1.61227629e-01  3.60989422e-01  2.74212211e-01 -1.38430834e-01
 -5.86703680e-02 -4.27209228e-01 -4.38389741e-02 -1.70130521e-01
 -2.79001564e-01 -5.08604087e-02 -2.22016856e-01  3.46666753e-01
 -1.82083368e-01 -1.79737844e-02 -7.58341700e-02 -2.81926543e-01
 -8.88730120e-03 -9.31498557e-02 -1.63259923e-01  2.63657838e-01
  2.68971026e-01 -1.65585026e-01 -1.38222620e-01 -1.05521366e-01
 -2.16932997e-01  1.53523952e-01 -6.68047294e-02 -1.14297360e-01
 -1.98990464e-01  9.14934743e-03  2.44847938e-01 -1.28512876e-02
  1.28243208e-01 -1.80381879e-01  1.76793709e-01  1.34143546e-01
 -9.09292847e-02  1.11920275e-02 -1.59795374e-01  4.03871059e-01
 -2.08633363e-01  2.61400253e-01 -1.77513242e-01  2.64400899e-01
 -3.74767929e-01 -1.41106667e-02  7.07195699e-02 -2.59310529e-02
 -1.52463704e-01 -2.09277481e-01  2.42659152e-01 -4.37896281e-01
 -2.74111658e-01  3.23784024e-01 -1.12194913e-02 -7.78998435e-03
 -2.63834894e-01 -1.86299264e-01 -1.20873287e-01  2.04141185e-01
  1.60952255e-01  3.01728785e-01  2.21852630e-01  1.73017696e-01
  3.71879220e-01  2.80739516e-01 -1.18493669e-01  1.09062918e-01
 -2.55998373e-01  3.87480080e-01  4.10263650e-02  2.02835858e-01
 -3.17999512e-01  3.78140330e-01  2.57947147e-01 -4.50112194e-01
  1.04353130e-01  1.40699465e-03  7.67216682e-02 -1.11133285e-01
  1.40065238e-01 -3.31422426e-02  6.38056397e-02 -1.78506866e-01
  1.02249458e-01 -1.90868706e-01 -2.67677069e-01  8.56479257e-02
  1.85055599e-01  2.22840309e-01 -1.93136290e-01 -1.12496831e-01
  2.01004639e-01 -3.48373577e-02 -1.59934118e-01  2.03856632e-01
  2.03415796e-01  1.91151500e-02 -2.14736730e-01 -2.01674789e-01
 -1.03147745e-01  2.00410113e-01  6.62044063e-02 -5.02013564e-02
 -1.48162618e-01 -1.72178164e-01 -1.56178564e-01  2.05861077e-01
 -2.44715880e-03 -4.20740098e-02  1.99603319e-01 -3.03595811e-01
 -2.62882337e-02  5.65342568e-02  1.27887994e-01  1.71164036e-01
 -1.49366796e-01 -6.41742051e-02  1.59788847e-01 -1.77765921e-01
  1.73824430e-01 -1.28364572e-02  3.04782897e-01  8.32331404e-02
  4.28962141e-01  1.86484933e-01  3.57698888e-01  1.70930754e-02
  1.14737764e-01  1.83813170e-01  7.07985610e-02  1.53863117e-01
  1.45394146e-01  6.10771216e-02 -7.36576989e-02  5.53056449e-02
  1.07640862e-01  8.00179467e-02  3.23191434e-02  3.09991091e-01
  3.02178174e-01 -9.09306332e-02  4.91853952e-02 -1.28031313e-01
 -2.54896469e-02  2.34120145e-01 -1.74658343e-01 -2.32459098e-01
  6.18232414e-02 -2.38484278e-01 -6.28195284e-03  1.03620939e-01
  2.82353729e-01 -6.52055070e-02  7.75345117e-02 -1.90856859e-01
 -1.25437349e-01  1.37492150e-01 -1.64269745e-01  2.51677603e-01
  2.33259335e-01  2.17757478e-01  2.26037607e-01  4.26998675e-01
 -1.67967141e-01  2.59857118e-01  7.12665543e-02  1.49024948e-01
 -4.46223438e-01  1.28380001e-01  1.54407173e-01 -2.38353878e-01
 -4.55187351e-01 -1.71284303e-02 -2.03437835e-01  4.44028795e-01
  1.49454489e-01  2.29066014e-01  5.37483320e-02  1.16622731e-01
  3.27921122e-01  8.48986357e-02  2.98905432e-01 -1.16589181e-01
  3.75571474e-02  2.16130674e-01  5.97562492e-02  1.57818839e-01
 -3.79134119e-01  1.97058737e-01  8.41842405e-03 -6.73631504e-02
  3.26564431e-01  1.02038927e-01  9.84950215e-02 -4.74490523e-02
 -3.58012021e-01 -8.46094415e-02 -2.53597409e-01  1.31108731e-01
 -1.36945480e-02 -2.58189082e-01 -4.04197037e-01 -9.93263200e-02
  7.22196922e-02 -3.21413815e-01  1.38105333e-01  5.27646877e-02
 -3.74778695e-02 -3.09642814e-02  8.79964158e-02  9.22843367e-02
  6.59269169e-02 -4.25867379e-01 -1.13668293e-01 -2.31259083e-03
  1.71499252e-02  4.65329364e-02  2.83751369e-01 -9.33092088e-06
  2.11278170e-01 -1.37060642e-01  4.17382754e-02 -7.07651116e-03
  1.57808796e-01 -6.90133646e-02  2.53847003e-01 -2.96002537e-01
  1.61520377e-01  9.76996198e-02 -2.18553003e-02 -1.24721631e-01
  1.75630823e-01 -6.57364130e-02 -2.27706671e-01 -1.50046155e-01
 -4.29430157e-01 -8.62716325e-03 -3.48888189e-01  8.30511972e-02
  1.19602770e-01 -1.06453761e-01 -3.39551032e-01  5.58682233e-02
 -1.50723115e-01 -8.26126337e-02 -1.29831970e-01  9.88700613e-02
  4.37329859e-01 -1.03127375e-01  2.38669097e-01 -8.08308348e-02
  3.22031081e-02 -4.68674600e-02 -1.37694642e-01 -3.00011188e-01
 -2.28143096e-01  1.68973625e-01 -1.38916388e-01 -2.30189320e-02
  7.20473751e-03  2.29728416e-01 -5.10682501e-02 -2.43143052e-01
  7.35338554e-02 -9.28391144e-02  1.04980737e-01 -1.35518312e-01
 -3.77203338e-02 -6.18087426e-02  3.51022571e-01 -1.79783516e-02
  3.15492228e-02 -5.28395176e-01 -6.82753976e-03 -7.57957473e-02
  5.80136776e-01  7.35457381e-03  2.11273469e-02  1.24203205e-01
 -1.12393416e-01  3.32168788e-01 -2.33854130e-01 -1.09314382e-01
  1.09809563e-01  6.32748082e-02 -3.05012822e-01 -1.37086868e-01] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
10/09/2021 11:08:28 - INFO - data_loader -   Writing example 5000 of 26078
10/09/2021 11:08:30 - INFO - data_loader -   Writing example 10000 of 26078
10/09/2021 11:08:33 - INFO - data_loader -   Writing example 15000 of 26078
10/09/2021 11:08:36 - INFO - data_loader -   Writing example 20000 of 26078
10/09/2021 11:08:38 - INFO - data_loader -   Writing example 25000 of 26078
10/09/2021 11:08:39 - INFO - data_loader -   Saving features into cached file ./data\cached_train_conda_bert-base-uncased_50
10/09/2021 11:09:59 - INFO - data_loader -   Creating features from dataset file at ./data
10/09/2021 11:09:59 - INFO - data_loader -   LOOKING AT ./data\conda\dev
10/09/2021 11:10:00 - INFO - data_loader -   Writing example 0 of 8705
10/09/2021 11:10:00 - INFO - data_loader -   *** Example ***
10/09/2021 11:10:00 - INFO - data_loader -   guid: dev-0
10/09/2021 11:10:00 - INFO - data_loader -   tokens: [CLS] g ##g [SEP]
10/09/2021 11:10:00 - INFO - data_loader -   input_ids: 101 1043 2290 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 11:10:00 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 11:10:00 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 11:10:00 - INFO - data_loader -   intent_label: 4 (id = 4)
10/09/2021 11:10:00 - INFO - data_loader -   slot_labels: 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 11:10:00 - INFO - data_loader -   ner_embeds: [-0.05268421 -0.3358649   0.27530029 -0.07744435 -0.07584086 -0.02695106
 -0.26804128  0.02627846 -0.10347202  0.2013707  -0.01272027  0.16158915
 -0.03340857  0.17287622 -0.18740179  0.26615396  0.09241544 -0.11608424
 -0.27987984 -0.28424925 -0.18137644 -0.22812925  0.0249024   0.30128998
  0.13045995  0.03118261  0.16935138 -0.06230416  0.17561074  0.00367108
 -0.07402565  0.04037194 -0.07837126 -0.1561325   0.20836185  0.14040159
  0.11099035  0.17083055 -0.35949063  0.03112581 -0.18540204  0.04089637
 -0.29396915  0.49076098 -0.05263726 -0.16885227  0.11559261  0.25719538
 -0.1559715  -0.06362429 -0.12877826  0.06794425 -0.01322358  0.26562798
  0.08987913  0.29401389 -0.37333494 -0.01440139  0.30768135 -0.37712052
 -0.108851    0.07931803  0.17231582 -0.44193396  0.03251904  0.0195513
 -0.03582918 -0.13726601 -0.28466982 -0.33915862 -0.0583167   0.01170416
  0.32957253  0.08330661  0.28316665  0.00079225  0.41026247  0.02413866
 -0.45413318 -0.1344302  -0.09248621  0.51263183 -0.13745138 -0.11134322
 -0.20985258  0.39278489 -0.1011213   0.18303782 -0.12043855  0.26268336
 -0.0461308   0.30422714  0.07902091 -0.15427054  0.18763816 -0.00932948
  0.02431204  0.30051631 -0.24693149  0.11975729 -0.0125444   0.13902089
 -0.25323379 -0.1082405   0.42633086  0.19724542 -0.07689937 -0.1337288
  0.27917713 -0.0091875   0.25963399 -0.14592938 -0.05517824  0.0350663
  0.20550938  0.11277337 -0.2699483   0.01591763 -0.00071367  0.07296164
  0.02445946  0.14451511 -0.04559916 -0.17699969 -0.42008832  0.10587756
  0.09828436  0.28259453 -0.0146672  -0.11086253 -0.35100189  0.04879292
 -0.0834544   0.16815855 -0.13103473 -0.02294332  0.36864796  0.14379583
  0.44768068 -0.23370998  0.152519    0.04665052 -0.17252302  0.31976756
 -0.16741526 -0.25466728 -0.26076594  0.00063117 -0.05335071  0.15843306
 -0.26611817  0.05734076 -0.08238135  0.18893163 -0.20564257 -0.16225532
 -0.20887086  0.08916163 -0.01871778  0.12805638  0.26127747 -0.0709104
 -0.27082589 -0.1627634   0.13914403  0.12214889 -0.1563787  -0.24772033
 -0.06986653  0.2272698  -0.05595371 -0.00991442 -0.20372061  0.04004419
 -0.04990653  0.43829471  0.11963772 -0.12598085  0.24185398 -0.04867083
 -0.08653479 -0.26793903  0.13082959 -0.43375427 -0.13357146  0.19298363
 -0.22029646  0.38383847 -0.07818928 -0.0058459  -0.32991308 -0.08181709
  0.14099021  0.09491039  0.21827479 -0.00399596 -0.08103576  0.13853465
  0.01428204  0.44172066  0.10182345  0.14742956 -0.14591892  0.33454806
  0.04376031  0.32970932  0.15365525 -0.22210287 -0.16479632 -0.28103629
  0.00301148  0.01037944  0.20718177 -0.2371673   0.33999005 -0.13203178
 -0.26044402 -0.22456646 -0.09428472  0.12473079 -0.10682054  0.08118179
  0.18629588 -0.10320079  0.10400119 -0.36503249  0.0367523  -0.26162294
 -0.13888274 -0.00607623  0.1842383  -0.33304039  0.17386849 -0.0694743
  0.03439113  0.08467512  0.23954627  0.3646954  -0.02856011 -0.21535675
  0.18716544  0.25370413 -0.18916315  0.1572178  -0.06640452  0.13099778
  0.01409951 -0.31194866 -0.14290154 -0.1712914  -0.32875261 -0.09570646
  0.28620249 -0.23103324  0.22911115  0.02136808 -0.04183525  0.2437249
 -0.1248548  -0.05797715  0.476778   -0.21734898  0.23745687  0.26735842
  0.27674222  0.07875728 -0.16760489 -0.46723711 -0.08130792  0.09524607
 -0.19139667  0.13001987  0.25027886 -0.01569632  0.08894423 -0.10037478
  0.12834264 -0.4296048   0.41507876  0.2195386  -0.00381741 -0.146727
  0.23849073  0.10347191  0.17253159 -0.4031671   0.19611832  0.17422171
  0.3443523  -0.18065456  0.04004083  0.10621159 -0.19717942  0.25161341
 -0.0291713   0.11438692  0.13997085  0.00901562 -0.24855603 -0.01550403] [ 9.94096473e-02  1.19312815e-01 -9.33764353e-02 -4.25696746e-02
  4.17188138e-01 -5.86546622e-02  2.15518206e-01  1.22023135e-01
  2.09057584e-01  1.17953038e-02  8.47322792e-02  1.43146262e-01
 -1.39627561e-01  2.59714156e-01 -2.64549553e-01  3.10089469e-01
  1.14079483e-01  3.03147167e-01 -8.15753713e-02  5.04350066e-01
  3.21641892e-01 -2.76540332e-02 -2.89069474e-01 -1.69619933e-01
 -5.03163755e-01 -4.60146755e-01  6.48206770e-02  4.45801973e-01
  6.41951337e-02 -5.35977893e-02 -2.68705990e-02  1.50703564e-01
 -4.72604990e-01  4.83997673e-01 -2.63399392e-01 -2.20703796e-01
  4.51787114e-01  1.18893191e-01 -5.47770679e-01 -5.17525971e-01
  1.19261786e-01  3.29121977e-01  7.83838518e-03 -1.79883689e-01
 -5.24080396e-01 -6.34573549e-02  2.21342385e-01 -2.15865135e-01
  1.48523942e-01  8.19553807e-02  2.70463079e-01  4.56108123e-01
 -4.05909717e-02 -2.17257753e-01  3.21579456e-01  1.30941933e-02
 -7.22500905e-02  1.47749320e-01 -6.29376888e-01  4.80538197e-02
 -2.36863703e-01  3.14069241e-01 -7.10393488e-02 -1.33733675e-01
 -1.82793349e-01  1.13440953e-01  1.47504091e-01 -4.49551672e-01
  7.72698000e-02 -5.79230428e-01 -1.88219279e-01 -1.42732821e-02
  4.45656292e-02 -2.22575843e-01 -3.89550954e-01 -1.01263719e-02
 -2.38270983e-01 -2.46616021e-01  4.08060908e-01  9.91034731e-02
  2.01077804e-01  2.81141669e-01 -2.55549788e-01 -2.65430033e-01
 -3.77000570e-01 -4.02990252e-01  6.89363182e-02  1.59485579e-01
 -1.83008499e-02 -2.02545688e-01  1.05150640e-01 -1.34824544e-01
  3.29241902e-01 -1.36965960e-01  8.68117288e-02 -3.67255747e-01
 -7.25254193e-02 -6.38537705e-01 -5.89296073e-02  2.01410532e-01
  9.42493752e-02  1.03793353e-01  2.69673645e-01 -3.93290132e-01
 -4.75863725e-01 -1.66134164e-01  1.05060376e-01 -3.35802168e-01
 -1.26313433e-01 -3.42342198e-01 -1.52601331e-01 -1.33479565e-01
  1.94103673e-01 -2.84942776e-01 -1.14353187e-01 -4.93788600e-01
 -6.43075109e-02 -4.09203768e-01 -5.92127681e-01  1.14830986e-01
  5.20076931e-01  2.06778437e-01  1.17242642e-01  5.09331822e-01
  1.69195116e-01 -1.59063801e-01  2.17850715e-01  1.52569026e-01
  1.44616619e-01 -4.42199260e-01 -2.67903786e-02  8.82498696e-02
 -1.61579624e-01 -4.06966090e-01  4.84902084e-01 -1.36901006e-01
  1.26930892e-01 -2.08858788e-01  2.00820848e-01 -2.46350765e-01
  2.38958970e-01  5.11010401e-02 -1.05898328e-01 -1.36692986e-01
  2.44770721e-01  2.95235142e-02 -1.33861884e-01  2.06235796e-02
  2.83613801e-02  8.40368494e-02 -8.52909908e-02 -3.50011289e-02
  2.67470628e-01 -5.16022682e-01  1.42725959e-01 -2.68871486e-01
 -4.13323581e-01  7.06061199e-02  2.05460563e-01 -3.88843715e-01
 -5.84297208e-03  6.73958063e-02  1.45167559e-01  8.47199932e-02
  6.60234928e-01 -2.02942431e-01  2.08981514e-01 -1.58144131e-01
  3.48434150e-01  1.28079623e-01  3.31026733e-01  2.61199564e-01
 -3.71263146e-01 -1.22195734e-02  2.24038541e-01 -3.16527814e-01
  6.78575188e-02  3.72334838e-01  5.95289879e-02 -8.18364918e-02
  9.55014974e-02 -1.27901271e-01 -1.55855313e-01  3.28307003e-01
  3.03833276e-01  1.48850635e-01  1.78786665e-01  7.63006285e-02
 -3.82620953e-02  1.17937714e-01 -4.82431501e-01  7.91997015e-02
 -3.26263428e-01  7.52013996e-02 -1.73647210e-01 -2.30165154e-01
 -1.39010713e-01  8.82228389e-02  1.18557245e-01 -2.89696127e-01
 -1.79604650e-01  4.97855060e-02 -2.28054952e-02 -1.36541590e-01
 -5.26000261e-02 -4.56149178e-03 -5.20279467e-01 -2.56557703e-01
  1.83626160e-01  3.93377542e-02  3.80189896e-01 -2.97209263e-01
  4.56239551e-01 -4.20859575e-01 -4.41898704e-01  3.19875479e-02
 -3.72062832e-01 -2.12315544e-01 -5.10225177e-01  2.31819659e-01
 -3.18632364e-01  3.62926662e-01 -3.01839709e-01 -2.85889953e-02
 -2.77682394e-01 -5.32362461e-01  2.03293175e-01 -2.71245122e-01
  2.63406355e-02  9.34485421e-02 -1.19484514e-01 -3.45702082e-01
  4.97622117e-02  3.06293309e-01  1.92443877e-01 -4.35656160e-01
 -7.90845416e-03 -4.17287834e-03 -9.52548161e-02 -5.97981095e-01
 -3.27611625e-01  5.36780746e-04  8.04049596e-02 -3.09665482e-02
 -1.42511427e-01 -6.08815253e-01  1.04902357e-01  2.01484337e-01
  3.92471999e-01  1.35647699e-01 -3.58042819e-03  8.59638825e-02
 -1.25722721e-01  9.83606651e-02 -2.21221969e-01  4.22261685e-01
 -8.87843370e-02 -3.87901336e-01  2.99093574e-01  7.04115033e-02
 -2.70217627e-01  3.63515764e-01  4.20968682e-01 -3.10121328e-01
  5.21569371e-01  3.46722811e-01  1.73930451e-01 -1.77179426e-01
  8.28839615e-02  5.99534333e-01 -8.26911405e-02  1.90694720e-01
 -1.78041190e-01 -2.08937898e-01 -2.09803835e-01  5.76521344e-02
  4.71725345e-01  1.94638416e-01  6.82845488e-02 -2.01363340e-01
  1.44115627e-01 -3.61593276e-01 -2.82532394e-01 -6.36797398e-02
 -1.48895010e-01 -1.19195864e-01  3.48304123e-01 -1.86844796e-01
 -2.50648052e-01 -2.49622064e-03  2.23419338e-01 -8.46120790e-02
 -3.27497005e-01  3.52137059e-01  1.00756988e-01  1.82901457e-01
  2.67331097e-02  4.13346112e-01  1.09819457e-01  2.43459269e-01] [ 1.98819295e-01  2.38625631e-01 -1.86752871e-01 -8.51393491e-02
  8.34376276e-01 -1.17309324e-01  4.31036413e-01  2.44046271e-01
  4.18115169e-01  2.35906076e-02  1.69464558e-01  2.86292523e-01
 -2.79255122e-01  5.19428313e-01 -5.29099107e-01  6.20178938e-01
  2.28158966e-01  6.06294334e-01 -1.63150743e-01  1.00870013e+00
  6.43283784e-01 -5.53080663e-02 -5.78138947e-01 -3.39239866e-01
 -1.00632751e+00 -9.20293510e-01  1.29641354e-01  8.91603947e-01
  1.28390267e-01 -1.07195579e-01 -5.37411980e-02  3.01407129e-01
 -9.45209980e-01  9.67995346e-01 -5.26798785e-01 -4.41407591e-01
  9.03574228e-01  2.37786382e-01 -1.09554136e+00 -1.03505194e+00
  2.38523573e-01  6.58243954e-01  1.56767704e-02 -3.59767377e-01
 -1.04816079e+00 -1.26914710e-01  4.42684770e-01 -4.31730270e-01
  2.97047883e-01  1.63910761e-01  5.40926158e-01  9.12216246e-01
 -8.11819434e-02 -4.34515506e-01  6.43158913e-01  2.61883866e-02
 -1.44500181e-01  2.95498639e-01 -1.25875378e+00  9.61076394e-02
 -4.73727405e-01  6.28138483e-01 -1.42078698e-01 -2.67467350e-01
 -3.65586698e-01  2.26881906e-01  2.95008183e-01 -8.99103343e-01
  1.54539600e-01 -1.15846086e+00 -3.76438558e-01 -2.85465643e-02
  8.91312584e-02 -4.45151687e-01 -7.79101908e-01 -2.02527437e-02
 -4.76541966e-01 -4.93232042e-01  8.16121817e-01  1.98206946e-01
  4.02155608e-01  5.62283337e-01 -5.11099577e-01 -5.30860066e-01
 -7.54001141e-01 -8.05980504e-01  1.37872636e-01  3.18971157e-01
 -3.66016999e-02 -4.05091375e-01  2.10301280e-01 -2.69649088e-01
  6.58483803e-01 -2.73931921e-01  1.73623458e-01 -7.34511495e-01
 -1.45050839e-01 -1.27707541e+00 -1.17859215e-01  4.02821064e-01
  1.88498750e-01  2.07586706e-01  5.39347291e-01 -7.86580265e-01
 -9.51727450e-01 -3.32268327e-01  2.10120752e-01 -6.71604335e-01
 -2.52626866e-01 -6.84684396e-01 -3.05202663e-01 -2.66959131e-01
  3.88207346e-01 -5.69885552e-01 -2.28706375e-01 -9.87577200e-01
 -1.28615022e-01 -8.18407536e-01 -1.18425536e+00  2.29661971e-01
  1.04015386e+00  4.13556874e-01  2.34485283e-01  1.01866364e+00
  3.38390231e-01 -3.18127602e-01  4.35701430e-01  3.05138052e-01
  2.89233238e-01 -8.84398520e-01 -5.35807572e-02  1.76499739e-01
 -3.23159248e-01 -8.13932180e-01  9.69804168e-01 -2.73802012e-01
  2.53861785e-01 -4.17717576e-01  4.01641697e-01 -4.92701530e-01
  4.77917939e-01  1.02202080e-01 -2.11796656e-01 -2.73385972e-01
  4.89541441e-01  5.90470284e-02 -2.67723769e-01  4.12471592e-02
  5.67227602e-02  1.68073699e-01 -1.70581982e-01 -7.00022578e-02
  5.34941256e-01 -1.03204536e+00  2.85451919e-01 -5.37742972e-01
 -8.26647162e-01  1.41212240e-01  4.10921127e-01 -7.77687430e-01
 -1.16859442e-02  1.34791613e-01  2.90335119e-01  1.69439986e-01
  1.32046986e+00 -4.05884862e-01  4.17963028e-01 -3.16288263e-01
  6.96868300e-01  2.56159246e-01  6.62053466e-01  5.22399127e-01
 -7.42526293e-01 -2.44391467e-02  4.48077083e-01 -6.33055627e-01
  1.35715038e-01  7.44669676e-01  1.19057976e-01 -1.63672984e-01
  1.91002995e-01 -2.55802542e-01 -3.11710626e-01  6.56614006e-01
  6.07666552e-01  2.97701269e-01  3.57573330e-01  1.52601257e-01
 -7.65241906e-02  2.35875428e-01 -9.64863002e-01  1.58399403e-01
 -6.52526855e-01  1.50402799e-01 -3.47294420e-01 -4.60330307e-01
 -2.78021425e-01  1.76445678e-01  2.37114489e-01 -5.79392254e-01
 -3.59209299e-01  9.95710120e-02 -4.56109904e-02 -2.73083180e-01
 -1.05200052e-01 -9.12298355e-03 -1.04055893e+00 -5.13115406e-01
  3.67252320e-01  7.86755085e-02  7.60379791e-01 -5.94418526e-01
  9.12479103e-01 -8.41719151e-01 -8.83797407e-01  6.39750957e-02
 -7.44125664e-01 -4.24631089e-01 -1.02045035e+00  4.63639319e-01
 -6.37264729e-01  7.25853324e-01 -6.03679419e-01 -5.71779907e-02
 -5.55364788e-01 -1.06472492e+00  4.06586349e-01 -5.42490244e-01
  5.26812710e-02  1.86897084e-01 -2.38969028e-01 -6.91404164e-01
  9.95244235e-02  6.12586617e-01  3.84887755e-01 -8.71312320e-01
 -1.58169083e-02 -8.34575668e-03 -1.90509632e-01 -1.19596219e+00
 -6.55223250e-01  1.07356149e-03  1.60809919e-01 -6.19330965e-02
 -2.85022855e-01 -1.21763051e+00  2.09804714e-01  4.02968675e-01
  7.84943998e-01  2.71295398e-01 -7.16085639e-03  1.71927765e-01
 -2.51445442e-01  1.96721330e-01 -4.42443937e-01  8.44523370e-01
 -1.77568674e-01 -7.75802672e-01  5.98187149e-01  1.40823007e-01
 -5.40435255e-01  7.27031529e-01  8.41937363e-01 -6.20242655e-01
  1.04313874e+00  6.93445623e-01  3.47860903e-01 -3.54358852e-01
  1.65767923e-01  1.19906867e+00 -1.65382281e-01  3.81389439e-01
 -3.56082380e-01 -4.17875797e-01 -4.19607669e-01  1.15304269e-01
  9.43450689e-01  3.89276832e-01  1.36569098e-01 -4.02726680e-01
  2.88231254e-01 -7.23186553e-01 -5.65064788e-01 -1.27359480e-01
 -2.97790021e-01 -2.38391727e-01  6.96608245e-01 -3.73689592e-01
 -5.01296103e-01 -4.99244127e-03  4.46838677e-01 -1.69224158e-01
 -6.54994011e-01  7.04274118e-01  2.01513976e-01  3.65802914e-01
  5.34662195e-02  8.26692224e-01  2.19638914e-01  4.86918539e-01] [ 3.23701560e-01  1.23859271e-01  3.17038149e-01 -1.99837953e-01
  1.45933881e-01  1.97479472e-01  1.11766860e-01 -2.97712028e-01
  2.12801516e-01 -8.30430072e-03 -1.36353567e-01  5.88244051e-02
 -1.61227629e-01  3.60989422e-01  2.74212211e-01 -1.38430834e-01
 -5.86703680e-02 -4.27209228e-01 -4.38389741e-02 -1.70130521e-01
 -2.79001564e-01 -5.08604087e-02 -2.22016856e-01  3.46666753e-01
 -1.82083368e-01 -1.79737844e-02 -7.58341700e-02 -2.81926543e-01
 -8.88730120e-03 -9.31498557e-02 -1.63259923e-01  2.63657838e-01
  2.68971026e-01 -1.65585026e-01 -1.38222620e-01 -1.05521366e-01
 -2.16932997e-01  1.53523952e-01 -6.68047294e-02 -1.14297360e-01
 -1.98990464e-01  9.14934743e-03  2.44847938e-01 -1.28512876e-02
  1.28243208e-01 -1.80381879e-01  1.76793709e-01  1.34143546e-01
 -9.09292847e-02  1.11920275e-02 -1.59795374e-01  4.03871059e-01
 -2.08633363e-01  2.61400253e-01 -1.77513242e-01  2.64400899e-01
 -3.74767929e-01 -1.41106667e-02  7.07195699e-02 -2.59310529e-02
 -1.52463704e-01 -2.09277481e-01  2.42659152e-01 -4.37896281e-01
 -2.74111658e-01  3.23784024e-01 -1.12194913e-02 -7.78998435e-03
 -2.63834894e-01 -1.86299264e-01 -1.20873287e-01  2.04141185e-01
  1.60952255e-01  3.01728785e-01  2.21852630e-01  1.73017696e-01
  3.71879220e-01  2.80739516e-01 -1.18493669e-01  1.09062918e-01
 -2.55998373e-01  3.87480080e-01  4.10263650e-02  2.02835858e-01
 -3.17999512e-01  3.78140330e-01  2.57947147e-01 -4.50112194e-01
  1.04353130e-01  1.40699465e-03  7.67216682e-02 -1.11133285e-01
  1.40065238e-01 -3.31422426e-02  6.38056397e-02 -1.78506866e-01
  1.02249458e-01 -1.90868706e-01 -2.67677069e-01  8.56479257e-02
  1.85055599e-01  2.22840309e-01 -1.93136290e-01 -1.12496831e-01
  2.01004639e-01 -3.48373577e-02 -1.59934118e-01  2.03856632e-01
  2.03415796e-01  1.91151500e-02 -2.14736730e-01 -2.01674789e-01
 -1.03147745e-01  2.00410113e-01  6.62044063e-02 -5.02013564e-02
 -1.48162618e-01 -1.72178164e-01 -1.56178564e-01  2.05861077e-01
 -2.44715880e-03 -4.20740098e-02  1.99603319e-01 -3.03595811e-01
 -2.62882337e-02  5.65342568e-02  1.27887994e-01  1.71164036e-01
 -1.49366796e-01 -6.41742051e-02  1.59788847e-01 -1.77765921e-01
  1.73824430e-01 -1.28364572e-02  3.04782897e-01  8.32331404e-02
  4.28962141e-01  1.86484933e-01  3.57698888e-01  1.70930754e-02
  1.14737764e-01  1.83813170e-01  7.07985610e-02  1.53863117e-01
  1.45394146e-01  6.10771216e-02 -7.36576989e-02  5.53056449e-02
  1.07640862e-01  8.00179467e-02  3.23191434e-02  3.09991091e-01
  3.02178174e-01 -9.09306332e-02  4.91853952e-02 -1.28031313e-01
 -2.54896469e-02  2.34120145e-01 -1.74658343e-01 -2.32459098e-01
  6.18232414e-02 -2.38484278e-01 -6.28195284e-03  1.03620939e-01
  2.82353729e-01 -6.52055070e-02  7.75345117e-02 -1.90856859e-01
 -1.25437349e-01  1.37492150e-01 -1.64269745e-01  2.51677603e-01
  2.33259335e-01  2.17757478e-01  2.26037607e-01  4.26998675e-01
 -1.67967141e-01  2.59857118e-01  7.12665543e-02  1.49024948e-01
 -4.46223438e-01  1.28380001e-01  1.54407173e-01 -2.38353878e-01
 -4.55187351e-01 -1.71284303e-02 -2.03437835e-01  4.44028795e-01
  1.49454489e-01  2.29066014e-01  5.37483320e-02  1.16622731e-01
  3.27921122e-01  8.48986357e-02  2.98905432e-01 -1.16589181e-01
  3.75571474e-02  2.16130674e-01  5.97562492e-02  1.57818839e-01
 -3.79134119e-01  1.97058737e-01  8.41842405e-03 -6.73631504e-02
  3.26564431e-01  1.02038927e-01  9.84950215e-02 -4.74490523e-02
 -3.58012021e-01 -8.46094415e-02 -2.53597409e-01  1.31108731e-01
 -1.36945480e-02 -2.58189082e-01 -4.04197037e-01 -9.93263200e-02
  7.22196922e-02 -3.21413815e-01  1.38105333e-01  5.27646877e-02
 -3.74778695e-02 -3.09642814e-02  8.79964158e-02  9.22843367e-02
  6.59269169e-02 -4.25867379e-01 -1.13668293e-01 -2.31259083e-03
  1.71499252e-02  4.65329364e-02  2.83751369e-01 -9.33092088e-06
  2.11278170e-01 -1.37060642e-01  4.17382754e-02 -7.07651116e-03
  1.57808796e-01 -6.90133646e-02  2.53847003e-01 -2.96002537e-01
  1.61520377e-01  9.76996198e-02 -2.18553003e-02 -1.24721631e-01
  1.75630823e-01 -6.57364130e-02 -2.27706671e-01 -1.50046155e-01
 -4.29430157e-01 -8.62716325e-03 -3.48888189e-01  8.30511972e-02
  1.19602770e-01 -1.06453761e-01 -3.39551032e-01  5.58682233e-02
 -1.50723115e-01 -8.26126337e-02 -1.29831970e-01  9.88700613e-02
  4.37329859e-01 -1.03127375e-01  2.38669097e-01 -8.08308348e-02
  3.22031081e-02 -4.68674600e-02 -1.37694642e-01 -3.00011188e-01
 -2.28143096e-01  1.68973625e-01 -1.38916388e-01 -2.30189320e-02
  7.20473751e-03  2.29728416e-01 -5.10682501e-02 -2.43143052e-01
  7.35338554e-02 -9.28391144e-02  1.04980737e-01 -1.35518312e-01
 -3.77203338e-02 -6.18087426e-02  3.51022571e-01 -1.79783516e-02
  3.15492228e-02 -5.28395176e-01 -6.82753976e-03 -7.57957473e-02
  5.80136776e-01  7.35457381e-03  2.11273469e-02  1.24203205e-01
 -1.12393416e-01  3.32168788e-01 -2.33854130e-01 -1.09314382e-01
  1.09809563e-01  6.32748082e-02 -3.05012822e-01 -1.37086868e-01] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
10/09/2021 11:10:00 - INFO - data_loader -   *** Example ***
10/09/2021 11:10:00 - INFO - data_loader -   guid: dev-1
10/09/2021 11:10:00 - INFO - data_loader -   tokens: [CLS] g ##g [SEP]
10/09/2021 11:10:00 - INFO - data_loader -   input_ids: 101 1043 2290 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 11:10:00 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 11:10:00 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 11:10:00 - INFO - data_loader -   intent_label: 4 (id = 4)
10/09/2021 11:10:00 - INFO - data_loader -   slot_labels: 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 11:10:00 - INFO - data_loader -   ner_embeds: [-0.05268421 -0.3358649   0.27530029 -0.07744435 -0.07584086 -0.02695106
 -0.26804128  0.02627846 -0.10347202  0.2013707  -0.01272027  0.16158915
 -0.03340857  0.17287622 -0.18740179  0.26615396  0.09241544 -0.11608424
 -0.27987984 -0.28424925 -0.18137644 -0.22812925  0.0249024   0.30128998
  0.13045995  0.03118261  0.16935138 -0.06230416  0.17561074  0.00367108
 -0.07402565  0.04037194 -0.07837126 -0.1561325   0.20836185  0.14040159
  0.11099035  0.17083055 -0.35949063  0.03112581 -0.18540204  0.04089637
 -0.29396915  0.49076098 -0.05263726 -0.16885227  0.11559261  0.25719538
 -0.1559715  -0.06362429 -0.12877826  0.06794425 -0.01322358  0.26562798
  0.08987913  0.29401389 -0.37333494 -0.01440139  0.30768135 -0.37712052
 -0.108851    0.07931803  0.17231582 -0.44193396  0.03251904  0.0195513
 -0.03582918 -0.13726601 -0.28466982 -0.33915862 -0.0583167   0.01170416
  0.32957253  0.08330661  0.28316665  0.00079225  0.41026247  0.02413866
 -0.45413318 -0.1344302  -0.09248621  0.51263183 -0.13745138 -0.11134322
 -0.20985258  0.39278489 -0.1011213   0.18303782 -0.12043855  0.26268336
 -0.0461308   0.30422714  0.07902091 -0.15427054  0.18763816 -0.00932948
  0.02431204  0.30051631 -0.24693149  0.11975729 -0.0125444   0.13902089
 -0.25323379 -0.1082405   0.42633086  0.19724542 -0.07689937 -0.1337288
  0.27917713 -0.0091875   0.25963399 -0.14592938 -0.05517824  0.0350663
  0.20550938  0.11277337 -0.2699483   0.01591763 -0.00071367  0.07296164
  0.02445946  0.14451511 -0.04559916 -0.17699969 -0.42008832  0.10587756
  0.09828436  0.28259453 -0.0146672  -0.11086253 -0.35100189  0.04879292
 -0.0834544   0.16815855 -0.13103473 -0.02294332  0.36864796  0.14379583
  0.44768068 -0.23370998  0.152519    0.04665052 -0.17252302  0.31976756
 -0.16741526 -0.25466728 -0.26076594  0.00063117 -0.05335071  0.15843306
 -0.26611817  0.05734076 -0.08238135  0.18893163 -0.20564257 -0.16225532
 -0.20887086  0.08916163 -0.01871778  0.12805638  0.26127747 -0.0709104
 -0.27082589 -0.1627634   0.13914403  0.12214889 -0.1563787  -0.24772033
 -0.06986653  0.2272698  -0.05595371 -0.00991442 -0.20372061  0.04004419
 -0.04990653  0.43829471  0.11963772 -0.12598085  0.24185398 -0.04867083
 -0.08653479 -0.26793903  0.13082959 -0.43375427 -0.13357146  0.19298363
 -0.22029646  0.38383847 -0.07818928 -0.0058459  -0.32991308 -0.08181709
  0.14099021  0.09491039  0.21827479 -0.00399596 -0.08103576  0.13853465
  0.01428204  0.44172066  0.10182345  0.14742956 -0.14591892  0.33454806
  0.04376031  0.32970932  0.15365525 -0.22210287 -0.16479632 -0.28103629
  0.00301148  0.01037944  0.20718177 -0.2371673   0.33999005 -0.13203178
 -0.26044402 -0.22456646 -0.09428472  0.12473079 -0.10682054  0.08118179
  0.18629588 -0.10320079  0.10400119 -0.36503249  0.0367523  -0.26162294
 -0.13888274 -0.00607623  0.1842383  -0.33304039  0.17386849 -0.0694743
  0.03439113  0.08467512  0.23954627  0.3646954  -0.02856011 -0.21535675
  0.18716544  0.25370413 -0.18916315  0.1572178  -0.06640452  0.13099778
  0.01409951 -0.31194866 -0.14290154 -0.1712914  -0.32875261 -0.09570646
  0.28620249 -0.23103324  0.22911115  0.02136808 -0.04183525  0.2437249
 -0.1248548  -0.05797715  0.476778   -0.21734898  0.23745687  0.26735842
  0.27674222  0.07875728 -0.16760489 -0.46723711 -0.08130792  0.09524607
 -0.19139667  0.13001987  0.25027886 -0.01569632  0.08894423 -0.10037478
  0.12834264 -0.4296048   0.41507876  0.2195386  -0.00381741 -0.146727
  0.23849073  0.10347191  0.17253159 -0.4031671   0.19611832  0.17422171
  0.3443523  -0.18065456  0.04004083  0.10621159 -0.19717942  0.25161341
 -0.0291713   0.11438692  0.13997085  0.00901562 -0.24855603 -0.01550403] [ 9.94096473e-02  1.19312815e-01 -9.33764353e-02 -4.25696746e-02
  4.17188138e-01 -5.86546622e-02  2.15518206e-01  1.22023135e-01
  2.09057584e-01  1.17953038e-02  8.47322792e-02  1.43146262e-01
 -1.39627561e-01  2.59714156e-01 -2.64549553e-01  3.10089469e-01
  1.14079483e-01  3.03147167e-01 -8.15753713e-02  5.04350066e-01
  3.21641892e-01 -2.76540332e-02 -2.89069474e-01 -1.69619933e-01
 -5.03163755e-01 -4.60146755e-01  6.48206770e-02  4.45801973e-01
  6.41951337e-02 -5.35977893e-02 -2.68705990e-02  1.50703564e-01
 -4.72604990e-01  4.83997673e-01 -2.63399392e-01 -2.20703796e-01
  4.51787114e-01  1.18893191e-01 -5.47770679e-01 -5.17525971e-01
  1.19261786e-01  3.29121977e-01  7.83838518e-03 -1.79883689e-01
 -5.24080396e-01 -6.34573549e-02  2.21342385e-01 -2.15865135e-01
  1.48523942e-01  8.19553807e-02  2.70463079e-01  4.56108123e-01
 -4.05909717e-02 -2.17257753e-01  3.21579456e-01  1.30941933e-02
 -7.22500905e-02  1.47749320e-01 -6.29376888e-01  4.80538197e-02
 -2.36863703e-01  3.14069241e-01 -7.10393488e-02 -1.33733675e-01
 -1.82793349e-01  1.13440953e-01  1.47504091e-01 -4.49551672e-01
  7.72698000e-02 -5.79230428e-01 -1.88219279e-01 -1.42732821e-02
  4.45656292e-02 -2.22575843e-01 -3.89550954e-01 -1.01263719e-02
 -2.38270983e-01 -2.46616021e-01  4.08060908e-01  9.91034731e-02
  2.01077804e-01  2.81141669e-01 -2.55549788e-01 -2.65430033e-01
 -3.77000570e-01 -4.02990252e-01  6.89363182e-02  1.59485579e-01
 -1.83008499e-02 -2.02545688e-01  1.05150640e-01 -1.34824544e-01
  3.29241902e-01 -1.36965960e-01  8.68117288e-02 -3.67255747e-01
 -7.25254193e-02 -6.38537705e-01 -5.89296073e-02  2.01410532e-01
  9.42493752e-02  1.03793353e-01  2.69673645e-01 -3.93290132e-01
 -4.75863725e-01 -1.66134164e-01  1.05060376e-01 -3.35802168e-01
 -1.26313433e-01 -3.42342198e-01 -1.52601331e-01 -1.33479565e-01
  1.94103673e-01 -2.84942776e-01 -1.14353187e-01 -4.93788600e-01
 -6.43075109e-02 -4.09203768e-01 -5.92127681e-01  1.14830986e-01
  5.20076931e-01  2.06778437e-01  1.17242642e-01  5.09331822e-01
  1.69195116e-01 -1.59063801e-01  2.17850715e-01  1.52569026e-01
  1.44616619e-01 -4.42199260e-01 -2.67903786e-02  8.82498696e-02
 -1.61579624e-01 -4.06966090e-01  4.84902084e-01 -1.36901006e-01
  1.26930892e-01 -2.08858788e-01  2.00820848e-01 -2.46350765e-01
  2.38958970e-01  5.11010401e-02 -1.05898328e-01 -1.36692986e-01
  2.44770721e-01  2.95235142e-02 -1.33861884e-01  2.06235796e-02
  2.83613801e-02  8.40368494e-02 -8.52909908e-02 -3.50011289e-02
  2.67470628e-01 -5.16022682e-01  1.42725959e-01 -2.68871486e-01
 -4.13323581e-01  7.06061199e-02  2.05460563e-01 -3.88843715e-01
 -5.84297208e-03  6.73958063e-02  1.45167559e-01  8.47199932e-02
  6.60234928e-01 -2.02942431e-01  2.08981514e-01 -1.58144131e-01
  3.48434150e-01  1.28079623e-01  3.31026733e-01  2.61199564e-01
 -3.71263146e-01 -1.22195734e-02  2.24038541e-01 -3.16527814e-01
  6.78575188e-02  3.72334838e-01  5.95289879e-02 -8.18364918e-02
  9.55014974e-02 -1.27901271e-01 -1.55855313e-01  3.28307003e-01
  3.03833276e-01  1.48850635e-01  1.78786665e-01  7.63006285e-02
 -3.82620953e-02  1.17937714e-01 -4.82431501e-01  7.91997015e-02
 -3.26263428e-01  7.52013996e-02 -1.73647210e-01 -2.30165154e-01
 -1.39010713e-01  8.82228389e-02  1.18557245e-01 -2.89696127e-01
 -1.79604650e-01  4.97855060e-02 -2.28054952e-02 -1.36541590e-01
 -5.26000261e-02 -4.56149178e-03 -5.20279467e-01 -2.56557703e-01
  1.83626160e-01  3.93377542e-02  3.80189896e-01 -2.97209263e-01
  4.56239551e-01 -4.20859575e-01 -4.41898704e-01  3.19875479e-02
 -3.72062832e-01 -2.12315544e-01 -5.10225177e-01  2.31819659e-01
 -3.18632364e-01  3.62926662e-01 -3.01839709e-01 -2.85889953e-02
 -2.77682394e-01 -5.32362461e-01  2.03293175e-01 -2.71245122e-01
  2.63406355e-02  9.34485421e-02 -1.19484514e-01 -3.45702082e-01
  4.97622117e-02  3.06293309e-01  1.92443877e-01 -4.35656160e-01
 -7.90845416e-03 -4.17287834e-03 -9.52548161e-02 -5.97981095e-01
 -3.27611625e-01  5.36780746e-04  8.04049596e-02 -3.09665482e-02
 -1.42511427e-01 -6.08815253e-01  1.04902357e-01  2.01484337e-01
  3.92471999e-01  1.35647699e-01 -3.58042819e-03  8.59638825e-02
 -1.25722721e-01  9.83606651e-02 -2.21221969e-01  4.22261685e-01
 -8.87843370e-02 -3.87901336e-01  2.99093574e-01  7.04115033e-02
 -2.70217627e-01  3.63515764e-01  4.20968682e-01 -3.10121328e-01
  5.21569371e-01  3.46722811e-01  1.73930451e-01 -1.77179426e-01
  8.28839615e-02  5.99534333e-01 -8.26911405e-02  1.90694720e-01
 -1.78041190e-01 -2.08937898e-01 -2.09803835e-01  5.76521344e-02
  4.71725345e-01  1.94638416e-01  6.82845488e-02 -2.01363340e-01
  1.44115627e-01 -3.61593276e-01 -2.82532394e-01 -6.36797398e-02
 -1.48895010e-01 -1.19195864e-01  3.48304123e-01 -1.86844796e-01
 -2.50648052e-01 -2.49622064e-03  2.23419338e-01 -8.46120790e-02
 -3.27497005e-01  3.52137059e-01  1.00756988e-01  1.82901457e-01
  2.67331097e-02  4.13346112e-01  1.09819457e-01  2.43459269e-01] [ 1.98819295e-01  2.38625631e-01 -1.86752871e-01 -8.51393491e-02
  8.34376276e-01 -1.17309324e-01  4.31036413e-01  2.44046271e-01
  4.18115169e-01  2.35906076e-02  1.69464558e-01  2.86292523e-01
 -2.79255122e-01  5.19428313e-01 -5.29099107e-01  6.20178938e-01
  2.28158966e-01  6.06294334e-01 -1.63150743e-01  1.00870013e+00
  6.43283784e-01 -5.53080663e-02 -5.78138947e-01 -3.39239866e-01
 -1.00632751e+00 -9.20293510e-01  1.29641354e-01  8.91603947e-01
  1.28390267e-01 -1.07195579e-01 -5.37411980e-02  3.01407129e-01
 -9.45209980e-01  9.67995346e-01 -5.26798785e-01 -4.41407591e-01
  9.03574228e-01  2.37786382e-01 -1.09554136e+00 -1.03505194e+00
  2.38523573e-01  6.58243954e-01  1.56767704e-02 -3.59767377e-01
 -1.04816079e+00 -1.26914710e-01  4.42684770e-01 -4.31730270e-01
  2.97047883e-01  1.63910761e-01  5.40926158e-01  9.12216246e-01
 -8.11819434e-02 -4.34515506e-01  6.43158913e-01  2.61883866e-02
 -1.44500181e-01  2.95498639e-01 -1.25875378e+00  9.61076394e-02
 -4.73727405e-01  6.28138483e-01 -1.42078698e-01 -2.67467350e-01
 -3.65586698e-01  2.26881906e-01  2.95008183e-01 -8.99103343e-01
  1.54539600e-01 -1.15846086e+00 -3.76438558e-01 -2.85465643e-02
  8.91312584e-02 -4.45151687e-01 -7.79101908e-01 -2.02527437e-02
 -4.76541966e-01 -4.93232042e-01  8.16121817e-01  1.98206946e-01
  4.02155608e-01  5.62283337e-01 -5.11099577e-01 -5.30860066e-01
 -7.54001141e-01 -8.05980504e-01  1.37872636e-01  3.18971157e-01
 -3.66016999e-02 -4.05091375e-01  2.10301280e-01 -2.69649088e-01
  6.58483803e-01 -2.73931921e-01  1.73623458e-01 -7.34511495e-01
 -1.45050839e-01 -1.27707541e+00 -1.17859215e-01  4.02821064e-01
  1.88498750e-01  2.07586706e-01  5.39347291e-01 -7.86580265e-01
 -9.51727450e-01 -3.32268327e-01  2.10120752e-01 -6.71604335e-01
 -2.52626866e-01 -6.84684396e-01 -3.05202663e-01 -2.66959131e-01
  3.88207346e-01 -5.69885552e-01 -2.28706375e-01 -9.87577200e-01
 -1.28615022e-01 -8.18407536e-01 -1.18425536e+00  2.29661971e-01
  1.04015386e+00  4.13556874e-01  2.34485283e-01  1.01866364e+00
  3.38390231e-01 -3.18127602e-01  4.35701430e-01  3.05138052e-01
  2.89233238e-01 -8.84398520e-01 -5.35807572e-02  1.76499739e-01
 -3.23159248e-01 -8.13932180e-01  9.69804168e-01 -2.73802012e-01
  2.53861785e-01 -4.17717576e-01  4.01641697e-01 -4.92701530e-01
  4.77917939e-01  1.02202080e-01 -2.11796656e-01 -2.73385972e-01
  4.89541441e-01  5.90470284e-02 -2.67723769e-01  4.12471592e-02
  5.67227602e-02  1.68073699e-01 -1.70581982e-01 -7.00022578e-02
  5.34941256e-01 -1.03204536e+00  2.85451919e-01 -5.37742972e-01
 -8.26647162e-01  1.41212240e-01  4.10921127e-01 -7.77687430e-01
 -1.16859442e-02  1.34791613e-01  2.90335119e-01  1.69439986e-01
  1.32046986e+00 -4.05884862e-01  4.17963028e-01 -3.16288263e-01
  6.96868300e-01  2.56159246e-01  6.62053466e-01  5.22399127e-01
 -7.42526293e-01 -2.44391467e-02  4.48077083e-01 -6.33055627e-01
  1.35715038e-01  7.44669676e-01  1.19057976e-01 -1.63672984e-01
  1.91002995e-01 -2.55802542e-01 -3.11710626e-01  6.56614006e-01
  6.07666552e-01  2.97701269e-01  3.57573330e-01  1.52601257e-01
 -7.65241906e-02  2.35875428e-01 -9.64863002e-01  1.58399403e-01
 -6.52526855e-01  1.50402799e-01 -3.47294420e-01 -4.60330307e-01
 -2.78021425e-01  1.76445678e-01  2.37114489e-01 -5.79392254e-01
 -3.59209299e-01  9.95710120e-02 -4.56109904e-02 -2.73083180e-01
 -1.05200052e-01 -9.12298355e-03 -1.04055893e+00 -5.13115406e-01
  3.67252320e-01  7.86755085e-02  7.60379791e-01 -5.94418526e-01
  9.12479103e-01 -8.41719151e-01 -8.83797407e-01  6.39750957e-02
 -7.44125664e-01 -4.24631089e-01 -1.02045035e+00  4.63639319e-01
 -6.37264729e-01  7.25853324e-01 -6.03679419e-01 -5.71779907e-02
 -5.55364788e-01 -1.06472492e+00  4.06586349e-01 -5.42490244e-01
  5.26812710e-02  1.86897084e-01 -2.38969028e-01 -6.91404164e-01
  9.95244235e-02  6.12586617e-01  3.84887755e-01 -8.71312320e-01
 -1.58169083e-02 -8.34575668e-03 -1.90509632e-01 -1.19596219e+00
 -6.55223250e-01  1.07356149e-03  1.60809919e-01 -6.19330965e-02
 -2.85022855e-01 -1.21763051e+00  2.09804714e-01  4.02968675e-01
  7.84943998e-01  2.71295398e-01 -7.16085639e-03  1.71927765e-01
 -2.51445442e-01  1.96721330e-01 -4.42443937e-01  8.44523370e-01
 -1.77568674e-01 -7.75802672e-01  5.98187149e-01  1.40823007e-01
 -5.40435255e-01  7.27031529e-01  8.41937363e-01 -6.20242655e-01
  1.04313874e+00  6.93445623e-01  3.47860903e-01 -3.54358852e-01
  1.65767923e-01  1.19906867e+00 -1.65382281e-01  3.81389439e-01
 -3.56082380e-01 -4.17875797e-01 -4.19607669e-01  1.15304269e-01
  9.43450689e-01  3.89276832e-01  1.36569098e-01 -4.02726680e-01
  2.88231254e-01 -7.23186553e-01 -5.65064788e-01 -1.27359480e-01
 -2.97790021e-01 -2.38391727e-01  6.96608245e-01 -3.73689592e-01
 -5.01296103e-01 -4.99244127e-03  4.46838677e-01 -1.69224158e-01
 -6.54994011e-01  7.04274118e-01  2.01513976e-01  3.65802914e-01
  5.34662195e-02  8.26692224e-01  2.19638914e-01  4.86918539e-01] [ 3.23701560e-01  1.23859271e-01  3.17038149e-01 -1.99837953e-01
  1.45933881e-01  1.97479472e-01  1.11766860e-01 -2.97712028e-01
  2.12801516e-01 -8.30430072e-03 -1.36353567e-01  5.88244051e-02
 -1.61227629e-01  3.60989422e-01  2.74212211e-01 -1.38430834e-01
 -5.86703680e-02 -4.27209228e-01 -4.38389741e-02 -1.70130521e-01
 -2.79001564e-01 -5.08604087e-02 -2.22016856e-01  3.46666753e-01
 -1.82083368e-01 -1.79737844e-02 -7.58341700e-02 -2.81926543e-01
 -8.88730120e-03 -9.31498557e-02 -1.63259923e-01  2.63657838e-01
  2.68971026e-01 -1.65585026e-01 -1.38222620e-01 -1.05521366e-01
 -2.16932997e-01  1.53523952e-01 -6.68047294e-02 -1.14297360e-01
 -1.98990464e-01  9.14934743e-03  2.44847938e-01 -1.28512876e-02
  1.28243208e-01 -1.80381879e-01  1.76793709e-01  1.34143546e-01
 -9.09292847e-02  1.11920275e-02 -1.59795374e-01  4.03871059e-01
 -2.08633363e-01  2.61400253e-01 -1.77513242e-01  2.64400899e-01
 -3.74767929e-01 -1.41106667e-02  7.07195699e-02 -2.59310529e-02
 -1.52463704e-01 -2.09277481e-01  2.42659152e-01 -4.37896281e-01
 -2.74111658e-01  3.23784024e-01 -1.12194913e-02 -7.78998435e-03
 -2.63834894e-01 -1.86299264e-01 -1.20873287e-01  2.04141185e-01
  1.60952255e-01  3.01728785e-01  2.21852630e-01  1.73017696e-01
  3.71879220e-01  2.80739516e-01 -1.18493669e-01  1.09062918e-01
 -2.55998373e-01  3.87480080e-01  4.10263650e-02  2.02835858e-01
 -3.17999512e-01  3.78140330e-01  2.57947147e-01 -4.50112194e-01
  1.04353130e-01  1.40699465e-03  7.67216682e-02 -1.11133285e-01
  1.40065238e-01 -3.31422426e-02  6.38056397e-02 -1.78506866e-01
  1.02249458e-01 -1.90868706e-01 -2.67677069e-01  8.56479257e-02
  1.85055599e-01  2.22840309e-01 -1.93136290e-01 -1.12496831e-01
  2.01004639e-01 -3.48373577e-02 -1.59934118e-01  2.03856632e-01
  2.03415796e-01  1.91151500e-02 -2.14736730e-01 -2.01674789e-01
 -1.03147745e-01  2.00410113e-01  6.62044063e-02 -5.02013564e-02
 -1.48162618e-01 -1.72178164e-01 -1.56178564e-01  2.05861077e-01
 -2.44715880e-03 -4.20740098e-02  1.99603319e-01 -3.03595811e-01
 -2.62882337e-02  5.65342568e-02  1.27887994e-01  1.71164036e-01
 -1.49366796e-01 -6.41742051e-02  1.59788847e-01 -1.77765921e-01
  1.73824430e-01 -1.28364572e-02  3.04782897e-01  8.32331404e-02
  4.28962141e-01  1.86484933e-01  3.57698888e-01  1.70930754e-02
  1.14737764e-01  1.83813170e-01  7.07985610e-02  1.53863117e-01
  1.45394146e-01  6.10771216e-02 -7.36576989e-02  5.53056449e-02
  1.07640862e-01  8.00179467e-02  3.23191434e-02  3.09991091e-01
  3.02178174e-01 -9.09306332e-02  4.91853952e-02 -1.28031313e-01
 -2.54896469e-02  2.34120145e-01 -1.74658343e-01 -2.32459098e-01
  6.18232414e-02 -2.38484278e-01 -6.28195284e-03  1.03620939e-01
  2.82353729e-01 -6.52055070e-02  7.75345117e-02 -1.90856859e-01
 -1.25437349e-01  1.37492150e-01 -1.64269745e-01  2.51677603e-01
  2.33259335e-01  2.17757478e-01  2.26037607e-01  4.26998675e-01
 -1.67967141e-01  2.59857118e-01  7.12665543e-02  1.49024948e-01
 -4.46223438e-01  1.28380001e-01  1.54407173e-01 -2.38353878e-01
 -4.55187351e-01 -1.71284303e-02 -2.03437835e-01  4.44028795e-01
  1.49454489e-01  2.29066014e-01  5.37483320e-02  1.16622731e-01
  3.27921122e-01  8.48986357e-02  2.98905432e-01 -1.16589181e-01
  3.75571474e-02  2.16130674e-01  5.97562492e-02  1.57818839e-01
 -3.79134119e-01  1.97058737e-01  8.41842405e-03 -6.73631504e-02
  3.26564431e-01  1.02038927e-01  9.84950215e-02 -4.74490523e-02
 -3.58012021e-01 -8.46094415e-02 -2.53597409e-01  1.31108731e-01
 -1.36945480e-02 -2.58189082e-01 -4.04197037e-01 -9.93263200e-02
  7.22196922e-02 -3.21413815e-01  1.38105333e-01  5.27646877e-02
 -3.74778695e-02 -3.09642814e-02  8.79964158e-02  9.22843367e-02
  6.59269169e-02 -4.25867379e-01 -1.13668293e-01 -2.31259083e-03
  1.71499252e-02  4.65329364e-02  2.83751369e-01 -9.33092088e-06
  2.11278170e-01 -1.37060642e-01  4.17382754e-02 -7.07651116e-03
  1.57808796e-01 -6.90133646e-02  2.53847003e-01 -2.96002537e-01
  1.61520377e-01  9.76996198e-02 -2.18553003e-02 -1.24721631e-01
  1.75630823e-01 -6.57364130e-02 -2.27706671e-01 -1.50046155e-01
 -4.29430157e-01 -8.62716325e-03 -3.48888189e-01  8.30511972e-02
  1.19602770e-01 -1.06453761e-01 -3.39551032e-01  5.58682233e-02
 -1.50723115e-01 -8.26126337e-02 -1.29831970e-01  9.88700613e-02
  4.37329859e-01 -1.03127375e-01  2.38669097e-01 -8.08308348e-02
  3.22031081e-02 -4.68674600e-02 -1.37694642e-01 -3.00011188e-01
 -2.28143096e-01  1.68973625e-01 -1.38916388e-01 -2.30189320e-02
  7.20473751e-03  2.29728416e-01 -5.10682501e-02 -2.43143052e-01
  7.35338554e-02 -9.28391144e-02  1.04980737e-01 -1.35518312e-01
 -3.77203338e-02 -6.18087426e-02  3.51022571e-01 -1.79783516e-02
  3.15492228e-02 -5.28395176e-01 -6.82753976e-03 -7.57957473e-02
  5.80136776e-01  7.35457381e-03  2.11273469e-02  1.24203205e-01
 -1.12393416e-01  3.32168788e-01 -2.33854130e-01 -1.09314382e-01
  1.09809563e-01  6.32748082e-02 -3.05012822e-01 -1.37086868e-01] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
10/09/2021 11:10:00 - INFO - data_loader -   *** Example ***
10/09/2021 11:10:00 - INFO - data_loader -   guid: dev-2
10/09/2021 11:10:00 - INFO - data_loader -   tokens: [CLS] g ##g [ sep ##a ] nice late game [SEP]
10/09/2021 11:10:00 - INFO - data_loader -   input_ids: 101 1043 2290 1031 19802 2050 1033 3835 2397 2208 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 11:10:00 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 11:10:00 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 11:10:00 - INFO - data_loader -   intent_label: 4 (id = 4)
10/09/2021 11:10:00 - INFO - data_loader -   slot_labels: 0 6 0 8 0 0 0 4 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 11:10:00 - INFO - data_loader -   ner_embeds: [-0.05268421 -0.3358649   0.27530029 -0.07744435 -0.07584086 -0.02695106
 -0.26804128  0.02627846 -0.10347202  0.2013707  -0.01272027  0.16158915
 -0.03340857  0.17287622 -0.18740179  0.26615396  0.09241544 -0.11608424
 -0.27987984 -0.28424925 -0.18137644 -0.22812925  0.0249024   0.30128998
  0.13045995  0.03118261  0.16935138 -0.06230416  0.17561074  0.00367108
 -0.07402565  0.04037194 -0.07837126 -0.1561325   0.20836185  0.14040159
  0.11099035  0.17083055 -0.35949063  0.03112581 -0.18540204  0.04089637
 -0.29396915  0.49076098 -0.05263726 -0.16885227  0.11559261  0.25719538
 -0.1559715  -0.06362429 -0.12877826  0.06794425 -0.01322358  0.26562798
  0.08987913  0.29401389 -0.37333494 -0.01440139  0.30768135 -0.37712052
 -0.108851    0.07931803  0.17231582 -0.44193396  0.03251904  0.0195513
 -0.03582918 -0.13726601 -0.28466982 -0.33915862 -0.0583167   0.01170416
  0.32957253  0.08330661  0.28316665  0.00079225  0.41026247  0.02413866
 -0.45413318 -0.1344302  -0.09248621  0.51263183 -0.13745138 -0.11134322
 -0.20985258  0.39278489 -0.1011213   0.18303782 -0.12043855  0.26268336
 -0.0461308   0.30422714  0.07902091 -0.15427054  0.18763816 -0.00932948
  0.02431204  0.30051631 -0.24693149  0.11975729 -0.0125444   0.13902089
 -0.25323379 -0.1082405   0.42633086  0.19724542 -0.07689937 -0.1337288
  0.27917713 -0.0091875   0.25963399 -0.14592938 -0.05517824  0.0350663
  0.20550938  0.11277337 -0.2699483   0.01591763 -0.00071367  0.07296164
  0.02445946  0.14451511 -0.04559916 -0.17699969 -0.42008832  0.10587756
  0.09828436  0.28259453 -0.0146672  -0.11086253 -0.35100189  0.04879292
 -0.0834544   0.16815855 -0.13103473 -0.02294332  0.36864796  0.14379583
  0.44768068 -0.23370998  0.152519    0.04665052 -0.17252302  0.31976756
 -0.16741526 -0.25466728 -0.26076594  0.00063117 -0.05335071  0.15843306
 -0.26611817  0.05734076 -0.08238135  0.18893163 -0.20564257 -0.16225532
 -0.20887086  0.08916163 -0.01871778  0.12805638  0.26127747 -0.0709104
 -0.27082589 -0.1627634   0.13914403  0.12214889 -0.1563787  -0.24772033
 -0.06986653  0.2272698  -0.05595371 -0.00991442 -0.20372061  0.04004419
 -0.04990653  0.43829471  0.11963772 -0.12598085  0.24185398 -0.04867083
 -0.08653479 -0.26793903  0.13082959 -0.43375427 -0.13357146  0.19298363
 -0.22029646  0.38383847 -0.07818928 -0.0058459  -0.32991308 -0.08181709
  0.14099021  0.09491039  0.21827479 -0.00399596 -0.08103576  0.13853465
  0.01428204  0.44172066  0.10182345  0.14742956 -0.14591892  0.33454806
  0.04376031  0.32970932  0.15365525 -0.22210287 -0.16479632 -0.28103629
  0.00301148  0.01037944  0.20718177 -0.2371673   0.33999005 -0.13203178
 -0.26044402 -0.22456646 -0.09428472  0.12473079 -0.10682054  0.08118179
  0.18629588 -0.10320079  0.10400119 -0.36503249  0.0367523  -0.26162294
 -0.13888274 -0.00607623  0.1842383  -0.33304039  0.17386849 -0.0694743
  0.03439113  0.08467512  0.23954627  0.3646954  -0.02856011 -0.21535675
  0.18716544  0.25370413 -0.18916315  0.1572178  -0.06640452  0.13099778
  0.01409951 -0.31194866 -0.14290154 -0.1712914  -0.32875261 -0.09570646
  0.28620249 -0.23103324  0.22911115  0.02136808 -0.04183525  0.2437249
 -0.1248548  -0.05797715  0.476778   -0.21734898  0.23745687  0.26735842
  0.27674222  0.07875728 -0.16760489 -0.46723711 -0.08130792  0.09524607
 -0.19139667  0.13001987  0.25027886 -0.01569632  0.08894423 -0.10037478
  0.12834264 -0.4296048   0.41507876  0.2195386  -0.00381741 -0.146727
  0.23849073  0.10347191  0.17253159 -0.4031671   0.19611832  0.17422171
  0.3443523  -0.18065456  0.04004083  0.10621159 -0.19717942  0.25161341
 -0.0291713   0.11438692  0.13997085  0.00901562 -0.24855603 -0.01550403] [ 9.94096473e-02  1.19312815e-01 -9.33764353e-02 -4.25696746e-02
  4.17188138e-01 -5.86546622e-02  2.15518206e-01  1.22023135e-01
  2.09057584e-01  1.17953038e-02  8.47322792e-02  1.43146262e-01
 -1.39627561e-01  2.59714156e-01 -2.64549553e-01  3.10089469e-01
  1.14079483e-01  3.03147167e-01 -8.15753713e-02  5.04350066e-01
  3.21641892e-01 -2.76540332e-02 -2.89069474e-01 -1.69619933e-01
 -5.03163755e-01 -4.60146755e-01  6.48206770e-02  4.45801973e-01
  6.41951337e-02 -5.35977893e-02 -2.68705990e-02  1.50703564e-01
 -4.72604990e-01  4.83997673e-01 -2.63399392e-01 -2.20703796e-01
  4.51787114e-01  1.18893191e-01 -5.47770679e-01 -5.17525971e-01
  1.19261786e-01  3.29121977e-01  7.83838518e-03 -1.79883689e-01
 -5.24080396e-01 -6.34573549e-02  2.21342385e-01 -2.15865135e-01
  1.48523942e-01  8.19553807e-02  2.70463079e-01  4.56108123e-01
 -4.05909717e-02 -2.17257753e-01  3.21579456e-01  1.30941933e-02
 -7.22500905e-02  1.47749320e-01 -6.29376888e-01  4.80538197e-02
 -2.36863703e-01  3.14069241e-01 -7.10393488e-02 -1.33733675e-01
 -1.82793349e-01  1.13440953e-01  1.47504091e-01 -4.49551672e-01
  7.72698000e-02 -5.79230428e-01 -1.88219279e-01 -1.42732821e-02
  4.45656292e-02 -2.22575843e-01 -3.89550954e-01 -1.01263719e-02
 -2.38270983e-01 -2.46616021e-01  4.08060908e-01  9.91034731e-02
  2.01077804e-01  2.81141669e-01 -2.55549788e-01 -2.65430033e-01
 -3.77000570e-01 -4.02990252e-01  6.89363182e-02  1.59485579e-01
 -1.83008499e-02 -2.02545688e-01  1.05150640e-01 -1.34824544e-01
  3.29241902e-01 -1.36965960e-01  8.68117288e-02 -3.67255747e-01
 -7.25254193e-02 -6.38537705e-01 -5.89296073e-02  2.01410532e-01
  9.42493752e-02  1.03793353e-01  2.69673645e-01 -3.93290132e-01
 -4.75863725e-01 -1.66134164e-01  1.05060376e-01 -3.35802168e-01
 -1.26313433e-01 -3.42342198e-01 -1.52601331e-01 -1.33479565e-01
  1.94103673e-01 -2.84942776e-01 -1.14353187e-01 -4.93788600e-01
 -6.43075109e-02 -4.09203768e-01 -5.92127681e-01  1.14830986e-01
  5.20076931e-01  2.06778437e-01  1.17242642e-01  5.09331822e-01
  1.69195116e-01 -1.59063801e-01  2.17850715e-01  1.52569026e-01
  1.44616619e-01 -4.42199260e-01 -2.67903786e-02  8.82498696e-02
 -1.61579624e-01 -4.06966090e-01  4.84902084e-01 -1.36901006e-01
  1.26930892e-01 -2.08858788e-01  2.00820848e-01 -2.46350765e-01
  2.38958970e-01  5.11010401e-02 -1.05898328e-01 -1.36692986e-01
  2.44770721e-01  2.95235142e-02 -1.33861884e-01  2.06235796e-02
  2.83613801e-02  8.40368494e-02 -8.52909908e-02 -3.50011289e-02
  2.67470628e-01 -5.16022682e-01  1.42725959e-01 -2.68871486e-01
 -4.13323581e-01  7.06061199e-02  2.05460563e-01 -3.88843715e-01
 -5.84297208e-03  6.73958063e-02  1.45167559e-01  8.47199932e-02
  6.60234928e-01 -2.02942431e-01  2.08981514e-01 -1.58144131e-01
  3.48434150e-01  1.28079623e-01  3.31026733e-01  2.61199564e-01
 -3.71263146e-01 -1.22195734e-02  2.24038541e-01 -3.16527814e-01
  6.78575188e-02  3.72334838e-01  5.95289879e-02 -8.18364918e-02
  9.55014974e-02 -1.27901271e-01 -1.55855313e-01  3.28307003e-01
  3.03833276e-01  1.48850635e-01  1.78786665e-01  7.63006285e-02
 -3.82620953e-02  1.17937714e-01 -4.82431501e-01  7.91997015e-02
 -3.26263428e-01  7.52013996e-02 -1.73647210e-01 -2.30165154e-01
 -1.39010713e-01  8.82228389e-02  1.18557245e-01 -2.89696127e-01
 -1.79604650e-01  4.97855060e-02 -2.28054952e-02 -1.36541590e-01
 -5.26000261e-02 -4.56149178e-03 -5.20279467e-01 -2.56557703e-01
  1.83626160e-01  3.93377542e-02  3.80189896e-01 -2.97209263e-01
  4.56239551e-01 -4.20859575e-01 -4.41898704e-01  3.19875479e-02
 -3.72062832e-01 -2.12315544e-01 -5.10225177e-01  2.31819659e-01
 -3.18632364e-01  3.62926662e-01 -3.01839709e-01 -2.85889953e-02
 -2.77682394e-01 -5.32362461e-01  2.03293175e-01 -2.71245122e-01
  2.63406355e-02  9.34485421e-02 -1.19484514e-01 -3.45702082e-01
  4.97622117e-02  3.06293309e-01  1.92443877e-01 -4.35656160e-01
 -7.90845416e-03 -4.17287834e-03 -9.52548161e-02 -5.97981095e-01
 -3.27611625e-01  5.36780746e-04  8.04049596e-02 -3.09665482e-02
 -1.42511427e-01 -6.08815253e-01  1.04902357e-01  2.01484337e-01
  3.92471999e-01  1.35647699e-01 -3.58042819e-03  8.59638825e-02
 -1.25722721e-01  9.83606651e-02 -2.21221969e-01  4.22261685e-01
 -8.87843370e-02 -3.87901336e-01  2.99093574e-01  7.04115033e-02
 -2.70217627e-01  3.63515764e-01  4.20968682e-01 -3.10121328e-01
  5.21569371e-01  3.46722811e-01  1.73930451e-01 -1.77179426e-01
  8.28839615e-02  5.99534333e-01 -8.26911405e-02  1.90694720e-01
 -1.78041190e-01 -2.08937898e-01 -2.09803835e-01  5.76521344e-02
  4.71725345e-01  1.94638416e-01  6.82845488e-02 -2.01363340e-01
  1.44115627e-01 -3.61593276e-01 -2.82532394e-01 -6.36797398e-02
 -1.48895010e-01 -1.19195864e-01  3.48304123e-01 -1.86844796e-01
 -2.50648052e-01 -2.49622064e-03  2.23419338e-01 -8.46120790e-02
 -3.27497005e-01  3.52137059e-01  1.00756988e-01  1.82901457e-01
  2.67331097e-02  4.13346112e-01  1.09819457e-01  2.43459269e-01] [ 1.98819295e-01  2.38625631e-01 -1.86752871e-01 -8.51393491e-02
  8.34376276e-01 -1.17309324e-01  4.31036413e-01  2.44046271e-01
  4.18115169e-01  2.35906076e-02  1.69464558e-01  2.86292523e-01
 -2.79255122e-01  5.19428313e-01 -5.29099107e-01  6.20178938e-01
  2.28158966e-01  6.06294334e-01 -1.63150743e-01  1.00870013e+00
  6.43283784e-01 -5.53080663e-02 -5.78138947e-01 -3.39239866e-01
 -1.00632751e+00 -9.20293510e-01  1.29641354e-01  8.91603947e-01
  1.28390267e-01 -1.07195579e-01 -5.37411980e-02  3.01407129e-01
 -9.45209980e-01  9.67995346e-01 -5.26798785e-01 -4.41407591e-01
  9.03574228e-01  2.37786382e-01 -1.09554136e+00 -1.03505194e+00
  2.38523573e-01  6.58243954e-01  1.56767704e-02 -3.59767377e-01
 -1.04816079e+00 -1.26914710e-01  4.42684770e-01 -4.31730270e-01
  2.97047883e-01  1.63910761e-01  5.40926158e-01  9.12216246e-01
 -8.11819434e-02 -4.34515506e-01  6.43158913e-01  2.61883866e-02
 -1.44500181e-01  2.95498639e-01 -1.25875378e+00  9.61076394e-02
 -4.73727405e-01  6.28138483e-01 -1.42078698e-01 -2.67467350e-01
 -3.65586698e-01  2.26881906e-01  2.95008183e-01 -8.99103343e-01
  1.54539600e-01 -1.15846086e+00 -3.76438558e-01 -2.85465643e-02
  8.91312584e-02 -4.45151687e-01 -7.79101908e-01 -2.02527437e-02
 -4.76541966e-01 -4.93232042e-01  8.16121817e-01  1.98206946e-01
  4.02155608e-01  5.62283337e-01 -5.11099577e-01 -5.30860066e-01
 -7.54001141e-01 -8.05980504e-01  1.37872636e-01  3.18971157e-01
 -3.66016999e-02 -4.05091375e-01  2.10301280e-01 -2.69649088e-01
  6.58483803e-01 -2.73931921e-01  1.73623458e-01 -7.34511495e-01
 -1.45050839e-01 -1.27707541e+00 -1.17859215e-01  4.02821064e-01
  1.88498750e-01  2.07586706e-01  5.39347291e-01 -7.86580265e-01
 -9.51727450e-01 -3.32268327e-01  2.10120752e-01 -6.71604335e-01
 -2.52626866e-01 -6.84684396e-01 -3.05202663e-01 -2.66959131e-01
  3.88207346e-01 -5.69885552e-01 -2.28706375e-01 -9.87577200e-01
 -1.28615022e-01 -8.18407536e-01 -1.18425536e+00  2.29661971e-01
  1.04015386e+00  4.13556874e-01  2.34485283e-01  1.01866364e+00
  3.38390231e-01 -3.18127602e-01  4.35701430e-01  3.05138052e-01
  2.89233238e-01 -8.84398520e-01 -5.35807572e-02  1.76499739e-01
 -3.23159248e-01 -8.13932180e-01  9.69804168e-01 -2.73802012e-01
  2.53861785e-01 -4.17717576e-01  4.01641697e-01 -4.92701530e-01
  4.77917939e-01  1.02202080e-01 -2.11796656e-01 -2.73385972e-01
  4.89541441e-01  5.90470284e-02 -2.67723769e-01  4.12471592e-02
  5.67227602e-02  1.68073699e-01 -1.70581982e-01 -7.00022578e-02
  5.34941256e-01 -1.03204536e+00  2.85451919e-01 -5.37742972e-01
 -8.26647162e-01  1.41212240e-01  4.10921127e-01 -7.77687430e-01
 -1.16859442e-02  1.34791613e-01  2.90335119e-01  1.69439986e-01
  1.32046986e+00 -4.05884862e-01  4.17963028e-01 -3.16288263e-01
  6.96868300e-01  2.56159246e-01  6.62053466e-01  5.22399127e-01
 -7.42526293e-01 -2.44391467e-02  4.48077083e-01 -6.33055627e-01
  1.35715038e-01  7.44669676e-01  1.19057976e-01 -1.63672984e-01
  1.91002995e-01 -2.55802542e-01 -3.11710626e-01  6.56614006e-01
  6.07666552e-01  2.97701269e-01  3.57573330e-01  1.52601257e-01
 -7.65241906e-02  2.35875428e-01 -9.64863002e-01  1.58399403e-01
 -6.52526855e-01  1.50402799e-01 -3.47294420e-01 -4.60330307e-01
 -2.78021425e-01  1.76445678e-01  2.37114489e-01 -5.79392254e-01
 -3.59209299e-01  9.95710120e-02 -4.56109904e-02 -2.73083180e-01
 -1.05200052e-01 -9.12298355e-03 -1.04055893e+00 -5.13115406e-01
  3.67252320e-01  7.86755085e-02  7.60379791e-01 -5.94418526e-01
  9.12479103e-01 -8.41719151e-01 -8.83797407e-01  6.39750957e-02
 -7.44125664e-01 -4.24631089e-01 -1.02045035e+00  4.63639319e-01
 -6.37264729e-01  7.25853324e-01 -6.03679419e-01 -5.71779907e-02
 -5.55364788e-01 -1.06472492e+00  4.06586349e-01 -5.42490244e-01
  5.26812710e-02  1.86897084e-01 -2.38969028e-01 -6.91404164e-01
  9.95244235e-02  6.12586617e-01  3.84887755e-01 -8.71312320e-01
 -1.58169083e-02 -8.34575668e-03 -1.90509632e-01 -1.19596219e+00
 -6.55223250e-01  1.07356149e-03  1.60809919e-01 -6.19330965e-02
 -2.85022855e-01 -1.21763051e+00  2.09804714e-01  4.02968675e-01
  7.84943998e-01  2.71295398e-01 -7.16085639e-03  1.71927765e-01
 -2.51445442e-01  1.96721330e-01 -4.42443937e-01  8.44523370e-01
 -1.77568674e-01 -7.75802672e-01  5.98187149e-01  1.40823007e-01
 -5.40435255e-01  7.27031529e-01  8.41937363e-01 -6.20242655e-01
  1.04313874e+00  6.93445623e-01  3.47860903e-01 -3.54358852e-01
  1.65767923e-01  1.19906867e+00 -1.65382281e-01  3.81389439e-01
 -3.56082380e-01 -4.17875797e-01 -4.19607669e-01  1.15304269e-01
  9.43450689e-01  3.89276832e-01  1.36569098e-01 -4.02726680e-01
  2.88231254e-01 -7.23186553e-01 -5.65064788e-01 -1.27359480e-01
 -2.97790021e-01 -2.38391727e-01  6.96608245e-01 -3.73689592e-01
 -5.01296103e-01 -4.99244127e-03  4.46838677e-01 -1.69224158e-01
 -6.54994011e-01  7.04274118e-01  2.01513976e-01  3.65802914e-01
  5.34662195e-02  8.26692224e-01  2.19638914e-01  4.86918539e-01] [-0.16743909  0.32148802 -0.49167016 -0.10943763  0.31561723  0.30283004
  0.14417282 -0.18377195  0.3903752  -0.06263071  0.15735121 -0.06020338
  0.21403159 -0.11482581 -0.31088796  0.00297563  0.26345962  0.17394826
 -0.28333354  0.49209505 -0.38175038 -0.02440399 -0.500521   -0.03106818
  0.01045403 -0.22386535 -0.59453934 -0.14550905  0.23947676  0.42387494
  0.14888883  0.06061133 -0.26765287  0.34978244 -0.07297093  0.00100594
 -0.15531713  0.30100974 -0.14684124 -0.17799428  0.02954767  0.18604849
 -0.30635539 -0.2727991  -0.07318144  0.07384863 -0.47842512  0.16245177
  0.03898357 -0.13185777 -0.53268945 -0.18845898  0.33661142 -0.03692679
 -0.18086477 -0.24162319  0.12841946 -0.04939046 -0.07692429  0.2346727
  0.14882626 -0.16151442 -0.3489905   0.03723747  0.21437132  0.27090043
  0.35418886 -0.11770505  0.06619719  0.28622076  0.19694996 -0.17546225
  0.38774481  0.09431728  0.345395   -0.460985   -0.34267348 -0.03016782
  0.25133085  0.06566126  0.07246657  0.01294966 -0.28564158 -0.27992502
  0.34943432  0.16850688  0.04289098 -0.1003227  -0.21834484 -0.19927749
  0.05785445 -0.37910908  0.16853943 -0.0166065   0.08880825 -0.04938443
  0.31724149  0.31035104 -0.3041952   0.20104083  0.41428345 -0.47394255
  0.38814822  0.37400621 -0.06160756  0.1728812  -0.0565789  -0.49362943
 -0.08249669  0.21434544  0.4246673  -0.15586217  0.10247602  0.124369
  0.19916505 -0.1493126   0.23470804  0.06179982  0.49766377  0.0799998
  0.13705085 -0.15669489  0.06247121 -0.06033319  0.2434355  -0.0680538
  0.19378556 -0.36312765  0.10867918 -0.04065241  0.19947612  0.12740184
  0.08098002 -0.2612204   0.18660586 -0.16869286 -0.01832465  0.18643223
  0.03614206 -0.24385764  0.19620283  0.08800557 -0.28187898 -0.27047226
 -0.25054154  0.14431387 -0.48470944  0.02805139  0.11303072  0.19343643
  0.17620403  0.1713946   0.23279339 -0.3336134   0.42544317  0.19298959
 -0.32102832 -0.2497642   0.17956066 -0.41140899  0.23352452 -0.09894067
  0.15590993 -0.18936482 -0.00301115 -0.02797545 -0.20089102 -0.08544934
  0.35790282  0.11825771 -0.28372523  0.15199639  0.13918979  0.02748257
  0.06235245 -0.2633782   0.28450468 -0.15732101  0.05759265  0.15850638
 -0.09372584  0.65335405 -0.11752973  0.31014892  0.30106646 -0.28609008
 -0.022501    0.25269312  0.08137676 -0.31597313  0.01183864  0.25039324
 -0.22030878  0.05517089  0.35836762 -0.35498738  0.41396043  0.15870056
  0.50537884  0.1191489  -0.28989881 -0.05953145  0.00635571 -0.05262715
 -0.19400549 -0.09291941  0.44332537 -0.02490679 -0.31340569  0.5415709
  0.18997191 -0.27399957  0.24994664 -0.19567043 -0.04527875  0.38473549
 -0.39007291 -0.06288782  0.0071259   0.0819592  -0.10632546  0.12179985
  0.04858959  0.39665926 -0.19764894  0.15184182  0.06113384  0.12987903
  0.26544651  0.15176326 -0.30722621 -0.22403237 -0.1419359   0.27182081
 -0.45932448 -0.04383741 -0.08642317 -0.23031212 -0.1685482   0.38533258
 -0.13540126  0.19588743 -0.14480667 -0.05635411  0.10360459 -0.3416799
 -0.01694224 -0.10080188  0.29106066 -0.03683211  0.38590077 -0.5065757
 -0.30405697 -0.26028347 -0.01307644  0.34494835  0.17119113 -0.14192133
 -0.38165575  0.29435658 -0.1634874  -0.05627406  0.36376047  0.28615552
 -0.14424802 -0.35891712 -0.2891669   0.00565932 -0.26661989 -0.34914005
 -0.31486192 -0.0509474  -0.28887069  0.09145693 -0.1438767   0.06975904
  0.28699648  0.42392528  0.18966234  0.01657389 -0.25566077 -0.57468092
 -0.28777736  0.28072006  0.09487454 -0.10859925  0.06609636 -0.11964687
  0.04833288  0.04798279 -0.06999223  0.17904411 -0.0828871  -0.56341767
  0.26344687 -0.20856997 -0.10508797 -0.22760002 -0.13645455  0.24377322] [-0.33487818  0.64297605 -0.98334032 -0.21887526  0.63123447  0.60566008
  0.28834563 -0.36754391  0.78075039 -0.12526141  0.31470242 -0.12040675
  0.42806318 -0.22965162 -0.62177593  0.00595126  0.52691925  0.34789652
 -0.56666708  0.98419011 -0.76350075 -0.04880799 -1.00104201 -0.06213637
  0.02090806 -0.44773069 -1.18907869 -0.2910181   0.47895351  0.84774989
  0.29777765  0.12122267 -0.53530574  0.69956487 -0.14594187  0.00201188
 -0.31063426  0.60201949 -0.29368249 -0.35598856  0.05909534  0.37209699
 -0.61271077 -0.54559821 -0.14636287  0.14769726 -0.95685023  0.32490355
  0.07796714 -0.26371554 -1.0653789  -0.37691796  0.67322284 -0.07385357
 -0.36172953 -0.48324639  0.25683892 -0.09878092 -0.15384857  0.46934539
  0.29765251 -0.32302883 -0.697981    0.07447494  0.42874265  0.54180086
  0.70837772 -0.23541011  0.13239439  0.57244152  0.39389992 -0.35092449
  0.77548963  0.18863456  0.69079    -0.92197001 -0.68534696 -0.06033564
  0.50266171  0.13132252  0.14493315  0.02589932 -0.57128316 -0.55985004
  0.69886863  0.33701375  0.08578196 -0.2006454  -0.43668967 -0.39855498
  0.11570891 -0.75821817  0.33707887 -0.033213    0.17761649 -0.09876885
  0.63448298  0.62070209 -0.60839039  0.40208167  0.82856691 -0.9478851
  0.77629644  0.74801242 -0.12321512  0.3457624  -0.11315781 -0.98725885
 -0.16499338  0.42869088  0.8493346  -0.31172433  0.20495205  0.24873799
  0.39833009 -0.2986252   0.46941608  0.12359964  0.99532753  0.15999961
  0.2741017  -0.31338978  0.12494242 -0.12066638  0.486871   -0.13610761
  0.38757113 -0.7262553   0.21735837 -0.08130482  0.39895225  0.25480369
  0.16196004 -0.52244079  0.37321171 -0.33738571 -0.03664931  0.37286445
  0.07228412 -0.48771527  0.39240566  0.17601115 -0.56375796 -0.54094452
 -0.50108308  0.28862774 -0.96941888  0.05610277  0.22606143  0.38687286
  0.35240805  0.3427892   0.46558678 -0.66722679  0.85088634  0.38597918
 -0.64205664 -0.49952841  0.35912132 -0.82281798  0.46704903 -0.19788134
  0.31181985 -0.37872964 -0.00602229 -0.0559509  -0.40178204 -0.17089868
  0.71580565  0.23651542 -0.56745046  0.30399278  0.27837959  0.05496513
  0.1247049  -0.52675641  0.56900936 -0.31464201  0.1151853   0.31701276
 -0.18745168  1.3067081  -0.23505947  0.62029785  0.60213292 -0.57218015
 -0.045002    0.50538623  0.16275352 -0.63194627  0.02367728  0.50078648
 -0.44061756  0.11034178  0.71673524 -0.70997477  0.82792085  0.31740111
  1.01075768  0.23829781 -0.57979763 -0.11906291  0.01271142 -0.10525431
 -0.38801098 -0.18583882  0.88665074 -0.04981358 -0.62681139  1.0831418
  0.37994382 -0.54799914  0.49989328 -0.39134085 -0.0905575   0.76947099
 -0.78014582 -0.12577564  0.0142518   0.16391841 -0.21265092  0.2435997
  0.09717919  0.79331851 -0.39529788  0.30368364  0.12226769  0.25975806
  0.53089303  0.30352652 -0.61445242 -0.44806474 -0.2838718   0.54364163
 -0.91864896 -0.08767483 -0.17284635 -0.46062425 -0.33709639  0.77066517
 -0.27080253  0.39177486 -0.28961334 -0.11270821  0.20720918 -0.6833598
 -0.03388449 -0.20160376  0.58212131 -0.07366421  0.77180153 -1.01315141
 -0.60811394 -0.52056694 -0.02615288  0.6898967   0.34238225 -0.28384265
 -0.76331151  0.58871317 -0.32697481 -0.11254813  0.72752094  0.57231104
 -0.28849605 -0.71783423 -0.5783338   0.01131864 -0.53323978 -0.6982801
 -0.62972385 -0.1018948  -0.57774138  0.18291385 -0.2877534   0.13951808
  0.57399297  0.84785056  0.37932467  0.03314777 -0.51132154 -1.14936185
 -0.57555473  0.56144011  0.18974908 -0.21719849  0.13219272 -0.23929374
  0.09666577  0.09596558 -0.13998446  0.35808823 -0.1657742  -1.12683535
  0.52689373 -0.41713995 -0.21017595 -0.45520005 -0.2729091   0.48754644] [-0.50231726  0.96446407 -1.47501048 -0.32831289  0.9468517   0.90849012
  0.43251845 -0.55131586  1.17112559 -0.18789212  0.47205363 -0.18061013
  0.64209478 -0.34447742 -0.93266389  0.00892688  0.79037887  0.52184477
 -0.85000062  1.47628516 -1.14525113 -0.07321198 -1.50156301 -0.09320455
  0.03136209 -0.67159604 -1.78361803 -0.43652715  0.71843027  1.27162483
  0.44666648  0.181834   -0.80295861  1.04934731 -0.2189128   0.00301782
 -0.46595138  0.90302923 -0.44052373 -0.53398284  0.08864301  0.55814548
 -0.91906616 -0.81839731 -0.21954431  0.22154588 -1.43527535  0.48735532
  0.11695071 -0.3955733  -1.59806836 -0.56537694  1.00983426 -0.11078036
 -0.5425943  -0.72486958  0.38525838 -0.14817137 -0.23077286  0.70401809
  0.44647877 -0.48454325 -1.0469715   0.11171241  0.64311397  0.81270128
  1.06256658 -0.35311516  0.19859158  0.85866228  0.59084988 -0.52638674
  1.16323444  0.28295184  1.036185   -1.38295501 -1.02802044 -0.09050347
  0.75399256  0.19698378  0.21739972  0.03884897 -0.85692474 -0.83977506
  1.04830295  0.50552063  0.12867294 -0.3009681  -0.65503451 -0.59783247
  0.17356336 -1.13732725  0.5056183  -0.0498195   0.26642474 -0.14815328
  0.95172447  0.93105313 -0.91258559  0.6031225   1.24285036 -1.42182764
  1.16444466  1.12201864 -0.18482267  0.5186436  -0.16973671 -1.48088828
 -0.24749006  0.64303632  1.2740019  -0.4675865   0.30742807  0.37310699
  0.59749514 -0.4479378   0.70412412  0.18539946  1.4929913   0.23999941
  0.41115256 -0.47008467  0.18741363 -0.18099958  0.73030651 -0.20416141
  0.58135669 -1.08938295  0.32603755 -0.12195723  0.59842837  0.38220553
  0.24294005 -0.78366119  0.55981757 -0.50607857 -0.05497396  0.55929668
  0.10842618 -0.73157291  0.58860849  0.26401672 -0.84563693 -0.81141677
 -0.75162461  0.43294162 -1.45412832  0.08415416  0.33909215  0.58030929
  0.52861208  0.5141838   0.69838017 -1.00084019  1.27632952  0.57896876
 -0.96308497 -0.74929261  0.53868198 -1.23422697  0.70057355 -0.29682201
  0.46772978 -0.56809446 -0.00903344 -0.08392635 -0.60267305 -0.25634801
  1.07370847  0.35477313 -0.8511757   0.45598917  0.41756938  0.0824477
  0.18705736 -0.79013461  0.85351405 -0.47196302  0.17277795  0.47551914
 -0.28117751  1.96006215 -0.3525892   0.93044677  0.90319937 -0.85827023
 -0.067503    0.75807935  0.24413028 -0.9479194   0.03551592  0.75117972
 -0.66092634  0.16551267  1.07510287 -1.06496215  1.24188128  0.47610167
  1.51613653  0.35744671 -0.86969644 -0.17859436  0.01906712 -0.15788146
 -0.58201647 -0.27875823  1.32997611 -0.07472036 -0.94021708  1.62471271
  0.56991573 -0.82199872  0.74983992 -0.58701128 -0.13583625  1.15420648
 -1.17021874 -0.18866345  0.0213777   0.24587761 -0.31897639  0.36539955
  0.14576878  1.18997777 -0.59294683  0.45552546  0.18340153  0.38963708
  0.79633954  0.45528978 -0.92167863 -0.67209712 -0.4258077   0.81546244
 -1.37797344 -0.13151224 -0.25926952 -0.69093637 -0.50564459  1.15599775
 -0.40620379  0.58766229 -0.43442    -0.16906232  0.31081378 -1.0250397
 -0.05082673 -0.30240563  0.87318197 -0.11049632  1.1577023  -1.51972711
 -0.91217092 -0.78085041 -0.03922932  1.03484505  0.51357338 -0.42576398
 -1.14496726  0.88306975 -0.49046221 -0.16882219  1.09128141  0.85846657
 -0.43274407 -1.07675135 -0.86750069  0.01697796 -0.79985967 -1.04742014
 -0.94458577 -0.15284221 -0.86661208  0.27437078 -0.4316301   0.20927712
  0.86098945  1.27177584  0.56898701  0.04972166 -0.76698232 -1.72404277
 -0.86333209  0.84216017  0.28462362 -0.32579774  0.19828907 -0.35894061
  0.14499865  0.14394837 -0.20997669  0.53713234 -0.24866129 -1.69025302
  0.7903406  -0.62570992 -0.31526392 -0.68280007 -0.40936366  0.73131967] [-0.66975635  1.28595209 -1.96668065 -0.43775052  1.26246893  1.21132016
  0.57669127 -0.73508781  1.56150079 -0.25052282  0.62940484 -0.24081351
  0.85612637 -0.45930323 -1.24355185  0.01190251  1.05383849  0.69579303
 -1.13333416  1.96838021 -1.5270015  -0.09761597 -2.00208402 -0.12427273
  0.04181613 -0.89546138 -2.37815738 -0.5820362   0.95790702  1.69549978
  0.59555531  0.24244533 -1.07061148  1.39912975 -0.29188374  0.00402377
 -0.62126851  1.20403898 -0.58736497 -0.71197712  0.11819068  0.74419397
 -1.22542155 -1.09119642 -0.29272574  0.29539451 -1.91370046  0.6498071
  0.15593427 -0.52743107 -2.13075781 -0.75383592  1.34644568 -0.14770715
 -0.72345906 -0.96649277  0.51367784 -0.19756183 -0.30769715  0.93869078
  0.59530503 -0.64605767 -1.395962    0.14894988  0.85748529  1.08360171
  1.41675544 -0.47082022  0.26478878  1.14488304  0.78779984 -0.70184898
  1.55097926  0.37726912  1.38158    -1.84394002 -1.37069392 -0.12067129
  1.00532341  0.26264504  0.2898663   0.05179863 -1.14256632 -1.11970007
  1.39773726  0.6740275   0.17156392 -0.4012908  -0.87337935 -0.79710996
  0.23141782 -1.51643634  0.67415774 -0.06642599  0.35523298 -0.19753771
  1.26896596  1.24140418 -1.21678078  0.80416334  1.65713382 -1.89577019
  1.55259287  1.49602485 -0.24643023  0.6915248  -0.22631562 -1.9745177
 -0.32998675  0.85738176  1.6986692  -0.62344867  0.40990409  0.49747598
  0.79666018 -0.5972504   0.93883216  0.24719928  1.99065506  0.31999922
  0.54820341 -0.62677956  0.24988484 -0.24133277  0.97374201 -0.27221522
  0.77514225 -1.4525106   0.43471673 -0.16260964  0.79790449  0.50960737
  0.32392007 -1.04488158  0.74642342 -0.67477143 -0.07329861  0.74572891
  0.14456823 -0.97543055  0.78481132  0.35202229 -1.12751591 -1.08188903
 -1.00216615  0.57725549 -1.93883777  0.11220554  0.45212287  0.77374572
  0.7048161   0.68557841  0.93117356 -1.33445358  1.70177269  0.77195835
 -1.28411329 -0.99905682  0.71824265 -1.64563596  0.93409806 -0.39576268
  0.6236397  -0.75745928 -0.01204459 -0.1119018  -0.80356407 -0.34179735
  1.4316113   0.47303084 -1.13490093  0.60798556  0.55675918  0.10993026
  0.24940981 -1.05351281  1.13801873 -0.62928402  0.2303706   0.63402551
 -0.37490335  2.61341619 -0.47011894  1.2405957   1.20426583 -1.1443603
 -0.090004    1.01077247  0.32550704 -1.26389253  0.04735456  1.00157297
 -0.88123512  0.22068356  1.43347049 -1.41994953  1.65584171  0.63480222
  2.02151537  0.47659561 -1.15959525 -0.23812582  0.02542283 -0.21050861
 -0.77602196 -0.37167764  1.77330148 -0.09962715 -1.25362277  2.16628361
  0.75988764 -1.09599829  0.99978656 -0.7826817  -0.181115    1.53894198
 -1.56029165 -0.25155127  0.02850359  0.32783681 -0.42530185  0.4871994
  0.19435838  1.58663702 -0.79059577  0.60736728  0.24453537  0.51951611
  1.06178606  0.60705304 -1.22890484 -0.89612949 -0.5677436   1.08728325
 -1.83729792 -0.17534965 -0.34569269 -0.9212485  -0.67419279  1.54133034
 -0.54160506  0.78354973 -0.57922667 -0.22541642  0.41441837 -1.3667196
 -0.06776898 -0.40320751  1.16424263 -0.14732842  1.54360306 -2.02630281
 -1.21622789 -1.04113388 -0.05230575  1.37979341  0.6847645  -0.56768531
 -1.52662301  1.17742634 -0.65394962 -0.22509626  1.45504189  1.14462209
 -0.57699209 -1.43566847 -1.15666759  0.02263727 -1.06647956 -1.39656019
 -1.25944769 -0.20378961 -1.15548277  0.36582771 -0.57550681  0.27903616
  1.14798594  1.69570112  0.75864935  0.06629555 -1.02264309 -2.2987237
 -1.15110946  1.12288022  0.37949815 -0.43439698  0.26438543 -0.47858748
  0.19333154  0.19193116 -0.27996892  0.71617645 -0.33154839 -2.25367069
  1.05378747 -0.83427989 -0.42035189 -0.91040009 -0.54581821  0.97509289] [-2.73470908e-01 -1.33838907e-01  1.70479193e-01  1.91072121e-01
 -1.92561030e-01 -4.38769668e-01 -3.70780259e-01 -4.56882298e-01
  9.05024558e-02  1.00060225e-01  2.34613240e-01  1.55064210e-01
 -1.13375410e-01 -3.09022099e-01 -2.22774684e-01  7.83629492e-02
  3.51435065e-01  2.87714958e-01 -4.54127401e-01 -1.42873719e-01
  1.19161539e-01  1.08398087e-01  9.00470018e-02 -2.61126459e-01
  1.63029507e-02  1.93583295e-01 -2.86777347e-01 -1.70014337e-01
 -2.90638618e-02  5.26739226e-04  2.28470534e-01  1.58259675e-01
  1.98402792e-01 -2.50014216e-01  2.53737897e-01  2.24287644e-01
 -1.35780200e-01  9.81433913e-02 -3.10325116e-01  1.68552056e-01
 -4.06028897e-01  1.10040970e-01 -3.77192914e-01 -3.06189686e-01
  1.75379679e-01 -3.52919430e-01 -3.22318226e-01  1.09195806e-01
 -1.51489004e-01 -5.34138530e-02 -3.38280112e-01  1.76731139e-01
 -9.01291221e-02  3.17867994e-01 -2.92837471e-01  6.49596930e-01
 -1.65730923e-01 -3.65816325e-01  1.05745941e-01 -3.25108320e-01
 -1.92632750e-01  4.09721017e-01  2.85721160e-02 -6.12077378e-02
 -2.11574286e-02 -3.11993092e-01 -3.15443009e-01 -9.38562825e-02
 -8.82555172e-02 -3.08136232e-02 -3.13186646e-01 -3.05473149e-01
 -6.93693310e-02  5.38216889e-01  4.59120199e-02  5.28086305e-01
 -4.07085456e-02  8.35429411e-03 -5.39972857e-02  5.91107793e-02
 -3.06867898e-01  2.01506585e-01  2.68536568e-01 -4.90860827e-02
 -3.65984797e-01  1.37848347e-01  2.16896877e-01 -2.09356204e-01
  1.56772301e-01  7.00079370e-03  1.09901726e-01 -7.88228959e-02
  2.80683544e-02 -2.67003365e-02  1.10151447e-01 -5.73751749e-03
 -3.14448059e-01  1.98784307e-01 -3.97206694e-01 -9.29026604e-02
  3.71421129e-01  3.47263694e-01 -4.69494089e-02  3.61633599e-01
  3.76282066e-01  2.51253068e-01 -6.91772923e-02  1.65767580e-01
 -7.38242455e-03 -2.65776485e-01  3.10407639e-01 -3.25848311e-02
 -3.11932545e-02 -1.32460445e-01 -2.47462466e-01  4.66058031e-02
 -3.57714333e-02 -1.29162637e-03 -1.25931334e-02 -2.32551664e-01
  2.44092762e-01 -4.05434489e-01 -1.06114201e-01  3.37093592e-01
 -2.00055644e-01  2.23979965e-01 -2.22337116e-02  3.36321816e-02
 -9.05346125e-02 -2.13860035e-01 -2.87745267e-01  2.32339785e-01
 -9.89699513e-02 -8.20777286e-03  2.31537580e-01 -3.46048445e-01
  7.50432909e-02 -2.55617589e-01 -2.88424969e-01 -1.33147568e-01
  8.14959258e-02 -2.65158862e-01  4.46455717e-01  3.27741690e-02
 -3.98681283e-01 -9.28548053e-02  6.44678134e-04  1.21163011e-01
 -3.17884773e-01  4.52992439e-01  2.96301991e-01 -2.12371677e-01
  1.13891475e-01 -1.54808357e-01  2.24587336e-01 -3.93253684e-01
  5.59745394e-02  1.73928887e-01 -2.17568371e-02  1.43511295e-01
  1.99813008e-01 -4.42973137e-01 -2.31955461e-02 -7.44826272e-02
  1.54492378e-01 -4.97721396e-02  2.50043660e-01  5.87027550e-01
 -5.95011786e-02 -1.00736357e-01 -2.24615648e-01 -1.17958516e-01
 -4.61907499e-02  2.05724221e-02 -3.90234500e-01  2.55820692e-01
  3.57483953e-01  7.81035796e-02 -1.57360688e-01 -4.27919656e-01
  5.16985357e-01 -5.08639477e-02 -2.85015017e-01 -3.57414633e-01
 -3.36101279e-02  1.28834527e-02 -1.36929974e-01  1.69590309e-01
  2.54084110e-01  3.02976929e-02 -4.50686127e-01 -1.81801260e-01
  2.65375167e-01 -5.83269857e-02  7.42989257e-02  1.23091355e-01
 -1.26927011e-02 -3.09176952e-01 -1.53705463e-01  1.41332045e-01
  2.46864155e-01 -4.00670409e-01 -1.41299725e-01  1.14022374e-01
  8.04776698e-02 -3.09056044e-01 -8.01958591e-02  8.07153359e-02
 -5.07625103e-01 -2.42016017e-01  2.69140024e-03  2.72571713e-01
  2.10887223e-01 -3.23292226e-01  2.23452628e-01 -2.63787597e-01
  4.35796455e-02 -5.98636642e-02  8.17040354e-02 -3.26289386e-02
  1.75819129e-01 -4.59713757e-01 -1.14362404e-01 -3.44544590e-01
  2.49145210e-01 -5.35496294e-01 -2.10800767e-01  3.70592356e-01
 -4.25764173e-01 -1.31162524e-01  1.48930654e-01  1.75298423e-01
  1.61269277e-01 -1.17896765e-01 -1.08217306e-01  5.52270524e-02
 -2.00544018e-04 -3.11945099e-02  1.40929818e-01 -4.59330112e-01
  6.28507882e-02  1.38157770e-01 -2.14674726e-01 -2.36343414e-01
 -2.19938397e-01 -1.55882716e-01  2.57282913e-01 -5.46628535e-01
  3.85143459e-01  1.24425732e-01 -2.65957952e-01  1.89651940e-02
  7.25497380e-02  2.71900501e-02  2.68628985e-01 -1.71229467e-01
 -3.11246395e-01  1.92167953e-01 -2.09542364e-01  3.38645220e-01
 -1.11957982e-01 -9.80704576e-02 -1.75958276e-01  9.01459232e-02
  5.03175139e-01 -7.84075782e-02  3.92672569e-02  2.26483226e-01
 -5.66774346e-02 -5.66011667e-01 -3.93219739e-01  2.31229454e-01
  3.71037959e-03 -3.36052775e-01  1.28197238e-01  2.21673816e-01
 -1.81155056e-01 -4.32013452e-01  1.42799690e-02  2.68864870e-01
 -6.24220222e-02 -2.75827825e-01  3.70239280e-02 -1.74242392e-01
  1.77418422e-02  5.77105060e-02 -1.26176119e-01  1.00607075e-01
  2.69824058e-01  1.91461802e-01 -7.56686437e-04  8.76274183e-02
  1.80939540e-01 -3.02846611e-01 -1.01806931e-01  2.87441164e-01
  1.72395870e-01 -3.09305757e-01  1.24496803e-01  3.93546879e-01] [ 5.53645715e-02 -1.47990242e-01  1.64235383e-01 -6.77267984e-02
 -4.23453301e-01  9.99144390e-02  5.11115119e-02  2.40057707e-01
  9.04093869e-03  1.37196705e-01  3.61088812e-02  1.00001104e-01
 -2.27431923e-01  1.12281702e-01  1.71424478e-01  3.22395086e-01
 -1.66442066e-01 -4.52654034e-01 -4.01911214e-02 -7.42120445e-02
 -1.61427230e-01 -2.96214283e-01  1.78172961e-01  3.35387111e-01
  1.57385841e-02  3.52781981e-01  2.29007125e-01 -7.45700449e-02
  2.14648724e-01  8.73547792e-02  6.79166093e-02  6.07791618e-02
 -1.43521473e-01 -4.45135348e-02 -3.67147997e-02 -1.02010339e-01
 -2.68703043e-01  1.82621956e-01 -5.87774031e-02  4.67554778e-02
  2.41962865e-01 -3.26953307e-02  3.10555063e-02  4.01745051e-01
  4.00783718e-02  8.62590596e-02 -4.25954282e-01  2.02666670e-01
 -2.08080381e-01 -2.55931348e-01 -2.38449395e-01  1.31851107e-01
  1.53598309e-01  3.45306098e-01 -3.93023491e-02  4.36487079e-01
  1.30931556e-01 -1.09672733e-01  2.87578255e-01  3.51676822e-01
 -2.21441507e-01 -3.80533212e-03 -2.58974787e-02 -4.67870772e-01
 -3.14116389e-01  6.66410327e-02  6.92176297e-02 -1.34216230e-02
 -2.24546090e-01 -9.29700807e-02  7.07657486e-02 -1.61338300e-01
  3.32130492e-01  3.24123114e-01 -4.30863984e-02 -2.84404159e-01
  1.06996067e-01  3.87331992e-01 -7.34858215e-02  2.12323576e-01
  2.31326874e-02  5.73288463e-02  9.86062735e-02  4.46063310e-01
 -4.11632925e-01  2.33565509e-01 -1.81637816e-02 -1.82182286e-02
  3.04075420e-01 -2.68410057e-01 -2.27643296e-01 -1.38463110e-01
 -3.17341179e-01  2.18674704e-01 -4.55555477e-04 -1.66652407e-02
  2.73210853e-01 -1.04458202e-02 -2.43183404e-01  4.41877455e-01
 -3.04158479e-01  1.53908595e-01  2.39371434e-01  3.92230460e-03
  5.82074165e-01  2.19812915e-01  1.62418246e-01  2.80473351e-01
  2.71231115e-01 -2.08849803e-01 -1.85146436e-01 -2.61871874e-01
  1.13596700e-01 -1.52916268e-01 -2.12716639e-01 -9.17145833e-02
  9.45976451e-02  1.69973627e-01  1.36068001e-01 -7.17890123e-03
 -2.57597156e-02 -3.77173781e-01 -9.05341133e-02 -3.29827517e-01
 -3.83459657e-01  9.88259818e-03  2.68896576e-02  1.70044750e-02
  1.37591281e-03 -2.16001511e-01 -1.38817236e-01 -2.14775160e-01
  3.59240741e-01 -1.12951688e-01 -2.99658477e-01  3.11100662e-01
  4.10448968e-01 -6.10299148e-02  3.93185079e-01  2.48430893e-01
 -3.41237485e-02  3.57675195e-01  2.63537854e-01  3.85654047e-02
 -1.01886757e-01  6.89927638e-02  1.23652540e-01 -3.35054547e-01
  2.08831817e-01  2.66032040e-01  1.42497793e-01  3.29129398e-01
 -1.44701675e-01 -1.30405858e-01 -2.22296983e-01 -1.90869689e-01
 -4.23538417e-01  2.62463540e-01 -2.57871866e-01  1.39853999e-01
 -1.55913839e-02 -1.54881001e-01  6.07155673e-02  2.88952649e-01
  2.83565938e-01 -5.21412715e-02  3.78444195e-01 -3.82907063e-01
 -2.05810815e-02  8.86189491e-02  2.85888761e-01  1.41275689e-01
  1.74989346e-02  4.42015171e-01  2.54551679e-01  1.26380324e-01
 -2.77643293e-01 -5.19481637e-02  2.43785188e-01 -1.56434909e-01
 -4.15135801e-01 -1.53654039e-01  2.79903889e-01 -2.21189275e-01
 -3.60706776e-01  8.23250040e-03 -2.87972271e-01  2.61598319e-01
  8.30621421e-02  2.24925742e-01 -3.21912646e-01  2.56164849e-01
  3.23907703e-01  3.05817246e-01  1.62691534e-01 -3.69043261e-01
 -2.69758180e-02  1.74703494e-01 -4.50356930e-01  1.72258630e-01
 -6.43322431e-03 -2.09233552e-01 -3.69205326e-02 -1.74643710e-01
  7.05501670e-03 -6.78609824e-03  2.14114636e-01 -1.40543971e-02
  1.34958580e-01  3.00124258e-01  5.16501628e-02 -9.83246565e-02
  7.30654821e-02 -2.05350518e-01 -1.26177132e-01 -2.27617890e-01
 -2.73013830e-01 -1.68524608e-01  2.12614864e-01  1.19794026e-01
  1.61170095e-01 -2.93704838e-01 -3.28074455e-01  9.22948122e-02
  1.96363851e-01 -4.12414700e-01  5.53826429e-02 -4.05373663e-01
  1.31360725e-01  2.23645076e-01  4.02019441e-01 -1.97757855e-01
  2.28923157e-01 -3.30650717e-01 -2.44620830e-01 -1.59457251e-01
  1.31649420e-01  1.09997258e-01 -3.49719793e-01  7.88583457e-02
  5.72969439e-03 -5.36322333e-02  9.90018398e-02  2.75320888e-01
 -8.10837001e-02  1.92574814e-01 -5.96938394e-02 -3.24360192e-01
  1.20429136e-01  2.43140355e-01 -3.82498860e-01  4.53595221e-02
  1.84639439e-01  6.28400594e-02  2.74830777e-02 -2.04732478e-01
  1.48681611e-01  1.31418183e-01  4.68984954e-02 -6.18878677e-02
  4.13349152e-01  1.32051334e-01 -3.68734635e-02 -1.48269325e-01
 -3.72796059e-01  2.92906146e-02 -2.10961565e-01  3.23964283e-04
  1.47812083e-01 -7.25238398e-02 -1.27057537e-01 -9.23488215e-02
 -1.51666000e-01  1.01486050e-01 -2.29200572e-01 -1.67644009e-01
  1.65650040e-01 -2.78367370e-01  1.94577962e-01  8.36116821e-02
  2.22167492e-01 -3.36802512e-01 -1.55602515e-01  1.71664059e-01
 -2.33340770e-01 -2.17990622e-01 -3.49216126e-02  9.46946517e-02
  4.31703418e-01  4.11377214e-02  1.04699947e-01 -3.47315997e-01
  5.44740483e-02  4.71333444e-01 -3.63524824e-01 -3.80469263e-01
  2.10616887e-01 -1.59253657e-01 -3.27117503e-01  3.50337386e-01] [ 2.35780969e-01  3.85825410e-02 -1.50690883e-01 -1.17342450e-01
  3.64899665e-01  3.36150676e-01 -3.23000029e-02 -4.86930966e-01
 -6.47521392e-02  5.42680472e-02  2.34264620e-02 -7.45355040e-02
  1.20433234e-01 -2.96229333e-01  5.44136241e-02  1.69862598e-01
  1.64858639e-01 -1.72842607e-01  4.51698482e-01 -4.23709542e-01
 -1.06450044e-01 -4.30465370e-01  4.83082719e-02  2.82175601e-01
  3.40733826e-01  1.23309575e-01  8.43878016e-02  2.75916845e-01
  1.88646674e-01  2.94272918e-02  3.28199826e-02  1.38058960e-01
 -1.36684254e-01 -9.53226462e-02 -5.43341756e-01  7.96237364e-02
 -1.84597597e-02  2.40339756e-01 -2.89960086e-01 -7.92519823e-02
  4.38268520e-02 -3.39978367e-01 -3.04353535e-01  3.76858503e-01
  4.21722502e-01  2.18215939e-02  2.31172144e-01 -6.04632404e-03
 -1.61579289e-02  3.46573412e-01 -1.23210798e-03  2.29666993e-01
  2.09263369e-01 -3.12085778e-01  1.33600503e-01  2.29585528e-01
 -6.35236204e-01 -3.90651792e-01 -3.96220058e-01 -1.94219097e-01
 -2.87115514e-01  3.34488451e-01  4.99248564e-01 -3.09302896e-01
 -3.16979319e-01 -1.70421258e-01 -2.92266518e-01  6.12304322e-02
 -5.32180704e-02 -3.97454761e-02 -2.73340195e-01  4.03105706e-01
  3.40185285e-01  2.47825369e-01  5.83860017e-02 -9.36620384e-02
 -6.03172541e-01  1.49637446e-01 -2.78887659e-01 -1.47715211e-01
  5.66191971e-01  2.41580620e-01 -4.48505506e-02 -5.66507280e-02
 -2.77342945e-01  5.45883417e-01 -2.71378130e-01 -3.87305528e-01
 -1.45715132e-01 -3.17565212e-03 -3.35706994e-02 -1.51372656e-01
 -2.73561920e-03  6.31819740e-02 -4.05299217e-02  3.07733953e-01
  3.64586234e-01 -4.61072512e-02 -3.00673008e-01 -1.48270279e-01
  2.74293751e-01 -2.43888259e-01  2.05546364e-01  8.28036368e-02
  2.26913303e-01 -7.37993345e-02 -3.43751162e-01  1.61240146e-01
  1.76494807e-01  2.37129018e-01 -3.88397664e-01  2.29407251e-01
  8.69991779e-02  2.25417525e-01  8.80335271e-03  4.45319682e-01
  7.95888603e-02 -7.22996518e-02 -5.16889170e-02 -3.13920975e-01
  2.41914213e-01  2.55008396e-02 -1.52186994e-02  3.21266145e-01
 -1.27329901e-01  4.19158101e-01  2.77564917e-02  4.05434705e-02
  2.40527123e-01 -2.07164928e-01  5.13297558e-01 -2.18634591e-01
  1.13816448e-02 -1.25925332e-01  3.00130963e-01  2.25707427e-01
  3.56720202e-02  1.84888884e-01  2.41698354e-01 -4.06958669e-01
  2.51492769e-01  3.74574959e-01 -3.36673945e-01  1.74248472e-01
  5.61074205e-02 -3.48213673e-01 -4.47525650e-01  5.10241129e-02
 -2.90971249e-01  6.07431047e-02 -3.68018568e-01 -6.13305205e-03
 -1.75802216e-01  5.83441295e-02  5.78800857e-04  2.70891517e-01
  2.52525300e-01  1.34062067e-01 -6.24623261e-02  1.21973328e-01
  6.65246248e-02  1.62649095e-01  2.21714780e-01  2.04741117e-02
  2.05755353e-01  1.23254336e-01  3.49970013e-01  5.95759824e-02
 -2.41091281e-01  2.10441768e-01 -2.07169175e-01  8.68420815e-04
  1.45446137e-01 -1.75144002e-01  3.14268738e-01  2.17287585e-01
  1.55388534e-01 -1.53598651e-01  2.53482722e-02 -2.84341592e-02
 -1.70913368e-01 -3.04385453e-01 -9.78691578e-02 -6.39781833e-01
 -2.39318721e-02 -2.29763776e-01 -6.41697049e-02  4.36822057e-01
 -2.62983274e-02  4.38451052e-01  2.01808214e-01  4.52709422e-02
  3.17518055e-01  2.83179462e-01  2.03982979e-01  8.18483606e-02
 -1.58776566e-01  1.12701161e-03  4.75796431e-01  2.30538528e-02
  3.41154337e-01 -1.20830081e-01  2.63229132e-01  8.64580087e-03
 -3.01672965e-01  1.76638365e-01  2.57385194e-01  3.49806808e-02
 -6.10282123e-01 -2.32593015e-01 -1.83596015e-01 -4.92491052e-02
  1.74774408e-01  1.90070599e-01  1.12887122e-01 -5.48902214e-01
  1.40780345e-01 -7.95197636e-02  6.22035516e-03  3.49693924e-01
 -2.30507001e-01  1.61646262e-01  3.97482030e-02 -2.67366797e-01
 -3.84411551e-02 -1.24244824e-01 -1.74924016e-01 -1.51537403e-01
  2.51280487e-01 -5.66361956e-02  1.21154385e-02 -3.96964282e-01
  3.38043779e-01 -5.17583974e-02 -2.43742034e-01  2.35649675e-01
 -5.51427193e-02 -4.94149894e-01  8.44895560e-03  2.08250448e-01
  2.76851118e-01 -1.34181648e-01 -5.65981150e-01  4.61654589e-02
  1.14399523e-01  5.11989594e-02  1.32149667e-01 -1.38401657e-01
  1.43203691e-01  3.24073732e-01 -2.23790318e-01  3.25860858e-01
  6.33917823e-02 -1.23820581e-01  6.79984987e-02  1.24509126e-01
 -7.55137131e-02  2.91571081e-01  8.55009928e-02  8.55751634e-02
 -1.80939026e-02  1.60525382e-01  1.93042353e-01 -2.34539449e-01
 -5.73131852e-02 -5.65114506e-02  1.80138916e-01  4.32276666e-01
  5.49030676e-02  1.42648816e-01 -7.42273554e-02  3.11018676e-01
 -4.53447662e-02  9.97777879e-02  1.50163844e-01 -3.98446977e-01
 -1.51469577e-02 -1.84542254e-01  6.89474344e-02  1.01182267e-01
  3.26873690e-01 -1.05785489e-01  4.43164743e-02 -2.14279637e-01
 -5.02740918e-03 -4.28519279e-01 -1.76572546e-01  3.13647628e-01
  4.12922412e-01 -1.84155613e-01  1.20451577e-01 -4.02657241e-01
  6.58139437e-02  3.38910967e-01 -3.17130417e-01  3.41143638e-01
  2.24867687e-01  1.65273156e-02 -2.71754079e-02  1.91641331e-01] [ 3.23701560e-01  1.23859271e-01  3.17038149e-01 -1.99837953e-01
  1.45933881e-01  1.97479472e-01  1.11766860e-01 -2.97712028e-01
  2.12801516e-01 -8.30430072e-03 -1.36353567e-01  5.88244051e-02
 -1.61227629e-01  3.60989422e-01  2.74212211e-01 -1.38430834e-01
 -5.86703680e-02 -4.27209228e-01 -4.38389741e-02 -1.70130521e-01
 -2.79001564e-01 -5.08604087e-02 -2.22016856e-01  3.46666753e-01
 -1.82083368e-01 -1.79737844e-02 -7.58341700e-02 -2.81926543e-01
 -8.88730120e-03 -9.31498557e-02 -1.63259923e-01  2.63657838e-01
  2.68971026e-01 -1.65585026e-01 -1.38222620e-01 -1.05521366e-01
 -2.16932997e-01  1.53523952e-01 -6.68047294e-02 -1.14297360e-01
 -1.98990464e-01  9.14934743e-03  2.44847938e-01 -1.28512876e-02
  1.28243208e-01 -1.80381879e-01  1.76793709e-01  1.34143546e-01
 -9.09292847e-02  1.11920275e-02 -1.59795374e-01  4.03871059e-01
 -2.08633363e-01  2.61400253e-01 -1.77513242e-01  2.64400899e-01
 -3.74767929e-01 -1.41106667e-02  7.07195699e-02 -2.59310529e-02
 -1.52463704e-01 -2.09277481e-01  2.42659152e-01 -4.37896281e-01
 -2.74111658e-01  3.23784024e-01 -1.12194913e-02 -7.78998435e-03
 -2.63834894e-01 -1.86299264e-01 -1.20873287e-01  2.04141185e-01
  1.60952255e-01  3.01728785e-01  2.21852630e-01  1.73017696e-01
  3.71879220e-01  2.80739516e-01 -1.18493669e-01  1.09062918e-01
 -2.55998373e-01  3.87480080e-01  4.10263650e-02  2.02835858e-01
 -3.17999512e-01  3.78140330e-01  2.57947147e-01 -4.50112194e-01
  1.04353130e-01  1.40699465e-03  7.67216682e-02 -1.11133285e-01
  1.40065238e-01 -3.31422426e-02  6.38056397e-02 -1.78506866e-01
  1.02249458e-01 -1.90868706e-01 -2.67677069e-01  8.56479257e-02
  1.85055599e-01  2.22840309e-01 -1.93136290e-01 -1.12496831e-01
  2.01004639e-01 -3.48373577e-02 -1.59934118e-01  2.03856632e-01
  2.03415796e-01  1.91151500e-02 -2.14736730e-01 -2.01674789e-01
 -1.03147745e-01  2.00410113e-01  6.62044063e-02 -5.02013564e-02
 -1.48162618e-01 -1.72178164e-01 -1.56178564e-01  2.05861077e-01
 -2.44715880e-03 -4.20740098e-02  1.99603319e-01 -3.03595811e-01
 -2.62882337e-02  5.65342568e-02  1.27887994e-01  1.71164036e-01
 -1.49366796e-01 -6.41742051e-02  1.59788847e-01 -1.77765921e-01
  1.73824430e-01 -1.28364572e-02  3.04782897e-01  8.32331404e-02
  4.28962141e-01  1.86484933e-01  3.57698888e-01  1.70930754e-02
  1.14737764e-01  1.83813170e-01  7.07985610e-02  1.53863117e-01
  1.45394146e-01  6.10771216e-02 -7.36576989e-02  5.53056449e-02
  1.07640862e-01  8.00179467e-02  3.23191434e-02  3.09991091e-01
  3.02178174e-01 -9.09306332e-02  4.91853952e-02 -1.28031313e-01
 -2.54896469e-02  2.34120145e-01 -1.74658343e-01 -2.32459098e-01
  6.18232414e-02 -2.38484278e-01 -6.28195284e-03  1.03620939e-01
  2.82353729e-01 -6.52055070e-02  7.75345117e-02 -1.90856859e-01
 -1.25437349e-01  1.37492150e-01 -1.64269745e-01  2.51677603e-01
  2.33259335e-01  2.17757478e-01  2.26037607e-01  4.26998675e-01
 -1.67967141e-01  2.59857118e-01  7.12665543e-02  1.49024948e-01
 -4.46223438e-01  1.28380001e-01  1.54407173e-01 -2.38353878e-01
 -4.55187351e-01 -1.71284303e-02 -2.03437835e-01  4.44028795e-01
  1.49454489e-01  2.29066014e-01  5.37483320e-02  1.16622731e-01
  3.27921122e-01  8.48986357e-02  2.98905432e-01 -1.16589181e-01
  3.75571474e-02  2.16130674e-01  5.97562492e-02  1.57818839e-01
 -3.79134119e-01  1.97058737e-01  8.41842405e-03 -6.73631504e-02
  3.26564431e-01  1.02038927e-01  9.84950215e-02 -4.74490523e-02
 -3.58012021e-01 -8.46094415e-02 -2.53597409e-01  1.31108731e-01
 -1.36945480e-02 -2.58189082e-01 -4.04197037e-01 -9.93263200e-02
  7.22196922e-02 -3.21413815e-01  1.38105333e-01  5.27646877e-02
 -3.74778695e-02 -3.09642814e-02  8.79964158e-02  9.22843367e-02
  6.59269169e-02 -4.25867379e-01 -1.13668293e-01 -2.31259083e-03
  1.71499252e-02  4.65329364e-02  2.83751369e-01 -9.33092088e-06
  2.11278170e-01 -1.37060642e-01  4.17382754e-02 -7.07651116e-03
  1.57808796e-01 -6.90133646e-02  2.53847003e-01 -2.96002537e-01
  1.61520377e-01  9.76996198e-02 -2.18553003e-02 -1.24721631e-01
  1.75630823e-01 -6.57364130e-02 -2.27706671e-01 -1.50046155e-01
 -4.29430157e-01 -8.62716325e-03 -3.48888189e-01  8.30511972e-02
  1.19602770e-01 -1.06453761e-01 -3.39551032e-01  5.58682233e-02
 -1.50723115e-01 -8.26126337e-02 -1.29831970e-01  9.88700613e-02
  4.37329859e-01 -1.03127375e-01  2.38669097e-01 -8.08308348e-02
  3.22031081e-02 -4.68674600e-02 -1.37694642e-01 -3.00011188e-01
 -2.28143096e-01  1.68973625e-01 -1.38916388e-01 -2.30189320e-02
  7.20473751e-03  2.29728416e-01 -5.10682501e-02 -2.43143052e-01
  7.35338554e-02 -9.28391144e-02  1.04980737e-01 -1.35518312e-01
 -3.77203338e-02 -6.18087426e-02  3.51022571e-01 -1.79783516e-02
  3.15492228e-02 -5.28395176e-01 -6.82753976e-03 -7.57957473e-02
  5.80136776e-01  7.35457381e-03  2.11273469e-02  1.24203205e-01
 -1.12393416e-01  3.32168788e-01 -2.33854130e-01 -1.09314382e-01
  1.09809563e-01  6.32748082e-02 -3.05012822e-01 -1.37086868e-01] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
10/09/2021 11:10:00 - INFO - data_loader -   *** Example ***
10/09/2021 11:10:00 - INFO - data_loader -   guid: dev-3
10/09/2021 11:10:00 - INFO - data_loader -   tokens: [CLS] fu ##k [SEP]
10/09/2021 11:10:00 - INFO - data_loader -   input_ids: 101 11865 2243 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 11:10:00 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 11:10:00 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 11:10:00 - INFO - data_loader -   intent_label: 2 (id = 2)
10/09/2021 11:10:00 - INFO - data_loader -   slot_labels: 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 11:10:00 - INFO - data_loader -   ner_embeds: [-0.05268421 -0.3358649   0.27530029 -0.07744435 -0.07584086 -0.02695106
 -0.26804128  0.02627846 -0.10347202  0.2013707  -0.01272027  0.16158915
 -0.03340857  0.17287622 -0.18740179  0.26615396  0.09241544 -0.11608424
 -0.27987984 -0.28424925 -0.18137644 -0.22812925  0.0249024   0.30128998
  0.13045995  0.03118261  0.16935138 -0.06230416  0.17561074  0.00367108
 -0.07402565  0.04037194 -0.07837126 -0.1561325   0.20836185  0.14040159
  0.11099035  0.17083055 -0.35949063  0.03112581 -0.18540204  0.04089637
 -0.29396915  0.49076098 -0.05263726 -0.16885227  0.11559261  0.25719538
 -0.1559715  -0.06362429 -0.12877826  0.06794425 -0.01322358  0.26562798
  0.08987913  0.29401389 -0.37333494 -0.01440139  0.30768135 -0.37712052
 -0.108851    0.07931803  0.17231582 -0.44193396  0.03251904  0.0195513
 -0.03582918 -0.13726601 -0.28466982 -0.33915862 -0.0583167   0.01170416
  0.32957253  0.08330661  0.28316665  0.00079225  0.41026247  0.02413866
 -0.45413318 -0.1344302  -0.09248621  0.51263183 -0.13745138 -0.11134322
 -0.20985258  0.39278489 -0.1011213   0.18303782 -0.12043855  0.26268336
 -0.0461308   0.30422714  0.07902091 -0.15427054  0.18763816 -0.00932948
  0.02431204  0.30051631 -0.24693149  0.11975729 -0.0125444   0.13902089
 -0.25323379 -0.1082405   0.42633086  0.19724542 -0.07689937 -0.1337288
  0.27917713 -0.0091875   0.25963399 -0.14592938 -0.05517824  0.0350663
  0.20550938  0.11277337 -0.2699483   0.01591763 -0.00071367  0.07296164
  0.02445946  0.14451511 -0.04559916 -0.17699969 -0.42008832  0.10587756
  0.09828436  0.28259453 -0.0146672  -0.11086253 -0.35100189  0.04879292
 -0.0834544   0.16815855 -0.13103473 -0.02294332  0.36864796  0.14379583
  0.44768068 -0.23370998  0.152519    0.04665052 -0.17252302  0.31976756
 -0.16741526 -0.25466728 -0.26076594  0.00063117 -0.05335071  0.15843306
 -0.26611817  0.05734076 -0.08238135  0.18893163 -0.20564257 -0.16225532
 -0.20887086  0.08916163 -0.01871778  0.12805638  0.26127747 -0.0709104
 -0.27082589 -0.1627634   0.13914403  0.12214889 -0.1563787  -0.24772033
 -0.06986653  0.2272698  -0.05595371 -0.00991442 -0.20372061  0.04004419
 -0.04990653  0.43829471  0.11963772 -0.12598085  0.24185398 -0.04867083
 -0.08653479 -0.26793903  0.13082959 -0.43375427 -0.13357146  0.19298363
 -0.22029646  0.38383847 -0.07818928 -0.0058459  -0.32991308 -0.08181709
  0.14099021  0.09491039  0.21827479 -0.00399596 -0.08103576  0.13853465
  0.01428204  0.44172066  0.10182345  0.14742956 -0.14591892  0.33454806
  0.04376031  0.32970932  0.15365525 -0.22210287 -0.16479632 -0.28103629
  0.00301148  0.01037944  0.20718177 -0.2371673   0.33999005 -0.13203178
 -0.26044402 -0.22456646 -0.09428472  0.12473079 -0.10682054  0.08118179
  0.18629588 -0.10320079  0.10400119 -0.36503249  0.0367523  -0.26162294
 -0.13888274 -0.00607623  0.1842383  -0.33304039  0.17386849 -0.0694743
  0.03439113  0.08467512  0.23954627  0.3646954  -0.02856011 -0.21535675
  0.18716544  0.25370413 -0.18916315  0.1572178  -0.06640452  0.13099778
  0.01409951 -0.31194866 -0.14290154 -0.1712914  -0.32875261 -0.09570646
  0.28620249 -0.23103324  0.22911115  0.02136808 -0.04183525  0.2437249
 -0.1248548  -0.05797715  0.476778   -0.21734898  0.23745687  0.26735842
  0.27674222  0.07875728 -0.16760489 -0.46723711 -0.08130792  0.09524607
 -0.19139667  0.13001987  0.25027886 -0.01569632  0.08894423 -0.10037478
  0.12834264 -0.4296048   0.41507876  0.2195386  -0.00381741 -0.146727
  0.23849073  0.10347191  0.17253159 -0.4031671   0.19611832  0.17422171
  0.3443523  -0.18065456  0.04004083  0.10621159 -0.19717942  0.25161341
 -0.0291713   0.11438692  0.13997085  0.00901562 -0.24855603 -0.01550403] [ 3.09551600e-02  4.92905732e-03 -1.29995421e-01  2.56451368e-01
  1.97170705e-01  3.04181278e-01 -5.55011630e-01 -3.09950262e-02
 -1.69141591e-01  3.67513537e-01 -3.98940444e-01 -5.90492086e-03
  1.10297345e-01 -2.58600354e-01  1.32613614e-01 -5.63519970e-02
  3.65529150e-01 -3.15039493e-02 -3.98502767e-01  1.48774246e-02
 -5.26697993e-01  2.87181616e-01  3.14606696e-01 -2.53846228e-01
 -5.16343787e-02 -2.30449468e-01 -1.64388329e-01 -2.23176647e-02
  2.58960038e-01  7.48061016e-02 -6.33068830e-02 -3.08970571e-01
 -6.12702966e-01 -2.12971717e-01 -4.32422101e-01 -3.38489324e-01
  2.24309802e-01  3.96112263e-01  4.16631579e-01  8.12590495e-02
 -1.54518187e-01  4.42936048e-02  1.21119633e-01 -3.41764033e-01
 -1.95110843e-01 -3.26959074e-01 -1.96935579e-01  6.21608973e-01
 -4.65639159e-02  1.04511432e-01  5.52316830e-02  1.57666311e-01
 -3.60528618e-01 -2.65441854e-02 -2.58416068e-02 -3.53142694e-02
 -5.53270504e-02 -2.04530045e-01  1.67008728e-01  4.18508112e-01
 -9.30499509e-02 -1.30808815e-01 -1.04944013e-01  1.10151758e-02
  1.22578196e-01 -3.35258484e-01 -6.45056143e-02  2.94176847e-01
 -2.84506589e-01 -4.86477390e-02  4.09562379e-01  1.93120822e-01
 -4.99313414e-01  2.83435229e-02 -1.76322728e-01  2.12679207e-01
  1.88827574e-01  3.06584239e-01  4.19281088e-02 -1.24286287e-01
  6.52141646e-02  8.77541006e-02  2.86340266e-01 -1.69900298e-01
 -3.13361555e-01 -2.04991013e-01  2.80752957e-01 -4.78553057e-01
  5.28967321e-01 -6.32351206e-04  1.33216083e-01  1.90285295e-01
  2.90790111e-01 -2.97248155e-01  2.04693720e-01  1.73735425e-01
  1.76457956e-01  1.88427314e-01 -4.04165983e-01  1.57572687e-01
 -8.95872712e-02  2.02677488e-01  2.98540890e-01 -1.47968173e-01
 -1.13015816e-01  7.39591792e-02  3.86800021e-02 -2.17269257e-01
 -2.68737108e-01 -2.17636615e-01 -1.74190924e-01 -2.92141438e-01
 -5.36956452e-02 -1.72333315e-01  8.42451528e-02 -2.19527748e-03
  2.68245608e-01 -1.66124940e-01  3.19809854e-01  2.42663488e-01
  1.61024600e-01  2.14159250e-01 -1.81900233e-01  4.31599915e-01
 -3.00771981e-01 -1.95756003e-01 -3.73778820e-01  1.84838008e-02
  1.22935735e-01 -8.74789357e-02 -1.13307051e-01  2.05478966e-01
 -4.92858887e-01 -5.51588424e-02 -1.43805176e-01 -2.41383508e-01
  2.85720453e-02  2.46111229e-02 -3.59248698e-01 -1.88536376e-01
  4.91336025e-02 -3.08351725e-01 -1.12840615e-01  6.99501708e-02
  1.66159123e-01  3.66072565e-01  2.08200440e-01  1.05881192e-01
  3.48632216e-01 -1.68321207e-02  2.21288174e-01  4.32278663e-02
 -1.23361334e-01 -1.19830757e-01  2.16497928e-01  5.61847150e-01
  7.14365691e-02  1.00420654e-01 -7.54512623e-02  4.83747780e-01
 -7.82947466e-02 -2.91354895e-01  3.23807262e-02  2.17362121e-02
  1.35528713e-01  3.58404517e-01  1.60311580e-01 -3.82236660e-01
  1.38444938e-02 -2.34011700e-03 -2.45246604e-01  3.60317379e-01
  2.02648357e-01 -1.49895042e-01  1.04728296e-01  3.23909253e-01
 -5.83419297e-03  4.53240544e-01 -2.15515524e-01  8.01909119e-02
  9.04553756e-02  5.79275750e-02 -3.16609830e-01  4.61569041e-01
  2.29087442e-01 -9.16235745e-02 -8.46999064e-02 -1.62267655e-01
 -2.29481235e-01  1.38120856e-02 -7.90016651e-02  5.83024859e-01
  2.39263520e-01 -3.13639119e-02  1.19901493e-01  5.23199746e-03
  2.17456579e-01 -2.95441300e-01  9.97065753e-02  4.02507186e-02
 -2.51296729e-01  2.18616068e-01 -1.89110875e-01 -3.21833462e-01
  3.74315888e-01 -3.82191986e-02 -5.90245575e-02  1.25303175e-02
  1.48075208e-01  1.34771377e-01 -1.85707495e-01 -3.32949787e-01
 -1.42108560e-01  1.08079374e-01  2.17518866e-01  5.32753281e-02
  9.28504393e-02 -9.29783210e-02 -3.20363998e-01  4.49063927e-01
 -1.23917788e-01 -1.90191612e-01  1.83468424e-02  6.85047545e-03
  2.10297406e-01 -1.46633554e-02 -3.06270003e-01  6.71834826e-01
 -4.20428127e-01 -9.34089273e-02  2.47470895e-03  2.68200755e-01
 -2.01684490e-01  2.47549549e-01  9.74251553e-02  9.23556834e-03
  2.48985127e-01 -3.69390398e-01  1.19682409e-01  2.84056604e-01
 -5.08868285e-02  2.05068082e-01 -2.74509788e-01 -5.59254050e-01
  1.11812368e-01  4.86438870e-02  7.70774707e-02 -2.54074514e-01
  6.50490224e-02  2.17569023e-01  1.01312883e-01  1.36673346e-01
  4.06983569e-02 -1.86062038e-01  5.64638264e-02  9.52767488e-03
  8.82129557e-03 -1.54440373e-01  9.17013213e-02  6.33797199e-02
  1.64633989e-01 -6.97623342e-02  5.10693073e-01 -9.31798592e-02
  2.89412260e-01  2.46000305e-01 -3.86336178e-01 -3.53942096e-01
 -1.97344765e-01  2.88585443e-02 -1.18566781e-01 -2.22382378e-02
 -2.51879126e-01  2.97803521e-01  2.14073546e-02 -2.62575597e-01
 -3.93667966e-02  1.27167165e-01  1.79523632e-01  8.87681171e-02
 -1.70046702e-01  5.78814894e-02  4.32796702e-02  3.98669600e-01
  1.25509184e-02 -8.80929753e-02  6.74331561e-03  3.19218159e-01
  5.69227226e-02  1.89473346e-01  2.53875256e-01  4.45361398e-02
  1.74654350e-01  2.16887474e-01 -1.29889712e-01 -4.20699082e-02
 -1.21126108e-01 -1.22014605e-01 -6.07094914e-03  2.70426095e-01] [ 6.19103201e-02  9.85811464e-03 -2.59990841e-01  5.12902737e-01
  3.94341409e-01  6.08362556e-01 -1.11002326e+00 -6.19900525e-02
 -3.38283181e-01  7.35027075e-01 -7.97880888e-01 -1.18098417e-02
  2.20594689e-01 -5.17200708e-01  2.65227228e-01 -1.12703994e-01
  7.31058300e-01 -6.30078986e-02 -7.97005534e-01  2.97548492e-02
 -1.05339599e+00  5.74363232e-01  6.29213393e-01 -5.07692456e-01
 -1.03268757e-01 -4.60898936e-01 -3.28776658e-01 -4.46353294e-02
  5.17920077e-01  1.49612203e-01 -1.26613766e-01 -6.17941141e-01
 -1.22540593e+00 -4.25943434e-01 -8.64844203e-01 -6.76978648e-01
  4.48619604e-01  7.92224526e-01  8.33263159e-01  1.62518099e-01
 -3.09036374e-01  8.85872096e-02  2.42239267e-01 -6.83528066e-01
 -3.90221685e-01 -6.53918147e-01 -3.93871158e-01  1.24321795e+00
 -9.31278318e-02  2.09022865e-01  1.10463366e-01  3.15332621e-01
 -7.21057236e-01 -5.30883707e-02 -5.16832136e-02 -7.06285387e-02
 -1.10654101e-01 -4.09060091e-01  3.34017456e-01  8.37016225e-01
 -1.86099902e-01 -2.61617631e-01 -2.09888026e-01  2.20303517e-02
  2.45156392e-01 -6.70516968e-01 -1.29011229e-01  5.88353693e-01
 -5.69013178e-01 -9.72954780e-02  8.19124758e-01  3.86241645e-01
 -9.98626828e-01  5.66870458e-02 -3.52645457e-01  4.25358415e-01
  3.77655149e-01  6.13168478e-01  8.38562176e-02 -2.48572573e-01
  1.30428329e-01  1.75508201e-01  5.72680533e-01 -3.39800596e-01
 -6.26723111e-01 -4.09982026e-01  5.61505914e-01 -9.57106113e-01
  1.05793464e+00 -1.26470241e-03  2.66432166e-01  3.80570590e-01
  5.81580222e-01 -5.94496310e-01  4.09387439e-01  3.47470850e-01
  3.52915913e-01  3.76854628e-01 -8.08331966e-01  3.15145373e-01
 -1.79174542e-01  4.05354977e-01  5.97081780e-01 -2.95936346e-01
 -2.26031631e-01  1.47918358e-01  7.73600042e-02 -4.34538513e-01
 -5.37474215e-01 -4.35273230e-01 -3.48381847e-01 -5.84282875e-01
 -1.07391290e-01 -3.44666630e-01  1.68490306e-01 -4.39055497e-03
  5.36491215e-01 -3.32249880e-01  6.39619708e-01  4.85326976e-01
  3.22049201e-01  4.28318501e-01 -3.63800466e-01  8.63199830e-01
 -6.01543963e-01 -3.91512007e-01 -7.47557640e-01  3.69676016e-02
  2.45871469e-01 -1.74957871e-01 -2.26614103e-01  4.10957932e-01
 -9.85717773e-01 -1.10317685e-01 -2.87610352e-01 -4.82767016e-01
  5.71440905e-02  4.92222458e-02 -7.18497396e-01 -3.77072752e-01
  9.82672051e-02 -6.16703451e-01 -2.25681230e-01  1.39900342e-01
  3.32318246e-01  7.32145131e-01  4.16400880e-01  2.11762384e-01
  6.97264433e-01 -3.36642414e-02  4.42576349e-01  8.64557326e-02
 -2.46722668e-01 -2.39661515e-01  4.32995856e-01  1.12369430e+00
  1.42873138e-01  2.00841308e-01 -1.50902525e-01  9.67495561e-01
 -1.56589493e-01 -5.82709789e-01  6.47614524e-02  4.34724241e-02
  2.71057427e-01  7.16809034e-01  3.20623159e-01 -7.64473319e-01
  2.76889876e-02 -4.68023401e-03 -4.90493208e-01  7.20634758e-01
  4.05296713e-01 -2.99790084e-01  2.09456593e-01  6.47818506e-01
 -1.16683859e-02  9.06481087e-01 -4.31031048e-01  1.60381824e-01
  1.80910751e-01  1.15855150e-01 -6.33219659e-01  9.23138082e-01
  4.58174884e-01 -1.83247149e-01 -1.69399813e-01 -3.24535310e-01
 -4.58962470e-01  2.76241712e-02 -1.58003330e-01  1.16604972e+00
  4.78527039e-01 -6.27278239e-02  2.39802986e-01  1.04639949e-02
  4.34913158e-01 -5.90882599e-01  1.99413151e-01  8.05014372e-02
 -5.02593458e-01  4.37232137e-01 -3.78221750e-01 -6.43666923e-01
  7.48631775e-01 -7.64383972e-02 -1.18049115e-01  2.50606351e-02
  2.96150416e-01  2.69542754e-01 -3.71414989e-01 -6.65899575e-01
 -2.84217119e-01  2.16158748e-01  4.35037732e-01  1.06550656e-01
  1.85700879e-01 -1.85956642e-01 -6.40727997e-01  8.98127854e-01
 -2.47835577e-01 -3.80383223e-01  3.66936848e-02  1.37009509e-02
  4.20594811e-01 -2.93267109e-02 -6.12540007e-01  1.34366965e+00
 -8.40856254e-01 -1.86817855e-01  4.94941790e-03  5.36401510e-01
 -4.03368980e-01  4.95099097e-01  1.94850311e-01  1.84711367e-02
  4.97970253e-01 -7.38780797e-01  2.39364818e-01  5.68113208e-01
 -1.01773657e-01  4.10136163e-01 -5.49019575e-01 -1.11850810e+00
  2.23624736e-01  9.72877741e-02  1.54154941e-01 -5.08149028e-01
  1.30098045e-01  4.35138047e-01  2.02625766e-01  2.73346692e-01
  8.13967139e-02 -3.72124076e-01  1.12927653e-01  1.90553498e-02
  1.76425911e-02 -3.08880746e-01  1.83402643e-01  1.26759440e-01
  3.29267979e-01 -1.39524668e-01  1.02138615e+00 -1.86359718e-01
  5.78824520e-01  4.92000610e-01 -7.72672355e-01 -7.07884192e-01
 -3.94689530e-01  5.77170886e-02 -2.37133563e-01 -4.44764756e-02
 -5.03758252e-01  5.95607042e-01  4.28147092e-02 -5.25151193e-01
 -7.87335932e-02  2.54334331e-01  3.59047264e-01  1.77536234e-01
 -3.40093404e-01  1.15762979e-01  8.65593404e-02  7.97339201e-01
  2.51018368e-02 -1.76185951e-01  1.34866312e-02  6.38436317e-01
  1.13845445e-01  3.78946692e-01  5.07750511e-01  8.90722796e-02
  3.49308699e-01  4.33774948e-01 -2.59779423e-01 -8.41398165e-02
 -2.42252216e-01 -2.44029209e-01 -1.21418983e-02  5.40852189e-01] [ 3.23701560e-01  1.23859271e-01  3.17038149e-01 -1.99837953e-01
  1.45933881e-01  1.97479472e-01  1.11766860e-01 -2.97712028e-01
  2.12801516e-01 -8.30430072e-03 -1.36353567e-01  5.88244051e-02
 -1.61227629e-01  3.60989422e-01  2.74212211e-01 -1.38430834e-01
 -5.86703680e-02 -4.27209228e-01 -4.38389741e-02 -1.70130521e-01
 -2.79001564e-01 -5.08604087e-02 -2.22016856e-01  3.46666753e-01
 -1.82083368e-01 -1.79737844e-02 -7.58341700e-02 -2.81926543e-01
 -8.88730120e-03 -9.31498557e-02 -1.63259923e-01  2.63657838e-01
  2.68971026e-01 -1.65585026e-01 -1.38222620e-01 -1.05521366e-01
 -2.16932997e-01  1.53523952e-01 -6.68047294e-02 -1.14297360e-01
 -1.98990464e-01  9.14934743e-03  2.44847938e-01 -1.28512876e-02
  1.28243208e-01 -1.80381879e-01  1.76793709e-01  1.34143546e-01
 -9.09292847e-02  1.11920275e-02 -1.59795374e-01  4.03871059e-01
 -2.08633363e-01  2.61400253e-01 -1.77513242e-01  2.64400899e-01
 -3.74767929e-01 -1.41106667e-02  7.07195699e-02 -2.59310529e-02
 -1.52463704e-01 -2.09277481e-01  2.42659152e-01 -4.37896281e-01
 -2.74111658e-01  3.23784024e-01 -1.12194913e-02 -7.78998435e-03
 -2.63834894e-01 -1.86299264e-01 -1.20873287e-01  2.04141185e-01
  1.60952255e-01  3.01728785e-01  2.21852630e-01  1.73017696e-01
  3.71879220e-01  2.80739516e-01 -1.18493669e-01  1.09062918e-01
 -2.55998373e-01  3.87480080e-01  4.10263650e-02  2.02835858e-01
 -3.17999512e-01  3.78140330e-01  2.57947147e-01 -4.50112194e-01
  1.04353130e-01  1.40699465e-03  7.67216682e-02 -1.11133285e-01
  1.40065238e-01 -3.31422426e-02  6.38056397e-02 -1.78506866e-01
  1.02249458e-01 -1.90868706e-01 -2.67677069e-01  8.56479257e-02
  1.85055599e-01  2.22840309e-01 -1.93136290e-01 -1.12496831e-01
  2.01004639e-01 -3.48373577e-02 -1.59934118e-01  2.03856632e-01
  2.03415796e-01  1.91151500e-02 -2.14736730e-01 -2.01674789e-01
 -1.03147745e-01  2.00410113e-01  6.62044063e-02 -5.02013564e-02
 -1.48162618e-01 -1.72178164e-01 -1.56178564e-01  2.05861077e-01
 -2.44715880e-03 -4.20740098e-02  1.99603319e-01 -3.03595811e-01
 -2.62882337e-02  5.65342568e-02  1.27887994e-01  1.71164036e-01
 -1.49366796e-01 -6.41742051e-02  1.59788847e-01 -1.77765921e-01
  1.73824430e-01 -1.28364572e-02  3.04782897e-01  8.32331404e-02
  4.28962141e-01  1.86484933e-01  3.57698888e-01  1.70930754e-02
  1.14737764e-01  1.83813170e-01  7.07985610e-02  1.53863117e-01
  1.45394146e-01  6.10771216e-02 -7.36576989e-02  5.53056449e-02
  1.07640862e-01  8.00179467e-02  3.23191434e-02  3.09991091e-01
  3.02178174e-01 -9.09306332e-02  4.91853952e-02 -1.28031313e-01
 -2.54896469e-02  2.34120145e-01 -1.74658343e-01 -2.32459098e-01
  6.18232414e-02 -2.38484278e-01 -6.28195284e-03  1.03620939e-01
  2.82353729e-01 -6.52055070e-02  7.75345117e-02 -1.90856859e-01
 -1.25437349e-01  1.37492150e-01 -1.64269745e-01  2.51677603e-01
  2.33259335e-01  2.17757478e-01  2.26037607e-01  4.26998675e-01
 -1.67967141e-01  2.59857118e-01  7.12665543e-02  1.49024948e-01
 -4.46223438e-01  1.28380001e-01  1.54407173e-01 -2.38353878e-01
 -4.55187351e-01 -1.71284303e-02 -2.03437835e-01  4.44028795e-01
  1.49454489e-01  2.29066014e-01  5.37483320e-02  1.16622731e-01
  3.27921122e-01  8.48986357e-02  2.98905432e-01 -1.16589181e-01
  3.75571474e-02  2.16130674e-01  5.97562492e-02  1.57818839e-01
 -3.79134119e-01  1.97058737e-01  8.41842405e-03 -6.73631504e-02
  3.26564431e-01  1.02038927e-01  9.84950215e-02 -4.74490523e-02
 -3.58012021e-01 -8.46094415e-02 -2.53597409e-01  1.31108731e-01
 -1.36945480e-02 -2.58189082e-01 -4.04197037e-01 -9.93263200e-02
  7.22196922e-02 -3.21413815e-01  1.38105333e-01  5.27646877e-02
 -3.74778695e-02 -3.09642814e-02  8.79964158e-02  9.22843367e-02
  6.59269169e-02 -4.25867379e-01 -1.13668293e-01 -2.31259083e-03
  1.71499252e-02  4.65329364e-02  2.83751369e-01 -9.33092088e-06
  2.11278170e-01 -1.37060642e-01  4.17382754e-02 -7.07651116e-03
  1.57808796e-01 -6.90133646e-02  2.53847003e-01 -2.96002537e-01
  1.61520377e-01  9.76996198e-02 -2.18553003e-02 -1.24721631e-01
  1.75630823e-01 -6.57364130e-02 -2.27706671e-01 -1.50046155e-01
 -4.29430157e-01 -8.62716325e-03 -3.48888189e-01  8.30511972e-02
  1.19602770e-01 -1.06453761e-01 -3.39551032e-01  5.58682233e-02
 -1.50723115e-01 -8.26126337e-02 -1.29831970e-01  9.88700613e-02
  4.37329859e-01 -1.03127375e-01  2.38669097e-01 -8.08308348e-02
  3.22031081e-02 -4.68674600e-02 -1.37694642e-01 -3.00011188e-01
 -2.28143096e-01  1.68973625e-01 -1.38916388e-01 -2.30189320e-02
  7.20473751e-03  2.29728416e-01 -5.10682501e-02 -2.43143052e-01
  7.35338554e-02 -9.28391144e-02  1.04980737e-01 -1.35518312e-01
 -3.77203338e-02 -6.18087426e-02  3.51022571e-01 -1.79783516e-02
  3.15492228e-02 -5.28395176e-01 -6.82753976e-03 -7.57957473e-02
  5.80136776e-01  7.35457381e-03  2.11273469e-02  1.24203205e-01
 -1.12393416e-01  3.32168788e-01 -2.33854130e-01 -1.09314382e-01
  1.09809563e-01  6.32748082e-02 -3.05012822e-01 -1.37086868e-01] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
10/09/2021 11:10:00 - INFO - data_loader -   *** Example ***
10/09/2021 11:10:00 - INFO - data_loader -   guid: dev-4
10/09/2021 11:10:00 - INFO - data_loader -   tokens: [CLS] ; ) [SEP]
10/09/2021 11:10:00 - INFO - data_loader -   input_ids: 101 1025 1007 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 11:10:00 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 11:10:00 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 11:10:00 - INFO - data_loader -   intent_label: 4 (id = 4)
10/09/2021 11:10:00 - INFO - data_loader -   slot_labels: 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 11:10:00 - INFO - data_loader -   ner_embeds: [-0.05268421 -0.3358649   0.27530029 -0.07744435 -0.07584086 -0.02695106
 -0.26804128  0.02627846 -0.10347202  0.2013707  -0.01272027  0.16158915
 -0.03340857  0.17287622 -0.18740179  0.26615396  0.09241544 -0.11608424
 -0.27987984 -0.28424925 -0.18137644 -0.22812925  0.0249024   0.30128998
  0.13045995  0.03118261  0.16935138 -0.06230416  0.17561074  0.00367108
 -0.07402565  0.04037194 -0.07837126 -0.1561325   0.20836185  0.14040159
  0.11099035  0.17083055 -0.35949063  0.03112581 -0.18540204  0.04089637
 -0.29396915  0.49076098 -0.05263726 -0.16885227  0.11559261  0.25719538
 -0.1559715  -0.06362429 -0.12877826  0.06794425 -0.01322358  0.26562798
  0.08987913  0.29401389 -0.37333494 -0.01440139  0.30768135 -0.37712052
 -0.108851    0.07931803  0.17231582 -0.44193396  0.03251904  0.0195513
 -0.03582918 -0.13726601 -0.28466982 -0.33915862 -0.0583167   0.01170416
  0.32957253  0.08330661  0.28316665  0.00079225  0.41026247  0.02413866
 -0.45413318 -0.1344302  -0.09248621  0.51263183 -0.13745138 -0.11134322
 -0.20985258  0.39278489 -0.1011213   0.18303782 -0.12043855  0.26268336
 -0.0461308   0.30422714  0.07902091 -0.15427054  0.18763816 -0.00932948
  0.02431204  0.30051631 -0.24693149  0.11975729 -0.0125444   0.13902089
 -0.25323379 -0.1082405   0.42633086  0.19724542 -0.07689937 -0.1337288
  0.27917713 -0.0091875   0.25963399 -0.14592938 -0.05517824  0.0350663
  0.20550938  0.11277337 -0.2699483   0.01591763 -0.00071367  0.07296164
  0.02445946  0.14451511 -0.04559916 -0.17699969 -0.42008832  0.10587756
  0.09828436  0.28259453 -0.0146672  -0.11086253 -0.35100189  0.04879292
 -0.0834544   0.16815855 -0.13103473 -0.02294332  0.36864796  0.14379583
  0.44768068 -0.23370998  0.152519    0.04665052 -0.17252302  0.31976756
 -0.16741526 -0.25466728 -0.26076594  0.00063117 -0.05335071  0.15843306
 -0.26611817  0.05734076 -0.08238135  0.18893163 -0.20564257 -0.16225532
 -0.20887086  0.08916163 -0.01871778  0.12805638  0.26127747 -0.0709104
 -0.27082589 -0.1627634   0.13914403  0.12214889 -0.1563787  -0.24772033
 -0.06986653  0.2272698  -0.05595371 -0.00991442 -0.20372061  0.04004419
 -0.04990653  0.43829471  0.11963772 -0.12598085  0.24185398 -0.04867083
 -0.08653479 -0.26793903  0.13082959 -0.43375427 -0.13357146  0.19298363
 -0.22029646  0.38383847 -0.07818928 -0.0058459  -0.32991308 -0.08181709
  0.14099021  0.09491039  0.21827479 -0.00399596 -0.08103576  0.13853465
  0.01428204  0.44172066  0.10182345  0.14742956 -0.14591892  0.33454806
  0.04376031  0.32970932  0.15365525 -0.22210287 -0.16479632 -0.28103629
  0.00301148  0.01037944  0.20718177 -0.2371673   0.33999005 -0.13203178
 -0.26044402 -0.22456646 -0.09428472  0.12473079 -0.10682054  0.08118179
  0.18629588 -0.10320079  0.10400119 -0.36503249  0.0367523  -0.26162294
 -0.13888274 -0.00607623  0.1842383  -0.33304039  0.17386849 -0.0694743
  0.03439113  0.08467512  0.23954627  0.3646954  -0.02856011 -0.21535675
  0.18716544  0.25370413 -0.18916315  0.1572178  -0.06640452  0.13099778
  0.01409951 -0.31194866 -0.14290154 -0.1712914  -0.32875261 -0.09570646
  0.28620249 -0.23103324  0.22911115  0.02136808 -0.04183525  0.2437249
 -0.1248548  -0.05797715  0.476778   -0.21734898  0.23745687  0.26735842
  0.27674222  0.07875728 -0.16760489 -0.46723711 -0.08130792  0.09524607
 -0.19139667  0.13001987  0.25027886 -0.01569632  0.08894423 -0.10037478
  0.12834264 -0.4296048   0.41507876  0.2195386  -0.00381741 -0.146727
  0.23849073  0.10347191  0.17253159 -0.4031671   0.19611832  0.17422171
  0.3443523  -0.18065456  0.04004083  0.10621159 -0.19717942  0.25161341
 -0.0291713   0.11438692  0.13997085  0.00901562 -0.24855603 -0.01550403] [-0.51233774  0.08140008  0.28191814  0.29640421 -0.05141266  0.03825579
 -0.09847494  0.10901181 -0.05219802  0.2134051   0.40210479  0.37325427
  0.21665399 -0.06021318 -0.06645185  0.08922379  0.33070886  0.12170944
 -0.06221674 -0.41340846 -0.13452916 -0.25144327 -0.33830607  0.67941028
  0.059664    0.14968079  0.38394317  0.26838371 -0.17366093  0.55959117
 -0.11518402  0.25039825  0.20504621 -0.04374346 -0.19178256  0.43514171
 -0.27208617 -0.05116383 -0.16975224  0.22281167 -0.0955876  -0.06869972
  0.02761936 -0.40219539  0.0517581  -0.19688621  0.11502847  0.15961264
  0.0678155   0.34427962  0.14781822  0.18462631 -0.30896044  0.4701508
  0.01391016  0.40690026  0.15123652 -0.18133545 -0.29274926 -0.07004888
 -0.24040723  0.16115396  0.22436775 -0.1886481  -0.06594457  0.17303561
 -0.27094951 -0.3110041  -0.17693405  0.37074286 -0.1747463  -0.3146579
 -0.00252642  0.05357274 -0.40381601 -0.02171244  0.10620873  0.63602424
 -0.11934772  0.16993329 -0.24872035  0.17153518  0.32363772 -0.40559003
 -0.37121886  0.14269172 -0.15831161 -0.09781815  0.54400778 -0.29045501
 -0.13263001  0.36237392  0.23912807 -0.00705324  0.40177539  0.22587132
 -0.15990192 -0.15721779 -0.35526136 -0.04844552  0.14886728  0.27134722
  0.00919098  0.00148324  0.70137811 -0.11980458 -0.22768326 -0.2313868
 -0.28095448 -0.52289939  0.08182946  0.18866877  0.17482196 -0.19623931
 -0.09373978  0.03144782  0.1366253   0.17853186  0.16840786 -0.45163926
  0.71559596 -0.16139483  0.18419518  0.36583015  0.29942155  0.36052731
 -0.07605443  0.42562759 -0.06088012 -0.07994853  0.06074056  0.03709468
  0.10548586  0.18412283  0.27626672 -0.14698833  0.24782351 -0.51232231
 -0.23301345 -0.1579358   0.37772509  0.19295657  0.36120301  0.14566322
 -0.02947765 -0.65639257  0.06397451 -0.17265613 -0.32282501  0.04382123
  0.15331204 -0.34302464  0.12980507  0.01771686  0.33870807  0.08638931
 -0.08187778  0.34765846  0.15279362  0.35520414  0.36877397  0.17915924
  0.07372696  0.18091048  0.39845431 -0.48556259  0.16425119  0.05264854
 -0.47981867 -0.19550744  0.13514058  0.41769546  0.33422616  0.16056244
  0.07344243  0.29646945  0.22042067 -0.37202898 -0.07908784 -0.40735835
  0.07737387 -0.11317343 -0.1318242  -0.21241908  0.25326625  0.33122864
 -0.62425816 -0.08433565 -0.46846792  0.10950541 -0.19845524  0.11164499
 -0.31216219 -0.15988684 -0.11174041 -0.0178483  -0.46489182  0.45792413
  0.11302001  0.46771944 -0.16723891 -0.14449194 -0.30118123  0.59780884
 -0.14857362 -0.29008672  0.15017909 -0.19277184  0.38172254 -0.15264751
  0.06044916  0.12432287 -0.0952725  -0.09651221 -0.47014856 -0.10053073
  0.04183375 -0.15900728  0.1115146  -0.33115587 -0.07700354  0.08147641
  0.1975777  -0.12903509  0.28612101 -0.43366709 -0.26217383  0.18279922
 -0.40886739 -0.20479465  0.26882648 -0.35610256  0.41908127 -0.22943966
  0.11320604  0.37502047  0.34097788  0.09596597  0.42164534 -0.38316095
 -0.14968999  0.550771   -0.33735728 -0.45964929 -0.36936063  0.20056589
  0.26785108 -0.44578385 -0.21385843 -0.00585234 -0.22268103  0.3901208
  0.20713317 -0.19193049 -0.16448537  0.02927412  0.38709939  0.45562187
 -0.36854136 -0.1302304   0.12775786 -0.40313748  0.31697792  0.09618888
  0.39070177  0.01285421 -0.29699746  0.10853468  0.12918538 -0.20236909
 -0.68833649  0.63813257  0.37747142 -0.01235306 -0.31887412 -0.17410463
 -0.05500194  0.02644821 -0.49334759 -0.22282317 -0.19903013 -0.32961693
 -0.26900494 -0.13374099  0.44349918 -0.36676934  0.21714187  0.10532368
  0.35203457 -0.32029095 -0.15523802  0.18198872 -0.44374734 -0.30742463
 -0.24871084  0.21534733  0.2669614  -0.08989209 -0.48125157 -0.088686  ] [-1.02467549  0.16280016  0.56383628  0.59280843 -0.10282532  0.07651158
 -0.19694988  0.21802361 -0.10439605  0.4268102   0.80420959  0.74650854
  0.43330798 -0.12042636 -0.1329037   0.17844757  0.66141772  0.24341889
 -0.12443349 -0.82681692 -0.26905832 -0.50288653 -0.67661214  1.35882056
  0.11932801  0.29936159  0.76788634  0.53676742 -0.34732187  1.11918235
 -0.23036803  0.5007965   0.41009241 -0.08748692 -0.38356513  0.87028342
 -0.54417235 -0.10232765 -0.33950448  0.44562334 -0.19117519 -0.13739944
  0.05523872 -0.80439079  0.10351619 -0.39377242  0.23005694  0.31922528
  0.135631    0.68855923  0.29563645  0.36925262 -0.61792088  0.9403016
  0.02782032  0.81380051  0.30247304 -0.3626709  -0.58549851 -0.14009777
 -0.48081446  0.32230791  0.44873551 -0.37729621 -0.13188915  0.34607121
 -0.54189903 -0.6220082  -0.3538681   0.74148571 -0.34949261 -0.62931579
 -0.00505284  0.10714549 -0.80763203 -0.04342489  0.21241745  1.27204847
 -0.23869544  0.33986658 -0.4974407   0.34307036  0.64727545 -0.81118006
 -0.74243772  0.28538343 -0.31662321 -0.1956363   1.08801556 -0.58091003
 -0.26526001  0.72474784  0.47825614 -0.01410648  0.80355078  0.45174265
 -0.31980383 -0.31443557 -0.71052271 -0.09689105  0.29773456  0.54269445
  0.01838196  0.00296647  1.40275621 -0.23960915 -0.45536652 -0.46277359
 -0.56190896 -1.04579878  0.16365892  0.37733755  0.34964392 -0.39247862
 -0.18747956  0.06289563  0.27325061  0.35706371  0.33681571 -0.90327853
  1.43119192 -0.32278967  0.36839035  0.73166031  0.5988431   0.72105461
 -0.15210886  0.85125518 -0.12176023 -0.15989706  0.12148113  0.07418936
  0.21097171  0.36824566  0.55253345 -0.29397666  0.49564701 -1.02464461
 -0.4660269  -0.3158716   0.75545019  0.38591313  0.72240603  0.29132643
 -0.0589553  -1.31278515  0.12794901 -0.34531227 -0.64565003  0.08764245
  0.30662408 -0.68604928  0.25961015  0.03543372  0.67741615  0.17277862
 -0.16375555  0.69531691  0.30558723  0.71040827  0.73754793  0.35831848
  0.14745392  0.36182097  0.79690862 -0.97112519  0.32850239  0.10529708
 -0.95963734 -0.39101487  0.27028117  0.83539093  0.66845232  0.32112488
  0.14688486  0.5929389   0.44084135 -0.74405795 -0.15817568 -0.8147167
  0.15474774 -0.22634685 -0.26364839 -0.42483816  0.50653249  0.66245729
 -1.24851632 -0.1686713  -0.93693584  0.21901082 -0.39691049  0.22328998
 -0.62432438 -0.31977367 -0.22348082 -0.0356966  -0.92978364  0.91584826
  0.22604002  0.93543887 -0.33447781 -0.28898388 -0.60236245  1.19561768
 -0.29714724 -0.58017343  0.30035818 -0.38554367  0.76344508 -0.30529502
  0.12089831  0.24864574 -0.19054501 -0.19302443 -0.94029713 -0.20106146
  0.0836675  -0.31801456  0.2230292  -0.66231173 -0.15400708  0.16295283
  0.3951554  -0.25807017  0.57224202 -0.86733419 -0.52434766  0.36559844
 -0.81773478 -0.40958929  0.53765297 -0.71220511  0.83816254 -0.45887932
  0.22641207  0.75004095  0.68195575  0.19193195  0.84329069 -0.7663219
 -0.29937997  1.101542   -0.67471457 -0.91929859 -0.73872125  0.40113178
  0.53570217 -0.89156771 -0.42771685 -0.01170469 -0.44536206  0.78024161
  0.41426635 -0.38386098 -0.32897073  0.05854825  0.77419877  0.91124374
 -0.73708272 -0.26046079  0.25551572 -0.80627495  0.63395584  0.19237776
  0.78140354  0.02570842 -0.59399492  0.21706936  0.25837076 -0.40473819
 -1.37667298  1.27626514  0.75494283 -0.02470613 -0.63774824 -0.34820926
 -0.11000388  0.05289643 -0.98669517 -0.44564635 -0.39806026 -0.65923387
 -0.53800988 -0.26748198  0.88699836 -0.73353869  0.43428373  0.21064736
  0.70406914 -0.64058191 -0.31047603  0.36397743 -0.88749468 -0.61484927
 -0.49742168  0.43069467  0.53392279 -0.17978418 -0.96250314 -0.17737199] [ 3.23701560e-01  1.23859271e-01  3.17038149e-01 -1.99837953e-01
  1.45933881e-01  1.97479472e-01  1.11766860e-01 -2.97712028e-01
  2.12801516e-01 -8.30430072e-03 -1.36353567e-01  5.88244051e-02
 -1.61227629e-01  3.60989422e-01  2.74212211e-01 -1.38430834e-01
 -5.86703680e-02 -4.27209228e-01 -4.38389741e-02 -1.70130521e-01
 -2.79001564e-01 -5.08604087e-02 -2.22016856e-01  3.46666753e-01
 -1.82083368e-01 -1.79737844e-02 -7.58341700e-02 -2.81926543e-01
 -8.88730120e-03 -9.31498557e-02 -1.63259923e-01  2.63657838e-01
  2.68971026e-01 -1.65585026e-01 -1.38222620e-01 -1.05521366e-01
 -2.16932997e-01  1.53523952e-01 -6.68047294e-02 -1.14297360e-01
 -1.98990464e-01  9.14934743e-03  2.44847938e-01 -1.28512876e-02
  1.28243208e-01 -1.80381879e-01  1.76793709e-01  1.34143546e-01
 -9.09292847e-02  1.11920275e-02 -1.59795374e-01  4.03871059e-01
 -2.08633363e-01  2.61400253e-01 -1.77513242e-01  2.64400899e-01
 -3.74767929e-01 -1.41106667e-02  7.07195699e-02 -2.59310529e-02
 -1.52463704e-01 -2.09277481e-01  2.42659152e-01 -4.37896281e-01
 -2.74111658e-01  3.23784024e-01 -1.12194913e-02 -7.78998435e-03
 -2.63834894e-01 -1.86299264e-01 -1.20873287e-01  2.04141185e-01
  1.60952255e-01  3.01728785e-01  2.21852630e-01  1.73017696e-01
  3.71879220e-01  2.80739516e-01 -1.18493669e-01  1.09062918e-01
 -2.55998373e-01  3.87480080e-01  4.10263650e-02  2.02835858e-01
 -3.17999512e-01  3.78140330e-01  2.57947147e-01 -4.50112194e-01
  1.04353130e-01  1.40699465e-03  7.67216682e-02 -1.11133285e-01
  1.40065238e-01 -3.31422426e-02  6.38056397e-02 -1.78506866e-01
  1.02249458e-01 -1.90868706e-01 -2.67677069e-01  8.56479257e-02
  1.85055599e-01  2.22840309e-01 -1.93136290e-01 -1.12496831e-01
  2.01004639e-01 -3.48373577e-02 -1.59934118e-01  2.03856632e-01
  2.03415796e-01  1.91151500e-02 -2.14736730e-01 -2.01674789e-01
 -1.03147745e-01  2.00410113e-01  6.62044063e-02 -5.02013564e-02
 -1.48162618e-01 -1.72178164e-01 -1.56178564e-01  2.05861077e-01
 -2.44715880e-03 -4.20740098e-02  1.99603319e-01 -3.03595811e-01
 -2.62882337e-02  5.65342568e-02  1.27887994e-01  1.71164036e-01
 -1.49366796e-01 -6.41742051e-02  1.59788847e-01 -1.77765921e-01
  1.73824430e-01 -1.28364572e-02  3.04782897e-01  8.32331404e-02
  4.28962141e-01  1.86484933e-01  3.57698888e-01  1.70930754e-02
  1.14737764e-01  1.83813170e-01  7.07985610e-02  1.53863117e-01
  1.45394146e-01  6.10771216e-02 -7.36576989e-02  5.53056449e-02
  1.07640862e-01  8.00179467e-02  3.23191434e-02  3.09991091e-01
  3.02178174e-01 -9.09306332e-02  4.91853952e-02 -1.28031313e-01
 -2.54896469e-02  2.34120145e-01 -1.74658343e-01 -2.32459098e-01
  6.18232414e-02 -2.38484278e-01 -6.28195284e-03  1.03620939e-01
  2.82353729e-01 -6.52055070e-02  7.75345117e-02 -1.90856859e-01
 -1.25437349e-01  1.37492150e-01 -1.64269745e-01  2.51677603e-01
  2.33259335e-01  2.17757478e-01  2.26037607e-01  4.26998675e-01
 -1.67967141e-01  2.59857118e-01  7.12665543e-02  1.49024948e-01
 -4.46223438e-01  1.28380001e-01  1.54407173e-01 -2.38353878e-01
 -4.55187351e-01 -1.71284303e-02 -2.03437835e-01  4.44028795e-01
  1.49454489e-01  2.29066014e-01  5.37483320e-02  1.16622731e-01
  3.27921122e-01  8.48986357e-02  2.98905432e-01 -1.16589181e-01
  3.75571474e-02  2.16130674e-01  5.97562492e-02  1.57818839e-01
 -3.79134119e-01  1.97058737e-01  8.41842405e-03 -6.73631504e-02
  3.26564431e-01  1.02038927e-01  9.84950215e-02 -4.74490523e-02
 -3.58012021e-01 -8.46094415e-02 -2.53597409e-01  1.31108731e-01
 -1.36945480e-02 -2.58189082e-01 -4.04197037e-01 -9.93263200e-02
  7.22196922e-02 -3.21413815e-01  1.38105333e-01  5.27646877e-02
 -3.74778695e-02 -3.09642814e-02  8.79964158e-02  9.22843367e-02
  6.59269169e-02 -4.25867379e-01 -1.13668293e-01 -2.31259083e-03
  1.71499252e-02  4.65329364e-02  2.83751369e-01 -9.33092088e-06
  2.11278170e-01 -1.37060642e-01  4.17382754e-02 -7.07651116e-03
  1.57808796e-01 -6.90133646e-02  2.53847003e-01 -2.96002537e-01
  1.61520377e-01  9.76996198e-02 -2.18553003e-02 -1.24721631e-01
  1.75630823e-01 -6.57364130e-02 -2.27706671e-01 -1.50046155e-01
 -4.29430157e-01 -8.62716325e-03 -3.48888189e-01  8.30511972e-02
  1.19602770e-01 -1.06453761e-01 -3.39551032e-01  5.58682233e-02
 -1.50723115e-01 -8.26126337e-02 -1.29831970e-01  9.88700613e-02
  4.37329859e-01 -1.03127375e-01  2.38669097e-01 -8.08308348e-02
  3.22031081e-02 -4.68674600e-02 -1.37694642e-01 -3.00011188e-01
 -2.28143096e-01  1.68973625e-01 -1.38916388e-01 -2.30189320e-02
  7.20473751e-03  2.29728416e-01 -5.10682501e-02 -2.43143052e-01
  7.35338554e-02 -9.28391144e-02  1.04980737e-01 -1.35518312e-01
 -3.77203338e-02 -6.18087426e-02  3.51022571e-01 -1.79783516e-02
  3.15492228e-02 -5.28395176e-01 -6.82753976e-03 -7.57957473e-02
  5.80136776e-01  7.35457381e-03  2.11273469e-02  1.24203205e-01
 -1.12393416e-01  3.32168788e-01 -2.33854130e-01 -1.09314382e-01
  1.09809563e-01  6.32748082e-02 -3.05012822e-01 -1.37086868e-01] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
10/09/2021 11:10:03 - INFO - data_loader -   Writing example 5000 of 8705
10/09/2021 11:10:05 - INFO - data_loader -   Saving features into cached file ./data\cached_dev_conda_bert-base-uncased_50
10/09/2021 11:10:24 - INFO - data_loader -   Creating features from dataset file at ./data
10/09/2021 11:10:24 - INFO - data_loader -   LOOKING AT ./data\conda\test
There is no test dataset provided
10/09/2021 11:10:25 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at C:\Users\k3lan/.cache\torch\transformers\4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
10/09/2021 11:10:26 - INFO - transformers.configuration_utils -   Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "conda",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

10/09/2021 11:10:26 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at C:\Users\k3lan/.cache\torch\transformers\f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
10/09/2021 11:10:27 - WARNING - transformers.modeling_utils -   Some weights of the model checkpoint at bert-base-uncased were not used when initializing JointBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing JointBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing JointBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
10/09/2021 11:10:27 - WARNING - transformers.modeling_utils -   Some weights of JointBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['intent_classifier.linear.weight', 'intent_classifier.linear.bias', 'slot_classifier.linear.weight', 'slot_classifier.linear.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
True
NVIDIA GeForce RTX 2070 Super with Max-Q Design
Using device: cuda
Train using train and val sets only
10/09/2021 11:10:31 - INFO - trainer -   ***** Running training *****
10/09/2021 11:10:31 - INFO - trainer -     Num examples = 26078
10/09/2021 11:10:31 - INFO - trainer -     Num Epochs = 20
10/09/2021 11:10:31 - INFO - trainer -     Total train batch size = 32
10/09/2021 11:10:31 - INFO - trainer -     Gradient Accumulation steps = 1
10/09/2021 11:10:31 - INFO - trainer -     Total optimization steps = 16300
10/09/2021 11:10:31 - INFO - trainer -     Logging steps = 200
10/09/2021 11:10:31 - INFO - trainer -     Save steps = 200
Epoch:   0%|                                                                                    | 0/20 [00:00<?, ?it/s]10/09/2021 11:11:16 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 199/815 [00:45<02:18,  4.45it/s]
10/09/2021 11:11:16 - INFO - trainer -     Num examples = 8705
10/09/2021 11:11:16 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:18<00:00,  7.55it/s]
10/09/2021 11:11:36 - INFO - trainer -   ***** Eval results *****
10/09/2021 11:11:36 - INFO - trainer -     T-F1 = 0.9357321710099231████████████████▌| 136/137 [00:18<00:00,  7.37it/s]
10/09/2021 11:11:36 - INFO - trainer -     T-F1(C) = 0.8597595878649111
10/09/2021 11:11:36 - INFO - trainer -     T-F1(D) = 0.6428571428571429
10/09/2021 11:11:36 - INFO - trainer -     T-F1(O) = 0.9747984139234106
10/09/2021 11:11:36 - INFO - trainer -     T-F1(P) = 0.9914398875686725
10/09/2021 11:11:36 - INFO - trainer -     T-F1(S) = 0.9487677371172517
10/09/2021 11:11:36 - INFO - trainer -     T-F1(T) = 0.9119064005505849
10/09/2021 11:11:36 - INFO - trainer -     U-F1(A) = 0.7673060884070058
10/09/2021 11:11:36 - INFO - trainer -     U-F1(E) = 0.8359550561797754
10/09/2021 11:11:36 - INFO - trainer -     U-F1(I) = 0.730728616684266
10/09/2021 11:11:36 - INFO - trainer -     U-F1(O) = 0.9454712784722754
10/09/2021 11:11:36 - INFO - trainer -     intent_acc = 0.9075244112578977
10/09/2021 11:11:36 - INFO - trainer -     loss = 0.4591578049381284
10/09/2021 11:11:36 - INFO - trainer -     semantic_frame_acc = 0.811143021252154
10/09/2021 11:11:36 - INFO - trainer -     slot_f1 = 0.9486120996441281
10/09/2021 11:11:36 - INFO - trainer -     slot_precision = 0.9456506314743862
10/09/2021 11:11:36 - INFO - trainer -     slot_recall = 0.9515921747822362

10/09/2021 11:11:36 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 11:11:36 - INFO - trainer -     T-F1 = 0.9357321710099231
10/09/2021 11:11:36 - INFO - trainer -     T-F1(C) = 0.8597595878649111
10/09/2021 11:11:36 - INFO - trainer -     T-F1(D) = 0.6428571428571429
10/09/2021 11:11:36 - INFO - trainer -     T-F1(O) = 0.9747984139234106
10/09/2021 11:11:36 - INFO - trainer -     T-F1(P) = 0.9914398875686725
10/09/2021 11:11:36 - INFO - trainer -     T-F1(S) = 0.9487677371172517
10/09/2021 11:11:36 - INFO - trainer -     T-F1(T) = 0.9119064005505849
10/09/2021 11:11:36 - INFO - trainer -     U-F1(A) = 0.7673060884070058
10/09/2021 11:11:36 - INFO - trainer -     U-F1(E) = 0.8359550561797754
10/09/2021 11:11:36 - INFO - trainer -     U-F1(I) = 0.730728616684266
10/09/2021 11:11:36 - INFO - trainer -     U-F1(O) = 0.9454712784722754
10/09/2021 11:11:36 - INFO - trainer -     intent_acc = 0.9075244112578977
10/09/2021 11:11:36 - INFO - trainer -     semantic_frame_acc = 0.811143021252154
10/09/2021 11:11:36 - INFO - trainer -     slot_f1 = 0.9486120996441281
10/09/2021 11:11:36 - INFO - trainer -     slot_precision = 0.9456506314743862
10/09/2021 11:11:36 - INFO - trainer -     slot_recall = 0.9515921747822362
10/09/2021 11:11:36 - INFO - transformers.configuration_utils -   Configuration saved in final_conda_bert_g_model\config.json
10/09/2021 11:11:36 - INFO - transformers.modeling_utils -   Model weights saved in final_conda_bert_g_model\pytorch_model.bin
10/09/2021 11:11:36 - INFO - trainer -   Saving model checkpoint to final_conda_bert_g_model
Best model saved
                                                                                                                       10/09/2021 11:12:22 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 399/815 [01:51<01:36,  4.33it/s]
10/09/2021 11:12:22 - INFO - trainer -     Num examples = 8705
10/09/2021 11:12:22 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:18<00:00,  7.42it/s]
10/09/2021 11:12:42 - INFO - trainer -   ***** Eval results *****
10/09/2021 11:12:42 - INFO - trainer -     T-F1 = 0.9694106641721235████████████████▌| 136/137 [00:18<00:00,  7.20it/s]
10/09/2021 11:12:42 - INFO - trainer -     T-F1(C) = 0.9433611884865366
10/09/2021 11:12:42 - INFO - trainer -     T-F1(D) = 0.8263305322128851
10/09/2021 11:12:42 - INFO - trainer -     T-F1(O) = 0.9852501125440246
10/09/2021 11:12:42 - INFO - trainer -     T-F1(P) = 0.9979555328392536
10/09/2021 11:12:42 - INFO - trainer -     T-F1(S) = 0.9786530366806975
10/09/2021 11:12:42 - INFO - trainer -     T-F1(T) = 0.9360838687859316
10/09/2021 11:12:42 - INFO - trainer -     U-F1(A) = 0.7919930374238467
10/09/2021 11:12:42 - INFO - trainer -     U-F1(E) = 0.8598210481465701
10/09/2021 11:12:42 - INFO - trainer -     U-F1(I) = 0.7372793354101765
10/09/2021 11:12:42 - INFO - trainer -     U-F1(O) = 0.9518956065168713
10/09/2021 11:12:42 - INFO - trainer -     intent_acc = 0.9170591614014934
10/09/2021 11:12:42 - INFO - trainer -     loss = 0.3766298451236565
10/09/2021 11:12:42 - INFO - trainer -     semantic_frame_acc = 0.862263067202757
10/09/2021 11:12:42 - INFO - trainer -     slot_f1 = 0.9757302405498283
10/09/2021 11:12:42 - INFO - trainer -     slot_precision = 0.978391959798995
10/09/2021 11:12:42 - INFO - trainer -     slot_recall = 0.9730829644438098

10/09/2021 11:12:42 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 11:12:42 - INFO - trainer -     T-F1 = 0.9694106641721235
10/09/2021 11:12:42 - INFO - trainer -     T-F1(C) = 0.9433611884865366
10/09/2021 11:12:42 - INFO - trainer -     T-F1(D) = 0.8263305322128851
10/09/2021 11:12:42 - INFO - trainer -     T-F1(O) = 0.9852501125440246
10/09/2021 11:12:42 - INFO - trainer -     T-F1(P) = 0.9979555328392536
10/09/2021 11:12:42 - INFO - trainer -     T-F1(S) = 0.9786530366806975
10/09/2021 11:12:42 - INFO - trainer -     T-F1(T) = 0.9360838687859316
10/09/2021 11:12:42 - INFO - trainer -     U-F1(A) = 0.7919930374238467
10/09/2021 11:12:42 - INFO - trainer -     U-F1(E) = 0.8598210481465701
10/09/2021 11:12:42 - INFO - trainer -     U-F1(I) = 0.7372793354101765
10/09/2021 11:12:42 - INFO - trainer -     U-F1(O) = 0.9518956065168713
10/09/2021 11:12:42 - INFO - trainer -     intent_acc = 0.9170591614014934
10/09/2021 11:12:42 - INFO - trainer -     semantic_frame_acc = 0.862263067202757
10/09/2021 11:12:42 - INFO - trainer -     slot_f1 = 0.9757302405498283
10/09/2021 11:12:42 - INFO - trainer -     slot_precision = 0.978391959798995
10/09/2021 11:12:42 - INFO - trainer -     slot_recall = 0.9730829644438098
10/09/2021 11:12:42 - INFO - transformers.configuration_utils -   Configuration saved in final_conda_bert_g_model\config.json
10/09/2021 11:12:42 - INFO - transformers.modeling_utils -   Model weights saved in final_conda_bert_g_model\pytorch_model.bin
10/09/2021 11:12:42 - INFO - trainer -   Saving model checkpoint to final_conda_bert_g_model
Best model saved
                                                                                                                       10/09/2021 11:13:29 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 599/815 [02:57<00:49,  4.33it/s]
10/09/2021 11:13:29 - INFO - trainer -     Num examples = 8705
10/09/2021 11:13:29 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:18<00:00,  7.33it/s]
10/09/2021 11:13:48 - INFO - trainer -   ***** Eval results *****
10/09/2021 11:13:48 - INFO - trainer -     T-F1 = 0.980587544065805█████████████████▌| 136/137 [00:18<00:00,  7.21it/s]
10/09/2021 11:13:48 - INFO - trainer -     T-F1(C) = 0.9694323144104803
10/09/2021 11:13:48 - INFO - trainer -     T-F1(D) = 0.8778625954198473
10/09/2021 11:13:48 - INFO - trainer -     T-F1(O) = 0.9900974411788007
10/09/2021 11:13:48 - INFO - trainer -     T-F1(P) = 0.9982101764254666
10/09/2021 11:13:48 - INFO - trainer -     T-F1(S) = 0.9863677673432293
10/09/2021 11:13:48 - INFO - trainer -     T-F1(T) = 0.9597761455054216
10/09/2021 11:13:48 - INFO - trainer -     U-F1(A) = 0.8067226890756303
10/09/2021 11:13:48 - INFO - trainer -     U-F1(E) = 0.8648648648648648
10/09/2021 11:13:48 - INFO - trainer -     U-F1(I) = 0.7224489795918367
10/09/2021 11:13:48 - INFO - trainer -     U-F1(O) = 0.9507183686080642
10/09/2021 11:13:48 - INFO - trainer -     intent_acc = 0.9167145318782309
10/09/2021 11:13:48 - INFO - trainer -     loss = 0.3432292467540633
10/09/2021 11:13:48 - INFO - trainer -     semantic_frame_acc = 0.8812176909821942
10/09/2021 11:13:48 - INFO - trainer -     slot_f1 = 0.9847766767198047
10/09/2021 11:13:48 - INFO - trainer -     slot_precision = 0.9904665607395637
10/09/2021 11:13:48 - INFO - trainer -     slot_recall = 0.9791517920891046

10/09/2021 11:13:48 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 11:13:48 - INFO - trainer -     T-F1 = 0.980587544065805
10/09/2021 11:13:48 - INFO - trainer -     T-F1(C) = 0.9694323144104803
10/09/2021 11:13:48 - INFO - trainer -     T-F1(D) = 0.8778625954198473
10/09/2021 11:13:48 - INFO - trainer -     T-F1(O) = 0.9900974411788007
10/09/2021 11:13:48 - INFO - trainer -     T-F1(P) = 0.9982101764254666
10/09/2021 11:13:48 - INFO - trainer -     T-F1(S) = 0.9863677673432293
10/09/2021 11:13:48 - INFO - trainer -     T-F1(T) = 0.9597761455054216
10/09/2021 11:13:48 - INFO - trainer -     U-F1(A) = 0.8067226890756303
10/09/2021 11:13:48 - INFO - trainer -     U-F1(E) = 0.8648648648648648
10/09/2021 11:13:48 - INFO - trainer -     U-F1(I) = 0.7224489795918367
10/09/2021 11:13:48 - INFO - trainer -     U-F1(O) = 0.9507183686080642
10/09/2021 11:13:48 - INFO - trainer -     intent_acc = 0.9167145318782309
10/09/2021 11:13:48 - INFO - trainer -     semantic_frame_acc = 0.8812176909821942
10/09/2021 11:13:48 - INFO - trainer -     slot_f1 = 0.9847766767198047
10/09/2021 11:13:48 - INFO - trainer -     slot_precision = 0.9904665607395637
10/09/2021 11:13:48 - INFO - trainer -     slot_recall = 0.9791517920891046
10/09/2021 11:13:48 - INFO - transformers.configuration_utils -   Configuration saved in final_conda_bert_g_model\config.json
10/09/2021 11:13:49 - INFO - transformers.modeling_utils -   Model weights saved in final_conda_bert_g_model\pytorch_model.bin
10/09/2021 11:13:49 - INFO - trainer -   Saving model checkpoint to final_conda_bert_g_model
Best model saved
                                                                                                                       10/09/2021 11:14:35 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 799/815 [04:04<00:03,  4.32it/s]
10/09/2021 11:14:35 - INFO - trainer -     Num examples = 8705
10/09/2021 11:14:35 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:18<00:00,  7.28it/s]
10/09/2021 11:14:55 - INFO - trainer -   ***** Eval results *****
10/09/2021 11:14:55 - INFO - trainer -     T-F1 = 0.9818181818181818████████████████▌| 136/137 [00:18<00:00,  7.15it/s]
10/09/2021 11:14:55 - INFO - trainer -     T-F1(C) = 0.966887417218543
10/09/2021 11:14:55 - INFO - trainer -     T-F1(D) = 0.9018087855297157
10/09/2021 11:14:55 - INFO - trainer -     T-F1(O) = 0.9910861145009816
10/09/2021 11:14:55 - INFO - trainer -     T-F1(P) = 0.9985949674287904
10/09/2021 11:14:55 - INFO - trainer -     T-F1(S) = 0.9899111579581388
10/09/2021 11:14:55 - INFO - trainer -     T-F1(T) = 0.9563106796116505
10/09/2021 11:14:55 - INFO - trainer -     U-F1(A) = 0.7976291278577476
10/09/2021 11:14:55 - INFO - trainer -     U-F1(E) = 0.8659528907922912
10/09/2021 11:14:55 - INFO - trainer -     U-F1(I) = 0.7494824016563147
10/09/2021 11:14:55 - INFO - trainer -     U-F1(O) = 0.9529702970297029
10/09/2021 11:14:55 - INFO - trainer -     intent_acc = 0.9194715680643308
10/09/2021 11:14:55 - INFO - trainer -     loss = 0.32474538425568245
10/09/2021 11:14:55 - INFO - trainer -     semantic_frame_acc = 0.8863871338311315
10/09/2021 11:14:55 - INFO - trainer -     slot_f1 = 0.9854710313068932
10/09/2021 11:14:55 - INFO - trainer -     slot_precision = 0.9854358535018205
10/09/2021 11:14:55 - INFO - trainer -     slot_recall = 0.9855062116235899

10/09/2021 11:14:55 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 11:14:55 - INFO - trainer -     T-F1 = 0.9818181818181818
10/09/2021 11:14:55 - INFO - trainer -     T-F1(C) = 0.966887417218543
10/09/2021 11:14:55 - INFO - trainer -     T-F1(D) = 0.9018087855297157
10/09/2021 11:14:55 - INFO - trainer -     T-F1(O) = 0.9910861145009816
10/09/2021 11:14:55 - INFO - trainer -     T-F1(P) = 0.9985949674287904
10/09/2021 11:14:55 - INFO - trainer -     T-F1(S) = 0.9899111579581388
10/09/2021 11:14:55 - INFO - trainer -     T-F1(T) = 0.9563106796116505
10/09/2021 11:14:55 - INFO - trainer -     U-F1(A) = 0.7976291278577476
10/09/2021 11:14:55 - INFO - trainer -     U-F1(E) = 0.8659528907922912
10/09/2021 11:14:55 - INFO - trainer -     U-F1(I) = 0.7494824016563147
10/09/2021 11:14:55 - INFO - trainer -     U-F1(O) = 0.9529702970297029
10/09/2021 11:14:55 - INFO - trainer -     intent_acc = 0.9194715680643308
10/09/2021 11:14:55 - INFO - trainer -     semantic_frame_acc = 0.8863871338311315
10/09/2021 11:14:55 - INFO - trainer -     slot_f1 = 0.9854710313068932
10/09/2021 11:14:55 - INFO - trainer -     slot_precision = 0.9854358535018205
10/09/2021 11:14:55 - INFO - trainer -     slot_recall = 0.9855062116235899
10/09/2021 11:14:55 - INFO - transformers.configuration_utils -   Configuration saved in final_conda_bert_g_model\config.json
10/09/2021 11:14:56 - INFO - transformers.modeling_utils -   Model weights saved in final_conda_bert_g_model\pytorch_model.bin
10/09/2021 11:14:56 - INFO - trainer -   Saving model checkpoint to final_conda_bert_g_model
Best model saved
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 815/815 [04:28<00:00,  3.03it/s]
Epoch:   5%|███▋                                                                     | 1/20 [04:28<1:25:07, 268.80s/it]10/09/2021 11:15:43 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 184/815 [00:43<02:27,  4.29it/s]
10/09/2021 11:15:43 - INFO - trainer -     Num examples = 8705
10/09/2021 11:15:43 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:18<00:00,  7.26it/s]
10/09/2021 11:16:03 - INFO - trainer -   ***** Eval results *****
10/09/2021 11:16:03 - INFO - trainer -     T-F1 = 0.9842394852186889████████████████▌| 136/137 [00:18<00:00,  7.11it/s]
10/09/2021 11:16:03 - INFO - trainer -     T-F1(C) = 0.9749235474006116
10/09/2021 11:16:03 - INFO - trainer -     T-F1(D) = 0.9178255372945638
10/09/2021 11:16:03 - INFO - trainer -     T-F1(O) = 0.9918298052947105
10/09/2021 11:16:03 - INFO - trainer -     T-F1(P) = 0.9978263649149726
10/09/2021 11:16:03 - INFO - trainer -     T-F1(S) = 0.9881363568103317
10/09/2021 11:16:03 - INFO - trainer -     T-F1(T) = 0.9672977624784854
10/09/2021 11:16:03 - INFO - trainer -     U-F1(A) = 0.797274275979557
10/09/2021 11:16:03 - INFO - trainer -     U-F1(E) = 0.855683269476373
10/09/2021 11:16:03 - INFO - trainer -     U-F1(I) = 0.7167113494191242
10/09/2021 11:16:03 - INFO - trainer -     U-F1(O) = 0.9494047619047619
10/09/2021 11:16:03 - INFO - trainer -     intent_acc = 0.9115450890292935
10/09/2021 11:16:03 - INFO - trainer -     loss = 0.332739953685851
10/09/2021 11:16:03 - INFO - trainer -     semantic_frame_acc = 0.8816771970132108
10/09/2021 11:16:03 - INFO - trainer -     slot_f1 = 0.9876120095676698
10/09/2021 11:16:03 - INFO - trainer -     slot_precision = 0.9876472688325598
10/09/2021 11:16:03 - INFO - trainer -     slot_recall = 0.98757675282022

10/09/2021 11:16:03 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 11:16:03 - INFO - trainer -     T-F1 = 0.9818181818181818
10/09/2021 11:16:03 - INFO - trainer -     T-F1(C) = 0.966887417218543
10/09/2021 11:16:03 - INFO - trainer -     T-F1(D) = 0.9018087855297157
10/09/2021 11:16:03 - INFO - trainer -     T-F1(O) = 0.9910861145009816
10/09/2021 11:16:03 - INFO - trainer -     T-F1(P) = 0.9985949674287904
10/09/2021 11:16:03 - INFO - trainer -     T-F1(S) = 0.9899111579581388
10/09/2021 11:16:03 - INFO - trainer -     T-F1(T) = 0.9563106796116505
10/09/2021 11:16:03 - INFO - trainer -     U-F1(A) = 0.7976291278577476
10/09/2021 11:16:03 - INFO - trainer -     U-F1(E) = 0.8659528907922912
10/09/2021 11:16:03 - INFO - trainer -     U-F1(I) = 0.7494824016563147
10/09/2021 11:16:03 - INFO - trainer -     U-F1(O) = 0.9529702970297029
10/09/2021 11:16:03 - INFO - trainer -     intent_acc = 0.9194715680643308
10/09/2021 11:16:03 - INFO - trainer -     semantic_frame_acc = 0.8863871338311315
10/09/2021 11:16:03 - INFO - trainer -     slot_f1 = 0.9854710313068932
10/09/2021 11:16:03 - INFO - trainer -     slot_precision = 0.9854358535018205
10/09/2021 11:16:03 - INFO - trainer -     slot_recall = 0.9855062116235899
                                                                                                                       10/09/2021 11:16:49 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 384/815 [01:49<01:40,  4.30it/s]
10/09/2021 11:16:49 - INFO - trainer -     Num examples = 8705
10/09/2021 11:16:49 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:18<00:00,  7.25it/s]
10/09/2021 11:17:09 - INFO - trainer -   ***** Eval results *****
10/09/2021 11:17:09 - INFO - trainer -     T-F1 = 0.9880138589755595████████████████▌| 136/137 [00:18<00:00,  7.14it/s]
10/09/2021 11:17:09 - INFO - trainer -     T-F1(C) = 0.9762711864406781
10/09/2021 11:17:09 - INFO - trainer -     T-F1(D) = 0.9335038363171354
10/09/2021 11:17:09 - INFO - trainer -     T-F1(O) = 0.993701370878103
10/09/2021 11:17:09 - INFO - trainer -     T-F1(P) = 0.9984670413898824
10/09/2021 11:17:09 - INFO - trainer -     T-F1(S) = 0.9930534581697372
10/09/2021 11:17:09 - INFO - trainer -     T-F1(T) = 0.9760499826449149
10/09/2021 11:17:09 - INFO - trainer -     U-F1(A) = 0.7996560619088564
10/09/2021 11:17:09 - INFO - trainer -     U-F1(E) = 0.8706860706860706
10/09/2021 11:17:09 - INFO - trainer -     U-F1(I) = 0.7541322314049587
10/09/2021 11:17:09 - INFO - trainer -     U-F1(O) = 0.9521516234270622
10/09/2021 11:17:09 - INFO - trainer -     intent_acc = 0.9197013210798392
10/09/2021 11:17:09 - INFO - trainer -     loss = 0.31572190685755147
10/09/2021 11:17:09 - INFO - trainer -     semantic_frame_acc = 0.8967260195290063
10/09/2021 11:17:09 - INFO - trainer -     slot_f1 = 0.9905471211687196
10/09/2021 11:17:09 - INFO - trainer -     slot_precision = 0.9935354115787961
10/09/2021 11:17:09 - INFO - trainer -     slot_recall = 0.98757675282022

10/09/2021 11:17:09 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 11:17:09 - INFO - trainer -     T-F1 = 0.9880138589755595
10/09/2021 11:17:09 - INFO - trainer -     T-F1(C) = 0.9762711864406781
10/09/2021 11:17:09 - INFO - trainer -     T-F1(D) = 0.9335038363171354
10/09/2021 11:17:09 - INFO - trainer -     T-F1(O) = 0.993701370878103
10/09/2021 11:17:09 - INFO - trainer -     T-F1(P) = 0.9984670413898824
10/09/2021 11:17:09 - INFO - trainer -     T-F1(S) = 0.9930534581697372
10/09/2021 11:17:09 - INFO - trainer -     T-F1(T) = 0.9760499826449149
10/09/2021 11:17:09 - INFO - trainer -     U-F1(A) = 0.7996560619088564
10/09/2021 11:17:09 - INFO - trainer -     U-F1(E) = 0.8706860706860706
10/09/2021 11:17:09 - INFO - trainer -     U-F1(I) = 0.7541322314049587
10/09/2021 11:17:09 - INFO - trainer -     U-F1(O) = 0.9521516234270622
10/09/2021 11:17:09 - INFO - trainer -     intent_acc = 0.9197013210798392
10/09/2021 11:17:09 - INFO - trainer -     semantic_frame_acc = 0.8967260195290063
10/09/2021 11:17:09 - INFO - trainer -     slot_f1 = 0.9905471211687196
10/09/2021 11:17:09 - INFO - trainer -     slot_precision = 0.9935354115787961
10/09/2021 11:17:09 - INFO - trainer -     slot_recall = 0.98757675282022
10/09/2021 11:17:09 - INFO - transformers.configuration_utils -   Configuration saved in final_conda_bert_g_model\config.json
10/09/2021 11:17:10 - INFO - transformers.modeling_utils -   Model weights saved in final_conda_bert_g_model\pytorch_model.bin
10/09/2021 11:17:10 - INFO - trainer -   Saving model checkpoint to final_conda_bert_g_model
Best model saved
                                                                                                                       10/09/2021 11:17:56 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 584/815 [02:56<00:53,  4.30it/s]
10/09/2021 11:17:56 - INFO - trainer -     Num examples = 8705
10/09/2021 11:17:56 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:18<00:00,  7.26it/s]
10/09/2021 11:18:16 - INFO - trainer -   ***** Eval results *****
10/09/2021 11:18:16 - INFO - trainer -     T-F1 = 0.9862809840487374████████████████▌| 136/137 [00:18<00:00,  7.10it/s]
10/09/2021 11:18:16 - INFO - trainer -     T-F1(C) = 0.9742658189524673
10/09/2021 11:18:16 - INFO - trainer -     T-F1(D) = 0.9262899262899263
10/09/2021 11:18:16 - INFO - trainer -     T-F1(O) = 0.992747270263808
10/09/2021 11:18:16 - INFO - trainer -     T-F1(P) = 0.9983395069612977
10/09/2021 11:18:16 - INFO - trainer -     T-F1(S) = 0.9936632468316234
10/09/2021 11:18:16 - INFO - trainer -     T-F1(T) = 0.9675657220894502
10/09/2021 11:18:16 - INFO - trainer -     U-F1(A) = 0.812720848056537
10/09/2021 11:18:16 - INFO - trainer -     U-F1(E) = 0.8666389696717905
10/09/2021 11:18:16 - INFO - trainer -     U-F1(I) = 0.7517039922103212
10/09/2021 11:18:16 - INFO - trainer -     U-F1(O) = 0.9529741513547181
10/09/2021 11:18:16 - INFO - trainer -     intent_acc = 0.9200459506031017
10/09/2021 11:18:16 - INFO - trainer -     loss = 0.32379838400078514
10/09/2021 11:18:16 - INFO - trainer -     semantic_frame_acc = 0.893049971280873
10/09/2021 11:18:16 - INFO - trainer -     slot_f1 = 0.9890603285464846
10/09/2021 11:18:16 - INFO - trainer -     slot_precision = 0.9872661307533613
10/09/2021 11:18:16 - INFO - trainer -     slot_recall = 0.9908610595459089

10/09/2021 11:18:16 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 11:18:16 - INFO - trainer -     T-F1 = 0.9880138589755595
10/09/2021 11:18:16 - INFO - trainer -     T-F1(C) = 0.9762711864406781
10/09/2021 11:18:16 - INFO - trainer -     T-F1(D) = 0.9335038363171354
10/09/2021 11:18:16 - INFO - trainer -     T-F1(O) = 0.993701370878103
10/09/2021 11:18:16 - INFO - trainer -     T-F1(P) = 0.9984670413898824
10/09/2021 11:18:16 - INFO - trainer -     T-F1(S) = 0.9930534581697372
10/09/2021 11:18:16 - INFO - trainer -     T-F1(T) = 0.9760499826449149
10/09/2021 11:18:16 - INFO - trainer -     U-F1(A) = 0.7996560619088564
10/09/2021 11:18:16 - INFO - trainer -     U-F1(E) = 0.8706860706860706
10/09/2021 11:18:16 - INFO - trainer -     U-F1(I) = 0.7541322314049587
10/09/2021 11:18:16 - INFO - trainer -     U-F1(O) = 0.9521516234270622
10/09/2021 11:18:16 - INFO - trainer -     intent_acc = 0.9197013210798392
10/09/2021 11:18:16 - INFO - trainer -     semantic_frame_acc = 0.8967260195290063
10/09/2021 11:18:16 - INFO - trainer -     slot_f1 = 0.9905471211687196
10/09/2021 11:18:16 - INFO - trainer -     slot_precision = 0.9935354115787961
10/09/2021 11:18:16 - INFO - trainer -     slot_recall = 0.98757675282022
                                                                                                                       10/09/2021 11:19:03 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 784/815 [04:03<00:07,  4.29it/s]
10/09/2021 11:19:03 - INFO - trainer -     Num examples = 8705
10/09/2021 11:19:03 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.21it/s]
10/09/2021 11:19:23 - INFO - trainer -   ***** Eval results *****
10/09/2021 11:19:23 - INFO - trainer -     T-F1 = 0.984868941757065█████████████████▌| 136/137 [00:18<00:00,  7.09it/s]
10/09/2021 11:19:23 - INFO - trainer -     T-F1(C) = 0.9652462979752191
10/09/2021 11:19:23 - INFO - trainer -     T-F1(D) = 0.9284818067754078
10/09/2021 11:19:23 - INFO - trainer -     T-F1(O) = 0.9927518916766228
10/09/2021 11:19:23 - INFO - trainer -     T-F1(P) = 0.9983390826625782
10/09/2021 11:19:23 - INFO - trainer -     T-F1(S) = 0.9926126941052315
10/09/2021 11:19:23 - INFO - trainer -     T-F1(T) = 0.9687607277720564
10/09/2021 11:19:23 - INFO - trainer -     U-F1(A) = 0.8051724137931036
10/09/2021 11:19:23 - INFO - trainer -     U-F1(E) = 0.8779045204900718
10/09/2021 11:19:23 - INFO - trainer -     U-F1(I) = 0.7442326980942828
10/09/2021 11:19:23 - INFO - trainer -     U-F1(O) = 0.954834704330281
10/09/2021 11:19:23 - INFO - trainer -     intent_acc = 0.922343480758185
10/09/2021 11:19:23 - INFO - trainer -     loss = 0.3094543239550434
10/09/2021 11:19:23 - INFO - trainer -     semantic_frame_acc = 0.8948879954049397
10/09/2021 11:19:23 - INFO - trainer -     slot_f1 = 0.9880179730404393
10/09/2021 11:19:23 - INFO - trainer -     slot_precision = 0.9869620974636648
10/09/2021 11:19:23 - INFO - trainer -     slot_recall = 0.9890761102384692

10/09/2021 11:19:23 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 11:19:23 - INFO - trainer -     T-F1 = 0.9880138589755595
10/09/2021 11:19:23 - INFO - trainer -     T-F1(C) = 0.9762711864406781
10/09/2021 11:19:23 - INFO - trainer -     T-F1(D) = 0.9335038363171354
10/09/2021 11:19:23 - INFO - trainer -     T-F1(O) = 0.993701370878103
10/09/2021 11:19:23 - INFO - trainer -     T-F1(P) = 0.9984670413898824
10/09/2021 11:19:23 - INFO - trainer -     T-F1(S) = 0.9930534581697372
10/09/2021 11:19:23 - INFO - trainer -     T-F1(T) = 0.9760499826449149
10/09/2021 11:19:23 - INFO - trainer -     U-F1(A) = 0.7996560619088564
10/09/2021 11:19:23 - INFO - trainer -     U-F1(E) = 0.8706860706860706
10/09/2021 11:19:23 - INFO - trainer -     U-F1(I) = 0.7541322314049587
10/09/2021 11:19:23 - INFO - trainer -     U-F1(O) = 0.9521516234270622
10/09/2021 11:19:23 - INFO - trainer -     intent_acc = 0.9197013210798392
10/09/2021 11:19:23 - INFO - trainer -     semantic_frame_acc = 0.8967260195290063
10/09/2021 11:19:23 - INFO - trainer -     slot_f1 = 0.9905471211687196
10/09/2021 11:19:23 - INFO - trainer -     slot_precision = 0.9935354115787961
10/09/2021 11:19:23 - INFO - trainer -     slot_recall = 0.98757675282022
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 815/815 [04:30<00:00,  3.01it/s]
Epoch:  10%|███████▎                                                                 | 2/20 [08:59<1:20:56, 269.82s/it]10/09/2021 11:20:10 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 169/815 [00:39<02:32,  4.23it/s]
10/09/2021 11:20:10 - INFO - trainer -     Num examples = 8705
10/09/2021 11:20:10 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:18<00:00,  7.22it/s]
10/09/2021 11:20:30 - INFO - trainer -   ***** Eval results *****
10/09/2021 11:20:30 - INFO - trainer -     T-F1 = 0.9863013698630136████████████████▌| 136/137 [00:18<00:00,  7.11it/s]
10/09/2021 11:20:30 - INFO - trainer -     T-F1(C) = 0.9780085522296884
10/09/2021 11:20:30 - INFO - trainer -     T-F1(D) = 0.9263420724094882
10/09/2021 11:20:30 - INFO - trainer -     T-F1(O) = 0.9929940024414841
10/09/2021 11:20:30 - INFO - trainer -     T-F1(P) = 0.9978269206186886
10/09/2021 11:20:30 - INFO - trainer -     T-F1(S) = 0.9936632468316234
10/09/2021 11:20:30 - INFO - trainer -     T-F1(T) = 0.9645776566757492
10/09/2021 11:20:30 - INFO - trainer -     U-F1(A) = 0.7965957446808509
10/09/2021 11:20:30 - INFO - trainer -     U-F1(E) = 0.8667820069204152
10/09/2021 11:20:30 - INFO - trainer -     U-F1(I) = 0.7492323439099283
10/09/2021 11:20:30 - INFO - trainer -     U-F1(O) = 0.9525722230804882
10/09/2021 11:20:30 - INFO - trainer -     intent_acc = 0.9192418150488225
10/09/2021 11:20:30 - INFO - trainer -     loss = 0.3330563931950252
10/09/2021 11:20:30 - INFO - trainer -     semantic_frame_acc = 0.8943136128661688
10/09/2021 11:20:30 - INFO - trainer -     slot_f1 = 0.9890078515346182
10/09/2021 11:20:30 - INFO - trainer -     slot_precision = 0.9887255601541316
10/09/2021 11:20:30 - INFO - trainer -     slot_recall = 0.989290304155362

10/09/2021 11:20:30 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 11:20:30 - INFO - trainer -     T-F1 = 0.9880138589755595
10/09/2021 11:20:30 - INFO - trainer -     T-F1(C) = 0.9762711864406781
10/09/2021 11:20:30 - INFO - trainer -     T-F1(D) = 0.9335038363171354
10/09/2021 11:20:30 - INFO - trainer -     T-F1(O) = 0.993701370878103
10/09/2021 11:20:30 - INFO - trainer -     T-F1(P) = 0.9984670413898824
10/09/2021 11:20:30 - INFO - trainer -     T-F1(S) = 0.9930534581697372
10/09/2021 11:20:30 - INFO - trainer -     T-F1(T) = 0.9760499826449149
10/09/2021 11:20:30 - INFO - trainer -     U-F1(A) = 0.7996560619088564
10/09/2021 11:20:30 - INFO - trainer -     U-F1(E) = 0.8706860706860706
10/09/2021 11:20:30 - INFO - trainer -     U-F1(I) = 0.7541322314049587
10/09/2021 11:20:30 - INFO - trainer -     U-F1(O) = 0.9521516234270622
10/09/2021 11:20:30 - INFO - trainer -     intent_acc = 0.9197013210798392
10/09/2021 11:20:30 - INFO - trainer -     semantic_frame_acc = 0.8967260195290063
10/09/2021 11:20:30 - INFO - trainer -     slot_f1 = 0.9905471211687196
10/09/2021 11:20:30 - INFO - trainer -     slot_precision = 0.9935354115787961
10/09/2021 11:20:30 - INFO - trainer -     slot_recall = 0.98757675282022
                                                                                                                       10/09/2021 11:21:17 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 369/815 [01:46<01:44,  4.25it/s]
10/09/2021 11:21:17 - INFO - trainer -     Num examples = 8705
10/09/2021 11:21:17 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:56<00:00,  2.42it/s]
10/09/2021 11:22:14 - INFO - trainer -   ***** Eval results *****
10/09/2021 11:22:14 - INFO - trainer -     T-F1 = 0.986911360566398█████████████████▌| 136/137 [00:56<00:00,  2.99it/s]
10/09/2021 11:22:14 - INFO - trainer -     T-F1(C) = 0.9768433881779403
10/09/2021 11:22:14 - INFO - trainer -     T-F1(D) = 0.9333333333333333
10/09/2021 11:22:14 - INFO - trainer -     T-F1(O) = 0.9932315859323159
10/09/2021 11:22:14 - INFO - trainer -     T-F1(P) = 0.9980825770164897
10/09/2021 11:22:14 - INFO - trainer -     T-F1(S) = 0.9933634992458521
10/09/2021 11:22:14 - INFO - trainer -     T-F1(T) = 0.9685362517099864
10/09/2021 11:22:14 - INFO - trainer -     U-F1(A) = 0.7986688851913477
10/09/2021 11:22:14 - INFO - trainer -     U-F1(E) = 0.8701964133219471
10/09/2021 11:22:14 - INFO - trainer -     U-F1(I) = 0.736842105263158
10/09/2021 11:22:14 - INFO - trainer -     U-F1(O) = 0.9520387439462584
10/09/2021 11:22:14 - INFO - trainer -     intent_acc = 0.9172889144170018
10/09/2021 11:22:14 - INFO - trainer -     loss = 0.33614224663181025
10/09/2021 11:22:14 - INFO - trainer -     semantic_frame_acc = 0.8928202182653647
10/09/2021 11:22:14 - INFO - trainer -     slot_f1 = 0.9896554184204893
10/09/2021 11:22:14 - INFO - trainer -     slot_precision = 0.9888793840889649
10/09/2021 11:22:14 - INFO - trainer -     slot_recall = 0.9904326717121233

10/09/2021 11:22:14 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 11:22:14 - INFO - trainer -     T-F1 = 0.9880138589755595
10/09/2021 11:22:14 - INFO - trainer -     T-F1(C) = 0.9762711864406781
10/09/2021 11:22:14 - INFO - trainer -     T-F1(D) = 0.9335038363171354
10/09/2021 11:22:14 - INFO - trainer -     T-F1(O) = 0.993701370878103
10/09/2021 11:22:14 - INFO - trainer -     T-F1(P) = 0.9984670413898824
10/09/2021 11:22:14 - INFO - trainer -     T-F1(S) = 0.9930534581697372
10/09/2021 11:22:14 - INFO - trainer -     T-F1(T) = 0.9760499826449149
10/09/2021 11:22:14 - INFO - trainer -     U-F1(A) = 0.7996560619088564
10/09/2021 11:22:14 - INFO - trainer -     U-F1(E) = 0.8706860706860706
10/09/2021 11:22:14 - INFO - trainer -     U-F1(I) = 0.7541322314049587
10/09/2021 11:22:14 - INFO - trainer -     U-F1(O) = 0.9521516234270622
10/09/2021 11:22:14 - INFO - trainer -     intent_acc = 0.9197013210798392
10/09/2021 11:22:14 - INFO - trainer -     semantic_frame_acc = 0.8967260195290063
10/09/2021 11:22:14 - INFO - trainer -     slot_f1 = 0.9905471211687196
10/09/2021 11:22:14 - INFO - trainer -     slot_precision = 0.9935354115787961
10/09/2021 11:22:14 - INFO - trainer -     slot_recall = 0.98757675282022
                                                                                                                       10/09/2021 11:23:51 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 569/815 [04:20<01:50,  2.23it/s]
10/09/2021 11:23:51 - INFO - trainer -     Num examples = 8705
10/09/2021 11:23:51 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:42<00:00,  3.26it/s]
10/09/2021 11:24:34 - INFO - trainer -   ***** Eval results *****
10/09/2021 11:24:34 - INFO - trainer -     T-F1 = 0.9878663431024827████████████████▌| 136/137 [00:42<00:00,  3.24it/s]
10/09/2021 11:24:34 - INFO - trainer -     T-F1(C) = 0.9768151311775473
10/09/2021 11:24:34 - INFO - trainer -     T-F1(D) = 0.925925925925926
10/09/2021 11:24:34 - INFO - trainer -     T-F1(O) = 0.9937957365574291
10/09/2021 11:24:34 - INFO - trainer -     T-F1(P) = 0.9983386581469648
10/09/2021 11:24:34 - INFO - trainer -     T-F1(S) = 0.9938131884714049
10/09/2021 11:24:34 - INFO - trainer -     T-F1(T) = 0.9757617728531857
10/09/2021 11:24:34 - INFO - trainer -     U-F1(A) = 0.7955326460481099
10/09/2021 11:24:34 - INFO - trainer -     U-F1(E) = 0.8584324989741485
10/09/2021 11:24:34 - INFO - trainer -     U-F1(I) = 0.7330232558139534
10/09/2021 11:24:34 - INFO - trainer -     U-F1(O) = 0.9480131930265432
10/09/2021 11:24:34 - INFO - trainer -     intent_acc = 0.9120045950603102
10/09/2021 11:24:34 - INFO - trainer -     loss = 0.3383053745258681
10/09/2021 11:24:34 - INFO - trainer -     semantic_frame_acc = 0.8893739230327398
10/09/2021 11:24:34 - INFO - trainer -     slot_f1 = 0.9903904547565463
10/09/2021 11:24:34 - INFO - trainer -     slot_precision = 0.9910631300493316
10/09/2021 11:24:34 - INFO - trainer -     slot_recall = 0.9897186919891475

10/09/2021 11:24:34 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 11:24:34 - INFO - trainer -     T-F1 = 0.9880138589755595
10/09/2021 11:24:34 - INFO - trainer -     T-F1(C) = 0.9762711864406781
10/09/2021 11:24:34 - INFO - trainer -     T-F1(D) = 0.9335038363171354
10/09/2021 11:24:34 - INFO - trainer -     T-F1(O) = 0.993701370878103
10/09/2021 11:24:34 - INFO - trainer -     T-F1(P) = 0.9984670413898824
10/09/2021 11:24:34 - INFO - trainer -     T-F1(S) = 0.9930534581697372
10/09/2021 11:24:34 - INFO - trainer -     T-F1(T) = 0.9760499826449149
10/09/2021 11:24:34 - INFO - trainer -     U-F1(A) = 0.7996560619088564
10/09/2021 11:24:34 - INFO - trainer -     U-F1(E) = 0.8706860706860706
10/09/2021 11:24:34 - INFO - trainer -     U-F1(I) = 0.7541322314049587
10/09/2021 11:24:34 - INFO - trainer -     U-F1(O) = 0.9521516234270622
10/09/2021 11:24:34 - INFO - trainer -     intent_acc = 0.9197013210798392
10/09/2021 11:24:34 - INFO - trainer -     semantic_frame_acc = 0.8967260195290063
10/09/2021 11:24:34 - INFO - trainer -     slot_f1 = 0.9905471211687196
10/09/2021 11:24:34 - INFO - trainer -     slot_precision = 0.9935354115787961
10/09/2021 11:24:34 - INFO - trainer -     slot_recall = 0.98757675282022
                                                                                                                       10/09/2021 11:26:07 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 769/815 [06:36<00:20,  2.29it/s]
10/09/2021 11:26:07 - INFO - trainer -     Num examples = 8705
10/09/2021 11:26:07 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:41<00:00,  3.26it/s]
10/09/2021 11:26:50 - INFO - trainer -   ***** Eval results *****
10/09/2021 11:26:50 - INFO - trainer -     T-F1 = 0.9891075686036183████████████████▌| 136/137 [00:41<00:00,  3.23it/s]
10/09/2021 11:26:50 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 11:26:50 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 11:26:50 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 11:26:50 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 11:26:50 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 11:26:50 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 11:26:50 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 11:26:50 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 11:26:50 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 11:26:50 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 11:26:50 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 11:26:50 - INFO - trainer -     loss = 0.33018099312351024
10/09/2021 11:26:50 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 11:26:50 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 11:26:50 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 11:26:50 - INFO - trainer -     slot_recall = 0.9896472940168499

10/09/2021 11:26:50 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 11:26:50 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 11:26:50 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 11:26:50 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 11:26:50 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 11:26:50 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 11:26:50 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 11:26:50 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 11:26:50 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 11:26:50 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 11:26:50 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 11:26:50 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 11:26:50 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 11:26:50 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 11:26:50 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 11:26:50 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 11:26:50 - INFO - trainer -     slot_recall = 0.9896472940168499
10/09/2021 11:26:50 - INFO - transformers.configuration_utils -   Configuration saved in final_conda_bert_g_model\config.json
10/09/2021 11:26:51 - INFO - transformers.modeling_utils -   Model weights saved in final_conda_bert_g_model\pytorch_model.bin
10/09/2021 11:26:51 - INFO - trainer -   Saving model checkpoint to final_conda_bert_g_model
Best model saved
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 815/815 [07:41<00:00,  1.77it/s]
Epoch:  15%|██████████▉                                                              | 3/20 [16:40<1:41:11, 357.14s/it]10/09/2021 11:28:19 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 154/815 [01:07<04:50,  2.27it/s]
10/09/2021 11:28:19 - INFO - trainer -     Num examples = 8705
10/09/2021 11:28:19 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:41<00:00,  3.34it/s]
10/09/2021 11:29:01 - INFO - trainer -   ***** Eval results *****
10/09/2021 11:29:01 - INFO - trainer -     T-F1 = 0.9880819366852887████████████████▌| 136/137 [00:41<00:00,  3.32it/s]
10/09/2021 11:29:01 - INFO - trainer -     T-F1(C) = 0.9822303921568628
10/09/2021 11:29:01 - INFO - trainer -     T-F1(D) = 0.9277845777233782
10/09/2021 11:29:01 - INFO - trainer -     T-F1(O) = 0.993893372982158
10/09/2021 11:29:01 - INFO - trainer -     T-F1(P) = 0.9984674329501916
10/09/2021 11:29:01 - INFO - trainer -     T-F1(S) = 0.9930681133212779
10/09/2021 11:29:01 - INFO - trainer -     T-F1(T) = 0.9723832253665189
10/09/2021 11:29:01 - INFO - trainer -     U-F1(A) = 0.7968056787932565
10/09/2021 11:29:01 - INFO - trainer -     U-F1(E) = 0.8512053200332502
10/09/2021 11:29:01 - INFO - trainer -     U-F1(I) = 0.7271028037383177
10/09/2021 11:29:01 - INFO - trainer -     U-F1(O) = 0.9480752713359881
10/09/2021 11:29:01 - INFO - trainer -     intent_acc = 0.9113153360137852
10/09/2021 11:29:01 - INFO - trainer -     loss = 0.3595049301447877
10/09/2021 11:29:01 - INFO - trainer -     semantic_frame_acc = 0.8899483055715106
10/09/2021 11:29:01 - INFO - trainer -     slot_f1 = 0.9905135520684737
10/09/2021 11:29:01 - INFO - trainer -     slot_precision = 0.9895254382214622
10/09/2021 11:29:01 - INFO - trainer -     slot_recall = 0.9915036412965872

10/09/2021 11:29:01 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 11:29:01 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 11:29:01 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 11:29:01 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 11:29:01 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 11:29:01 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 11:29:01 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 11:29:01 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 11:29:01 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 11:29:01 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 11:29:01 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 11:29:01 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 11:29:01 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 11:29:01 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 11:29:01 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 11:29:01 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 11:29:01 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 11:30:28 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 354/815 [03:16<03:19,  2.32it/s]
10/09/2021 11:30:28 - INFO - trainer -     Num examples = 8705
10/09/2021 11:30:28 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:41<00:00,  3.34it/s]
10/09/2021 11:31:10 - INFO - trainer -   ***** Eval results *****
10/09/2021 11:31:10 - INFO - trainer -     T-F1 = 0.989775433026752█████████████████▌| 136/137 [00:41<00:00,  3.27it/s]
10/09/2021 11:31:10 - INFO - trainer -     T-F1(C) = 0.9822412737293326
10/09/2021 11:31:10 - INFO - trainer -     T-F1(D) = 0.9523809523809523
10/09/2021 11:31:10 - INFO - trainer -     T-F1(O) = 0.9945659377070907
10/09/2021 11:31:10 - INFO - trainer -     T-F1(P) = 0.9985956849227627
10/09/2021 11:31:10 - INFO - trainer -     T-F1(S) = 0.992764546276756
10/09/2021 11:31:10 - INFO - trainer -     T-F1(T) = 0.9778393351800554
10/09/2021 11:31:10 - INFO - trainer -     U-F1(A) = 0.7957931638913234
10/09/2021 11:31:10 - INFO - trainer -     U-F1(E) = 0.8607068607068608
10/09/2021 11:31:10 - INFO - trainer -     U-F1(I) = 0.724820143884892
10/09/2021 11:31:10 - INFO - trainer -     U-F1(O) = 0.9477728983688833
10/09/2021 11:31:10 - INFO - trainer -     intent_acc = 0.9115450890292935
10/09/2021 11:31:10 - INFO - trainer -     loss = 0.35283014602469703
10/09/2021 11:31:10 - INFO - trainer -     semantic_frame_acc = 0.8932797242963814
10/09/2021 11:31:10 - INFO - trainer -     slot_f1 = 0.9920674623025798
10/09/2021 11:31:10 - INFO - trainer -     slot_precision = 0.9929899856938483
10/09/2021 11:31:10 - INFO - trainer -     slot_recall = 0.9911466514350993

10/09/2021 11:31:10 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 11:31:10 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 11:31:10 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 11:31:10 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 11:31:10 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 11:31:10 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 11:31:10 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 11:31:10 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 11:31:10 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 11:31:10 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 11:31:10 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 11:31:10 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 11:31:10 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 11:31:10 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 11:31:10 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 11:31:10 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 11:31:10 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 11:32:38 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 554/815 [05:26<01:54,  2.27it/s]
10/09/2021 11:32:38 - INFO - trainer -     Num examples = 8705
10/09/2021 11:32:38 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:41<00:00,  3.31it/s]
10/09/2021 11:33:21 - INFO - trainer -   ***** Eval results *****
10/09/2021 11:33:21 - INFO - trainer -     T-F1 = 0.9858188896097877████████████████▌| 136/137 [00:41<00:00,  3.33it/s]
10/09/2021 11:33:21 - INFO - trainer -     T-F1(C) = 0.9793564055859137
10/09/2021 11:33:21 - INFO - trainer -     T-F1(D) = 0.892485549132948
10/09/2021 11:33:21 - INFO - trainer -     T-F1(O) = 0.9925196326367629
10/09/2021 11:33:21 - INFO - trainer -     T-F1(P) = 0.9985967597907897
10/09/2021 11:33:21 - INFO - trainer -     T-F1(S) = 0.9923273657289002
10/09/2021 11:33:21 - INFO - trainer -     T-F1(T) = 0.9717013296965564
10/09/2021 11:33:21 - INFO - trainer -     U-F1(A) = 0.7919463087248322
10/09/2021 11:33:21 - INFO - trainer -     U-F1(E) = 0.8681506849315068
10/09/2021 11:33:21 - INFO - trainer -     U-F1(I) = 0.7483629560336764
10/09/2021 11:33:21 - INFO - trainer -     U-F1(O) = 0.9509092328104269
10/09/2021 11:33:21 - INFO - trainer -     intent_acc = 0.9164847788627226
10/09/2021 11:33:21 - INFO - trainer -     loss = 0.3646930697149713
10/09/2021 11:33:21 - INFO - trainer -     semantic_frame_acc = 0.8905226881102815
10/09/2021 11:33:21 - INFO - trainer -     slot_f1 = 0.9886977537674153
10/09/2021 11:33:21 - INFO - trainer -     slot_precision = 0.9843595187544232
10/09/2021 11:33:21 - INFO - trainer -     slot_recall = 0.993074396687134

10/09/2021 11:33:21 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 11:33:21 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 11:33:21 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 11:33:21 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 11:33:21 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 11:33:21 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 11:33:21 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 11:33:21 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 11:33:21 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 11:33:21 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 11:33:21 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 11:33:21 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 11:33:21 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 11:33:21 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 11:33:21 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 11:33:21 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 11:33:21 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 11:34:52 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 754/815 [07:40<00:26,  2.29it/s]
10/09/2021 11:34:52 - INFO - trainer -     Num examples = 8705
10/09/2021 11:34:52 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:41<00:00,  3.32it/s]
10/09/2021 11:35:35 - INFO - trainer -   ***** Eval results *****
10/09/2021 11:35:35 - INFO - trainer -     T-F1 = 0.9892402999673948████████████████▌| 136/137 [00:41<00:00,  3.27it/s]
10/09/2021 11:35:35 - INFO - trainer -     T-F1(C) = 0.9822954822954824
10/09/2021 11:35:35 - INFO - trainer -     T-F1(D) = 0.9456790123456791
10/09/2021 11:35:35 - INFO - trainer -     T-F1(O) = 0.9943463835434638
10/09/2021 11:35:35 - INFO - trainer -     T-F1(P) = 0.9983420482081368
10/09/2021 11:35:35 - INFO - trainer -     T-F1(S) = 0.9942667471333736
10/09/2021 11:35:35 - INFO - trainer -     T-F1(T) = 0.9732326698695951
10/09/2021 11:35:35 - INFO - trainer -     U-F1(A) = 0.7910189982728842
10/09/2021 11:35:35 - INFO - trainer -     U-F1(E) = 0.8604060913705583
10/09/2021 11:35:35 - INFO - trainer -     U-F1(I) = 0.7492625368731564
10/09/2021 11:35:35 - INFO - trainer -     U-F1(O) = 0.9500427317224769
10/09/2021 11:35:35 - INFO - trainer -     intent_acc = 0.9155657668006892
10/09/2021 11:35:35 - INFO - trainer -     loss = 0.3662808305272887
10/09/2021 11:35:35 - INFO - trainer -     semantic_frame_acc = 0.8960367604824814
10/09/2021 11:35:35 - INFO - trainer -     slot_f1 = 0.9914023759409225
10/09/2021 11:35:35 - INFO - trainer -     slot_precision = 0.9907308377896613
10/09/2021 11:35:35 - INFO - trainer -     slot_recall = 0.9920748250749679

10/09/2021 11:35:35 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 11:35:35 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 11:35:35 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 11:35:35 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 11:35:35 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 11:35:35 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 11:35:35 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 11:35:35 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 11:35:35 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 11:35:35 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 11:35:35 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 11:35:35 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 11:35:35 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 11:35:35 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 11:35:35 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 11:35:35 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 11:35:35 - INFO - trainer -     slot_recall = 0.9896472940168499
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 815/815 [08:49<00:00,  1.54it/s]
Epoch:  20%|██████████████▌                                                          | 4/20 [25:30<1:53:24, 425.29s/it]10/09/2021 11:37:02 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 139/815 [01:00<04:54,  2.29it/s]
10/09/2021 11:37:02 - INFO - trainer -     Num examples = 8705
10/09/2021 11:37:02 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:40<00:00,  3.35it/s]
10/09/2021 11:37:44 - INFO - trainer -   ***** Eval results *****
10/09/2021 11:37:44 - INFO - trainer -     T-F1 = 0.9889199255121044████████████████▌| 136/137 [00:40<00:00,  3.32it/s]
10/09/2021 11:37:44 - INFO - trainer -     T-F1(C) = 0.9834761321909424
10/09/2021 11:37:44 - INFO - trainer -     T-F1(D) = 0.9547738693467336
10/09/2021 11:37:44 - INFO - trainer -     T-F1(O) = 0.993999575191164
10/09/2021 11:37:44 - INFO - trainer -     T-F1(P) = 0.9991068010718387
10/09/2021 11:37:44 - INFO - trainer -     T-F1(S) = 0.9920288765227853
10/09/2021 11:37:44 - INFO - trainer -     T-F1(T) = 0.9699658703071673
10/09/2021 11:37:44 - INFO - trainer -     U-F1(A) = 0.7887082976903336
10/09/2021 11:37:44 - INFO - trainer -     U-F1(E) = 0.8621966269025093
10/09/2021 11:37:44 - INFO - trainer -     U-F1(I) = 0.7112676056338029
10/09/2021 11:37:44 - INFO - trainer -     U-F1(O) = 0.9438219977907527
10/09/2021 11:37:44 - INFO - trainer -     intent_acc = 0.9068351522113728
10/09/2021 11:37:44 - INFO - trainer -     loss = 0.4302347613920043
10/09/2021 11:37:44 - INFO - trainer -     semantic_frame_acc = 0.8854681217690982
10/09/2021 11:37:44 - INFO - trainer -     slot_f1 = 0.9911927259761097
10/09/2021 11:37:44 - INFO - trainer -     slot_precision = 0.9900277797563929
10/09/2021 11:37:44 - INFO - trainer -     slot_recall = 0.9923604169641582

10/09/2021 11:37:44 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 11:37:44 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 11:37:44 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 11:37:44 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 11:37:44 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 11:37:44 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 11:37:44 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 11:37:44 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 11:37:44 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 11:37:44 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 11:37:44 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 11:37:44 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 11:37:44 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 11:37:44 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 11:37:44 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 11:37:44 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 11:37:44 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 11:39:12 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 339/815 [03:10<03:28,  2.28it/s]
10/09/2021 11:39:12 - INFO - trainer -     Num examples = 8705
10/09/2021 11:39:12 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:41<00:00,  3.33it/s]
10/09/2021 11:39:54 - INFO - trainer -   ***** Eval results *****
10/09/2021 11:39:54 - INFO - trainer -     T-F1 = 0.9893215201678714████████████████▌| 136/137 [00:41<00:00,  3.35it/s]
10/09/2021 11:39:54 - INFO - trainer -     T-F1(C) = 0.9843988987457938
10/09/2021 11:39:54 - INFO - trainer -     T-F1(D) = 0.9331683168316831
10/09/2021 11:39:54 - INFO - trainer -     T-F1(O) = 0.9942969309530758
10/09/2021 11:39:54 - INFO - trainer -     T-F1(P) = 0.9989788103140158
10/09/2021 11:39:54 - INFO - trainer -     T-F1(S) = 0.9936708860759494
10/09/2021 11:39:54 - INFO - trainer -     T-F1(T) = 0.9744651483781919
10/09/2021 11:39:54 - INFO - trainer -     U-F1(A) = 0.7811387900355873
10/09/2021 11:39:54 - INFO - trainer -     U-F1(E) = 0.8567818028643639
10/09/2021 11:39:54 - INFO - trainer -     U-F1(I) = 0.7141585040071238
10/09/2021 11:39:54 - INFO - trainer -     U-F1(O) = 0.9467511142387991
10/09/2021 11:39:54 - INFO - trainer -     intent_acc = 0.9087880528431935
10/09/2021 11:39:54 - INFO - trainer -     loss = 0.4236222412862074
10/09/2021 11:39:54 - INFO - trainer -     semantic_frame_acc = 0.8885697874784606
10/09/2021 11:39:54 - INFO - trainer -     slot_f1 = 0.9915750392688848
10/09/2021 11:39:54 - INFO - trainer -     slot_precision = 0.9915750392688848
10/09/2021 11:39:54 - INFO - trainer -     slot_recall = 0.9915750392688848

10/09/2021 11:39:54 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 11:39:54 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 11:39:54 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 11:39:54 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 11:39:54 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 11:39:54 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 11:39:54 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 11:39:54 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 11:39:54 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 11:39:54 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 11:39:54 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 11:39:54 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 11:39:54 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 11:39:54 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 11:39:54 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 11:39:54 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 11:39:54 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 11:41:20 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 539/815 [05:18<01:59,  2.31it/s]
10/09/2021 11:41:20 - INFO - trainer -     Num examples = 8705
10/09/2021 11:41:20 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:40<00:00,  3.35it/s]
10/09/2021 11:42:02 - INFO - trainer -   ***** Eval results *****
10/09/2021 11:42:02 - INFO - trainer -     T-F1 = 0.9872194079100246████████████████▌| 136/137 [00:40<00:00,  3.29it/s]
10/09/2021 11:42:02 - INFO - trainer -     T-F1(C) = 0.9816737935247404
10/09/2021 11:42:02 - INFO - trainer -     T-F1(D) = 0.9365853658536584
10/09/2021 11:42:02 - INFO - trainer -     T-F1(O) = 0.9934355648869162
10/09/2021 11:42:02 - INFO - trainer -     T-F1(P) = 0.9989790709545686
10/09/2021 11:42:02 - INFO - trainer -     T-F1(S) = 0.9915688045769347
10/09/2021 11:42:02 - INFO - trainer -     T-F1(T) = 0.966383701188455
10/09/2021 11:42:02 - INFO - trainer -     U-F1(A) = 0.7732406602953953
10/09/2021 11:42:02 - INFO - trainer -     U-F1(E) = 0.8614107883817428
10/09/2021 11:42:02 - INFO - trainer -     U-F1(I) = 0.7225691347011596
10/09/2021 11:42:02 - INFO - trainer -     U-F1(O) = 0.9462602137020741
10/09/2021 11:42:02 - INFO - trainer -     intent_acc = 0.9086731763354394
10/09/2021 11:42:02 - INFO - trainer -     loss = 0.4385025806335841
10/09/2021 11:42:02 - INFO - trainer -     semantic_frame_acc = 0.8854681217690982
10/09/2021 11:42:02 - INFO - trainer -     slot_f1 = 0.9898493428785127
10/09/2021 11:42:02 - INFO - trainer -     slot_precision = 0.9875630729869945
10/09/2021 11:42:02 - INFO - trainer -     slot_recall = 0.9921462230472654

10/09/2021 11:42:02 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 11:42:02 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 11:42:02 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 11:42:02 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 11:42:02 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 11:42:02 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 11:42:02 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 11:42:02 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 11:42:02 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 11:42:02 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 11:42:02 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 11:42:02 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 11:42:02 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 11:42:02 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 11:42:02 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 11:42:02 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 11:42:02 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 11:43:30 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 739/815 [07:29<00:33,  2.28it/s]
10/09/2021 11:43:30 - INFO - trainer -     Num examples = 8705
10/09/2021 11:43:30 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:46<00:00,  2.97it/s]
10/09/2021 11:44:18 - INFO - trainer -   ***** Eval results *****
10/09/2021 11:44:18 - INFO - trainer -     T-F1 = 0.9894599384385785████████████████▌| 136/137 [00:46<00:00,  3.35it/s]
10/09/2021 11:44:18 - INFO - trainer -     T-F1(C) = 0.9825847846012832
10/09/2021 11:44:18 - INFO - trainer -     T-F1(D) = 0.94320987654321
10/09/2021 11:44:18 - INFO - trainer -     T-F1(O) = 0.9945094294581045
10/09/2021 11:44:18 - INFO - trainer -     T-F1(P) = 0.9984682154710237
10/09/2021 11:44:18 - INFO - trainer -     T-F1(S) = 0.9930555555555556
10/09/2021 11:44:18 - INFO - trainer -     T-F1(T) = 0.9775939331265081
10/09/2021 11:44:18 - INFO - trainer -     U-F1(A) = 0.7786526684164479
10/09/2021 11:44:18 - INFO - trainer -     U-F1(E) = 0.8646616541353384
10/09/2021 11:44:18 - INFO - trainer -     U-F1(I) = 0.7404718693284937
10/09/2021 11:44:18 - INFO - trainer -     U-F1(O) = 0.950434578341555
10/09/2021 11:44:18 - INFO - trainer -     intent_acc = 0.9140723721998851
10/09/2021 11:44:18 - INFO - trainer -     loss = 0.42175720917166337
10/09/2021 11:44:18 - INFO - trainer -     semantic_frame_acc = 0.8941987363584147
10/09/2021 11:44:18 - INFO - trainer -     slot_f1 = 0.9917172438414852
10/09/2021 11:44:18 - INFO - trainer -     slot_precision = 0.9917880605541274
10/09/2021 11:44:18 - INFO - trainer -     slot_recall = 0.9916464372411824

10/09/2021 11:44:18 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 11:44:18 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 11:44:18 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 11:44:18 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 11:44:18 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 11:44:18 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 11:44:18 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 11:44:18 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 11:44:18 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 11:44:18 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 11:44:18 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 11:44:18 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 11:44:18 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 11:44:18 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 11:44:18 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 11:44:18 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 11:44:18 - INFO - trainer -     slot_recall = 0.9896472940168499
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 815/815 [08:49<00:00,  1.54it/s]
Epoch:  25%|██████████████████▎                                                      | 5/20 [34:19<1:55:41, 462.79s/it]10/09/2021 11:45:44 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 124/815 [00:53<05:01,  2.29it/s]
10/09/2021 11:45:44 - INFO - trainer -     Num examples = 8705
10/09/2021 11:45:44 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:45<00:00,  3.03it/s]
10/09/2021 11:46:31 - INFO - trainer -   ***** Eval results *****
10/09/2021 11:46:31 - INFO - trainer -     T-F1 = 0.9882265345060264████████████████▌| 136/137 [00:45<00:00,  3.37it/s]
10/09/2021 11:46:31 - INFO - trainer -     T-F1(C) = 0.9819627025374503
10/09/2021 11:46:31 - INFO - trainer -     T-F1(D) = 0.9387254901960784
10/09/2021 11:46:31 - INFO - trainer -     T-F1(O) = 0.9938122427300492
10/09/2021 11:46:31 - INFO - trainer -     T-F1(P) = 0.9988513082322911
10/09/2021 11:46:31 - INFO - trainer -     T-F1(S) = 0.9944167798400483
10/09/2021 11:46:31 - INFO - trainer -     T-F1(T) = 0.9666666666666668
10/09/2021 11:46:31 - INFO - trainer -     U-F1(A) = 0.7649769585253456
10/09/2021 11:46:31 - INFO - trainer -     U-F1(E) = 0.8606965174129353
10/09/2021 11:46:31 - INFO - trainer -     U-F1(I) = 0.751219512195122
10/09/2021 11:46:31 - INFO - trainer -     U-F1(O) = 0.9506517690875232
10/09/2021 11:46:31 - INFO - trainer -     intent_acc = 0.9148765077541643
10/09/2021 11:46:31 - INFO - trainer -     loss = 0.44503594266529445
10/09/2021 11:46:31 - INFO - trainer -     semantic_frame_acc = 0.8927053417576105
10/09/2021 11:46:31 - INFO - trainer -     slot_f1 = 0.9907321594068582
10/09/2021 11:46:31 - INFO - trainer -     slot_precision = 0.989251138952164
10/09/2021 11:46:31 - INFO - trainer -     slot_recall = 0.992217621019563

10/09/2021 11:46:31 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 11:46:31 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 11:46:31 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 11:46:31 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 11:46:31 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 11:46:31 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 11:46:31 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 11:46:31 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 11:46:31 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 11:46:31 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 11:46:31 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 11:46:31 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 11:46:31 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 11:46:31 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 11:46:31 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 11:46:31 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 11:46:31 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 11:47:57 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 324/815 [03:06<03:30,  2.34it/s]
10/09/2021 11:47:57 - INFO - trainer -     Num examples = 8705
10/09/2021 11:47:57 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:42<00:00,  3.22it/s]
10/09/2021 11:48:40 - INFO - trainer -   ***** Eval results *****
10/09/2021 11:48:40 - INFO - trainer -     T-F1 = 0.9901091723430063████████████████▌| 136/137 [00:42<00:00,  3.33it/s]
10/09/2021 11:48:40 - INFO - trainer -     T-F1(C) = 0.9843510279226756
10/09/2021 11:48:40 - INFO - trainer -     T-F1(D) = 0.9365853658536584
10/09/2021 11:48:40 - INFO - trainer -     T-F1(O) = 0.9948554760010606
10/09/2021 11:48:40 - INFO - trainer -     T-F1(P) = 0.9992339121552605
10/09/2021 11:48:40 - INFO - trainer -     T-F1(S) = 0.9942667471333736
10/09/2021 11:48:40 - INFO - trainer -     T-F1(T) = 0.9775474956822107
10/09/2021 11:48:40 - INFO - trainer -     U-F1(A) = 0.7865748709122203
10/09/2021 11:48:40 - INFO - trainer -     U-F1(E) = 0.8554216867469879
10/09/2021 11:48:40 - INFO - trainer -     U-F1(I) = 0.7502448579823702
10/09/2021 11:48:40 - INFO - trainer -     U-F1(O) = 0.9514066496163683
10/09/2021 11:48:40 - INFO - trainer -     intent_acc = 0.9157955198161976
10/09/2021 11:48:40 - INFO - trainer -     loss = 0.4810953444740089
10/09/2021 11:48:40 - INFO - trainer -     semantic_frame_acc = 0.8970706490522689
10/09/2021 11:48:40 - INFO - trainer -     slot_f1 = 0.9922148417970145
10/09/2021 11:48:40 - INFO - trainer -     slot_precision = 0.9925693055158616
10/09/2021 11:48:40 - INFO - trainer -     slot_recall = 0.9918606311580751

10/09/2021 11:48:40 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 11:48:40 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 11:48:40 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 11:48:40 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 11:48:40 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 11:48:40 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 11:48:40 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 11:48:40 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 11:48:40 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 11:48:40 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 11:48:40 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 11:48:40 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 11:48:40 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 11:48:40 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 11:48:40 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 11:48:40 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 11:48:40 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 11:50:07 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 524/815 [05:15<02:06,  2.30it/s]
10/09/2021 11:50:07 - INFO - trainer -     Num examples = 8705
10/09/2021 11:50:07 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:43<00:00,  3.18it/s]
10/09/2021 11:50:51 - INFO - trainer -   ***** Eval results *****
10/09/2021 11:50:51 - INFO - trainer -     T-F1 = 0.9888247345874465████████████████▌| 136/137 [00:43<00:00,  3.44it/s]
10/09/2021 11:50:51 - INFO - trainer -     T-F1(C) = 0.9808102345415779
10/09/2021 11:50:51 - INFO - trainer -     T-F1(D) = 0.9429657794676806
10/09/2021 11:50:51 - INFO - trainer -     T-F1(O) = 0.9944249761070405
10/09/2021 11:50:51 - INFO - trainer -     T-F1(P) = 0.9989790709545686
10/09/2021 11:50:51 - INFO - trainer -     T-F1(S) = 0.9948717948717949
10/09/2021 11:50:51 - INFO - trainer -     T-F1(T) = 0.9693669162695712
10/09/2021 11:50:51 - INFO - trainer -     U-F1(A) = 0.7771135781383434
10/09/2021 11:50:51 - INFO - trainer -     U-F1(E) = 0.854104636324968
10/09/2021 11:50:51 - INFO - trainer -     U-F1(I) = 0.7309160305343512
10/09/2021 11:50:51 - INFO - trainer -     U-F1(O) = 0.9489096573208723
10/09/2021 11:50:51 - INFO - trainer -     intent_acc = 0.9114302125215393
10/09/2021 11:50:51 - INFO - trainer -     loss = 0.47678856219990984
10/09/2021 11:50:51 - INFO - trainer -     semantic_frame_acc = 0.891671453187823
10/09/2021 11:50:51 - INFO - trainer -     slot_f1 = 0.9912268188302424
10/09/2021 11:50:51 - INFO - trainer -     slot_precision = 0.9902379934444919
10/09/2021 11:50:51 - INFO - trainer -     slot_recall = 0.992217621019563

10/09/2021 11:50:51 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 11:50:51 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 11:50:51 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 11:50:51 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 11:50:51 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 11:50:51 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 11:50:51 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 11:50:51 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 11:50:51 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 11:50:51 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 11:50:51 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 11:50:51 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 11:50:51 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 11:50:51 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 11:50:51 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 11:50:51 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 11:50:51 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 11:52:17 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 724/815 [07:26<00:39,  2.33it/s]
10/09/2021 11:52:17 - INFO - trainer -     Num examples = 8705
10/09/2021 11:52:17 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:40<00:00,  3.36it/s]
10/09/2021 11:52:59 - INFO - trainer -   ***** Eval results *****
10/09/2021 11:52:59 - INFO - trainer -     T-F1 = 0.9898933445112011████████████████▌| 136/137 [00:40<00:00,  3.16it/s]
10/09/2021 11:52:59 - INFO - trainer -     T-F1(C) = 0.9855872431769396
10/09/2021 11:52:59 - INFO - trainer -     T-F1(D) = 0.9403166869671133
10/09/2021 11:52:59 - INFO - trainer -     T-F1(O) = 0.994717702333236
10/09/2021 11:52:59 - INFO - trainer -     T-F1(P) = 0.9989793314621077
10/09/2021 11:52:59 - INFO - trainer -     T-F1(S) = 0.993513350429929
10/09/2021 11:52:59 - INFO - trainer -     T-F1(T) = 0.9760438056125942
10/09/2021 11:52:59 - INFO - trainer -     U-F1(A) = 0.7756849315068493
10/09/2021 11:52:59 - INFO - trainer -     U-F1(E) = 0.8665808665808665
10/09/2021 11:52:59 - INFO - trainer -     U-F1(I) = 0.7458256029684601
10/09/2021 11:52:59 - INFO - trainer -     U-F1(O) = 0.9511415880931972
10/09/2021 11:52:59 - INFO - trainer -     intent_acc = 0.9153360137851809
10/09/2021 11:52:59 - INFO - trainer -     loss = 0.44490082580706675
10/09/2021 11:52:59 - INFO - trainer -     semantic_frame_acc = 0.8967260195290063
10/09/2021 11:52:59 - INFO - trainer -     slot_f1 = 0.9921175589399723
10/09/2021 11:52:59 - INFO - trainer -     slot_precision = 0.9912336968141972
10/09/2021 11:52:59 - INFO - trainer -     slot_recall = 0.9930029987148365

10/09/2021 11:52:59 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 11:52:59 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 11:52:59 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 11:52:59 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 11:52:59 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 11:52:59 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 11:52:59 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 11:52:59 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 11:52:59 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 11:52:59 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 11:52:59 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 11:52:59 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 11:52:59 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 11:52:59 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 11:52:59 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 11:52:59 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 11:52:59 - INFO - trainer -     slot_recall = 0.9896472940168499
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 815/815 [08:47<00:00,  1.55it/s]
Epoch:  30%|█████████████████████▉                                                   | 6/20 [43:06<1:53:06, 484.76s/it]10/09/2021 11:54:26 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 109/815 [00:47<05:04,  2.32it/s]
10/09/2021 11:54:26 - INFO - trainer -     Num examples = 8705
10/09/2021 11:54:26 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:45<00:00,  2.99it/s]
10/09/2021 11:55:13 - INFO - trainer -   ***** Eval results *****
10/09/2021 11:55:13 - INFO - trainer -     T-F1 = 0.9885196374622357████████████████▌| 136/137 [00:45<00:00,  3.38it/s]
10/09/2021 11:55:13 - INFO - trainer -     T-F1(C) = 0.9831958447907119
10/09/2021 11:55:13 - INFO - trainer -     T-F1(D) = 0.9493201483312731
10/09/2021 11:55:13 - INFO - trainer -     T-F1(O) = 0.9941268702330649
10/09/2021 11:55:13 - INFO - trainer -     T-F1(P) = 0.9991065730695597
10/09/2021 11:55:13 - INFO - trainer -     T-F1(S) = 0.990985576923077
10/09/2021 11:55:13 - INFO - trainer -     T-F1(T) = 0.9714479945615226
10/09/2021 11:55:13 - INFO - trainer -     U-F1(A) = 0.7852112676056339
10/09/2021 11:55:13 - INFO - trainer -     U-F1(E) = 0.8610054921841994
10/09/2021 11:55:13 - INFO - trainer -     U-F1(I) = 0.7216117216117217
10/09/2021 11:55:13 - INFO - trainer -     U-F1(O) = 0.9492001560671088
10/09/2021 11:55:13 - INFO - trainer -     intent_acc = 0.9122343480758185
10/09/2021 11:55:13 - INFO - trainer -     loss = 0.5333068071669953
10/09/2021 11:55:13 - INFO - trainer -     semantic_frame_acc = 0.8915565766800689
10/09/2021 11:55:13 - INFO - trainer -     slot_f1 = 0.9909897076106698
10/09/2021 11:55:13 - INFO - trainer -     slot_precision = 0.9886307112911249
10/09/2021 11:55:13 - INFO - trainer -     slot_recall = 0.9933599885763245

10/09/2021 11:55:13 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 11:55:13 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 11:55:13 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 11:55:13 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 11:55:13 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 11:55:13 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 11:55:13 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 11:55:13 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 11:55:13 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 11:55:13 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 11:55:13 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 11:55:13 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 11:55:13 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 11:55:13 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 11:55:13 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 11:55:13 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 11:55:13 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 11:56:39 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 309/815 [03:01<03:40,  2.30it/s]
10/09/2021 11:56:39 - INFO - trainer -     Num examples = 8705
10/09/2021 11:56:39 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:42<00:00,  3.19it/s]
10/09/2021 11:57:23 - INFO - trainer -   ***** Eval results *****
10/09/2021 11:57:23 - INFO - trainer -     T-F1 = 0.9878734377177903████████████████▌| 136/137 [00:42<00:00,  3.36it/s]
10/09/2021 11:57:23 - INFO - trainer -     T-F1(C) = 0.9793313069908813
10/09/2021 11:57:23 - INFO - trainer -     T-F1(D) = 0.9320388349514563
10/09/2021 11:57:23 - INFO - trainer -     T-F1(O) = 0.9938598123388533
10/09/2021 11:57:23 - INFO - trainer -     T-F1(P) = 0.9988516013780784
10/09/2021 11:57:23 - INFO - trainer -     T-F1(S) = 0.9930743751881963
10/09/2021 11:57:23 - INFO - trainer -     T-F1(T) = 0.9720136518771331
10/09/2021 11:57:23 - INFO - trainer -     U-F1(A) = 0.7790594498669033
10/09/2021 11:57:23 - INFO - trainer -     U-F1(E) = 0.8603066439522997
10/09/2021 11:57:23 - INFO - trainer -     U-F1(I) = 0.7384324834749765
10/09/2021 11:57:23 - INFO - trainer -     U-F1(O) = 0.9501397949673811
10/09/2021 11:57:23 - INFO - trainer -     intent_acc = 0.9140723721998851
10/09/2021 11:57:23 - INFO - trainer -     loss = 0.5018070730398558
10/09/2021 11:57:23 - INFO - trainer -     semantic_frame_acc = 0.8919012062033315
10/09/2021 11:57:23 - INFO - trainer -     slot_f1 = 0.9903507210254586
10/09/2021 11:57:23 - INFO - trainer -     slot_precision = 0.987783223240287
10/09/2021 11:57:23 - INFO - trainer -     slot_recall = 0.992931600742539

10/09/2021 11:57:23 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 11:57:23 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 11:57:23 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 11:57:23 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 11:57:23 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 11:57:23 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 11:57:23 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 11:57:23 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 11:57:23 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 11:57:23 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 11:57:23 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 11:57:23 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 11:57:23 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 11:57:23 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 11:57:23 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 11:57:23 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 11:57:23 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 11:58:49 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 509/815 [05:11<02:11,  2.33it/s]
10/09/2021 11:58:49 - INFO - trainer -     Num examples = 8705
10/09/2021 11:58:49 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:41<00:00,  3.27it/s]
10/09/2021 11:59:32 - INFO - trainer -   ***** Eval results *****
10/09/2021 11:59:32 - INFO - trainer -     T-F1 = 0.9886490509862299████████████████▌| 136/137 [00:41<00:00,  3.39it/s]
10/09/2021 11:59:32 - INFO - trainer -     T-F1(C) = 0.9810860280658938
10/09/2021 11:59:32 - INFO - trainer -     T-F1(D) = 0.9322033898305085
10/09/2021 11:59:32 - INFO - trainer -     T-F1(O) = 0.9939970250743733
10/09/2021 11:59:32 - INFO - trainer -     T-F1(P) = 0.9988510149368058
10/09/2021 11:59:32 - INFO - trainer -     T-F1(S) = 0.9938206480783723
10/09/2021 11:59:32 - INFO - trainer -     T-F1(T) = 0.9740082079343365
10/09/2021 11:59:32 - INFO - trainer -     U-F1(A) = 0.7733782645324347
10/09/2021 11:59:32 - INFO - trainer -     U-F1(E) = 0.8597972972972973
10/09/2021 11:59:32 - INFO - trainer -     U-F1(I) = 0.7029438001784122
10/09/2021 11:59:32 - INFO - trainer -     U-F1(O) = 0.9448719962305638
10/09/2021 11:59:32 - INFO - trainer -     intent_acc = 0.9060310166570936
10/09/2021 11:59:32 - INFO - trainer -     loss = 0.5155790929648988
10/09/2021 11:59:32 - INFO - trainer -     semantic_frame_acc = 0.8848937392303274
10/09/2021 11:59:32 - INFO - trainer -     slot_f1 = 0.9910186043196235
10/09/2021 11:59:32 - INFO - trainer -     slot_precision = 0.9893965271847424
10/09/2021 11:59:32 - INFO - trainer -     slot_recall = 0.9926460088533485

10/09/2021 11:59:32 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 11:59:32 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 11:59:32 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 11:59:32 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 11:59:32 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 11:59:32 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 11:59:32 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 11:59:32 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 11:59:32 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 11:59:32 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 11:59:32 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 11:59:32 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 11:59:32 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 11:59:32 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 11:59:32 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 11:59:32 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 11:59:32 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:00:58 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 709/815 [07:20<00:45,  2.31it/s]
10/09/2021 12:00:58 - INFO - trainer -     Num examples = 8705
10/09/2021 12:00:58 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:42<00:00,  3.19it/s]
10/09/2021 12:01:42 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:01:42 - INFO - trainer -     T-F1 = 0.988701353047845█████████████████▌| 136/137 [00:42<00:00,  3.38it/s]
10/09/2021 12:01:42 - INFO - trainer -     T-F1(C) = 0.9813967673071059
10/09/2021 12:01:42 - INFO - trainer -     T-F1(D) = 0.9478908188585607
10/09/2021 12:01:42 - INFO - trainer -     T-F1(O) = 0.9940218402104313
10/09/2021 12:01:42 - INFO - trainer -     T-F1(P) = 0.9982151963284039
10/09/2021 12:01:42 - INFO - trainer -     T-F1(S) = 0.9930722891566265
10/09/2021 12:01:42 - INFO - trainer -     T-F1(T) = 0.9727705922396188
10/09/2021 12:01:42 - INFO - trainer -     U-F1(A) = 0.7926112510495382
10/09/2021 12:01:42 - INFO - trainer -     U-F1(E) = 0.8721868365180466
10/09/2021 12:01:42 - INFO - trainer -     U-F1(I) = 0.7441424554826617
10/09/2021 12:01:42 - INFO - trainer -     U-F1(O) = 0.9503789950769712
10/09/2021 12:01:42 - INFO - trainer -     intent_acc = 0.9163699023549684
10/09/2021 12:01:42 - INFO - trainer -     loss = 0.5261811681833615
10/09/2021 12:01:42 - INFO - trainer -     semantic_frame_acc = 0.8947731188971855
10/09/2021 12:01:42 - INFO - trainer -     slot_f1 = 0.9911296355669551
10/09/2021 12:01:42 - INFO - trainer -     slot_precision = 0.9890508354070388
10/09/2021 12:01:42 - INFO - trainer -     slot_recall = 0.9932171926317293

10/09/2021 12:01:42 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:01:42 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:01:42 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:01:42 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:01:42 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:01:42 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:01:42 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:01:42 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:01:42 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:01:42 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:01:42 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:01:42 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:01:42 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:01:42 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:01:42 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:01:42 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:01:42 - INFO - trainer -     slot_recall = 0.9896472940168499
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 815/815 [08:49<00:00,  1.54it/s]
Epoch:  35%|█████████████████████████▌                                               | 7/20 [51:56<1:48:11, 499.37s/it]10/09/2021 12:03:08 - INFO - trainer -   ***** Running evaluation on dev dataset ***** | 94/815 [00:40<05:08,  2.34it/s]
10/09/2021 12:03:08 - INFO - trainer -     Num examples = 8705
10/09/2021 12:03:08 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:42<00:00,  3.24it/s]
10/09/2021 12:03:51 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:03:51 - INFO - trainer -     T-F1 = 0.9899771572420867████████████████▌| 136/137 [00:42<00:00,  3.43it/s]
10/09/2021 12:03:51 - INFO - trainer -     T-F1(C) = 0.9834963325183373
10/09/2021 12:03:51 - INFO - trainer -     T-F1(D) = 0.9410319410319411
10/09/2021 12:03:51 - INFO - trainer -     T-F1(O) = 0.9948266256334067
10/09/2021 12:03:51 - INFO - trainer -     T-F1(P) = 0.9987238386932108
10/09/2021 12:03:51 - INFO - trainer -     T-F1(S) = 0.9945701357466064
10/09/2021 12:03:51 - INFO - trainer -     T-F1(T) = 0.9768885822697482
10/09/2021 12:03:51 - INFO - trainer -     U-F1(A) = 0.7816482582837724
10/09/2021 12:03:51 - INFO - trainer -     U-F1(E) = 0.8657228657228657
10/09/2021 12:03:51 - INFO - trainer -     U-F1(I) = 0.743515850144092
10/09/2021 12:03:51 - INFO - trainer -     U-F1(O) = 0.9504704144312262
10/09/2021 12:03:51 - INFO - trainer -     intent_acc = 0.9153360137851809
10/09/2021 12:03:51 - INFO - trainer -     loss = 0.556602672460263
10/09/2021 12:03:51 - INFO - trainer -     semantic_frame_acc = 0.8967260195290063
10/09/2021 12:03:51 - INFO - trainer -     slot_f1 = 0.9920405468108647
10/09/2021 12:03:51 - INFO - trainer -     slot_precision = 0.9918635357933052
10/09/2021 12:03:51 - INFO - trainer -     slot_recall = 0.992217621019563

10/09/2021 12:03:51 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:03:51 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:03:51 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:03:51 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:03:51 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:03:51 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:03:51 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:03:51 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:03:51 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:03:51 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:03:51 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:03:51 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:03:51 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:03:51 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:03:51 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:03:51 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:03:51 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:05:17 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 294/815 [02:49<03:47,  2.29it/s]
10/09/2021 12:05:17 - INFO - trainer -     Num examples = 8705
10/09/2021 12:05:17 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:41<00:00,  3.34it/s]
10/09/2021 12:05:59 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:05:59 - INFO - trainer -     T-F1 = 0.9880481793238153████████████████▌| 136/137 [00:41<00:00,  3.32it/s]
10/09/2021 12:05:59 - INFO - trainer -     T-F1(C) = 0.9825634750688284
10/09/2021 12:05:59 - INFO - trainer -     T-F1(D) = 0.928657799274486
10/09/2021 12:05:59 - INFO - trainer -     T-F1(O) = 0.9937036741850641
10/09/2021 12:05:59 - INFO - trainer -     T-F1(P) = 0.9988516013780784
10/09/2021 12:05:59 - INFO - trainer -     T-F1(S) = 0.990985576923077
10/09/2021 12:05:59 - INFO - trainer -     T-F1(T) = 0.9752916952642416
10/09/2021 12:05:59 - INFO - trainer -     U-F1(A) = 0.7695004382120946
10/09/2021 12:05:59 - INFO - trainer -     U-F1(E) = 0.8613445378151261
10/09/2021 12:05:59 - INFO - trainer -     U-F1(I) = 0.7085201793721974
10/09/2021 12:05:59 - INFO - trainer -     U-F1(O) = 0.9470800062627212
10/09/2021 12:05:59 - INFO - trainer -     intent_acc = 0.9084434233199311
10/09/2021 12:05:59 - INFO - trainer -     loss = 0.579531276567557
10/09/2021 12:05:59 - INFO - trainer -     semantic_frame_acc = 0.8866168868466399
10/09/2021 12:05:59 - INFO - trainer -     slot_f1 = 0.9905942710560068
10/09/2021 12:05:59 - INFO - trainer -     slot_precision = 0.9886218176646281
10/09/2021 12:05:59 - INFO - trainer -     slot_recall = 0.9925746108810509

10/09/2021 12:05:59 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:05:59 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:05:59 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:05:59 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:05:59 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:05:59 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:05:59 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:05:59 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:05:59 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:05:59 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:05:59 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:05:59 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:05:59 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:05:59 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:05:59 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:05:59 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:05:59 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:07:27 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 494/815 [04:59<03:18,  1.62it/s]
10/09/2021 12:07:27 - INFO - trainer -     Num examples = 8705
10/09/2021 12:07:27 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:41<00:00,  3.34it/s]
10/09/2021 12:08:10 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:08:10 - INFO - trainer -     T-F1 = 0.9902161759224748████████████████▌| 136/137 [00:41<00:00,  3.35it/s]
10/09/2021 12:08:10 - INFO - trainer -     T-F1(C) = 0.9816961561928006
10/09/2021 12:08:10 - INFO - trainer -     T-F1(D) = 0.9506172839506173
10/09/2021 12:08:10 - INFO - trainer -     T-F1(O) = 0.9949575371549894
10/09/2021 12:08:10 - INFO - trainer -     T-F1(P) = 0.9988516013780784
10/09/2021 12:08:10 - INFO - trainer -     T-F1(S) = 0.9939704552306301
10/09/2021 12:08:10 - INFO - trainer -     T-F1(T) = 0.9790017211703959
10/09/2021 12:08:10 - INFO - trainer -     U-F1(A) = 0.7606142728093948
10/09/2021 12:08:10 - INFO - trainer -     U-F1(E) = 0.8557004627681951
10/09/2021 12:08:10 - INFO - trainer -     U-F1(I) = 0.715846994535519
10/09/2021 12:08:10 - INFO - trainer -     U-F1(O) = 0.9462114125350796
10/09/2021 12:08:10 - INFO - trainer -     intent_acc = 0.9075244112578977
10/09/2021 12:08:10 - INFO - trainer -     loss = 0.5613109086741936
10/09/2021 12:08:10 - INFO - trainer -     semantic_frame_acc = 0.8900631820792648
10/09/2021 12:08:10 - INFO - trainer -     slot_f1 = 0.9922939707456297
10/09/2021 12:08:10 - INFO - trainer -     slot_precision = 0.991657159155733
10/09/2021 12:08:10 - INFO - trainer -     slot_recall = 0.992931600742539

10/09/2021 12:08:10 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:08:10 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:08:10 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:08:10 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:08:10 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:08:10 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:08:10 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:08:10 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:08:10 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:08:10 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:08:10 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:08:10 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:08:10 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:08:10 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:08:10 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:08:10 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:08:10 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:09:01 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 694/815 [06:33<00:27,  4.38it/s]
10/09/2021 12:09:01 - INFO - trainer -     Num examples = 8705
10/09/2021 12:09:01 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:18<00:00,  7.34it/s]
10/09/2021 12:09:21 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:09:21 - INFO - trainer -     T-F1 = 0.9886543290244583████████████████▌| 136/137 [00:18<00:00,  7.17it/s]
10/09/2021 12:09:21 - INFO - trainer -     T-F1(C) = 0.9819957277998169
10/09/2021 12:09:21 - INFO - trainer -     T-F1(D) = 0.9367396593673966
10/09/2021 12:09:21 - INFO - trainer -     T-F1(O) = 0.9942611190817792
10/09/2021 12:09:21 - INFO - trainer -     T-F1(P) = 0.9987241643276347
10/09/2021 12:09:21 - INFO - trainer -     T-F1(S) = 0.9921780986762937
10/09/2021 12:09:21 - INFO - trainer -     T-F1(T) = 0.9756932557343375
10/09/2021 12:09:21 - INFO - trainer -     U-F1(A) = 0.782608695652174
10/09/2021 12:09:21 - INFO - trainer -     U-F1(E) = 0.8661283467913303
10/09/2021 12:09:21 - INFO - trainer -     U-F1(I) = 0.7214953271028037
10/09/2021 12:09:21 - INFO - trainer -     U-F1(O) = 0.9486357595184114
10/09/2021 12:09:21 - INFO - trainer -     intent_acc = 0.9121194715680643
10/09/2021 12:09:21 - INFO - trainer -     loss = 0.5547474169331249
10/09/2021 12:09:21 - INFO - trainer -     semantic_frame_acc = 0.8912119471568064
10/09/2021 12:09:21 - INFO - trainer -     slot_f1 = 0.9910218041898247
10/09/2021 12:09:21 - INFO - trainer -     slot_precision = 0.9890484995022045
10/09/2021 12:09:21 - INFO - trainer -     slot_recall = 0.9930029987148365

10/09/2021 12:09:21 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:09:21 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:09:21 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:09:21 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:09:21 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:09:21 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:09:21 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:09:21 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:09:21 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:09:21 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:09:21 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:09:21 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:09:21 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:09:21 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:09:21 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:09:21 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:09:21 - INFO - trainer -     slot_recall = 0.9896472940168499
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 815/815 [07:21<00:00,  1.85it/s]
Epoch:  40%|█████████████████████████████▏                                           | 8/20 [59:17<1:36:09, 480.83s/it]10/09/2021 12:10:07 - INFO - trainer -   ***** Running evaluation on dev dataset ***** | 79/815 [00:18<02:49,  4.34it/s]
10/09/2021 12:10:07 - INFO - trainer -     Num examples = 8705
10/09/2021 12:10:07 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:18<00:00,  7.27it/s]
10/09/2021 12:10:26 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:10:26 - INFO - trainer -     T-F1 = 0.9899874260699483████████████████▌| 136/137 [00:18<00:00,  7.13it/s]
10/09/2021 12:10:26 - INFO - trainer -     T-F1(C) = 0.9843606255749769
10/09/2021 12:10:26 - INFO - trainer -     T-F1(D) = 0.9467162329615861
10/09/2021 12:10:26 - INFO - trainer -     T-F1(O) = 0.9947705131268084
10/09/2021 12:10:26 - INFO - trainer -     T-F1(P) = 0.9988518943742825
10/09/2021 12:10:26 - INFO - trainer -     T-F1(S) = 0.9929270127915727
10/09/2021 12:10:26 - INFO - trainer -     T-F1(T) = 0.9777473467990413
10/09/2021 12:10:26 - INFO - trainer -     U-F1(A) = 0.7634584013050572
10/09/2021 12:10:26 - INFO - trainer -     U-F1(E) = 0.8632115548003398
10/09/2021 12:10:26 - INFO - trainer -     U-F1(I) = 0.7372400756143669
10/09/2021 12:10:26 - INFO - trainer -     U-F1(O) = 0.9469151268399624
10/09/2021 12:10:26 - INFO - trainer -     intent_acc = 0.9099368179207352
10/09/2021 12:10:26 - INFO - trainer -     loss = 0.5857341209325403
10/09/2021 12:10:26 - INFO - trainer -     semantic_frame_acc = 0.891671453187823
10/09/2021 12:10:26 - INFO - trainer -     slot_f1 = 0.9920810444460297
10/09/2021 12:10:26 - INFO - trainer -     slot_precision = 0.9913031080695751
10/09/2021 12:10:26 - INFO - trainer -     slot_recall = 0.9928602027702413

10/09/2021 12:10:26 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:10:26 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:10:26 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:10:26 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:10:26 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:10:26 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:10:26 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:10:26 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:10:26 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:10:26 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:10:26 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:10:26 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:10:26 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:10:26 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:10:26 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:10:26 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:10:26 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:11:13 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 279/815 [01:24<02:03,  4.35it/s]
10/09/2021 12:11:13 - INFO - trainer -     Num examples = 8705
10/09/2021 12:11:13 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:18<00:00,  7.25it/s]
10/09/2021 12:11:32 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:11:32 - INFO - trainer -     T-F1 = 0.9892953551149586████████████████▌| 136/137 [00:18<00:00,  7.08it/s]
10/09/2021 12:11:32 - INFO - trainer -     T-F1(C) = 0.9808219178082193
10/09/2021 12:11:32 - INFO - trainer -     T-F1(D) = 0.9423312883435583
10/09/2021 12:11:32 - INFO - trainer -     T-F1(O) = 0.9945297148016359
10/09/2021 12:11:32 - INFO - trainer -     T-F1(P) = 0.9988513082322911
10/09/2021 12:11:32 - INFO - trainer -     T-F1(S) = 0.9930743751881963
10/09/2021 12:11:32 - INFO - trainer -     T-F1(T) = 0.9776555517359917
10/09/2021 12:11:32 - INFO - trainer -     U-F1(A) = 0.7806563039723662
10/09/2021 12:11:32 - INFO - trainer -     U-F1(E) = 0.8707079270877491
10/09/2021 12:11:32 - INFO - trainer -     U-F1(I) = 0.7301293900184841
10/09/2021 12:11:32 - INFO - trainer -     U-F1(O) = 0.9498087580985092
10/09/2021 12:11:32 - INFO - trainer -     intent_acc = 0.9141872487076392
10/09/2021 12:11:32 - INFO - trainer -     loss = 0.584907273512315
10/09/2021 12:11:32 - INFO - trainer -     semantic_frame_acc = 0.894428489373923
10/09/2021 12:11:32 - INFO - trainer -     slot_f1 = 0.9915139413820152
10/09/2021 12:11:32 - INFO - trainer -     slot_precision = 0.9903133903133903
10/09/2021 12:11:32 - INFO - trainer -     slot_recall = 0.9927174068256461

10/09/2021 12:11:32 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:11:32 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:11:32 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:11:32 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:11:32 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:11:32 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:11:32 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:11:32 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:11:32 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:11:32 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:11:32 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:11:32 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:11:32 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:11:32 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:11:32 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:11:32 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:11:32 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:12:19 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 479/815 [02:30<01:17,  4.33it/s]
10/09/2021 12:12:19 - INFO - trainer -     Num examples = 8705
10/09/2021 12:12:19 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:18<00:00,  7.22it/s]
10/09/2021 12:12:39 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:12:39 - INFO - trainer -     T-F1 = 0.9906061597420199████████████████▌| 136/137 [00:18<00:00,  7.07it/s]
10/09/2021 12:12:39 - INFO - trainer -     T-F1(C) = 0.9819073903710519
10/09/2021 12:12:39 - INFO - trainer -     T-F1(D) = 0.9488139825218477
10/09/2021 12:12:39 - INFO - trainer -     T-F1(O) = 0.9949399952314092
10/09/2021 12:12:39 - INFO - trainer -     T-F1(P) = 0.9991061167156174
10/09/2021 12:12:39 - INFO - trainer -     T-F1(S) = 0.9950128457004684
10/09/2021 12:12:39 - INFO - trainer -     T-F1(T) = 0.9788708001385521
10/09/2021 12:12:39 - INFO - trainer -     U-F1(A) = 0.7699194270367056
10/09/2021 12:12:39 - INFO - trainer -     U-F1(E) = 0.8634249471458774
10/09/2021 12:12:39 - INFO - trainer -     U-F1(I) = 0.7197802197802198
10/09/2021 12:12:39 - INFO - trainer -     U-F1(O) = 0.9485821128077283
10/09/2021 12:12:39 - INFO - trainer -     intent_acc = 0.911200459506031
10/09/2021 12:12:39 - INFO - trainer -     loss = 0.5905597602682363
10/09/2021 12:12:39 - INFO - trainer -     semantic_frame_acc = 0.8932797242963814
10/09/2021 12:12:39 - INFO - trainer -     slot_f1 = 0.9926333857817193
10/09/2021 12:12:39 - INFO - trainer -     slot_precision = 0.9943401633471844
10/09/2021 12:12:39 - INFO - trainer -     slot_recall = 0.9909324575182065

10/09/2021 12:12:39 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:12:39 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:12:39 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:12:39 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:12:39 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:12:39 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:12:39 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:12:39 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:12:39 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:12:39 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:12:39 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:12:39 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:12:39 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:12:39 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:12:39 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:12:39 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:12:39 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:13:25 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 679/815 [03:36<00:31,  4.30it/s]
10/09/2021 12:13:25 - INFO - trainer -     Num examples = 8705
10/09/2021 12:13:25 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:18<00:00,  7.21it/s]
10/09/2021 12:13:45 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:13:45 - INFO - trainer -     T-F1 = 0.9905774792424668████████████████▌| 136/137 [00:18<00:00,  7.08it/s]
10/09/2021 12:13:45 - INFO - trainer -     T-F1(C) = 0.9816737935247404
10/09/2021 12:13:45 - INFO - trainer -     T-F1(D) = 0.9491945477075588
10/09/2021 12:13:45 - INFO - trainer -     T-F1(O) = 0.995067098074577
10/09/2021 12:13:45 - INFO - trainer -     T-F1(P) = 0.9992341077355119
10/09/2021 12:13:45 - INFO - trainer -     T-F1(S) = 0.9944100317268469
10/09/2021 12:13:45 - INFO - trainer -     T-F1(T) = 0.9800275482093663
10/09/2021 12:13:45 - INFO - trainer -     U-F1(A) = 0.7796024200518582
10/09/2021 12:13:45 - INFO - trainer -     U-F1(E) = 0.8578574406002502
10/09/2021 12:13:45 - INFO - trainer -     U-F1(I) = 0.7289719626168225
10/09/2021 12:13:45 - INFO - trainer -     U-F1(O) = 0.9491551939924907
10/09/2021 12:13:45 - INFO - trainer -     intent_acc = 0.9117748420448019
10/09/2021 12:13:45 - INFO - trainer -     loss = 0.5929113650023402
10/09/2021 12:13:45 - INFO - trainer -     semantic_frame_acc = 0.8941987363584147
10/09/2021 12:13:45 - INFO - trainer -     slot_f1 = 0.9926793557833089
10/09/2021 12:13:45 - INFO - trainer -     slot_precision = 0.9929984996785025
10/09/2021 12:13:45 - INFO - trainer -     slot_recall = 0.9923604169641582

10/09/2021 12:13:45 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:13:45 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:13:45 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:13:45 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:13:45 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:13:45 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:13:45 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:13:45 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:13:45 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:13:45 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:13:45 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:13:45 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:13:45 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:13:45 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:13:45 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:13:45 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:13:45 - INFO - trainer -     slot_recall = 0.9896472940168499
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 815/815 [04:28<00:00,  3.04it/s]
Epoch:  45%|███████████████████████████████▉                                       | 9/20 [1:03:45<1:15:57, 414.36s/it]10/09/2021 12:14:31 - INFO - trainer -   ***** Running evaluation on dev dataset ***** | 64/815 [00:14<02:54,  4.31it/s]
10/09/2021 12:14:31 - INFO - trainer -     Num examples = 8705
10/09/2021 12:14:31 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:18<00:00,  7.22it/s]
10/09/2021 12:14:51 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:14:51 - INFO - trainer -     T-F1 = 0.9903075489282386████████████████▌| 136/137 [00:18<00:00,  7.10it/s]
10/09/2021 12:14:51 - INFO - trainer -     T-F1(C) = 0.9813740458015267
10/09/2021 12:14:51 - INFO - trainer -     T-F1(D) = 0.9504950495049505
10/09/2021 12:14:51 - INFO - trainer -     T-F1(O) = 0.9949580723914659
10/09/2021 12:14:51 - INFO - trainer -     T-F1(P) = 0.9985967597907897
10/09/2021 12:14:51 - INFO - trainer -     T-F1(S) = 0.9951690821256038
10/09/2021 12:14:51 - INFO - trainer -     T-F1(T) = 0.9780370624571036
10/09/2021 12:14:51 - INFO - trainer -     U-F1(A) = 0.787085514834206
10/09/2021 12:14:51 - INFO - trainer -     U-F1(E) = 0.8685567010309279
10/09/2021 12:14:51 - INFO - trainer -     U-F1(I) = 0.7401725790987536
10/09/2021 12:14:51 - INFO - trainer -     U-F1(O) = 0.9507484681610177
10/09/2021 12:14:51 - INFO - trainer -     intent_acc = 0.9163699023549684
10/09/2021 12:14:51 - INFO - trainer -     loss = 0.6166948432582482
10/09/2021 12:14:51 - INFO - trainer -     semantic_frame_acc = 0.8981045376220563
10/09/2021 12:14:51 - INFO - trainer -     slot_f1 = 0.9924355955184472
10/09/2021 12:14:51 - INFO - trainer -     slot_precision = 0.9919400855920114
10/09/2021 12:14:51 - INFO - trainer -     slot_recall = 0.992931600742539

10/09/2021 12:14:51 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:14:51 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:14:51 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:14:51 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:14:51 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:14:51 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:14:51 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:14:51 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:14:51 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:14:51 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:14:51 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:14:51 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:14:51 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:14:51 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:14:51 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:14:51 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:14:51 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:15:38 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 264/815 [01:21<02:07,  4.33it/s]
10/09/2021 12:15:38 - INFO - trainer -     Num examples = 8705
10/09/2021 12:15:38 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:18<00:00,  7.21it/s]
10/09/2021 12:15:58 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:15:58 - INFO - trainer -     T-F1 = 0.9893933755117231████████████████▌| 136/137 [00:18<00:00,  7.08it/s]
10/09/2021 12:15:58 - INFO - trainer -     T-F1(C) = 0.9807750991760756
10/09/2021 12:15:58 - INFO - trainer -     T-F1(D) = 0.9469790382244143
10/09/2021 12:15:58 - INFO - trainer -     T-F1(O) = 0.9943688907777306
10/09/2021 12:15:58 - INFO - trainer -     T-F1(P) = 0.9988521872210178
10/09/2021 12:15:58 - INFO - trainer -     T-F1(S) = 0.9935231209519505
10/09/2021 12:15:58 - INFO - trainer -     T-F1(T) = 0.9760928961748634
10/09/2021 12:15:58 - INFO - trainer -     U-F1(A) = 0.7783595113438044
10/09/2021 12:15:58 - INFO - trainer -     U-F1(E) = 0.8598210481465701
10/09/2021 12:15:58 - INFO - trainer -     U-F1(I) = 0.7330754352030948
10/09/2021 12:15:58 - INFO - trainer -     U-F1(O) = 0.9503997516106498
10/09/2021 12:15:58 - INFO - trainer -     intent_acc = 0.9139574956921309
10/09/2021 12:15:58 - INFO - trainer -     loss = 0.5799264632318174
10/09/2021 12:15:58 - INFO - trainer -     semantic_frame_acc = 0.8940838598506605
10/09/2021 12:15:58 - INFO - trainer -     slot_f1 = 0.9917325921174541
10/09/2021 12:15:58 - INFO - trainer -     slot_precision = 0.9899686966420034
10/09/2021 12:15:58 - INFO - trainer -     slot_recall = 0.9935027845209196

10/09/2021 12:15:58 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:15:58 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:15:58 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:15:58 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:15:58 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:15:58 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:15:58 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:15:58 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:15:58 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:15:58 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:15:58 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:15:58 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:15:58 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:15:58 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:15:58 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:15:58 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:15:58 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:16:44 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 464/815 [02:27<01:21,  4.31it/s]
10/09/2021 12:16:44 - INFO - trainer -     Num examples = 8705
10/09/2021 12:16:44 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.19it/s]
10/09/2021 12:17:04 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:17:04 - INFO - trainer -     T-F1 = 0.9897108803948043████████████████▌| 136/137 [00:19<00:00,  7.04it/s]
10/09/2021 12:17:04 - INFO - trainer -     T-F1(C) = 0.9798657718120806
10/09/2021 12:17:04 - INFO - trainer -     T-F1(D) = 0.9344660194174758
10/09/2021 12:17:04 - INFO - trainer -     T-F1(O) = 0.9945041816009559
10/09/2021 12:17:04 - INFO - trainer -     T-F1(P) = 0.9993618379068283
10/09/2021 12:17:04 - INFO - trainer -     T-F1(S) = 0.9942684766214178
10/09/2021 12:17:04 - INFO - trainer -     T-F1(T) = 0.9800824175824177
10/09/2021 12:17:04 - INFO - trainer -     U-F1(A) = 0.7796024200518582
10/09/2021 12:17:04 - INFO - trainer -     U-F1(E) = 0.8659265584970112
10/09/2021 12:17:04 - INFO - trainer -     U-F1(I) = 0.7217068645640075
10/09/2021 12:17:04 - INFO - trainer -     U-F1(O) = 0.9498948024624017
10/09/2021 12:17:04 - INFO - trainer -     intent_acc = 0.9131533601378518
10/09/2021 12:17:04 - INFO - trainer -     loss = 0.6313555147927968
10/09/2021 12:17:04 - INFO - trainer -     semantic_frame_acc = 0.8940838598506605
10/09/2021 12:17:04 - INFO - trainer -     slot_f1 = 0.9919771795328935
10/09/2021 12:17:04 - INFO - trainer -     slot_precision = 0.990811311346962
10/09/2021 12:17:04 - INFO - trainer -     slot_recall = 0.9931457946594316

10/09/2021 12:17:04 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:17:04 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:17:04 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:17:04 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:17:04 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:17:04 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:17:04 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:17:04 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:17:04 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:17:04 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:17:04 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:17:04 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:17:04 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:17:04 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:17:04 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:17:04 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:17:04 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:17:51 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 664/815 [03:33<00:34,  4.34it/s]
10/09/2021 12:17:51 - INFO - trainer -     Num examples = 8705
10/09/2021 12:17:51 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:18<00:00,  7.21it/s]
10/09/2021 12:18:11 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:18:11 - INFO - trainer -     T-F1 = 0.9905427440018635████████████████▌| 136/137 [00:18<00:00,  7.05it/s]
10/09/2021 12:18:11 - INFO - trainer -     T-F1(C) = 0.9810860280658938
10/09/2021 12:18:11 - INFO - trainer -     T-F1(D) = 0.9551122194513715
10/09/2021 12:18:11 - INFO - trainer -     T-F1(O) = 0.9948247034156957
10/09/2021 12:18:11 - INFO - trainer -     T-F1(P) = 0.9991065730695597
10/09/2021 12:18:11 - INFO - trainer -     T-F1(S) = 0.9950203712086917
10/09/2021 12:18:11 - INFO - trainer -     T-F1(T) = 0.9777625726992815
10/09/2021 12:18:11 - INFO - trainer -     U-F1(A) = 0.7736486486486487
10/09/2021 12:18:11 - INFO - trainer -     U-F1(E) = 0.8483333333333333
10/09/2021 12:18:11 - INFO - trainer -     U-F1(I) = 0.7319884726224782
10/09/2021 12:18:11 - INFO - trainer -     U-F1(O) = 0.9464215877982012
10/09/2021 12:18:11 - INFO - trainer -     intent_acc = 0.9083285468121769
10/09/2021 12:18:11 - INFO - trainer -     loss = 0.6289073004066327
10/09/2021 12:18:11 - INFO - trainer -     semantic_frame_acc = 0.8902929350947731
10/09/2021 12:18:11 - INFO - trainer -     slot_f1 = 0.9926153187542364
10/09/2021 12:18:11 - INFO - trainer -     slot_precision = 0.9919429590017825
10/09/2021 12:18:11 - INFO - trainer -     slot_recall = 0.9932885906040269

10/09/2021 12:18:11 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:18:11 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:18:11 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:18:11 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:18:11 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:18:11 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:18:11 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:18:11 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:18:11 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:18:11 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:18:11 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:18:11 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:18:11 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:18:11 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:18:11 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:18:11 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:18:11 - INFO - trainer -     slot_recall = 0.9896472940168499
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 815/815 [04:29<00:00,  3.03it/s]
Epoch:  50%|███████████████████████████████████                                   | 10/20 [1:08:14<1:01:34, 369.49s/it]10/09/2021 12:18:57 - INFO - trainer -   ***** Running evaluation on dev dataset ***** | 49/815 [00:11<02:56,  4.33it/s]
10/09/2021 12:18:57 - INFO - trainer -     Num examples = 8705
10/09/2021 12:18:57 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.21it/s]
10/09/2021 12:19:17 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:19:17 - INFO - trainer -     T-F1 = 0.9892012660584621████████████████▌| 136/137 [00:18<00:00,  7.09it/s]
10/09/2021 12:19:17 - INFO - trainer -     T-F1(C) = 0.9813512687251604
10/09/2021 12:19:17 - INFO - trainer -     T-F1(D) = 0.9503722084367247
10/09/2021 12:19:17 - INFO - trainer -     T-F1(O) = 0.9943175783324483
10/09/2021 12:19:17 - INFO - trainer -     T-F1(P) = 0.9991063449508489
10/09/2021 12:19:17 - INFO - trainer -     T-F1(S) = 0.9926282533473749
10/09/2021 12:19:17 - INFO - trainer -     T-F1(T) = 0.9743764947044755
10/09/2021 12:19:17 - INFO - trainer -     U-F1(A) = 0.779949022939677
10/09/2021 12:19:17 - INFO - trainer -     U-F1(E) = 0.8658484976724504
10/09/2021 12:19:17 - INFO - trainer -     U-F1(I) = 0.7318489835430784
10/09/2021 12:19:17 - INFO - trainer -     U-F1(O) = 0.9503778141310275
10/09/2021 12:19:17 - INFO - trainer -     intent_acc = 0.9144170017231477
10/09/2021 12:19:17 - INFO - trainer -     loss = 0.6443479962521199
10/09/2021 12:19:17 - INFO - trainer -     semantic_frame_acc = 0.8947731188971855
10/09/2021 12:19:17 - INFO - trainer -     slot_f1 = 0.9916224020534028
10/09/2021 12:19:17 - INFO - trainer -     slot_precision = 0.9902456390174439
10/09/2021 12:19:17 - INFO - trainer -     slot_recall = 0.9930029987148365

10/09/2021 12:19:17 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:19:17 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:19:17 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:19:17 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:19:17 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:19:17 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:19:17 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:19:17 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:19:17 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:19:17 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:19:17 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:19:17 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:19:17 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:19:17 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:19:17 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:19:17 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:19:17 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:20:03 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 249/815 [01:17<02:11,  4.29it/s]
10/09/2021 12:20:03 - INFO - trainer -     Num examples = 8705
10/09/2021 12:20:03 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.20it/s]
10/09/2021 12:20:24 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:20:24 - INFO - trainer -     T-F1 = 0.9896619167365185████████████████▌| 136/137 [00:19<00:00,  7.07it/s]
10/09/2021 12:20:24 - INFO - trainer -     T-F1(C) = 0.9804639804639805
10/09/2021 12:20:24 - INFO - trainer -     T-F1(D) = 0.9503722084367247
10/09/2021 12:20:24 - INFO - trainer -     T-F1(O) = 0.9946376426864878
10/09/2021 12:20:24 - INFO - trainer -     T-F1(P) = 0.9989790709545686
10/09/2021 12:20:24 - INFO - trainer -     T-F1(S) = 0.9936727930099427
10/09/2021 12:20:24 - INFO - trainer -     T-F1(T) = 0.9766963673749143
10/09/2021 12:20:24 - INFO - trainer -     U-F1(A) = 0.769742310889443
10/09/2021 12:20:24 - INFO - trainer -     U-F1(E) = 0.8594276094276094
10/09/2021 12:20:24 - INFO - trainer -     U-F1(I) = 0.7122557726465364
10/09/2021 12:20:24 - INFO - trainer -     U-F1(O) = 0.9457693821330185
10/09/2021 12:20:24 - INFO - trainer -     intent_acc = 0.9067202757036186
10/09/2021 12:20:24 - INFO - trainer -     loss = 0.673013472778342
10/09/2021 12:20:24 - INFO - trainer -     semantic_frame_acc = 0.8877656519241816
10/09/2021 12:20:24 - INFO - trainer -     slot_f1 = 0.9919760350914733
10/09/2021 12:20:24 - INFO - trainer -     slot_precision = 0.9909511934449591
10/09/2021 12:20:24 - INFO - trainer -     slot_recall = 0.9930029987148365

10/09/2021 12:20:24 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:20:24 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:20:24 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:20:24 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:20:24 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:20:24 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:20:24 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:20:24 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:20:24 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:20:24 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:20:24 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:20:24 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:20:24 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:20:24 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:20:24 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:20:24 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:20:24 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:21:10 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 449/815 [02:24<01:24,  4.33it/s]
10/09/2021 12:21:10 - INFO - trainer -     Num examples = 8705
10/09/2021 12:21:10 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.21it/s]
10/09/2021 12:21:30 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:21:30 - INFO - trainer -     T-F1 = 0.9906306810236329████████████████▌| 136/137 [00:18<00:00,  7.07it/s]
10/09/2021 12:21:30 - INFO - trainer -     T-F1(C) = 0.9834862385321099
10/09/2021 12:21:30 - INFO - trainer -     T-F1(D) = 0.9563046192259675
10/09/2021 12:21:30 - INFO - trainer -     T-F1(O) = 0.9948794141837574
10/09/2021 12:21:30 - INFO - trainer -     T-F1(P) = 0.9988518943742825
10/09/2021 12:21:30 - INFO - trainer -     T-F1(S) = 0.9947201689545935
10/09/2021 12:21:30 - INFO - trainer -     T-F1(T) = 0.9766643788606726
10/09/2021 12:21:30 - INFO - trainer -     U-F1(A) = 0.7735077677841375
10/09/2021 12:21:30 - INFO - trainer -     U-F1(E) = 0.8586911213005419
10/09/2021 12:21:30 - INFO - trainer -     U-F1(I) = 0.7326355851569935
10/09/2021 12:21:30 - INFO - trainer -     U-F1(O) = 0.9477899034309492
10/09/2021 12:21:30 - INFO - trainer -     intent_acc = 0.9102814474439977
10/09/2021 12:21:30 - INFO - trainer -     loss = 0.6548419629449252
10/09/2021 12:21:30 - INFO - trainer -     semantic_frame_acc = 0.8928202182653647
10/09/2021 12:21:30 - INFO - trainer -     slot_f1 = 0.9926475836961953
10/09/2021 12:21:30 - INFO - trainer -     slot_precision = 0.9924350556665715
10/09/2021 12:21:30 - INFO - trainer -     slot_recall = 0.9928602027702413

10/09/2021 12:21:30 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:21:30 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:21:30 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:21:30 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:21:30 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:21:30 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:21:30 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:21:30 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:21:30 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:21:30 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:21:30 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:21:30 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:21:30 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:21:30 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:21:30 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:21:30 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:21:30 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:22:16 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 649/815 [03:30<00:38,  4.29it/s]
10/09/2021 12:22:16 - INFO - trainer -     Num examples = 8705
10/09/2021 12:22:16 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.20it/s]
10/09/2021 12:22:36 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:22:36 - INFO - trainer -     T-F1 = 0.9889752058426757████████████████▌| 136/137 [00:19<00:00,  7.08it/s]
10/09/2021 12:22:36 - INFO - trainer -     T-F1(C) = 0.9825741363497401
10/09/2021 12:22:36 - INFO - trainer -     T-F1(D) = 0.9411764705882353
10/09/2021 12:22:36 - INFO - trainer -     T-F1(O) = 0.9941828034106303
10/09/2021 12:22:36 - INFO - trainer -     T-F1(P) = 0.9987241643276347
10/09/2021 12:22:36 - INFO - trainer -     T-F1(S) = 0.99471857552437
10/09/2021 12:22:36 - INFO - trainer -     T-F1(T) = 0.970458404074703
10/09/2021 12:22:36 - INFO - trainer -     U-F1(A) = 0.7628318584070796
10/09/2021 12:22:36 - INFO - trainer -     U-F1(E) = 0.8497748669668441
10/09/2021 12:22:36 - INFO - trainer -     U-F1(I) = 0.705161854768154
10/09/2021 12:22:36 - INFO - trainer -     U-F1(O) = 0.9439105089018434
10/09/2021 12:22:36 - INFO - trainer -     intent_acc = 0.9032739804709937
10/09/2021 12:22:36 - INFO - trainer -     loss = 0.6501290939240988
10/09/2021 12:22:36 - INFO - trainer -     semantic_frame_acc = 0.8830557151062608
10/09/2021 12:22:36 - INFO - trainer -     slot_f1 = 0.9912671538050258
10/09/2021 12:22:36 - INFO - trainer -     slot_precision = 0.9897501601537476
10/09/2021 12:22:36 - INFO - trainer -     slot_recall = 0.9927888047979437

10/09/2021 12:22:36 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:22:36 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:22:36 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:22:36 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:22:36 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:22:36 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:22:36 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:22:36 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:22:36 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:22:36 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:22:36 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:22:36 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:22:36 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:22:36 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:22:36 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:22:36 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:22:36 - INFO - trainer -     slot_recall = 0.9896472940168499
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 815/815 [04:29<00:00,  3.03it/s]
Epoch:  55%|███████████████████████████████████████▌                                | 11/20 [1:12:43<50:48, 338.75s/it]10/09/2021 12:23:23 - INFO - trainer -   ***** Running evaluation on dev dataset ***** | 34/815 [00:07<03:01,  4.31it/s]
10/09/2021 12:23:23 - INFO - trainer -     Num examples = 8705
10/09/2021 12:23:23 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.20it/s]
10/09/2021 12:23:43 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:23:43 - INFO - trainer -     T-F1 = 0.9892453093719445████████████████▌| 136/137 [00:18<00:00,  7.08it/s]
10/09/2021 12:23:43 - INFO - trainer -     T-F1(C) = 0.9772105742935279
10/09/2021 12:23:43 - INFO - trainer -     T-F1(D) = 0.9516728624535317
10/09/2021 12:23:43 - INFO - trainer -     T-F1(O) = 0.9943448825169255
10/09/2021 12:23:43 - INFO - trainer -     T-F1(P) = 0.9988518943742825
10/09/2021 12:23:43 - INFO - trainer -     T-F1(S) = 0.9941220798794271
10/09/2021 12:23:43 - INFO - trainer -     T-F1(T) = 0.9762641898864809
10/09/2021 12:23:43 - INFO - trainer -     U-F1(A) = 0.7780725022104331
10/09/2021 12:23:43 - INFO - trainer -     U-F1(E) = 0.8639658848614071
10/09/2021 12:23:43 - INFO - trainer -     U-F1(I) = 0.7102473498233215
10/09/2021 12:23:43 - INFO - trainer -     U-F1(O) = 0.9479768786127168
10/09/2021 12:23:43 - INFO - trainer -     intent_acc = 0.9101665709362435
10/09/2021 12:23:43 - INFO - trainer -     loss = 0.644304373420955
10/09/2021 12:23:43 - INFO - trainer -     semantic_frame_acc = 0.8898334290637565
10/09/2021 12:23:43 - INFO - trainer -     slot_f1 = 0.9915486930784866
10/09/2021 12:23:43 - INFO - trainer -     slot_precision = 0.9904538006696587
10/09/2021 12:23:43 - INFO - trainer -     slot_recall = 0.9926460088533485

10/09/2021 12:23:43 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:23:43 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:23:43 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:23:43 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:23:43 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:23:43 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:23:43 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:23:43 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:23:43 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:23:43 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:23:43 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:23:43 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:23:43 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:23:43 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:23:43 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:23:43 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:23:43 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:24:29 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 234/815 [01:14<02:14,  4.32it/s]
10/09/2021 12:24:29 - INFO - trainer -     Num examples = 8705
10/09/2021 12:24:29 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.21it/s]
10/09/2021 12:24:49 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:24:49 - INFO - trainer -     T-F1 = 0.9898848645877033████████████████▌| 136/137 [00:18<00:00,  7.10it/s]
10/09/2021 12:24:49 - INFO - trainer -     T-F1(C) = 0.9816625916870415
10/09/2021 12:24:49 - INFO - trainer -     T-F1(D) = 0.9411764705882353
10/09/2021 12:24:49 - INFO - trainer -     T-F1(O) = 0.9947202249873975
10/09/2021 12:24:49 - INFO - trainer -     T-F1(P) = 0.9985949674287904
10/09/2021 12:24:49 - INFO - trainer -     T-F1(S) = 0.9942719324690985
10/09/2021 12:24:49 - INFO - trainer -     T-F1(T) = 0.9793246037215713
10/09/2021 12:24:49 - INFO - trainer -     U-F1(A) = 0.7818499127399651
10/09/2021 12:24:49 - INFO - trainer -     U-F1(E) = 0.8687042617305208
10/09/2021 12:24:49 - INFO - trainer -     U-F1(I) = 0.7332704995287463
10/09/2021 12:24:49 - INFO - trainer -     U-F1(O) = 0.9510869565217392
10/09/2021 12:24:49 - INFO - trainer -     intent_acc = 0.9156806433084435
10/09/2021 12:24:49 - INFO - trainer -     loss = 0.6753796047671702
10/09/2021 12:24:49 - INFO - trainer -     semantic_frame_acc = 0.8960367604824814
10/09/2021 12:24:49 - INFO - trainer -     slot_f1 = 0.9919697348227988
10/09/2021 12:24:49 - INFO - trainer -     slot_precision = 0.9917219724541497
10/09/2021 12:24:49 - INFO - trainer -     slot_recall = 0.992217621019563

10/09/2021 12:24:49 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:24:49 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:24:49 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:24:49 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:24:49 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:24:49 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:24:49 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:24:49 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:24:49 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:24:49 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:24:49 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:24:49 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:24:49 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:24:49 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:24:49 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:24:49 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:24:49 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:25:35 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 434/815 [02:20<01:28,  4.32it/s]
10/09/2021 12:25:35 - INFO - trainer -     Num examples = 8705
10/09/2021 12:25:35 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.21it/s]
10/09/2021 12:25:55 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:25:55 - INFO - trainer -     T-F1 = 0.9898980494390391████████████████▌| 136/137 [00:18<00:00,  7.08it/s]
10/09/2021 12:25:55 - INFO - trainer -     T-F1(C) = 0.9832163564235581
10/09/2021 12:25:55 - INFO - trainer -     T-F1(D) = 0.9356014580801945
10/09/2021 12:25:55 - INFO - trainer -     T-F1(O) = 0.9946100947879882
10/09/2021 12:25:55 - INFO - trainer -     T-F1(P) = 0.9989793314621077
10/09/2021 12:25:55 - INFO - trainer -     T-F1(S) = 0.9945717732207479
10/09/2021 12:25:55 - INFO - trainer -     T-F1(T) = 0.9776709034695981
10/09/2021 12:25:55 - INFO - trainer -     U-F1(A) = 0.7836153161175424
10/09/2021 12:25:55 - INFO - trainer -     U-F1(E) = 0.8636953699697101
10/09/2021 12:25:55 - INFO - trainer -     U-F1(I) = 0.7243947858472998
10/09/2021 12:25:55 - INFO - trainer -     U-F1(O) = 0.9508603317315145
10/09/2021 12:25:55 - INFO - trainer -     intent_acc = 0.9145318782309018
10/09/2021 12:25:55 - INFO - trainer -     loss = 0.681959666305474
10/09/2021 12:25:55 - INFO - trainer -     semantic_frame_acc = 0.8953475014359563
10/09/2021 12:25:55 - INFO - trainer -     slot_f1 = 0.9920479263987448
10/09/2021 12:25:55 - INFO - trainer -     slot_precision = 0.9909524827242289
10/09/2021 12:25:55 - INFO - trainer -     slot_recall = 0.9931457946594316

10/09/2021 12:25:55 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:25:55 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:25:55 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:25:55 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:25:55 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:25:55 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:25:55 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:25:55 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:25:55 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:25:55 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:25:55 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:25:55 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:25:55 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:25:55 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:25:55 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:25:55 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:25:55 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:26:42 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 634/815 [03:26<00:41,  4.33it/s]
10/09/2021 12:26:42 - INFO - trainer -     Num examples = 8705
10/09/2021 12:26:42 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.21it/s]
10/09/2021 12:27:02 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:27:02 - INFO - trainer -     T-F1 = 0.9908607665765178████████████████▌| 136/137 [00:18<00:00,  7.09it/s]
10/09/2021 12:27:02 - INFO - trainer -     T-F1(C) = 0.9837771655953473
10/09/2021 12:27:02 - INFO - trainer -     T-F1(D) = 0.9538077403245944
10/09/2021 12:27:02 - INFO - trainer -     T-F1(O) = 0.9951721576741472
10/09/2021 12:27:02 - INFO - trainer -     T-F1(P) = 0.9988516013780784
10/09/2021 12:27:02 - INFO - trainer -     T-F1(S) = 0.9939722724532851
10/09/2021 12:27:02 - INFO - trainer -     T-F1(T) = 0.9803786574870913
10/09/2021 12:27:02 - INFO - trainer -     U-F1(A) = 0.7679324894514769
10/09/2021 12:27:02 - INFO - trainer -     U-F1(E) = 0.8682761541719609
10/09/2021 12:27:02 - INFO - trainer -     U-F1(I) = 0.7392996108949416
10/09/2021 12:27:02 - INFO - trainer -     U-F1(O) = 0.9502960423808039
10/09/2021 12:27:02 - INFO - trainer -     intent_acc = 0.9143021252153934
10/09/2021 12:27:02 - INFO - trainer -     loss = 0.6611417462160457
10/09/2021 12:27:02 - INFO - trainer -     semantic_frame_acc = 0.8973004020677772
10/09/2021 12:27:02 - INFO - trainer -     slot_f1 = 0.9928596929667975
10/09/2021 12:27:02 - INFO - trainer -     slot_precision = 0.9929305912596401
10/09/2021 12:27:02 - INFO - trainer -     slot_recall = 0.9927888047979437

10/09/2021 12:27:02 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:27:02 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:27:02 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:27:02 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:27:02 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:27:02 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:27:02 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:27:02 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:27:02 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:27:02 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:27:02 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:27:02 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:27:02 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:27:02 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:27:02 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:27:02 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:27:02 - INFO - trainer -     slot_recall = 0.9896472940168499
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 815/815 [04:28<00:00,  3.03it/s]
Epoch:  60%|███████████████████████████████████████████▏                            | 12/20 [1:17:12<42:19, 317.49s/it]10/09/2021 12:27:48 - INFO - trainer -   ***** Running evaluation on dev dataset ***** | 19/815 [00:04<03:04,  4.32it/s]
10/09/2021 12:27:48 - INFO - trainer -     Num examples = 8705
10/09/2021 12:27:48 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.21it/s]
10/09/2021 12:28:08 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:28:08 - INFO - trainer -     T-F1 = 0.990952336535771█████████████████▌| 136/137 [00:18<00:00,  7.09it/s]
10/09/2021 12:28:08 - INFO - trainer -     T-F1(C) = 0.9837870908534722
10/09/2021 12:28:08 - INFO - trainer -     T-F1(D) = 0.9539227895392279
10/09/2021 12:28:08 - INFO - trainer -     T-F1(O) = 0.9951726698848867
10/09/2021 12:28:08 - INFO - trainer -     T-F1(P) = 0.9988516013780784
10/09/2021 12:28:08 - INFO - trainer -     T-F1(S) = 0.9948717948717949
10/09/2021 12:28:08 - INFO - trainer -     T-F1(T) = 0.9789872545642438
10/09/2021 12:28:08 - INFO - trainer -     U-F1(A) = 0.7768888888888889
10/09/2021 12:28:08 - INFO - trainer -     U-F1(E) = 0.8587281263337602
10/09/2021 12:28:08 - INFO - trainer -     U-F1(I) = 0.7349282296650719
10/09/2021 12:28:08 - INFO - trainer -     U-F1(O) = 0.9498332945646274
10/09/2021 12:28:08 - INFO - trainer -     intent_acc = 0.9134979896611143
10/09/2021 12:28:08 - INFO - trainer -     loss = 0.6785769980021814
10/09/2021 12:28:08 - INFO - trainer -     semantic_frame_acc = 0.8967260195290063
10/09/2021 12:28:08 - INFO - trainer -     slot_f1 = 0.992894633484486
10/09/2021 12:28:08 - INFO - trainer -     slot_precision = 0.9930719234340404
10/09/2021 12:28:08 - INFO - trainer -     slot_recall = 0.9927174068256461

10/09/2021 12:28:08 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:28:08 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:28:08 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:28:08 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:28:08 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:28:08 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:28:08 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:28:08 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:28:08 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:28:08 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:28:08 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:28:08 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:28:08 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:28:08 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:28:08 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:28:08 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:28:08 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:28:54 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 219/815 [01:10<02:18,  4.31it/s]
10/09/2021 12:28:54 - INFO - trainer -     Num examples = 8705
10/09/2021 12:28:54 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.20it/s]
10/09/2021 12:29:14 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:29:14 - INFO - trainer -     T-F1 = 0.9894776049911537████████████████▌| 136/137 [00:19<00:00,  7.08it/s]
10/09/2021 12:29:14 - INFO - trainer -     T-F1(C) = 0.9825528007346189
10/09/2021 12:29:14 - INFO - trainer -     T-F1(D) = 0.9482758620689655
10/09/2021 12:29:14 - INFO - trainer -     T-F1(O) = 0.9944777783677587
10/09/2021 12:29:14 - INFO - trainer -     T-F1(P) = 0.9987241643276347
10/09/2021 12:29:14 - INFO - trainer -     T-F1(S) = 0.9930764599638773
10/09/2021 12:29:14 - INFO - trainer -     T-F1(T) = 0.975659924580048
10/09/2021 12:29:14 - INFO - trainer -     U-F1(A) = 0.7660311958405546
10/09/2021 12:29:14 - INFO - trainer -     U-F1(E) = 0.8570244508910071
10/09/2021 12:29:14 - INFO - trainer -     U-F1(I) = 0.7269338303821061
10/09/2021 12:29:14 - INFO - trainer -     U-F1(O) = 0.947533281127643
10/09/2021 12:29:14 - INFO - trainer -     intent_acc = 0.9093624353819644
10/09/2021 12:29:14 - INFO - trainer -     loss = 0.7088202734580425
10/09/2021 12:29:14 - INFO - trainer -     semantic_frame_acc = 0.8900631820792648
10/09/2021 12:29:14 - INFO - trainer -     slot_f1 = 0.9917620626939124
10/09/2021 12:29:14 - INFO - trainer -     slot_precision = 0.9907374421090132
10/09/2021 12:29:14 - INFO - trainer -     slot_recall = 0.9927888047979437

10/09/2021 12:29:14 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:29:14 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:29:14 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:29:14 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:29:14 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:29:14 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:29:14 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:29:14 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:29:14 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:29:14 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:29:14 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:29:14 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:29:14 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:29:14 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:29:14 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:29:14 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:29:14 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:30:01 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 419/815 [02:17<01:31,  4.31it/s]
10/09/2021 12:30:01 - INFO - trainer -     Num examples = 8705
10/09/2021 12:30:01 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.20it/s]
10/09/2021 12:30:21 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:30:21 - INFO - trainer -     T-F1 = 0.9896657666883903████████████████▌| 136/137 [00:19<00:00,  7.09it/s]
10/09/2021 12:30:21 - INFO - trainer -     T-F1(C) = 0.9816737935247404
10/09/2021 12:30:21 - INFO - trainer -     T-F1(D) = 0.947109471094711
10/09/2021 12:30:21 - INFO - trainer -     T-F1(O) = 0.9945833997132388
10/09/2021 12:30:21 - INFO - trainer -     T-F1(P) = 0.9985971177145773
10/09/2021 12:30:21 - INFO - trainer -     T-F1(S) = 0.9938225101702577
10/09/2021 12:30:21 - INFO - trainer -     T-F1(T) = 0.977031196434693
10/09/2021 12:30:21 - INFO - trainer -     U-F1(A) = 0.7586790855207451
10/09/2021 12:30:21 - INFO - trainer -     U-F1(E) = 0.8514261387824605
10/09/2021 12:30:21 - INFO - trainer -     U-F1(I) = 0.7348119575699131
10/09/2021 12:30:21 - INFO - trainer -     U-F1(O) = 0.9472864595499494
10/09/2021 12:30:21 - INFO - trainer -     intent_acc = 0.9089029293509477
10/09/2021 12:30:21 - INFO - trainer -     loss = 0.7188961509127428
10/09/2021 12:30:21 - INFO - trainer -     semantic_frame_acc = 0.8904078116025272
10/09/2021 12:30:21 - INFO - trainer -     slot_f1 = 0.9918699186991871
10/09/2021 12:30:21 - INFO - trainer -     slot_precision = 0.9907394215700243
10/09/2021 12:30:21 - INFO - trainer -     slot_recall = 0.9930029987148365

10/09/2021 12:30:21 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:30:21 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:30:21 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:30:21 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:30:21 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:30:21 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:30:21 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:30:21 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:30:21 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:30:21 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:30:21 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:30:21 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:30:21 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:30:21 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:30:21 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:30:21 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:30:21 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:31:07 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 619/815 [03:23<00:45,  4.31it/s]
10/09/2021 12:31:07 - INFO - trainer -     Num examples = 8705
10/09/2021 12:31:07 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.20it/s]
10/09/2021 12:31:27 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:31:27 - INFO - trainer -     T-F1 = 0.9886458818054908████████████████▌| 136/137 [00:19<00:00,  7.12it/s]
10/09/2021 12:31:27 - INFO - trainer -     T-F1(C) = 0.9801405438435686
10/09/2021 12:31:27 - INFO - trainer -     T-F1(D) = 0.9424724602203182
10/09/2021 12:31:27 - INFO - trainer -     T-F1(O) = 0.9940510968290222
10/09/2021 12:31:27 - INFO - trainer -     T-F1(P) = 0.998469387755102
10/09/2021 12:31:27 - INFO - trainer -     T-F1(S) = 0.9930722891566265
10/09/2021 12:31:27 - INFO - trainer -     T-F1(T) = 0.9746575342465753
10/09/2021 12:31:27 - INFO - trainer -     U-F1(A) = 0.7662222222222222
10/09/2021 12:31:27 - INFO - trainer -     U-F1(E) = 0.8615253515125693
10/09/2021 12:31:27 - INFO - trainer -     U-F1(I) = 0.7392550143266475
10/09/2021 12:31:27 - INFO - trainer -     U-F1(O) = 0.9501202389263828
10/09/2021 12:31:27 - INFO - trainer -     intent_acc = 0.9136128661688685
10/09/2021 12:31:27 - INFO - trainer -     loss = 0.6900332383848651
10/09/2021 12:31:27 - INFO - trainer -     semantic_frame_acc = 0.8924755887421022
10/09/2021 12:31:27 - INFO - trainer -     slot_f1 = 0.9910160427807485
10/09/2021 12:31:27 - INFO - trainer -     slot_precision = 0.9896753061805753
10/09/2021 12:31:27 - INFO - trainer -     slot_recall = 0.9923604169641582

10/09/2021 12:31:27 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:31:27 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:31:27 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:31:27 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:31:27 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:31:27 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:31:27 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:31:27 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:31:27 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:31:27 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:31:27 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:31:27 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:31:27 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:31:27 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:31:27 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:31:27 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:31:27 - INFO - trainer -     slot_recall = 0.9896472940168499
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 815/815 [04:28<00:00,  3.03it/s]
Epoch:  65%|██████████████████████████████████████████████▊                         | 13/20 [1:21:41<35:19, 302.79s/it]10/09/2021 12:32:13 - INFO - trainer -   ***** Running evaluation on dev dataset *****  | 4/815 [00:00<03:07,  4.32it/s]
10/09/2021 12:32:13 - INFO - trainer -     Num examples = 8705
10/09/2021 12:32:13 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.18it/s]
10/09/2021 12:32:34 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:32:34 - INFO - trainer -     T-F1 = 0.9898895774122909████████████████▌| 136/137 [00:19<00:00,  7.06it/s]
10/09/2021 12:32:34 - INFO - trainer -     T-F1(C) = 0.9828641370869033
10/09/2021 12:32:34 - INFO - trainer -     T-F1(D) = 0.9503722084367247
10/09/2021 12:32:34 - INFO - trainer -     T-F1(O) = 0.9947188238104084
10/09/2021 12:32:34 - INFO - trainer -     T-F1(P) = 0.9985971177145773
10/09/2021 12:32:34 - INFO - trainer -     T-F1(S) = 0.9930722891566265
10/09/2021 12:32:34 - INFO - trainer -     T-F1(T) = 0.9779917469050895
10/09/2021 12:32:34 - INFO - trainer -     U-F1(A) = 0.770940170940171
10/09/2021 12:32:34 - INFO - trainer -     U-F1(E) = 0.8632296548785684
10/09/2021 12:32:34 - INFO - trainer -     U-F1(I) = 0.7129963898916968
10/09/2021 12:32:34 - INFO - trainer -     U-F1(O) = 0.9470473210793899
10/09/2021 12:32:34 - INFO - trainer -     intent_acc = 0.9090178058587018
10/09/2021 12:32:34 - INFO - trainer -     loss = 0.685905507128825
10/09/2021 12:32:34 - INFO - trainer -     semantic_frame_acc = 0.8907524411257898
10/09/2021 12:32:34 - INFO - trainer -     slot_f1 = 0.9920433867342205
10/09/2021 12:32:34 - INFO - trainer -     slot_precision = 0.9915127309036446
10/09/2021 12:32:34 - INFO - trainer -     slot_recall = 0.9925746108810509

10/09/2021 12:32:34 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:32:34 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:32:34 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:32:34 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:32:34 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:32:34 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:32:34 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:32:34 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:32:34 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:32:34 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:32:34 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:32:34 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:32:34 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:32:34 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:32:34 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:32:34 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:32:34 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:33:20 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 204/815 [01:07<02:21,  4.33it/s]
10/09/2021 12:33:20 - INFO - trainer -     Num examples = 8705
10/09/2021 12:33:20 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.21it/s]
10/09/2021 12:33:40 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:33:40 - INFO - trainer -     T-F1 = 0.9892943585924409████████████████▌| 136/137 [00:18<00:00,  7.08it/s]
10/09/2021 12:33:40 - INFO - trainer -     T-F1(C) = 0.980213089802131
10/09/2021 12:33:40 - INFO - trainer -     T-F1(D) = 0.943765281173594
10/09/2021 12:33:40 - INFO - trainer -     T-F1(O) = 0.9942644715878917
10/09/2021 12:33:40 - INFO - trainer -     T-F1(P) = 0.9991063449508489
10/09/2021 12:33:40 - INFO - trainer -     T-F1(S) = 0.9944201477906802
10/09/2021 12:33:40 - INFO - trainer -     T-F1(T) = 0.9742886527254028
10/09/2021 12:33:40 - INFO - trainer -     U-F1(A) = 0.7700440528634362
10/09/2021 12:33:40 - INFO - trainer -     U-F1(E) = 0.8616932103939647
10/09/2021 12:33:40 - INFO - trainer -     U-F1(I) = 0.7159309021113244
10/09/2021 12:33:40 - INFO - trainer -     U-F1(O) = 0.9488596559508055
10/09/2021 12:33:40 - INFO - trainer -     intent_acc = 0.9113153360137852
10/09/2021 12:33:40 - INFO - trainer -     loss = 0.6959959952025606
10/09/2021 12:33:40 - INFO - trainer -     semantic_frame_acc = 0.8915565766800689
10/09/2021 12:33:40 - INFO - trainer -     slot_f1 = 0.991657159155733
10/09/2021 12:33:40 - INFO - trainer -     slot_precision = 0.9903859849024356
10/09/2021 12:33:40 - INFO - trainer -     slot_recall = 0.992931600742539

10/09/2021 12:33:40 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:33:40 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:33:40 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:33:40 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:33:40 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:33:40 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:33:40 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:33:40 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:33:40 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:33:40 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:33:40 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:33:40 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:33:40 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:33:40 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:33:40 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:33:40 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:33:40 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:34:26 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 404/815 [02:13<01:35,  4.30it/s]
10/09/2021 12:34:26 - INFO - trainer -     Num examples = 8705
10/09/2021 12:34:26 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.20it/s]
10/09/2021 12:34:46 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:34:46 - INFO - trainer -     T-F1 = 0.990215264187867█████████████████▌| 136/137 [00:19<00:00,  7.09it/s]
10/09/2021 12:34:46 - INFO - trainer -     T-F1(C) = 0.9825847846012832
10/09/2021 12:34:46 - INFO - trainer -     T-F1(D) = 0.9515527950310559
10/09/2021 12:34:46 - INFO - trainer -     T-F1(O) = 0.9948516533092724
10/09/2021 12:34:46 - INFO - trainer -     T-F1(P) = 0.9987241643276347
10/09/2021 12:34:46 - INFO - trainer -     T-F1(S) = 0.9941220798794271
10/09/2021 12:34:46 - INFO - trainer -     T-F1(T) = 0.9776709034695981
10/09/2021 12:34:46 - INFO - trainer -     U-F1(A) = 0.7722602739726028
10/09/2021 12:34:46 - INFO - trainer -     U-F1(E) = 0.8642186165670368
10/09/2021 12:34:46 - INFO - trainer -     U-F1(I) = 0.7282809611829943
10/09/2021 12:34:46 - INFO - trainer -     U-F1(O) = 0.9488219691059447
10/09/2021 12:34:46 - INFO - trainer -     intent_acc = 0.911889718552556
10/09/2021 12:34:46 - INFO - trainer -     loss = 0.719786485453847
10/09/2021 12:34:46 - INFO - trainer -     semantic_frame_acc = 0.8939689833429064
10/09/2021 12:34:46 - INFO - trainer -     slot_f1 = 0.9924001855353766
10/09/2021 12:34:46 - INFO - trainer -     slot_precision = 0.9918693388488695
10/09/2021 12:34:46 - INFO - trainer -     slot_recall = 0.992931600742539

10/09/2021 12:34:46 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:34:46 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:34:46 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:34:46 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:34:46 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:34:46 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:34:46 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:34:46 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:34:46 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:34:46 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:34:46 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:34:46 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:34:46 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:34:46 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:34:46 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:34:46 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:34:46 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:35:33 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 604/815 [03:20<00:48,  4.33it/s]
10/09/2021 12:35:33 - INFO - trainer -     Num examples = 8705
10/09/2021 12:35:33 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.21it/s]
10/09/2021 12:35:53 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:35:53 - INFO - trainer -     T-F1 = 0.990073169595004█████████████████▌| 136/137 [00:18<00:00,  7.09it/s]
10/09/2021 12:35:53 - INFO - trainer -     T-F1(C) = 0.9828850855745721
10/09/2021 12:35:53 - INFO - trainer -     T-F1(D) = 0.9514321295143212
10/09/2021 12:35:53 - INFO - trainer -     T-F1(O) = 0.9947196646058322
10/09/2021 12:35:53 - INFO - trainer -     T-F1(P) = 0.9983420482081368
10/09/2021 12:35:53 - INFO - trainer -     T-F1(S) = 0.9938225101702577
10/09/2021 12:35:53 - INFO - trainer -     T-F1(T) = 0.9779614325068869
10/09/2021 12:35:53 - INFO - trainer -     U-F1(A) = 0.7836663770634231
10/09/2021 12:35:53 - INFO - trainer -     U-F1(E) = 0.8550786230344242
10/09/2021 12:35:53 - INFO - trainer -     U-F1(I) = 0.7203703703703703
10/09/2021 12:35:53 - INFO - trainer -     U-F1(O) = 0.9476064244503352
10/09/2021 12:35:53 - INFO - trainer -     intent_acc = 0.9101665709362435
10/09/2021 12:35:53 - INFO - trainer -     loss = 0.6965802681425639
10/09/2021 12:35:53 - INFO - trainer -     semantic_frame_acc = 0.8919012062033315
10/09/2021 12:35:53 - INFO - trainer -     slot_f1 = 0.9922917707515523
10/09/2021 12:35:53 - INFO - trainer -     slot_precision = 0.9919377853881278
10/09/2021 12:35:53 - INFO - trainer -     slot_recall = 0.9926460088533485

10/09/2021 12:35:53 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:35:53 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:35:53 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:35:53 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:35:53 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:35:53 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:35:53 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:35:53 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:35:53 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:35:53 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:35:53 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:35:53 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:35:53 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:35:53 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:35:53 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:35:53 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:35:53 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:36:39 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 804/815 [04:26<00:02,  4.33it/s]
10/09/2021 12:36:39 - INFO - trainer -     Num examples = 8705
10/09/2021 12:36:39 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.20it/s]
10/09/2021 12:36:59 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:36:59 - INFO - trainer -     T-F1 = 0.9904460082956611████████████████▌| 136/137 [00:19<00:00,  7.08it/s]
10/09/2021 12:36:59 - INFO - trainer -     T-F1(C) = 0.983206106870229
10/09/2021 12:36:59 - INFO - trainer -     T-F1(D) = 0.948019801980198
10/09/2021 12:36:59 - INFO - trainer -     T-F1(O) = 0.9948258020006898
10/09/2021 12:36:59 - INFO - trainer -     T-F1(P) = 0.998469778117827
10/09/2021 12:36:59 - INFO - trainer -     T-F1(S) = 0.9947201689545935
10/09/2021 12:36:59 - INFO - trainer -     T-F1(T) = 0.9789872545642438
10/09/2021 12:36:59 - INFO - trainer -     U-F1(A) = 0.7694886839899414
10/09/2021 12:36:59 - INFO - trainer -     U-F1(E) = 0.86504895700298
10/09/2021 12:36:59 - INFO - trainer -     U-F1(I) = 0.7241063244729606
10/09/2021 12:36:59 - INFO - trainer -     U-F1(O) = 0.9473272286139156
10/09/2021 12:36:59 - INFO - trainer -     intent_acc = 0.9100516944284893
10/09/2021 12:36:59 - INFO - trainer -     loss = 0.7111895352409325
10/09/2021 12:36:59 - INFO - trainer -     semantic_frame_acc = 0.8923607122343481
10/09/2021 12:36:59 - INFO - trainer -     slot_f1 = 0.9925058882306759
10/09/2021 12:36:59 - INFO - trainer -     slot_precision = 0.9921518264840182
10/09/2021 12:36:59 - INFO - trainer -     slot_recall = 0.9928602027702413

10/09/2021 12:36:59 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:36:59 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:36:59 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:36:59 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:36:59 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:36:59 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:36:59 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:36:59 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:36:59 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:36:59 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:36:59 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:36:59 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:36:59 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:36:59 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:36:59 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:36:59 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:36:59 - INFO - trainer -     slot_recall = 0.9896472940168499
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 815/815 [04:49<00:00,  2.82it/s]
Epoch:  70%|██████████████████████████████████████████████████▍                     | 14/20 [1:26:30<29:51, 298.63s/it]10/09/2021 12:37:45 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 189/815 [00:43<02:24,  4.33it/s]
10/09/2021 12:37:45 - INFO - trainer -     Num examples = 8705
10/09/2021 12:37:45 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:18<00:00,  7.21it/s]
10/09/2021 12:38:05 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:38:05 - INFO - trainer -     T-F1 = 0.9909531803767954████████████████▌| 136/137 [00:18<00:00,  7.10it/s]
10/09/2021 12:38:05 - INFO - trainer -     T-F1(C) = 0.9846907532149418
10/09/2021 12:38:05 - INFO - trainer -     T-F1(D) = 0.9539227895392279
10/09/2021 12:38:05 - INFO - trainer -     T-F1(O) = 0.9951193633952254
10/09/2021 12:38:05 - INFO - trainer -     T-F1(P) = 0.998469778117827
10/09/2021 12:38:05 - INFO - trainer -     T-F1(S) = 0.9951719975859987
10/09/2021 12:38:05 - INFO - trainer -     T-F1(T) = 0.9783132530120482
10/09/2021 12:38:05 - INFO - trainer -     U-F1(A) = 0.7769911504424779
10/09/2021 12:38:05 - INFO - trainer -     U-F1(E) = 0.858603066439523
10/09/2021 12:38:05 - INFO - trainer -     U-F1(I) = 0.733772342427093
10/09/2021 12:38:05 - INFO - trainer -     U-F1(O) = 0.9495687310591343
10/09/2021 12:38:05 - INFO - trainer -     intent_acc = 0.9129236071223434
10/09/2021 12:38:05 - INFO - trainer -     loss = 0.7213650096460019
10/09/2021 12:38:05 - INFO - trainer -     semantic_frame_acc = 0.8963813900057438
10/09/2021 12:38:05 - INFO - trainer -     slot_f1 = 0.9929310960371296
10/09/2021 12:38:05 - INFO - trainer -     slot_precision = 0.9930019994287347
10/09/2021 12:38:05 - INFO - trainer -     slot_recall = 0.9928602027702413

10/09/2021 12:38:05 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:38:05 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:38:05 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:38:05 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:38:05 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:38:05 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:38:05 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:38:05 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:38:05 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:38:05 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:38:05 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:38:05 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:38:05 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:38:05 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:38:05 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:38:05 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:38:05 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:38:52 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 389/815 [01:50<01:38,  4.31it/s]
10/09/2021 12:38:52 - INFO - trainer -     Num examples = 8705
10/09/2021 12:38:52 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.06it/s]
10/09/2021 12:39:12 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:39:12 - INFO - trainer -     T-F1 = 0.9896724972087829████████████████▌| 136/137 [00:19<00:00,  7.09it/s]
10/09/2021 12:39:12 - INFO - trainer -     T-F1(C) = 0.9835365853658536
10/09/2021 12:39:12 - INFO - trainer -     T-F1(D) = 0.9421894218942188
10/09/2021 12:39:12 - INFO - trainer -     T-F1(O) = 0.9943688907777306
10/09/2021 12:39:12 - INFO - trainer -     T-F1(P) = 0.9987244897959183
10/09/2021 12:39:12 - INFO - trainer -     T-F1(S) = 0.9938225101702577
10/09/2021 12:39:12 - INFO - trainer -     T-F1(T) = 0.9760765550239233
10/09/2021 12:39:12 - INFO - trainer -     U-F1(A) = 0.7790393013100437
10/09/2021 12:39:12 - INFO - trainer -     U-F1(E) = 0.8594757198109153
10/09/2021 12:39:12 - INFO - trainer -     U-F1(I) = 0.7067137809187279
10/09/2021 12:39:12 - INFO - trainer -     U-F1(O) = 0.9470560674683742
10/09/2021 12:39:12 - INFO - trainer -     intent_acc = 0.9086731763354394
10/09/2021 12:39:12 - INFO - trainer -     loss = 0.736767712526744
10/09/2021 12:39:12 - INFO - trainer -     semantic_frame_acc = 0.8886846639862148
10/09/2021 12:39:12 - INFO - trainer -     slot_f1 = 0.9919452562549005
10/09/2021 12:39:12 - INFO - trainer -     slot_precision = 0.9903216623968119
10/09/2021 12:39:12 - INFO - trainer -     slot_recall = 0.9935741824932172

10/09/2021 12:39:12 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:39:12 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:39:12 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:39:12 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:39:12 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:39:12 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:39:12 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:39:12 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:39:12 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:39:12 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:39:12 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:39:12 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:39:12 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:39:12 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:39:12 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:39:12 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:39:12 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:39:59 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 589/815 [02:57<00:52,  4.34it/s]
10/09/2021 12:39:59 - INFO - trainer -     Num examples = 8705
10/09/2021 12:39:59 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.14it/s]
10/09/2021 12:40:19 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:40:19 - INFO - trainer -     T-F1 = 0.9903138679333147████████████████▌| 136/137 [00:19<00:00,  7.04it/s]
10/09/2021 12:40:19 - INFO - trainer -     T-F1(C) = 0.983206106870229
10/09/2021 12:40:19 - INFO - trainer -     T-F1(D) = 0.9491945477075588
10/09/2021 12:40:19 - INFO - trainer -     T-F1(O) = 0.9947438279798249
10/09/2021 12:40:19 - INFO - trainer -     T-F1(P) = 0.9987244897959183
10/09/2021 12:40:19 - INFO - trainer -     T-F1(S) = 0.9950218735857596
10/09/2021 12:40:19 - INFO - trainer -     T-F1(T) = 0.976394115634622
10/09/2021 12:40:19 - INFO - trainer -     U-F1(A) = 0.7798960138648179
10/09/2021 12:40:19 - INFO - trainer -     U-F1(E) = 0.860748843079512
10/09/2021 12:40:19 - INFO - trainer -     U-F1(I) = 0.7366375121477163
10/09/2021 12:40:19 - INFO - trainer -     U-F1(O) = 0.949727626459144
10/09/2021 12:40:19 - INFO - trainer -     intent_acc = 0.9137277426766226
10/09/2021 12:40:19 - INFO - trainer -     loss = 0.7140013479588793
10/09/2021 12:40:19 - INFO - trainer -     semantic_frame_acc = 0.895807007466973
10/09/2021 12:40:19 - INFO - trainer -     slot_f1 = 0.99247423048115
10/09/2021 12:40:19 - INFO - trainer -     slot_precision = 0.9915900506022379
10/09/2021 12:40:19 - INFO - trainer -     slot_recall = 0.9933599885763245

10/09/2021 12:40:19 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:40:19 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:40:19 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:40:19 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:40:19 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:40:19 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:40:19 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:40:19 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:40:19 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:40:19 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:40:19 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:40:19 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:40:19 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:40:19 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:40:19 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:40:19 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:40:19 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:41:05 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 789/815 [04:03<00:06,  4.28it/s]
10/09/2021 12:41:05 - INFO - trainer -     Num examples = 8705
10/09/2021 12:41:05 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.16it/s]
10/09/2021 12:41:26 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:41:26 - INFO - trainer -     T-F1 = 0.9910456114168453████████████████▌| 136/137 [00:19<00:00,  7.05it/s]
10/09/2021 12:41:26 - INFO - trainer -     T-F1(C) = 0.9846719803801349
10/09/2021 12:41:26 - INFO - trainer -     T-F1(D) = 0.9491945477075588
10/09/2021 12:41:26 - INFO - trainer -     T-F1(O) = 0.9952257174685694
10/09/2021 12:41:26 - INFO - trainer -     T-F1(P) = 0.9993618379068283
10/09/2021 12:41:26 - INFO - trainer -     T-F1(S) = 0.9950218735857596
10/09/2021 12:41:26 - INFO - trainer -     T-F1(T) = 0.9783430732210381
10/09/2021 12:41:26 - INFO - trainer -     U-F1(A) = 0.7801418439716313
10/09/2021 12:41:26 - INFO - trainer -     U-F1(E) = 0.8627622377622378
10/09/2021 12:41:26 - INFO - trainer -     U-F1(I) = 0.745631067961165
10/09/2021 12:41:26 - INFO - trainer -     U-F1(O) = 0.9507867941993213
10/09/2021 12:41:26 - INFO - trainer -     intent_acc = 0.9160252728317059
10/09/2021 12:41:26 - INFO - trainer -     loss = 0.7147919532484341
10/09/2021 12:41:26 - INFO - trainer -     semantic_frame_acc = 0.8992533026995979
10/09/2021 12:41:26 - INFO - trainer -     slot_f1 = 0.9930734075978292
10/09/2021 12:41:26 - INFO - trainer -     slot_precision = 0.9932152549635767
10/09/2021 12:41:26 - INFO - trainer -     slot_recall = 0.992931600742539

10/09/2021 12:41:26 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:41:26 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:41:26 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:41:26 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:41:26 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:41:26 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:41:26 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:41:26 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:41:26 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:41:26 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:41:26 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:41:26 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:41:26 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:41:26 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:41:26 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:41:26 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:41:26 - INFO - trainer -     slot_recall = 0.9896472940168499
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 815/815 [04:30<00:00,  3.02it/s]
Epoch:  75%|██████████████████████████████████████████████████████                  | 15/20 [1:31:00<24:10, 290.03s/it]10/09/2021 12:42:12 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 174/815 [00:40<02:29,  4.29it/s]
10/09/2021 12:42:12 - INFO - trainer -     Num examples = 8705
10/09/2021 12:42:12 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.18it/s]
10/09/2021 12:42:32 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:42:32 - INFO - trainer -     T-F1 = 0.9909069713219865████████████████▌| 136/137 [00:19<00:00,  7.02it/s]
10/09/2021 12:42:32 - INFO - trainer -     T-F1(C) = 0.9825847846012832
10/09/2021 12:42:32 - INFO - trainer -     T-F1(D) = 0.9502487562189055
10/09/2021 12:42:32 - INFO - trainer -     T-F1(O) = 0.9951988116395661
10/09/2021 12:42:32 - INFO - trainer -     T-F1(P) = 0.9988518943742825
10/09/2021 12:42:32 - INFO - trainer -     T-F1(S) = 0.9953207547169811
10/09/2021 12:42:32 - INFO - trainer -     T-F1(T) = 0.9800275482093663
10/09/2021 12:42:32 - INFO - trainer -     U-F1(A) = 0.7781629116117851
10/09/2021 12:42:32 - INFO - trainer -     U-F1(E) = 0.8597739640016744
10/09/2021 12:42:32 - INFO - trainer -     U-F1(I) = 0.7180899908172635
10/09/2021 12:42:32 - INFO - trainer -     U-F1(O) = 0.9478791673188292
10/09/2021 12:42:32 - INFO - trainer -     intent_acc = 0.9101665709362435
10/09/2021 12:42:32 - INFO - trainer -     loss = 0.7452673121675935
10/09/2021 12:42:32 - INFO - trainer -     semantic_frame_acc = 0.8935094773118897
10/09/2021 12:42:32 - INFO - trainer -     slot_f1 = 0.9929310960371296
10/09/2021 12:42:32 - INFO - trainer -     slot_precision = 0.9930019994287347
10/09/2021 12:42:32 - INFO - trainer -     slot_recall = 0.9928602027702413

10/09/2021 12:42:32 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:42:32 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:42:32 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:42:32 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:42:32 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:42:32 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:42:32 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:42:32 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:42:32 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:42:32 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:42:32 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:42:32 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:42:32 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:42:32 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:42:32 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:42:32 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:42:32 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:43:19 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 374/815 [01:46<01:41,  4.33it/s]
10/09/2021 12:43:19 - INFO - trainer -     Num examples = 8705
10/09/2021 12:43:19 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.18it/s]
10/09/2021 12:43:39 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:43:39 - INFO - trainer -     T-F1 = 0.9909548675867214████████████████▌| 136/137 [00:19<00:00,  7.07it/s]
10/09/2021 12:43:39 - INFO - trainer -     T-F1(C) = 0.9826060421116876
10/09/2021 12:43:39 - INFO - trainer -     T-F1(D) = 0.9515527950310559
10/09/2021 12:43:39 - INFO - trainer -     T-F1(O) = 0.9952249575551783
10/09/2021 12:43:39 - INFO - trainer -     T-F1(P) = 0.9988518943742825
10/09/2021 12:43:39 - INFO - trainer -     T-F1(S) = 0.9951705402958043
10/09/2021 12:43:39 - INFO - trainer -     T-F1(T) = 0.9803516028955532
10/09/2021 12:43:39 - INFO - trainer -     U-F1(A) = 0.7817083692838653
10/09/2021 12:43:39 - INFO - trainer -     U-F1(E) = 0.8629787234042554
10/09/2021 12:43:39 - INFO - trainer -     U-F1(I) = 0.7207373271889401
10/09/2021 12:43:39 - INFO - trainer -     U-F1(O) = 0.9491260923845194
10/09/2021 12:43:39 - INFO - trainer -     intent_acc = 0.9121194715680643
10/09/2021 12:43:39 - INFO - trainer -     loss = 0.7389626900067346
10/09/2021 12:43:39 - INFO - trainer -     semantic_frame_acc = 0.8953475014359563
10/09/2021 12:43:39 - INFO - trainer -     slot_f1 = 0.992931600742539
10/09/2021 12:43:39 - INFO - trainer -     slot_precision = 0.992931600742539
10/09/2021 12:43:39 - INFO - trainer -     slot_recall = 0.992931600742539

10/09/2021 12:43:39 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:43:39 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:43:39 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:43:39 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:43:39 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:43:39 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:43:39 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:43:39 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:43:39 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:43:39 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:43:39 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:43:39 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:43:39 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:43:39 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:43:39 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:43:39 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:43:39 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:44:25 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 574/815 [02:53<00:55,  4.32it/s]
10/09/2021 12:44:25 - INFO - trainer -     Num examples = 8705
10/09/2021 12:44:25 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.19it/s]
10/09/2021 12:44:45 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:44:45 - INFO - trainer -     T-F1 = 0.9893953488372093████████████████▌| 136/137 [00:19<00:00,  7.03it/s]
10/09/2021 12:44:45 - INFO - trainer -     T-F1(C) = 0.9811320754716981
10/09/2021 12:44:45 - INFO - trainer -     T-F1(D) = 0.9423312883435583
10/09/2021 12:44:45 - INFO - trainer -     T-F1(O) = 0.9943682924237593
10/09/2021 12:44:45 - INFO - trainer -     T-F1(P) = 0.9989793314621077
10/09/2021 12:44:45 - INFO - trainer -     T-F1(S) = 0.9942719324690985
10/09/2021 12:44:45 - INFO - trainer -     T-F1(T) = 0.9750597881790228
10/09/2021 12:44:45 - INFO - trainer -     U-F1(A) = 0.7782646801051709
10/09/2021 12:44:45 - INFO - trainer -     U-F1(E) = 0.8598912588874948
10/09/2021 12:44:45 - INFO - trainer -     U-F1(I) = 0.7295238095238096
10/09/2021 12:44:45 - INFO - trainer -     U-F1(O) = 0.9491736825693794
10/09/2021 12:44:45 - INFO - trainer -     intent_acc = 0.9124641010913268
10/09/2021 12:44:45 - INFO - trainer -     loss = 0.7308662620672182
10/09/2021 12:44:45 - INFO - trainer -     semantic_frame_acc = 0.8924755887421022
10/09/2021 12:44:45 - INFO - trainer -     slot_f1 = 0.991625387548555
10/09/2021 12:44:45 - INFO - trainer -     slot_precision = 0.9898968338669513
10/09/2021 12:44:45 - INFO - trainer -     slot_recall = 0.9933599885763245

10/09/2021 12:44:45 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:44:45 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:44:45 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:44:45 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:44:45 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:44:45 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:44:45 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:44:45 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:44:45 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:44:45 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:44:45 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:44:45 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:44:45 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:44:45 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:44:45 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:44:45 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:44:45 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:45:31 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 774/815 [03:59<00:09,  4.32it/s]
10/09/2021 12:45:31 - INFO - trainer -     Num examples = 8705
10/09/2021 12:45:31 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.20it/s]
10/09/2021 12:45:52 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:45:52 - INFO - trainer -     T-F1 = 0.9906333007129875████████████████▌| 136/137 [00:19<00:00,  7.07it/s]
10/09/2021 12:45:52 - INFO - trainer -     T-F1(C) = 0.9835164835164836
10/09/2021 12:45:52 - INFO - trainer -     T-F1(D) = 0.9458128078817735
10/09/2021 12:45:52 - INFO - trainer -     T-F1(O) = 0.9950908849674938
10/09/2021 12:45:52 - INFO - trainer -     T-F1(P) = 0.9985967597907897
10/09/2021 12:45:52 - INFO - trainer -     T-F1(S) = 0.9951705402958043
10/09/2021 12:45:52 - INFO - trainer -     T-F1(T) = 0.9793530626290433
10/09/2021 12:45:52 - INFO - trainer -     U-F1(A) = 0.7853492333901192
10/09/2021 12:45:52 - INFO - trainer -     U-F1(E) = 0.863502729945401
10/09/2021 12:45:52 - INFO - trainer -     U-F1(I) = 0.7294776119402986
10/09/2021 12:45:52 - INFO - trainer -     U-F1(O) = 0.9492294453571148
10/09/2021 12:45:52 - INFO - trainer -     intent_acc = 0.9129236071223434
10/09/2021 12:45:52 - INFO - trainer -     loss = 0.7275916617592592
10/09/2021 12:45:52 - INFO - trainer -     semantic_frame_acc = 0.8953475014359563
10/09/2021 12:45:52 - INFO - trainer -     slot_f1 = 0.9926486332167583
10/09/2021 12:45:52 - INFO - trainer -     slot_precision = 0.9922945205479452
10/09/2021 12:45:52 - INFO - trainer -     slot_recall = 0.9930029987148365

10/09/2021 12:45:52 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:45:52 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:45:52 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:45:52 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:45:52 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:45:52 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:45:52 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:45:52 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:45:52 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:45:52 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:45:52 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:45:52 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:45:52 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:45:52 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:45:52 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:45:52 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:45:52 - INFO - trainer -     slot_recall = 0.9896472940168499
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 815/815 [04:29<00:00,  3.03it/s]
Epoch:  80%|█████████████████████████████████████████████████████████▌              | 16/20 [1:35:29<18:55, 283.81s/it]10/09/2021 12:46:38 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 159/815 [00:36<02:31,  4.32it/s]
10/09/2021 12:46:38 - INFO - trainer -     Num examples = 8705
10/09/2021 12:46:38 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.20it/s]
10/09/2021 12:46:58 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:46:58 - INFO - trainer -     T-F1 = 0.990497484628284█████████████████▌| 136/137 [00:19<00:00,  7.08it/s]
10/09/2021 12:46:58 - INFO - trainer -     T-F1(C) = 0.9820395738203958
10/09/2021 12:46:58 - INFO - trainer -     T-F1(D) = 0.9458128078817735
10/09/2021 12:46:58 - INFO - trainer -     T-F1(O) = 0.9949570018048626
10/09/2021 12:46:58 - INFO - trainer -     T-F1(P) = 0.9988516013780784
10/09/2021 12:46:58 - INFO - trainer -     T-F1(S) = 0.9953207547169811
10/09/2021 12:46:58 - INFO - trainer -     T-F1(T) = 0.9790305947060846
10/09/2021 12:46:58 - INFO - trainer -     U-F1(A) = 0.7781690140845071
10/09/2021 12:46:58 - INFO - trainer -     U-F1(E) = 0.867429055484964
10/09/2021 12:46:58 - INFO - trainer -     U-F1(I) = 0.7274418604651162
10/09/2021 12:46:58 - INFO - trainer -     U-F1(O) = 0.950459573142234
10/09/2021 12:46:58 - INFO - trainer -     intent_acc = 0.9141872487076392
10/09/2021 12:46:58 - INFO - trainer -     loss = 0.7325633357923323
10/09/2021 12:46:58 - INFO - trainer -     semantic_frame_acc = 0.8963813900057438
10/09/2021 12:46:58 - INFO - trainer -     slot_f1 = 0.992579908675799
10/09/2021 12:46:58 - INFO - trainer -     slot_precision = 0.9918722372736347
10/09/2021 12:46:58 - INFO - trainer -     slot_recall = 0.9932885906040269

10/09/2021 12:46:58 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:46:58 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:46:58 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:46:58 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:46:58 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:46:58 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:46:58 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:46:58 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:46:58 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:46:58 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:46:58 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:46:58 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:46:58 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:46:58 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:46:58 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:46:58 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:46:58 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:47:44 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 359/815 [01:43<01:45,  4.33it/s]
10/09/2021 12:47:44 - INFO - trainer -     Num examples = 8705
10/09/2021 12:47:44 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.20it/s]
10/09/2021 12:48:04 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:48:04 - INFO - trainer -     T-F1 = 0.9909565541674435████████████████▌| 136/137 [00:19<00:00,  7.07it/s]
10/09/2021 12:48:04 - INFO - trainer -     T-F1(C) = 0.9841075794621027
10/09/2021 12:48:04 - INFO - trainer -     T-F1(D) = 0.9467162329615861
10/09/2021 12:48:04 - INFO - trainer -     T-F1(O) = 0.9952244508118434
10/09/2021 12:48:04 - INFO - trainer -     T-F1(P) = 0.9989790709545686
10/09/2021 12:48:04 - INFO - trainer -     T-F1(S) = 0.9948702474351238
10/09/2021 12:48:04 - INFO - trainer -     T-F1(T) = 0.9804056376761774
10/09/2021 12:48:04 - INFO - trainer -     U-F1(A) = 0.7822299651567944
10/09/2021 12:48:04 - INFO - trainer -     U-F1(E) = 0.8696785403996525
10/09/2021 12:48:04 - INFO - trainer -     U-F1(I) = 0.7260909935004641
10/09/2021 12:48:04 - INFO - trainer -     U-F1(O) = 0.9511759683303579
10/09/2021 12:48:04 - INFO - trainer -     intent_acc = 0.9153360137851809
10/09/2021 12:48:04 - INFO - trainer -     loss = 0.7329784308915599
10/09/2021 12:48:04 - INFO - trainer -     semantic_frame_acc = 0.8982194141298104
10/09/2021 12:48:04 - INFO - trainer -     slot_f1 = 0.9929685548060105
10/09/2021 12:48:04 - INFO - trainer -     slot_precision = 0.9927913782028406
10/09/2021 12:48:04 - INFO - trainer -     slot_recall = 0.9931457946594316

10/09/2021 12:48:04 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:48:04 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:48:04 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:48:04 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:48:04 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:48:04 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:48:04 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:48:04 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:48:04 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:48:04 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:48:04 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:48:04 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:48:04 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:48:04 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:48:04 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:48:04 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:48:04 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:48:50 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 559/815 [02:49<00:59,  4.33it/s]
10/09/2021 12:48:50 - INFO - trainer -     Num examples = 8705
10/09/2021 12:48:50 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.18it/s]
10/09/2021 12:49:11 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:49:11 - INFO - trainer -     T-F1 = 0.9906812039884446████████████████▌| 136/137 [00:19<00:00,  7.04it/s]
10/09/2021 12:49:11 - INFO - trainer -     T-F1(C) = 0.9829059829059829
10/09/2021 12:49:11 - INFO - trainer -     T-F1(D) = 0.9469790382244143
10/09/2021 12:49:11 - INFO - trainer -     T-F1(O) = 0.9950639562655911
10/09/2021 12:49:11 - INFO - trainer -     T-F1(P) = 0.9987241643276347
10/09/2021 12:49:11 - INFO - trainer -     T-F1(S) = 0.9950203712086917
10/09/2021 12:49:11 - INFO - trainer -     T-F1(T) = 0.9800687285223368
10/09/2021 12:49:11 - INFO - trainer -     U-F1(A) = 0.7783505154639174
10/09/2021 12:49:11 - INFO - trainer -     U-F1(E) = 0.8654822335025381
10/09/2021 12:49:11 - INFO - trainer -     U-F1(I) = 0.7186932849364791
10/09/2021 12:49:11 - INFO - trainer -     U-F1(O) = 0.9478873239436619
10/09/2021 12:49:11 - INFO - trainer -     intent_acc = 0.9108558299827685
10/09/2021 12:49:11 - INFO - trainer -     loss = 0.7395878456947526
10/09/2021 12:49:11 - INFO - trainer -     semantic_frame_acc = 0.8933946008041356
10/09/2021 12:49:11 - INFO - trainer -     slot_f1 = 0.9927210447441661
10/09/2021 12:49:11 - INFO - trainer -     slot_precision = 0.992225392296719
10/09/2021 12:49:11 - INFO - trainer -     slot_recall = 0.9932171926317293

10/09/2021 12:49:11 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:49:11 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:49:11 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:49:11 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:49:11 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:49:11 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:49:11 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:49:11 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:49:11 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:49:11 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:49:11 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:49:11 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:49:11 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:49:11 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:49:11 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:49:11 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:49:11 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:49:57 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 759/815 [03:55<00:12,  4.34it/s]
10/09/2021 12:49:57 - INFO - trainer -     Num examples = 8705
10/09/2021 12:49:57 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.20it/s]
10/09/2021 12:50:17 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:50:17 - INFO - trainer -     T-F1 = 0.991277578245254█████████████████▌| 136/137 [00:19<00:00,  7.09it/s]
10/09/2021 12:50:17 - INFO - trainer -     T-F1(C) = 0.9844084377866096
10/09/2021 12:50:17 - INFO - trainer -     T-F1(D) = 0.9503722084367247
10/09/2021 12:50:17 - INFO - trainer -     T-F1(O) = 0.9954117491048933
10/09/2021 12:50:17 - INFO - trainer -     T-F1(P) = 0.9988513082322911
10/09/2021 12:50:17 - INFO - trainer -     T-F1(S) = 0.9950203712086917
10/09/2021 12:50:17 - INFO - trainer -     T-F1(T) = 0.9813793103448275
10/09/2021 12:50:17 - INFO - trainer -     U-F1(A) = 0.7869415807560138
10/09/2021 12:50:17 - INFO - trainer -     U-F1(E) = 0.8608659100462379
10/09/2021 12:50:17 - INFO - trainer -     U-F1(I) = 0.7300672430355427
10/09/2021 12:50:17 - INFO - trainer -     U-F1(O) = 0.9493216903165445
10/09/2021 12:50:17 - INFO - trainer -     intent_acc = 0.913268236645606
10/09/2021 12:50:17 - INFO - trainer -     loss = 0.7424854535451644
10/09/2021 12:50:17 - INFO - trainer -     semantic_frame_acc = 0.8966111430212521
10/09/2021 12:50:17 - INFO - trainer -     slot_f1 = 0.9932152549635767
10/09/2021 12:50:17 - INFO - trainer -     slot_precision = 0.9934990712958994
10/09/2021 12:50:17 - INFO - trainer -     slot_recall = 0.992931600742539

10/09/2021 12:50:17 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:50:17 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:50:17 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:50:17 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:50:17 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:50:17 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:50:17 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:50:17 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:50:17 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:50:17 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:50:17 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:50:17 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:50:17 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:50:17 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:50:17 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:50:17 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:50:17 - INFO - trainer -     slot_recall = 0.9896472940168499
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 815/815 [04:28<00:00,  3.03it/s]
Epoch:  85%|█████████████████████████████████████████████████████████████▏          | 17/20 [1:39:58<13:58, 279.35s/it]10/09/2021 12:51:03 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 144/815 [00:33<02:34,  4.34it/s]
10/09/2021 12:51:03 - INFO - trainer -     Num examples = 8705
10/09/2021 12:51:03 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.20it/s]
10/09/2021 12:51:23 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:51:23 - INFO - trainer -     T-F1 = 0.9903156718502654████████████████▌| 136/137 [00:19<00:00,  7.07it/s]
10/09/2021 12:51:23 - INFO - trainer -     T-F1(C) = 0.9817407181984175
10/09/2021 12:51:23 - INFO - trainer -     T-F1(D) = 0.9494451294697904
10/09/2021 12:51:23 - INFO - trainer -     T-F1(O) = 0.9948494663622365
10/09/2021 12:51:23 - INFO - trainer -     T-F1(P) = 0.9987241643276347
10/09/2021 12:51:23 - INFO - trainer -     T-F1(S) = 0.9947217614236163
10/09/2021 12:51:23 - INFO - trainer -     T-F1(T) = 0.9787087912087913
10/09/2021 12:51:23 - INFO - trainer -     U-F1(A) = 0.7822299651567944
10/09/2021 12:51:23 - INFO - trainer -     U-F1(E) = 0.8627284317892052
10/09/2021 12:51:23 - INFO - trainer -     U-F1(I) = 0.7194656488549618
10/09/2021 12:51:23 - INFO - trainer -     U-F1(O) = 0.9493818521110333
10/09/2021 12:51:23 - INFO - trainer -     intent_acc = 0.9128087306145893
10/09/2021 12:51:23 - INFO - trainer -     loss = 0.7455075497606881
10/09/2021 12:51:23 - INFO - trainer -     semantic_frame_acc = 0.894428489373923
10/09/2021 12:51:23 - INFO - trainer -     slot_f1 = 0.9924039798865948
10/09/2021 12:51:23 - INFO - trainer -     slot_precision = 0.9913786961168507
10/09/2021 12:51:23 - INFO - trainer -     slot_recall = 0.9934313865486221

10/09/2021 12:51:23 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:51:23 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:51:23 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:51:23 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:51:23 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:51:23 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:51:23 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:51:23 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:51:23 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:51:23 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:51:23 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:51:23 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:51:23 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:51:23 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:51:23 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:51:23 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:51:23 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:52:10 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 344/815 [01:39<01:49,  4.29it/s]
10/09/2021 12:52:10 - INFO - trainer -     Num examples = 8705
10/09/2021 12:52:10 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.19it/s]
10/09/2021 12:52:30 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:52:30 - INFO - trainer -     T-F1 = 0.9909573972219633████████████████▌| 136/137 [00:19<00:00,  7.10it/s]
10/09/2021 12:52:30 - INFO - trainer -     T-F1(C) = 0.9841075794621027
10/09/2021 12:52:30 - INFO - trainer -     T-F1(D) = 0.9447852760736197
10/09/2021 12:52:30 - INFO - trainer -     T-F1(O) = 0.9953303263465109
10/09/2021 12:52:30 - INFO - trainer -     T-F1(P) = 0.9988516013780784
10/09/2021 12:52:30 - INFO - trainer -     T-F1(S) = 0.9954710144927537
10/09/2021 12:52:30 - INFO - trainer -     T-F1(T) = 0.9800412938747418
10/09/2021 12:52:30 - INFO - trainer -     U-F1(A) = 0.7873070325900514
10/09/2021 12:52:30 - INFO - trainer -     U-F1(E) = 0.8663239074550128
10/09/2021 12:52:30 - INFO - trainer -     U-F1(I) = 0.7320388349514564
10/09/2021 12:52:30 - INFO - trainer -     U-F1(O) = 0.9503105590062113
10/09/2021 12:52:30 - INFO - trainer -     intent_acc = 0.9152211372774268
10/09/2021 12:52:30 - INFO - trainer -     loss = 0.7392549364920302
10/09/2021 12:52:30 - INFO - trainer -     semantic_frame_acc = 0.8983342906375646
10/09/2021 12:52:30 - INFO - trainer -     slot_f1 = 0.9929331144264402
10/09/2021 12:52:30 - INFO - trainer -     slot_precision = 0.9927205252640594
10/09/2021 12:52:30 - INFO - trainer -     slot_recall = 0.9931457946594316

10/09/2021 12:52:30 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:52:30 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:52:30 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:52:30 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:52:30 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:52:30 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:52:30 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:52:30 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:52:30 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:52:30 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:52:30 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:52:30 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:52:30 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:52:30 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:52:30 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:52:30 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:52:30 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:53:16 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 544/815 [02:46<01:02,  4.32it/s]
10/09/2021 12:53:16 - INFO - trainer -     Num examples = 8705
10/09/2021 12:53:16 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.18it/s]
10/09/2021 12:53:36 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:53:36 - INFO - trainer -     T-F1 = 0.9906838084591019████████████████▌| 136/137 [00:19<00:00,  7.08it/s]
10/09/2021 12:53:36 - INFO - trainer -     T-F1(C) = 0.9823386114494518
10/09/2021 12:53:36 - INFO - trainer -     T-F1(D) = 0.9494451294697904
10/09/2021 12:53:36 - INFO - trainer -     T-F1(O) = 0.9950100859963903
10/09/2021 12:53:36 - INFO - trainer -     T-F1(P) = 0.9987241643276347
10/09/2021 12:53:36 - INFO - trainer -     T-F1(S) = 0.9951705402958043
10/09/2021 12:53:36 - INFO - trainer -     T-F1(T) = 0.9797181161911309
10/09/2021 12:53:36 - INFO - trainer -     U-F1(A) = 0.7781629116117851
10/09/2021 12:53:36 - INFO - trainer -     U-F1(E) = 0.8660409556313993
10/09/2021 12:53:36 - INFO - trainer -     U-F1(I) = 0.7165281625115419
10/09/2021 12:53:36 - INFO - trainer -     U-F1(O) = 0.9489437992049263
10/09/2021 12:53:36 - INFO - trainer -     intent_acc = 0.9120045950603102
10/09/2021 12:53:36 - INFO - trainer -     loss = 0.7464768516445633
10/09/2021 12:53:36 - INFO - trainer -     semantic_frame_acc = 0.894428489373923
10/09/2021 12:53:36 - INFO - trainer -     slot_f1 = 0.9927226027397261
10/09/2021 12:53:36 - INFO - trainer -     slot_precision = 0.9920148296021674
10/09/2021 12:53:36 - INFO - trainer -     slot_recall = 0.9934313865486221

10/09/2021 12:53:36 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:53:36 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:53:36 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:53:36 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:53:36 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:53:36 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:53:36 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:53:36 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:53:36 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:53:36 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:53:36 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:53:36 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:53:36 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:53:36 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:53:36 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:53:36 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:53:36 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:54:22 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 744/815 [03:52<00:16,  4.31it/s]
10/09/2021 12:54:22 - INFO - trainer -     Num examples = 8705
10/09/2021 12:54:22 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.19it/s]
10/09/2021 12:54:43 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:54:43 - INFO - trainer -     T-F1 = 0.9908231238645363████████████████▌| 136/137 [00:19<00:00,  7.06it/s]
10/09/2021 12:54:43 - INFO - trainer -     T-F1(C) = 0.9829372333942717
10/09/2021 12:54:43 - INFO - trainer -     T-F1(D) = 0.9482758620689655
10/09/2021 12:54:43 - INFO - trainer -     T-F1(O) = 0.9950898426095496
10/09/2021 12:54:43 - INFO - trainer -     T-F1(P) = 0.9987241643276347
10/09/2021 12:54:43 - INFO - trainer -     T-F1(S) = 0.9951705402958043
10/09/2021 12:54:43 - INFO - trainer -     T-F1(T) = 0.9804056376761774
10/09/2021 12:54:43 - INFO - trainer -     U-F1(A) = 0.7802385008517888
10/09/2021 12:54:43 - INFO - trainer -     U-F1(E) = 0.8652064026958718
10/09/2021 12:54:43 - INFO - trainer -     U-F1(I) = 0.7255813953488373
10/09/2021 12:54:43 - INFO - trainer -     U-F1(O) = 0.9490889184327833
10/09/2021 12:54:43 - INFO - trainer -     intent_acc = 0.9124641010913268
10/09/2021 12:54:43 - INFO - trainer -     loss = 0.7626576854937233
10/09/2021 12:54:43 - INFO - trainer -     semantic_frame_acc = 0.895117748420448
10/09/2021 12:54:43 - INFO - trainer -     slot_f1 = 0.9927934356047092
10/09/2021 12:54:43 - INFO - trainer -     slot_precision = 0.992156303479749
10/09/2021 12:54:43 - INFO - trainer -     slot_recall = 0.9934313865486221

10/09/2021 12:54:43 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:54:43 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:54:43 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:54:43 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:54:43 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:54:43 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:54:43 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:54:43 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:54:43 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:54:43 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:54:43 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:54:43 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:54:43 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:54:43 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:54:43 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:54:43 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:54:43 - INFO - trainer -     slot_recall = 0.9896472940168499
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 815/815 [04:29<00:00,  3.03it/s]
Epoch:  90%|████████████████████████████████████████████████████████████████▊       | 18/20 [1:44:28<09:12, 276.26s/it]10/09/2021 12:55:29 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 129/815 [00:29<02:39,  4.31it/s]
10/09/2021 12:55:29 - INFO - trainer -     Num examples = 8705
10/09/2021 12:55:29 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.19it/s]
10/09/2021 12:55:49 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:55:49 - INFO - trainer -     T-F1 = 0.9911933274311543████████████████▌| 136/137 [00:19<00:00,  7.05it/s]
10/09/2021 12:55:49 - INFO - trainer -     T-F1(C) = 0.9838365355291248
10/09/2021 12:55:49 - INFO - trainer -     T-F1(D) = 0.9493201483312731
10/09/2021 12:55:49 - INFO - trainer -     T-F1(O) = 0.9953029217418995
10/09/2021 12:55:49 - INFO - trainer -     T-F1(P) = 0.9989790709545686
10/09/2021 12:55:49 - INFO - trainer -     T-F1(S) = 0.9954723815273167
10/09/2021 12:55:49 - INFO - trainer -     T-F1(T) = 0.9804190999656477
10/09/2021 12:55:49 - INFO - trainer -     U-F1(A) = 0.7866323907455013
10/09/2021 12:55:49 - INFO - trainer -     U-F1(E) = 0.8652958455728075
10/09/2021 12:55:49 - INFO - trainer -     U-F1(I) = 0.7269267364414844
10/09/2021 12:55:49 - INFO - trainer -     U-F1(O) = 0.949488640799438
10/09/2021 12:55:49 - INFO - trainer -     intent_acc = 0.9136128661688685
10/09/2021 12:55:49 - INFO - trainer -     loss = 0.7653881729058717
10/09/2021 12:55:49 - INFO - trainer -     semantic_frame_acc = 0.8969557725445146
10/09/2021 12:55:49 - INFO - trainer -     slot_f1 = 0.9931132917038358
10/09/2021 12:55:49 - INFO - trainer -     slot_precision = 0.992652828304444
10/09/2021 12:55:49 - INFO - trainer -     slot_recall = 0.9935741824932172

10/09/2021 12:55:49 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:55:49 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:55:49 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:55:49 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:55:49 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:55:49 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:55:49 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:55:49 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:55:49 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:55:49 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:55:49 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:55:49 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:55:49 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:55:49 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:55:49 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:55:49 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:55:49 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:56:35 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 329/815 [01:36<01:52,  4.33it/s]
10/09/2021 12:56:35 - INFO - trainer -     Num examples = 8705
10/09/2021 12:56:35 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.20it/s]
10/09/2021 12:56:55 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:56:55 - INFO - trainer -     T-F1 = 0.991329479768786█████████████████▌| 136/137 [00:19<00:00,  7.07it/s]
10/09/2021 12:56:55 - INFO - trainer -     T-F1(C) = 0.9841172877214416
10/09/2021 12:56:55 - INFO - trainer -     T-F1(D) = 0.9493201483312731
10/09/2021 12:56:55 - INFO - trainer -     T-F1(O) = 0.995383635784782
10/09/2021 12:56:55 - INFO - trainer -     T-F1(P) = 0.9989790709545686
10/09/2021 12:56:55 - INFO - trainer -     T-F1(S) = 0.9954710144927537
10/09/2021 12:56:55 - INFO - trainer -     T-F1(T) = 0.9810931591612239
10/09/2021 12:56:55 - INFO - trainer -     U-F1(A) = 0.7814113597246127
10/09/2021 12:56:55 - INFO - trainer -     U-F1(E) = 0.8629908103592315
10/09/2021 12:56:55 - INFO - trainer -     U-F1(I) = 0.73046875
10/09/2021 12:56:55 - INFO - trainer -     U-F1(O) = 0.9496492595479346
10/09/2021 12:56:55 - INFO - trainer -     intent_acc = 0.9136128661688685
10/09/2021 12:56:55 - INFO - trainer -     loss = 0.7609446492022962
10/09/2021 12:56:55 - INFO - trainer -     semantic_frame_acc = 0.897185525560023
10/09/2021 12:56:55 - INFO - trainer -     slot_f1 = 0.9932181610508282
10/09/2021 12:56:55 - INFO - trainer -     slot_precision = 0.9930763740185582
10/09/2021 12:56:55 - INFO - trainer -     slot_recall = 0.9933599885763245

10/09/2021 12:56:55 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:56:55 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:56:55 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:56:55 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:56:55 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:56:55 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:56:55 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:56:55 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:56:55 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:56:55 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:56:55 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:56:55 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:56:55 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:56:55 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:56:55 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:56:55 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:56:55 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:57:42 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 529/815 [02:42<01:05,  4.34it/s]
10/09/2021 12:57:42 - INFO - trainer -     Num examples = 8705
10/09/2021 12:57:42 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.19it/s]
10/09/2021 12:58:02 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:58:02 - INFO - trainer -     T-F1 = 0.9912313432835821████████████████▌| 136/137 [00:19<00:00,  7.09it/s]
10/09/2021 12:58:02 - INFO - trainer -     T-F1(C) = 0.9840978593272172
10/09/2021 12:58:02 - INFO - trainer -     T-F1(D) = 0.9468479604449939
10/09/2021 12:58:02 - INFO - trainer -     T-F1(O) = 0.9953851050286442
10/09/2021 12:58:02 - INFO - trainer -     T-F1(P) = 0.9989790709545686
10/09/2021 12:58:02 - INFO - trainer -     T-F1(S) = 0.9954710144927537
10/09/2021 12:58:02 - INFO - trainer -     T-F1(T) = 0.9810410203378145
10/09/2021 12:58:02 - INFO - trainer -     U-F1(A) = 0.7799827437446075
10/09/2021 12:58:02 - INFO - trainer -     U-F1(E) = 0.8656210258584146
10/09/2021 12:58:02 - INFO - trainer -     U-F1(I) = 0.7285024154589372
10/09/2021 12:58:02 - INFO - trainer -     U-F1(O) = 0.9499883332037022
10/09/2021 12:58:02 - INFO - trainer -     intent_acc = 0.9140723721998851
10/09/2021 12:58:02 - INFO - trainer -     loss = 0.7465794962232514
10/09/2021 12:58:02 - INFO - trainer -     semantic_frame_acc = 0.8973004020677772
10/09/2021 12:58:02 - INFO - trainer -     slot_f1 = 0.9931797893233352
10/09/2021 12:58:02 - INFO - trainer -     slot_precision = 0.9934281020072863
10/09/2021 12:58:02 - INFO - trainer -     slot_recall = 0.992931600742539

10/09/2021 12:58:02 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:58:02 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:58:02 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:58:02 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:58:02 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:58:02 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:58:02 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:58:02 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:58:02 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:58:02 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:58:02 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:58:02 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:58:02 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:58:02 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:58:02 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:58:02 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:58:02 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 12:58:48 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 729/815 [03:48<00:20,  4.30it/s]
10/09/2021 12:58:48 - INFO - trainer -     Num examples = 8705
10/09/2021 12:58:48 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.19it/s]
10/09/2021 12:59:08 - INFO - trainer -   ***** Eval results *****
10/09/2021 12:59:08 - INFO - trainer -     T-F1 = 0.9912346139500187████████████████▌| 136/137 [00:19<00:00,  7.07it/s]
10/09/2021 12:59:08 - INFO - trainer -     T-F1(C) = 0.9841075794621027
10/09/2021 12:59:08 - INFO - trainer -     T-F1(D) = 0.9469790382244143
10/09/2021 12:59:08 - INFO - trainer -     T-F1(O) = 0.9953841256366723
10/09/2021 12:59:08 - INFO - trainer -     T-F1(P) = 0.9988516013780784
10/09/2021 12:59:08 - INFO - trainer -     T-F1(S) = 0.9954710144927537
10/09/2021 12:59:08 - INFO - trainer -     T-F1(T) = 0.981404958677686
10/09/2021 12:59:08 - INFO - trainer -     U-F1(A) = 0.7777777777777778
10/09/2021 12:59:08 - INFO - trainer -     U-F1(E) = 0.8650927487352446
10/09/2021 12:59:08 - INFO - trainer -     U-F1(I) = 0.7225929456625357
10/09/2021 12:59:08 - INFO - trainer -     U-F1(O) = 0.9495988159227234
10/09/2021 12:59:08 - INFO - trainer -     intent_acc = 0.9130384836300977
10/09/2021 12:59:08 - INFO - trainer -     loss = 0.7547337256763283
10/09/2021 12:59:08 - INFO - trainer -     semantic_frame_acc = 0.8966111430212521
10/09/2021 12:59:08 - INFO - trainer -     slot_f1 = 0.993181737050655
10/09/2021 12:59:08 - INFO - trainer -     slot_precision = 0.9931462840008567
10/09/2021 12:59:08 - INFO - trainer -     slot_recall = 0.9932171926317293

10/09/2021 12:59:08 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 12:59:08 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 12:59:08 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 12:59:08 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 12:59:08 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 12:59:08 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 12:59:08 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 12:59:08 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 12:59:08 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 12:59:08 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 12:59:08 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 12:59:08 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 12:59:08 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 12:59:08 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 12:59:08 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 12:59:08 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 12:59:08 - INFO - trainer -     slot_recall = 0.9896472940168499
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 815/815 [04:28<00:00,  3.03it/s]
Epoch:  95%|████████████████████████████████████████████████████████████████████▍   | 19/20 [1:48:56<04:34, 274.07s/it]10/09/2021 12:59:54 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 114/815 [00:26<02:42,  4.30it/s]
10/09/2021 12:59:54 - INFO - trainer -     Num examples = 8705
10/09/2021 12:59:54 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.19it/s]
10/09/2021 13:00:15 - INFO - trainer -   ***** Eval results *****
10/09/2021 13:00:15 - INFO - trainer -     T-F1 = 0.9909582401193138████████████████▌| 136/137 [00:19<00:00,  7.07it/s]
10/09/2021 13:00:15 - INFO - trainer -     T-F1(C) = 0.9838069049801406
10/09/2021 13:00:15 - INFO - trainer -     T-F1(D) = 0.9447852760736197
10/09/2021 13:00:15 - INFO - trainer -     T-F1(O) = 0.9952770112502654
10/09/2021 13:00:15 - INFO - trainer -     T-F1(P) = 0.9988516013780784
10/09/2021 13:00:15 - INFO - trainer -     T-F1(S) = 0.9953221668930134
10/09/2021 13:00:15 - INFO - trainer -     T-F1(T) = 0.9807162534435261
10/09/2021 13:00:15 - INFO - trainer -     U-F1(A) = 0.7782571182053495
10/09/2021 13:00:15 - INFO - trainer -     U-F1(E) = 0.863770560944749
10/09/2021 13:00:15 - INFO - trainer -     U-F1(I) = 0.7231208372978115
10/09/2021 13:00:15 - INFO - trainer -     U-F1(O) = 0.9490996960012471
10/09/2021 13:00:15 - INFO - trainer -     intent_acc = 0.9124641010913268
10/09/2021 13:00:15 - INFO - trainer -     loss = 0.758325410895279
10/09/2021 13:00:15 - INFO - trainer -     semantic_frame_acc = 0.8956921309592188
10/09/2021 13:00:15 - INFO - trainer -     slot_f1 = 0.9929336188436831
10/09/2021 13:00:15 - INFO - trainer -     slot_precision = 0.9926502069359212
10/09/2021 13:00:15 - INFO - trainer -     slot_recall = 0.9932171926317293

10/09/2021 13:00:15 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 13:00:15 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 13:00:15 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 13:00:15 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 13:00:15 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 13:00:15 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 13:00:15 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 13:00:15 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 13:00:15 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 13:00:15 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 13:00:15 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 13:00:15 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 13:00:15 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 13:00:15 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 13:00:15 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 13:00:15 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 13:00:15 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 13:01:01 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 314/815 [01:32<01:56,  4.31it/s]
10/09/2021 13:01:01 - INFO - trainer -     Num examples = 8705
10/09/2021 13:01:01 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.20it/s]
10/09/2021 13:01:21 - INFO - trainer -   ***** Eval results *****
10/09/2021 13:01:21 - INFO - trainer -     T-F1 = 0.9910959862011096████████████████▌| 136/137 [00:19<00:00,  7.08it/s]
10/09/2021 13:01:21 - INFO - trainer -     T-F1(C) = 0.9834963325183373
10/09/2021 13:01:21 - INFO - trainer -     T-F1(D) = 0.945945945945946
10/09/2021 13:01:21 - INFO - trainer -     T-F1(O) = 0.9953041678826308
10/09/2021 13:01:21 - INFO - trainer -     T-F1(P) = 0.9988516013780784
10/09/2021 13:01:21 - INFO - trainer -     T-F1(S) = 0.9954723815273167
10/09/2021 13:01:21 - INFO - trainer -     T-F1(T) = 0.9813921433494143
10/09/2021 13:01:21 - INFO - trainer -     U-F1(A) = 0.7796901893287436
10/09/2021 13:01:21 - INFO - trainer -     U-F1(E) = 0.863770560944749
10/09/2021 13:01:21 - INFO - trainer -     U-F1(I) = 0.721747388414055
10/09/2021 13:01:21 - INFO - trainer -     U-F1(O) = 0.9490018714909545
10/09/2021 13:01:21 - INFO - trainer -     intent_acc = 0.9123492245835727
10/09/2021 13:01:21 - INFO - trainer -     loss = 0.7608552860218991
10/09/2021 13:01:21 - INFO - trainer -     semantic_frame_acc = 0.8956921309592188
10/09/2021 13:01:21 - INFO - trainer -     slot_f1 = 0.9930394431554523
10/09/2021 13:01:21 - INFO - trainer -     slot_precision = 0.9929331144264402
10/09/2021 13:01:21 - INFO - trainer -     slot_recall = 0.9931457946594316

10/09/2021 13:01:21 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 13:01:21 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 13:01:21 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 13:01:21 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 13:01:21 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 13:01:21 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 13:01:21 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 13:01:21 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 13:01:21 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 13:01:21 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 13:01:21 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 13:01:21 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 13:01:21 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 13:01:21 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 13:01:21 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 13:01:21 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 13:01:21 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 13:02:07 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 514/815 [02:39<01:09,  4.33it/s]
10/09/2021 13:02:07 - INFO - trainer -     Num examples = 8705
10/09/2021 13:02:07 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.20it/s]
10/09/2021 13:02:27 - INFO - trainer -   ***** Eval results *****
10/09/2021 13:02:27 - INFO - trainer -     T-F1 = 0.9910976462363086████████████████▌| 136/137 [00:19<00:00,  7.09it/s]
10/09/2021 13:02:27 - INFO - trainer -     T-F1(C) = 0.9838069049801406
10/09/2021 13:02:27 - INFO - trainer -     T-F1(D) = 0.945945945945946
10/09/2021 13:02:27 - INFO - trainer -     T-F1(O) = 0.9953036695056914
10/09/2021 13:02:27 - INFO - trainer -     T-F1(P) = 0.9988516013780784
10/09/2021 13:02:27 - INFO - trainer -     T-F1(S) = 0.9954723815273167
10/09/2021 13:02:27 - INFO - trainer -     T-F1(T) = 0.9810671256454389
10/09/2021 13:02:27 - INFO - trainer -     U-F1(A) = 0.7765314926660914
10/09/2021 13:02:27 - INFO - trainer -     U-F1(E) = 0.8645215918712955
10/09/2021 13:02:27 - INFO - trainer -     U-F1(I) = 0.724365004703669
10/09/2021 13:02:27 - INFO - trainer -     U-F1(O) = 0.9491657570559802
10/09/2021 13:02:27 - INFO - trainer -     intent_acc = 0.9124641010913268
10/09/2021 13:02:27 - INFO - trainer -     loss = 0.7610684394667857
10/09/2021 13:02:27 - INFO - trainer -     semantic_frame_acc = 0.8959218839747272
10/09/2021 13:02:27 - INFO - trainer -     slot_f1 = 0.9930404368464256
10/09/2021 13:02:27 - INFO - trainer -     slot_precision = 0.9927924070505959
10/09/2021 13:02:27 - INFO - trainer -     slot_recall = 0.9932885906040269

10/09/2021 13:02:27 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 13:02:27 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 13:02:27 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 13:02:27 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 13:02:27 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 13:02:27 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 13:02:27 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 13:02:27 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 13:02:27 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 13:02:27 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 13:02:27 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 13:02:27 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 13:02:27 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 13:02:27 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 13:02:27 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 13:02:27 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 13:02:27 - INFO - trainer -     slot_recall = 0.9896472940168499
                                                                                                                       10/09/2021 13:03:13 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 714/815 [03:45<00:23,  4.31it/s]
10/09/2021 13:03:13 - INFO - trainer -     Num examples = 8705
10/09/2021 13:03:13 - INFO - trainer -     Batch size = 64
Evaluating: 100%|████████████████████████████████████████████████████████████████████| 137/137 [00:19<00:00,  7.20it/s]
10/09/2021 13:03:34 - INFO - trainer -   ***** Eval results *****
10/09/2021 13:03:34 - INFO - trainer -     T-F1 = 0.9910044278722908████████████████▌| 136/137 [00:19<00:00,  7.07it/s]
10/09/2021 13:03:34 - INFO - trainer -     T-F1(C) = 0.9834963325183373
10/09/2021 13:03:34 - INFO - trainer -     T-F1(D) = 0.947109471094711
10/09/2021 13:03:34 - INFO - trainer -     T-F1(O) = 0.9952506036243997
10/09/2021 13:03:34 - INFO - trainer -     T-F1(P) = 0.9988516013780784
10/09/2021 13:03:34 - INFO - trainer -     T-F1(S) = 0.9951719975859987
10/09/2021 13:03:34 - INFO - trainer -     T-F1(T) = 0.9810671256454389
10/09/2021 13:03:34 - INFO - trainer -     U-F1(A) = 0.7786391042204995
10/09/2021 13:03:34 - INFO - trainer -     U-F1(E) = 0.8640611724723875
10/09/2021 13:03:34 - INFO - trainer -     U-F1(I) = 0.7229601518026565
10/09/2021 13:03:34 - INFO - trainer -     U-F1(O) = 0.9493030137839732
10/09/2021 13:03:34 - INFO - trainer -     intent_acc = 0.9126938541068351
10/09/2021 13:03:34 - INFO - trainer -     loss = 0.7580342634263861
10/09/2021 13:03:34 - INFO - trainer -     semantic_frame_acc = 0.8960367604824814
10/09/2021 13:03:34 - INFO - trainer -     slot_f1 = 0.9929690567115171
10/09/2021 13:03:34 - INFO - trainer -     slot_precision = 0.9927210447441661
10/09/2021 13:03:34 - INFO - trainer -     slot_recall = 0.9932171926317293

10/09/2021 13:03:34 - INFO - trainer -   ***** Current best eval results based on JSA *****
10/09/2021 13:03:34 - INFO - trainer -     T-F1 = 0.9891075686036183
10/09/2021 13:03:34 - INFO - trainer -     T-F1(C) = 0.9819516671765066
10/09/2021 13:03:34 - INFO - trainer -     T-F1(D) = 0.933497536945813
10/09/2021 13:03:34 - INFO - trainer -     T-F1(O) = 0.9943050883373508
10/09/2021 13:03:34 - INFO - trainer -     T-F1(P) = 0.9987222080245336
10/09/2021 13:03:34 - INFO - trainer -     T-F1(S) = 0.9933434190620272
10/09/2021 13:03:34 - INFO - trainer -     T-F1(T) = 0.977035490605428
10/09/2021 13:03:34 - INFO - trainer -     U-F1(A) = 0.7975022301516503
10/09/2021 13:03:34 - INFO - trainer -     U-F1(E) = 0.8748921484037964
10/09/2021 13:03:34 - INFO - trainer -     U-F1(I) = 0.7489878542510121
10/09/2021 13:03:34 - INFO - trainer -     U-F1(O) = 0.9540167911884772
10/09/2021 13:03:34 - INFO - trainer -     intent_acc = 0.9217690982194141
10/09/2021 13:03:34 - INFO - trainer -     semantic_frame_acc = 0.9012062033314188
10/09/2021 13:03:34 - INFO - trainer -     slot_f1 = 0.9914523801008547
10/09/2021 13:03:34 - INFO - trainer -     slot_precision = 0.9932640630598352
10/09/2021 13:03:34 - INFO - trainer -     slot_recall = 0.9896472940168499
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 815/815 [04:28<00:00,  3.03it/s]
Epoch: 100%|████████████████████████████████████████████████████████████████████████| 20/20 [1:53:25<00:00, 340.29s/it]
