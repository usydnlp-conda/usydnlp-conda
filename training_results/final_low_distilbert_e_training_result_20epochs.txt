 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
10/09/2021 09:17:13 - INFO - data_loader -   *** Example ***
10/09/2021 09:17:13 - INFO - data_loader -   guid: dev-4
10/09/2021 09:17:13 - INFO - data_loader -   tokens: [CLS] i don ##t care stop ping me [SEP]
10/09/2021 09:17:13 - INFO - data_loader -   input_ids: 101 1045 2123 2102 2729 2644 17852 2033 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 09:17:13 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 09:17:13 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 09:17:13 - INFO - data_loader -   intent_label: 4 (id = 4)
10/09/2021 09:17:13 - INFO - data_loader -   slot_labels: 0 5 4 0 6 4 3 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 09:17:14 - INFO - data_loader -   ner_embeds: [ 1.920e-01  3.000e-02 -5.410e-01 -2.490e-01  8.700e-02 -4.460e-01
  3.700e-01  4.680e-01 -1.500e-02 -3.350e-01  8.400e-02  2.480e-01
 -1.150e-01 -2.240e-01 -1.040e-01 -2.340e-01 -4.870e-01  4.340e-01
 -1.940e-01 -4.700e-02  2.050e-01 -2.130e-01 -3.940e-01  4.730e-01
 -4.530e-01  3.110e-01 -1.390e-01  5.000e-01 -2.430e-01 -6.130e-01
  6.620e-01  5.020e-01 -1.150e-01 -6.000e-02 -5.620e-01  4.210e-01
  1.010e-01 -4.600e-02  4.170e-01 -1.920e-01 -4.670e-01  4.930e-01
  4.420e-01  1.300e-02 -2.280e-01 -2.030e-01 -1.410e-01  2.710e-01
  1.180e-01 -3.380e-01  3.520e-01  2.730e-01 -4.710e-01 -5.990e-01
 -4.630e-01 -2.470e-01  4.560e-01  1.350e-01  9.400e-02  1.007e+00
  6.660e-01 -8.600e-02 -1.050e-01 -1.010e+00  4.700e-02  7.100e-02
 -6.450e-01 -5.600e-02 -6.300e-02  1.000e-03  2.210e-01  1.970e-01
  2.000e-03  3.970e-01  5.380e-01  9.700e-02 -1.100e-01  6.210e-01
  3.560e-01  4.540e-01  1.090e-01 -1.180e-01  8.800e-02  1.500e-01
 -3.390e-01 -1.920e-01 -4.030e-01 -3.470e-01  2.930e-01  5.400e-02
  1.510e-01  3.640e-01  1.860e-01 -6.300e-01 -1.040e-01 -7.130e-01
  2.080e-01  4.060e-01 -3.940e-01  6.600e-02  2.450e-01  4.080e-01
  1.033e+00  2.930e-01  9.500e-02 -8.000e-03  4.320e-01 -3.220e-01
 -5.650e-01 -9.600e-02 -3.080e-01 -5.730e-01 -4.070e-01  2.750e-01
  1.480e-01 -1.800e-02  7.280e-01 -5.440e-01 -1.052e+00  1.100e-02
  5.480e-01 -1.490e-01  1.250e-01 -3.130e-01 -3.500e-02  3.750e-01
 -7.790e-01 -3.370e-01  2.200e-02 -4.770e-01 -6.280e-01  3.620e-01
  6.600e-02  1.410e-01 -2.860e-01  2.920e-01 -6.900e-02  1.100e-02
 -5.110e-01 -1.430e-01 -1.240e-01  5.520e-01 -2.400e-01 -1.520e-01
 -6.000e-03 -2.080e-01  8.300e-02 -1.270e-01 -1.990e-01 -1.500e-01
 -1.870e-01 -3.200e-02 -3.700e-02 -2.480e-01 -3.860e-01 -1.285e+00
  2.650e-01 -4.450e-01 -1.560e-01  3.110e-01  9.000e-03 -7.970e-01
 -2.300e-02 -1.270e-01 -5.870e-01  3.300e-01  4.850e-01  4.660e-01
 -6.440e-01 -3.770e-01 -2.550e-01  7.000e-03 -2.550e-01  6.240e-01
  2.890e-01 -1.080e-01 -3.260e-01  3.380e-01 -2.090e-01 -3.150e-01
  6.170e-01 -7.300e-02 -1.430e-01  3.330e-01 -1.950e-01  2.340e-01
  8.350e-01  1.350e-01 -2.530e-01  3.400e-02  5.290e-01 -2.620e-01
 -9.700e-02  2.980e-01  5.290e-01  2.400e-02 -3.210e-01  4.540e-01
 -4.950e-01  4.050e-01 -3.840e-01  4.150e-01  5.030e-01 -1.390e-01
 -2.590e-01 -1.340e-01 -7.320e-01 -2.700e-01 -1.260e-01  5.950e-01
  2.060e-01 -2.770e-01  6.900e-02 -1.018e+00 -2.200e-02  2.900e-02
 -2.990e-01  3.420e-01 -3.030e-01 -8.000e-02  7.420e-01 -3.800e-02
  1.460e-01 -3.710e-01 -7.460e-01 -4.520e-01 -1.200e-02  2.840e-01
  3.180e-01 -7.600e-01 -2.800e-01 -1.160e-01  6.600e-02  4.190e-01
 -2.280e-01  1.480e-01 -5.000e-02  3.200e-01 -9.700e-02 -4.520e-01
  7.450e-01 -9.400e-02  7.330e-01 -4.370e-01  4.890e-01 -3.090e-01
  2.210e-01 -3.140e-01 -2.210e-01 -7.700e-01  7.300e-02  5.160e-01
  7.950e-01 -4.280e-01  2.950e-01 -5.410e-01  5.650e-01 -3.180e-01
 -3.050e-01 -3.640e-01 -5.400e-02 -9.980e-01 -4.050e-01 -3.300e-01
 -2.520e-01 -4.550e-01 -1.160e-01  1.400e-02  6.800e-02 -6.900e-02
 -8.400e-02  2.220e-01  4.010e-01 -6.300e-02  1.850e-01  6.600e-01
  1.520e-01 -9.000e-03  6.190e-01 -3.460e-01  7.700e-02 -8.500e-02
  6.600e-02  5.580e-01  2.950e-01 -2.670e-01 -2.700e-01 -7.500e-02
  1.600e-01 -4.590e-01 -4.390e-01 -2.710e-01  4.490e-01  3.450e-01
 -2.730e-01 -4.570e-01  2.840e-01 -3.900e-02 -2.000e-03  8.700e-02] [-0.014  0.175  0.009  0.085 -0.281 -0.155  0.032 -0.276  0.097  0.249
  0.098  0.287  0.059  0.264  0.24  -0.057 -0.166  0.01   0.206  0.295
 -0.185  0.084  0.025  0.133 -0.108 -0.115  0.238  0.167  0.369 -0.248
  0.322  0.04   0.011  0.12   0.328  0.272  0.134  0.125 -0.14   0.08
 -0.029  0.037 -0.099 -0.135 -0.152 -0.044  0.034 -0.093 -0.079 -0.242
 -0.082  0.127  0.032  0.174  0.159 -0.034 -0.03   0.194 -0.294 -0.122
  0.056 -0.049  0.275  0.134  0.227  0.149 -0.334 -0.107  0.01  -0.008
 -0.118 -0.111  0.008  0.016 -0.013  0.201  0.247 -0.34  -0.006 -0.171
  0.321 -0.405  0.166 -0.286 -0.14  -0.29  -0.255 -0.112 -0.511 -0.34
 -0.019 -0.14  -0.191  0.145  0.084 -0.425  0.269  0.115 -0.125  0.155
  0.124 -0.025 -0.017  0.008  0.103 -0.407  0.145 -0.334 -0.312 -0.209
  0.003  0.071 -0.213  0.011  0.044 -0.074 -0.018 -0.172 -0.078 -0.273
 -0.067  0.187 -0.128 -0.47  -0.358 -0.181 -0.046 -0.149 -0.139 -0.18
  0.125 -0.387 -0.014 -0.131 -0.253 -0.316 -0.102  0.299  0.092  0.25
  0.002  0.332  0.037 -0.06  -0.247  0.01   0.316 -0.23  -0.128  0.165
 -0.193  0.038 -0.102 -0.163 -0.355 -0.019  0.124 -0.216 -0.119 -0.018
  0.262 -0.271 -0.259  0.299  0.147 -0.217 -0.06  -0.261 -0.266 -0.12
  0.263 -0.024 -0.12   0.213  0.175  0.214 -0.225 -0.361  0.317  0.123
  0.067 -0.068  0.094  0.226  0.083 -0.15   0.124  0.181  0.192 -0.022
  0.003  0.042 -0.136 -0.03  -0.057  0.019  0.293 -0.153 -0.048  0.006
  0.133  0.496  0.365  0.125  0.205 -0.02  -0.323 -0.264  0.091 -0.099
  0.072 -0.013 -0.157 -0.045  0.726 -0.064 -0.078 -0.134  0.125  0.488
 -0.127  0.056 -0.036 -0.121 -0.083 -0.219 -0.293 -0.012  0.323 -0.084
  0.078 -0.081 -0.364 -0.165  0.242 -0.459  0.063 -0.214 -0.31  -0.34
 -0.11   0.116 -0.07   0.059  0.089  0.069  0.163  0.095  0.378  0.055
  0.396 -0.106 -0.047 -0.124 -0.133 -0.109  0.112 -0.07  -0.282  0.084
  0.153  0.077 -0.044  0.169 -0.095 -0.066 -0.342 -0.043  0.048 -0.023
 -0.252 -0.264  0.375  0.026 -0.099 -0.209  0.037  0.073  0.273 -0.505
  0.238  0.087  0.113  0.359  0.105  0.47   0.127 -0.304 -0.325 -0.112
  0.019 -0.054  0.171  0.084 -0.231 -0.061 -0.104 -0.107 -0.16   0.174] [-0.419  0.043 -0.369  0.081 -0.36  -0.334  0.144  0.041  0.139 -0.179
  0.099  0.205 -0.106  0.121 -0.128  0.08  -0.221  0.06   0.025 -0.128
  0.108  0.312  0.051  0.147  0.349 -0.024  0.048 -0.337 -0.402 -0.215
  0.278  0.201 -0.478  0.192  0.189  0.407  0.136 -0.052  0.381  0.584
 -0.529 -0.166 -0.266  0.062 -0.173  0.07  -0.197  0.09  -0.057 -0.115
 -0.141  0.116 -0.19  -0.044 -0.345  0.153 -0.264  0.177 -0.37   0.332
  0.231  0.39   0.344 -0.292  0.009  0.318 -0.361  0.104 -0.199  0.464
 -0.223 -0.163 -0.097  0.094 -0.087  0.149 -0.379  0.156  0.063 -0.017
  0.04  -0.366  0.491  0.093 -0.499 -0.317 -0.061  0.23  -0.443 -0.079
  0.009  0.043 -0.178 -0.053 -0.235 -0.515  0.093  0.316 -0.456 -0.058
 -0.037  0.065  0.12  -0.038 -0.039  0.025  0.083 -0.26  -0.353 -0.113
 -0.198 -0.023  0.096 -0.133 -0.192  0.236 -0.066 -0.323  0.241 -0.028
 -0.137 -0.135  0.091  0.075 -0.466 -0.279 -0.088 -0.184  0.139 -0.182
 -0.337 -0.283 -0.074 -0.101  0.404 -0.308 -0.14   0.135  0.03   0.6
 -0.311  0.058  0.171 -0.168 -0.288 -0.355 -0.138 -0.019 -0.323  0.198
 -0.182 -0.226 -0.262  0.038 -0.171  0.202 -0.045  0.321 -0.026 -0.157
  0.298 -0.2   -0.106 -0.164  0.069  0.118  0.533 -0.275 -0.286 -0.297
  0.219  0.152 -0.484 -0.099 -0.239 -0.064 -0.243 -0.02  -0.071 -0.006
  0.081  0.303  0.054  0.291 -0.055 -0.161 -0.061  0.346 -0.239 -0.361
  0.009 -0.073 -0.142 -0.615 -0.126  0.487  0.243  0.052  0.024  0.085
  0.025  0.383  0.135 -0.129  0.061 -0.083  0.084 -0.124 -0.273 -0.159
  0.385 -0.463  0.244 -0.428  0.472 -0.222 -0.329  0.123 -0.105  0.322
  0.197 -0.052 -0.098 -0.092 -0.468 -0.304 -0.272 -0.075  0.004  0.441
  0.171  0.042 -0.242 -0.082 -0.066  0.09  -0.174  0.071 -0.139 -0.616
  0.264  0.115  0.293  0.076 -0.051 -0.128  0.049 -0.087  0.265 -0.169
  0.289 -0.054 -0.057  0.052  0.018  0.203  0.196 -0.184  0.028 -0.064
  0.167 -0.094 -0.189 -0.024  0.078  0.047 -0.424 -0.196 -0.362 -0.105
 -0.011  0.17   0.027 -0.411 -0.285  0.149  0.426  0.383  0.16  -0.181
  0.353 -0.062  0.266  0.451  0.065  0.041  0.048 -0.017 -0.501 -0.215
 -0.092 -0.081 -0.337 -0.096  0.002 -0.128  0.158  0.185 -0.426  0.073] [-0.838  0.086 -0.738  0.162 -0.72  -0.668  0.288  0.082  0.278 -0.358
  0.198  0.41  -0.212  0.242 -0.256  0.16  -0.442  0.12   0.05  -0.256
  0.216  0.624  0.102  0.294  0.698 -0.048  0.096 -0.674 -0.804 -0.43
  0.556  0.402 -0.956  0.384  0.378  0.814  0.272 -0.104  0.762  1.168
 -1.058 -0.332 -0.532  0.124 -0.346  0.14  -0.394  0.18  -0.114 -0.23
 -0.282  0.232 -0.38  -0.088 -0.69   0.306 -0.528  0.354 -0.74   0.664
  0.462  0.78   0.688 -0.584  0.018  0.636 -0.722  0.208 -0.398  0.928
 -0.446 -0.326 -0.194  0.188 -0.174  0.298 -0.758  0.312  0.126 -0.034
  0.08  -0.732  0.982  0.186 -0.998 -0.634 -0.122  0.46  -0.886 -0.158
  0.018  0.086 -0.356 -0.106 -0.47  -1.03   0.186  0.632 -0.912 -0.116
 -0.074  0.13   0.24  -0.076 -0.078  0.05   0.166 -0.52  -0.706 -0.226
 -0.396 -0.046  0.192 -0.266 -0.384  0.472 -0.132 -0.646  0.482 -0.056
 -0.274 -0.27   0.182  0.15  -0.932 -0.558 -0.176 -0.368  0.278 -0.364
 -0.674 -0.566 -0.148 -0.202  0.808 -0.616 -0.28   0.27   0.06   1.2
 -0.622  0.116  0.342 -0.336 -0.576 -0.71  -0.276 -0.038 -0.646  0.396
 -0.364 -0.452 -0.524  0.076 -0.342  0.404 -0.09   0.642 -0.052 -0.314
  0.596 -0.4   -0.212 -0.328  0.138  0.236  1.066 -0.55  -0.572 -0.594
  0.438  0.304 -0.968 -0.198 -0.478 -0.128 -0.486 -0.04  -0.142 -0.012
  0.162  0.606  0.108  0.582 -0.11  -0.322 -0.122  0.692 -0.478 -0.722
  0.018 -0.146 -0.284 -1.23  -0.252  0.974  0.486  0.104  0.048  0.17
  0.05   0.766  0.27  -0.258  0.122 -0.166  0.168 -0.248 -0.546 -0.318
  0.77  -0.926  0.488 -0.856  0.944 -0.444 -0.658  0.246 -0.21   0.644
  0.394 -0.104 -0.196 -0.184 -0.936 -0.608 -0.544 -0.15   0.008  0.882
  0.342  0.084 -0.484 -0.164 -0.132  0.18  -0.348  0.142 -0.278 -1.232
  0.528  0.23   0.586  0.152 -0.102 -0.256  0.098 -0.174  0.53  -0.338
  0.578 -0.108 -0.114  0.104  0.036  0.406  0.392 -0.368  0.056 -0.128
  0.334 -0.188 -0.378 -0.048  0.156  0.094 -0.848 -0.392 -0.724 -0.21
 -0.022  0.34   0.054 -0.822 -0.57   0.298  0.852  0.766  0.32  -0.362
  0.706 -0.124  0.532  0.902  0.13   0.082  0.096 -0.034 -1.002 -0.43
 -0.184 -0.162 -0.674 -0.192  0.004 -0.256  0.316  0.37  -0.852  0.146] [-0.449  0.01  -0.251 -0.063  0.384 -0.636  0.038  0.264 -0.211  0.1
 -0.591 -0.069  0.159  0.129 -0.47  -0.031 -0.438 -0.117  0.151 -0.323
  0.211  0.135  0.343 -0.06   0.086 -0.078 -0.272  0.24   0.007 -0.189
  0.401 -0.118 -0.204 -0.122 -0.247  0.002  0.249 -0.018 -0.067 -0.348
 -0.25   0.178 -0.212  0.161  0.245 -0.151  0.613 -0.121  0.102 -0.111
  0.128 -0.108 -0.363 -0.441 -0.419 -0.148 -0.722 -0.205 -0.082 -0.473
 -0.004  0.374 -0.274 -0.057 -0.25  -0.016 -0.031 -0.075  0.243 -0.066
 -0.243 -0.189 -0.361 -0.015 -0.179  0.698 -0.274 -0.515 -0.086  0.018
 -0.262 -0.618  0.119  0.39   0.201 -0.213  0.422  0.204 -0.475 -0.041
 -0.349  0.24  -0.033 -0.068 -0.378 -0.068  0.088  0.505 -0.13   0.107
 -0.611  0.321  0.316  0.267 -0.361 -0.199  0.246 -0.259  0.179 -0.218
 -0.462 -0.039  0.012 -0.108 -0.131 -0.034  0.104 -0.437 -0.004 -0.026
  0.407 -0.215  0.324  0.082  0.142 -0.192 -0.286 -0.056  0.433 -0.04
  0.385 -0.47   0.214  0.181 -0.241 -0.488 -0.035 -0.303 -0.255  0.348
  0.236 -0.106  0.244 -0.013  0.338  0.243 -0.163  0.165 -0.216 -0.282
 -0.093 -0.24  -0.308  0.734  0.009 -0.173  0.227  0.245  0.255  0.045
  0.139  0.464  0.244 -0.255 -0.05   0.23   0.584 -0.231 -0.45   0.156
  0.048  0.168  0.031  0.149 -0.179  0.448  0.07  -0.317  0.174  0.466
  0.304  0.116  0.487 -0.099  0.107 -0.104 -0.319  0.182  0.508 -0.679
  0.152 -0.139 -0.419 -0.537 -0.139 -0.079 -0.704  0.414 -0.371 -0.236
 -0.018  0.118  0.286  0.386 -0.349  0.232  0.442  0.115 -0.006 -0.162
  0.498  0.397 -0.231 -0.534  0.873 -0.496 -0.004 -0.32  -0.126  0.159
  0.409 -0.571  0.15   0.243  0.007  0.087 -0.346 -0.321  0.554  0.538
 -0.102 -0.159  0.295 -0.546  0.757  0.116 -0.32   0.527 -0.325 -0.082
 -0.008 -0.321 -0.224 -0.275  0.332  0.281 -0.042  0.173  0.688 -0.124
  0.306 -0.018  0.12   0.332 -0.567 -0.256  0.309 -0.254  0.865 -0.16
  0.214 -0.423  0.366  0.22   0.276  0.187  0.054  0.197 -0.382  0.009
  0.432 -0.186 -0.465 -0.244 -0.756 -0.291  0.226 -0.209  0.175 -0.388
  0.109  0.538 -0.425 -0.415 -0.222  0.575  0.058 -0.113 -0.392 -0.087
  0.188 -0.324  0.333 -0.323  0.155  0.296 -0.323 -0.459 -0.18   0.625] [ 5.900e-02 -5.500e-02 -1.990e-01 -1.830e-01 -5.350e-01  8.500e-02
 -1.710e-01  1.500e-02 -1.940e-01 -2.250e-01 -1.200e-01 -2.210e-01
  3.280e-01  2.800e-02  8.000e-02  2.660e-01 -6.280e-01 -2.190e-01
  2.280e-01  2.570e-01  2.910e-01  1.800e-02 -4.000e-02  5.450e-01
  2.180e-01 -5.990e-01  2.540e-01 -1.130e-01 -3.900e-02  1.670e-01
  2.290e-01  2.490e-01  4.300e-01 -1.390e-01  4.050e-01 -1.350e-01
 -1.000e-03 -3.530e-01  2.300e-01  2.910e-01  2.800e-01  1.050e-01
 -2.030e-01 -2.120e-01  5.100e-02 -5.500e-02  2.200e-01  2.680e-01
 -1.680e-01 -3.870e-01 -3.130e-01  1.430e-01 -2.560e-01  5.900e-02
 -2.760e-01 -4.180e-01 -4.950e-01 -4.720e-01  7.010e-01 -2.720e-01
 -5.640e-01 -1.780e-01  2.600e-01 -2.330e-01 -1.440e-01 -3.100e-01
 -2.780e-01 -5.600e-02 -2.520e-01  3.170e-01 -1.880e-01  2.220e-01
  5.290e-01  2.090e-01 -6.420e-01  8.100e-02 -4.730e-01 -2.910e-01
  1.920e-01  9.200e-02  5.640e-01 -2.110e-01  1.610e-01  2.060e-01
  2.400e-02  1.660e-01  1.300e-02 -7.200e-02 -4.460e-01  2.000e-02
 -1.200e-01 -1.100e-01 -3.950e-01  1.690e-01 -4.200e-02  3.050e-01
  2.900e-02  2.760e-01 -1.470e-01 -5.800e-02 -1.010e-01  8.100e-02
  3.200e-02  9.000e-02  6.920e-01 -1.500e-01  1.073e+00  2.710e-01
  2.200e-01  5.990e-01  1.030e-01 -2.140e-01 -3.210e-01  4.770e-01
  6.650e-01  8.000e-02  2.630e-01 -7.050e-01 -5.080e-01 -8.970e-01
  1.500e-02  3.230e-01  1.840e-01  2.400e-02  1.640e-01  1.500e-02
  6.700e-02  2.620e-01 -2.800e-01 -6.330e-01 -4.720e-01  2.700e-01
  8.260e-01  3.310e-01  4.330e-01 -4.000e-01 -2.690e-01 -2.670e-01
 -2.070e-01 -1.280e-01 -5.500e-02 -1.510e-01  4.310e-01  1.000e-02
 -2.500e-02  1.890e-01  2.880e-01 -1.770e-01  4.800e-02  4.680e-01
 -8.160e-01  4.510e-01  3.050e-01  2.300e-02  1.570e-01 -7.300e-02
  2.320e-01  2.900e-02 -2.810e-01 -7.900e-02  9.340e-01  5.000e-02
 -4.960e-01 -8.950e-01  7.300e-02  5.910e-01 -4.210e-01 -3.340e-01
  1.740e-01 -1.290e-01 -7.000e-03 -3.290e-01 -5.970e-01 -5.000e-02
 -1.770e-01 -1.280e-01 -3.910e-01 -1.160e-01 -3.080e-01 -2.260e-01
  7.530e-01 -8.200e-02 -4.610e-01  2.700e-02 -3.890e-01 -4.420e-01
 -3.120e-01 -1.800e-01 -1.400e-01  4.600e-02  2.810e-01 -7.100e-02
  1.680e-01  2.910e-01  2.580e-01 -1.090e-01 -1.400e-02  5.010e-01
 -1.000e-01 -1.890e-01 -9.800e-02 -4.250e-01  4.300e-01 -1.350e-01
 -2.520e-01 -9.000e-02 -2.180e-01 -2.170e-01 -5.330e-01  1.520e-01
  1.390e-01 -8.200e-02  3.060e-01 -2.900e-01  3.180e-01 -3.690e-01
 -3.730e-01 -3.580e-01 -1.330e-01  6.090e-01  2.070e-01  4.930e-01
  4.320e-01  1.910e-01 -4.600e-01  2.030e-01 -9.000e-02  9.200e-02
  2.060e-01 -4.030e-01  5.800e-02 -4.020e-01 -4.230e-01  1.400e-02
  1.490e-01 -1.058e+00  1.720e-01  2.140e-01  6.830e-01  4.180e-01
  5.070e-01 -3.360e-01 -5.000e-02 -5.140e-01  5.160e-01 -4.690e-01
 -5.600e-02 -8.000e-02  2.330e-01  2.520e-01 -5.800e-02  1.360e-01
  9.060e-01 -7.220e-01  1.800e-01  1.490e-01  6.920e-01  3.200e-01
 -3.330e-01  9.000e-02  9.530e-01  3.070e-01 -3.650e-01 -3.110e-01
 -6.790e-01  7.080e-01  2.160e-01 -1.630e-01 -3.450e-01 -3.100e-01
  3.390e-01 -2.680e-01  2.820e-01 -2.070e-01  3.280e-01  1.210e-01
  1.210e-01 -1.400e-01  6.040e-01  6.000e-03  2.100e-02  2.200e-02
  2.650e-01 -4.510e-01  1.710e-01  2.680e-01 -3.780e-01 -2.440e-01
  3.560e-01 -2.970e-01  1.900e-02  1.810e-01 -5.000e-02 -5.770e-01
 -5.000e-03 -1.340e-01  4.540e-01  7.120e-01 -7.480e-01 -8.260e-01] [ 2.900e-01  2.240e-01 -2.860e-01 -2.220e-01 -5.860e-01 -2.770e-01
 -7.500e-02 -2.500e-01  2.180e-01 -7.100e-02 -6.280e-01  8.100e-02
 -3.500e-02  5.000e-02  7.360e-01 -1.140e-01  2.080e-01  3.010e-01
 -3.000e-01 -1.800e-01 -1.050e-01  8.400e-02 -6.000e-02  3.320e-01
  2.980e-01  5.430e-01  6.350e-01 -2.930e-01 -5.350e-01  3.990e-01
  1.000e-02 -5.920e-01  1.200e-01  1.630e-01  5.900e-02  6.800e-02
  6.410e-01  5.400e-02  3.730e-01  1.930e-01 -5.240e-01 -1.270e-01
 -1.890e-01  7.900e-02  2.280e-01 -1.450e-01  6.810e-01 -3.900e-02
 -3.900e-01  3.800e-02 -9.700e-02  2.210e-01 -4.800e-01  1.190e-01
 -9.100e-02 -3.000e-03  4.930e-01  3.400e-02 -2.100e-02 -5.870e-01
 -5.700e-02 -2.050e-01 -4.040e-01  1.930e-01  5.400e-02  1.320e-01
  4.710e-01 -1.350e-01 -7.400e-02 -2.870e-01 -3.710e-01 -1.460e-01
 -1.710e-01 -9.000e-03  6.930e-01  5.000e-01 -1.640e-01 -2.080e-01
 -2.190e-01 -3.290e-01  4.260e-01  4.150e-01 -3.280e-01  1.150e-01
 -4.440e-01  1.600e-02  4.450e-01 -2.690e-01 -3.880e-01  1.180e-01
 -1.900e-01 -8.010e-01  2.570e-01 -2.360e-01 -1.450e-01 -2.170e-01
  6.690e-01  7.010e-01 -4.100e-02 -2.830e-01 -2.820e-01 -2.400e-02
  2.980e-01 -1.410e-01  1.180e-01 -7.750e-01 -1.070e-01  3.410e-01
 -2.760e-01 -6.100e-02 -4.400e-02  1.890e-01  1.380e-01  3.420e-01
 -1.060e-01  2.780e-01  1.800e-02  6.400e-02 -6.000e-02  1.020e-01
  2.650e-01  4.620e-01  6.500e-02 -1.480e-01 -2.270e-01  2.080e-01
 -2.650e-01 -2.560e-01  2.620e-01 -6.030e-01  1.360e-01 -3.740e-01
  7.730e-01 -3.400e-01 -2.100e-01 -2.500e-01 -9.000e-03 -1.480e-01
  5.920e-01  4.810e-01 -3.440e-01  5.710e-01  1.690e-01 -8.700e-02
  1.170e-01 -4.840e-01 -2.900e-02  7.110e-01 -5.800e-02 -3.850e-01
  1.980e-01  1.500e-01  3.990e-01  3.060e-01 -4.210e-01 -3.260e-01
 -1.650e-01 -1.900e-02 -5.300e-01 -4.430e-01  3.180e-01 -6.190e-01
  1.860e-01 -1.160e-01 -6.500e-02  2.040e-01  4.900e-02  2.380e-01
 -7.200e-02 -1.240e-01  5.110e-01  2.050e-01  1.350e-01  1.340e-01
 -1.180e-01 -3.960e-01 -4.220e-01 -4.910e-01  1.000e-03  3.520e-01
 -4.100e-02  1.060e-01 -3.290e-01  1.160e-01 -6.480e-01  7.120e-01
  1.780e-01  1.000e-01  1.720e-01 -2.040e-01 -3.700e-01  1.810e-01
 -1.900e-01  5.500e-02  4.090e-01  3.930e-01 -1.860e-01 -3.930e-01
 -1.070e-01  7.980e-01 -1.940e-01 -2.490e-01  9.000e-02  3.890e-01
  8.170e-01  1.360e-01 -2.880e-01 -2.060e-01  1.330e-01 -1.400e-01
  5.440e-01 -3.140e-01 -3.800e-01 -1.570e-01 -7.400e-02 -1.300e-02
 -1.670e-01  1.910e-01 -3.020e-01 -4.200e-02  1.680e-01  2.100e-02
  5.110e-01  5.660e-01 -1.490e-01 -2.220e-01 -4.340e-01  5.280e-01
  2.460e-01 -1.530e-01  3.600e-02  3.500e-02 -5.690e-01  4.140e-01
  6.730e-01 -2.040e-01 -4.190e-01  5.270e-01  6.900e-02  1.790e-01
  6.320e-01 -1.460e-01  3.800e-02 -1.135e+00 -1.870e-01 -6.150e-01
 -2.000e-02 -3.360e-01 -3.450e-01 -8.700e-02  3.420e-01 -1.680e-01
  1.700e-01 -1.830e-01 -4.400e-01  2.600e-02  2.550e-01 -3.400e-02
  3.650e-01  3.700e-02 -9.640e-01  3.600e-01 -1.510e-01  6.210e-01
  2.140e-01 -4.300e-02  5.900e-02  1.500e-02 -3.000e-01  1.500e-02
 -8.310e-01  1.800e-01  3.830e-01 -2.360e-01  8.200e-02 -2.600e-01
  5.230e-01  0.000e+00  3.190e-01 -1.370e-01  4.200e-02  4.310e-01
 -2.600e-01  2.300e-02  2.300e-01  3.150e-01  4.200e-02  2.840e-01
 -1.950e-01  7.300e-02  1.044e+00  1.870e-01 -6.800e-02 -3.490e-01
  5.460e-01 -1.970e-01 -5.200e-02 -1.000e-01 -2.780e-01 -9.000e-03] [-0.075  0.598 -0.353  0.034 -0.448 -0.362 -0.13  -0.226  0.02   0.1
 -0.227  0.144 -0.128  0.206  0.131 -0.131 -0.045 -0.019 -0.225  0.365
 -0.013  0.022  0.095  0.144  0.425  0.375 -0.117 -0.436 -0.051  0.205
 -0.328  0.243  0.127  0.064  0.367 -0.02   0.311 -0.017 -0.049  0.152
 -0.316 -0.089  0.147 -0.04  -0.111  0.25  -0.207  0.147 -0.095 -0.472
  0.104 -0.37  -0.286  0.251  0.073 -0.011 -0.105  0.219 -0.429 -0.108
 -0.021 -0.034 -0.042  0.067 -0.118  0.295 -0.059 -0.203 -0.12  -0.154
 -0.649 -0.027 -0.162 -0.265  0.001  0.183 -0.019  0.163 -0.347 -0.367
  0.195 -0.065  0.145  0.163 -0.097 -0.395 -0.174  0.061 -0.367 -0.116
 -0.057 -0.205  0.061 -0.293 -0.064 -0.419  0.11   0.314 -0.222  0.202
 -0.018 -0.203 -0.017  0.201  0.016 -0.154  0.323 -0.235 -0.086 -0.222
  0.109 -0.036 -0.206  0.2   -0.106  0.103 -0.245  0.047  0.344 -0.296
 -0.109  0.334  0.459 -0.161 -0.091 -0.187  0.151  0.097  0.345 -0.243
 -0.091 -0.036  0.22   0.093 -0.2   -0.469 -0.108  0.187  0.095  0.076
  0.127  0.428 -0.087  0.04   0.325  0.075 -0.024 -0.227 -0.071 -0.002
 -0.374  0.118 -0.53  -0.187 -0.204 -0.019 -0.048  0.119 -0.31   0.112
  0.324 -0.09  -0.548 -0.333  0.034  0.154  0.232 -0.398  0.177 -0.058
  0.238 -0.15   0.174  0.45   0.205  0.248 -0.278 -0.303  0.236  0.608
  0.158 -0.017  0.    -0.027  0.196 -0.026 -0.224 -0.033  0.02  -0.252
 -0.17  -0.107 -0.006 -0.532 -0.024  0.153  0.283  0.055  0.144  0.239
 -0.084 -0.074  0.219  0.001 -0.156 -0.137 -0.105  0.098 -0.086  0.087
 -0.131  0.166 -0.192 -0.38   0.447 -0.099 -0.238 -0.174  0.193  0.187
  0.204  0.238  0.164 -0.328 -0.261  0.201  0.231 -0.287  0.37   0.229
 -0.268  0.158 -0.751 -0.039 -0.037 -0.39  -0.371  0.253 -0.141 -0.036
  0.046 -0.153 -0.033 -0.214 -0.063 -0.081  0.044 -0.098  0.05   0.117
  0.092  0.572 -0.208 -0.221 -0.165 -0.262  0.209 -0.162  0.222 -0.127
 -0.035 -0.116  0.497  0.028  0.027  0.371 -0.053 -0.264  0.055  0.109
  0.047 -0.319 -0.097 -0.137 -0.184 -0.333  0.252  0.085  0.242 -0.383
  0.195 -0.06   0.093  0.358 -0.131  0.334 -0.012  0.047 -0.35  -0.899
 -0.105  0.382 -0.345  0.026 -0.209 -0.067 -0.056  0.291  0.287  0.176] [ 1.190e-01 -3.600e-02  4.260e-01  1.670e-01 -4.560e-01  9.120e-01
  4.560e-01  4.570e-01 -2.290e-01 -6.000e-01  5.300e-02  2.450e-01
  5.470e-01  3.000e-03 -2.830e-01  3.600e-01 -3.530e-01  2.210e-01
  1.000e-03  7.590e-01  2.920e-01 -8.700e-02  3.590e-01  3.780e-01
 -4.060e-01 -8.240e-01  4.610e-01  3.930e-01 -1.960e-01  2.710e-01
  4.740e-01 -1.390e-01  1.024e+00 -3.140e-01 -3.850e-01  9.200e-02
 -5.610e-01 -3.530e-01  1.660e-01 -1.250e-01 -1.940e-01  1.269e+00
 -4.430e-01 -9.900e-02 -6.960e-01  2.330e-01  3.490e-01 -4.220e-01
  3.110e-01  7.080e-01  1.730e-01  9.060e-01  1.500e-02 -3.180e-01
 -5.150e-01 -2.720e-01 -6.400e-01  1.000e-03  3.720e-01  3.370e-01
 -1.400e+00  1.000e-02 -3.710e-01 -8.500e-02 -6.140e-01 -5.000e-01
  3.390e-01  4.000e-02 -3.650e-01  7.770e-01  4.120e-01  2.020e-01
  1.770e-01 -2.840e-01 -3.290e-01  1.368e+00 -1.360e-01  1.690e-01
  1.170e-01 -3.100e-02  7.470e-01 -2.580e-01 -1.570e-01  4.620e-01
 -2.900e-02 -5.010e-01 -3.540e-01 -3.670e-01 -1.990e-01 -1.120e-01
  4.600e-02  5.070e-01 -2.260e-01  5.600e-02  4.700e-02 -4.150e-01
  4.010e-01  1.170e-01  4.550e-01  2.120e-01  3.450e-01  2.290e-01
  9.820e-01 -5.950e-01 -1.830e-01 -3.510e-01  6.360e-01  5.420e-01
 -6.650e-01  6.400e-01 -8.110e-01 -4.480e-01  1.690e-01  6.060e-01
  4.080e-01  6.260e-01  2.660e-01 -3.940e-01 -1.250e-01  3.200e-01
  3.660e-01 -3.640e-01  2.280e-01 -1.550e-01 -4.550e-01  4.680e-01
 -4.770e-01 -3.500e-02  4.460e-01 -3.730e-01 -5.650e-01 -6.030e-01
  8.380e-01  4.600e-01 -7.200e-02 -3.480e-01 -2.260e-01  4.000e-03
 -2.870e-01  3.300e-02 -2.890e-01 -3.730e-01  6.560e-01  1.600e-02
 -6.680e-01  1.200e-01 -8.900e-02 -1.310e-01 -2.730e-01 -6.600e-02
 -4.160e-01  6.760e-01 -4.670e-01  3.310e-01  3.060e-01  3.210e-01
  2.100e-01 -2.380e-01 -7.860e-01  4.940e-01 -2.170e-01  3.670e-01
 -1.260e-01 -2.040e-01  1.400e-02 -4.500e-02  8.610e-01  6.050e-01
 -5.100e-02  2.210e-01  1.120e-01 -2.930e-01 -6.300e-01 -2.690e-01
  3.920e-01  2.530e-01 -2.310e-01 -2.820e-01  3.830e-01  2.020e-01
  2.220e-01  1.010e+00  1.900e-01  8.400e-02  7.460e-01 -6.370e-01
 -3.620e-01 -6.040e-01 -7.680e-01  4.400e-02  3.820e-01 -1.570e-01
  4.670e-01 -3.590e-01  6.100e-01 -6.840e-01 -1.510e-01  3.250e-01
  1.970e-01 -2.410e-01  5.700e-02  1.840e-01 -2.520e-01  2.530e-01
  5.800e-01 -6.700e-02 -9.240e-01 -2.920e-01 -8.900e-02 -6.630e-01
 -4.140e-01 -4.360e-01  1.620e-01 -8.040e-01  3.830e-01 -2.800e-02
  3.670e-01 -2.050e-01 -5.430e-01  1.560e-01  9.310e-01 -1.310e-01
  5.950e-01  1.270e-01 -5.830e-01  6.540e-01 -1.480e-01  2.980e-01
  3.810e-01  1.340e-01  9.000e-02  1.730e-01  2.200e-01  1.890e-01
  4.510e-01 -9.320e-01 -4.300e-02  3.910e-01  2.490e-01  1.900e-01
 -2.470e-01  6.520e-01  7.200e-02  1.700e-01 -5.820e-01  4.410e-01
 -6.140e-01  6.500e-01  2.060e-01  3.020e-01  1.110e-01  3.310e-01
 -1.870e-01 -1.040e-01  1.240e-01 -4.760e-01  1.290e-01  2.870e-01
 -3.240e-01 -2.470e-01 -3.070e-01  4.500e-02  1.770e-01 -4.800e-02
  2.060e-01 -2.000e-01  3.720e-01 -4.870e-01 -1.140e-01 -7.350e-01
  4.000e-02 -1.720e-01  4.010e-01 -7.110e-01  4.900e-01  5.480e-01
  4.250e-01 -4.470e-01  6.780e-01  2.740e-01 -3.400e-02  2.330e-01
  6.600e-02 -5.230e-01  5.980e-01 -1.100e-02 -5.900e-02 -3.500e-02
  1.810e-01 -9.600e-02 -9.000e-03 -4.640e-01  1.670e-01  1.820e-01
  4.380e-01  2.890e-01  6.260e-01  4.080e-01 -4.030e-01 -4.440e-01] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
10/09/2021 09:17:16 - INFO - data_loader -   Saving features into cached file ./data\cached_dev_low_distilbert-base-uncased_50
10/09/2021 09:17:24 - INFO - data_loader -   Creating features from dataset file at ./data
10/09/2021 09:17:24 - INFO - data_loader -   LOOKING AT ./data\low\test
10/09/2021 09:17:24 - INFO - data_loader -   Writing example 0 of 3628
10/09/2021 09:17:24 - INFO - data_loader -   *** Example ***
10/09/2021 09:17:24 - INFO - data_loader -   guid: test-0
10/09/2021 09:17:24 - INFO - data_loader -   tokens: [CLS] guys together [SEP]
10/09/2021 09:17:24 - INFO - data_loader -   input_ids: 101 4364 2362 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 09:17:24 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 09:17:24 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 09:17:24 - INFO - data_loader -   intent_label: 4 (id = 4)
10/09/2021 09:17:24 - INFO - data_loader -   slot_labels: 0 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 09:17:24 - INFO - data_loader -   ner_embeds: [ 1.920e-01  3.000e-02 -5.410e-01 -2.490e-01  8.700e-02 -4.460e-01
  3.700e-01  4.680e-01 -1.500e-02 -3.350e-01  8.400e-02  2.480e-01
 -1.150e-01 -2.240e-01 -1.040e-01 -2.340e-01 -4.870e-01  4.340e-01
 -1.940e-01 -4.700e-02  2.050e-01 -2.130e-01 -3.940e-01  4.730e-01
 -4.530e-01  3.110e-01 -1.390e-01  5.000e-01 -2.430e-01 -6.130e-01
  6.620e-01  5.020e-01 -1.150e-01 -6.000e-02 -5.620e-01  4.210e-01
  1.010e-01 -4.600e-02  4.170e-01 -1.920e-01 -4.670e-01  4.930e-01
  4.420e-01  1.300e-02 -2.280e-01 -2.030e-01 -1.410e-01  2.710e-01
  1.180e-01 -3.380e-01  3.520e-01  2.730e-01 -4.710e-01 -5.990e-01
 -4.630e-01 -2.470e-01  4.560e-01  1.350e-01  9.400e-02  1.007e+00
  6.660e-01 -8.600e-02 -1.050e-01 -1.010e+00  4.700e-02  7.100e-02
 -6.450e-01 -5.600e-02 -6.300e-02  1.000e-03  2.210e-01  1.970e-01
  2.000e-03  3.970e-01  5.380e-01  9.700e-02 -1.100e-01  6.210e-01
  3.560e-01  4.540e-01  1.090e-01 -1.180e-01  8.800e-02  1.500e-01
 -3.390e-01 -1.920e-01 -4.030e-01 -3.470e-01  2.930e-01  5.400e-02
  1.510e-01  3.640e-01  1.860e-01 -6.300e-01 -1.040e-01 -7.130e-01
  2.080e-01  4.060e-01 -3.940e-01  6.600e-02  2.450e-01  4.080e-01
  1.033e+00  2.930e-01  9.500e-02 -8.000e-03  4.320e-01 -3.220e-01
 -5.650e-01 -9.600e-02 -3.080e-01 -5.730e-01 -4.070e-01  2.750e-01
  1.480e-01 -1.800e-02  7.280e-01 -5.440e-01 -1.052e+00  1.100e-02
  5.480e-01 -1.490e-01  1.250e-01 -3.130e-01 -3.500e-02  3.750e-01
 -7.790e-01 -3.370e-01  2.200e-02 -4.770e-01 -6.280e-01  3.620e-01
  6.600e-02  1.410e-01 -2.860e-01  2.920e-01 -6.900e-02  1.100e-02
 -5.110e-01 -1.430e-01 -1.240e-01  5.520e-01 -2.400e-01 -1.520e-01
 -6.000e-03 -2.080e-01  8.300e-02 -1.270e-01 -1.990e-01 -1.500e-01
 -1.870e-01 -3.200e-02 -3.700e-02 -2.480e-01 -3.860e-01 -1.285e+00
  2.650e-01 -4.450e-01 -1.560e-01  3.110e-01  9.000e-03 -7.970e-01
 -2.300e-02 -1.270e-01 -5.870e-01  3.300e-01  4.850e-01  4.660e-01
 -6.440e-01 -3.770e-01 -2.550e-01  7.000e-03 -2.550e-01  6.240e-01
  2.890e-01 -1.080e-01 -3.260e-01  3.380e-01 -2.090e-01 -3.150e-01
  6.170e-01 -7.300e-02 -1.430e-01  3.330e-01 -1.950e-01  2.340e-01
  8.350e-01  1.350e-01 -2.530e-01  3.400e-02  5.290e-01 -2.620e-01
 -9.700e-02  2.980e-01  5.290e-01  2.400e-02 -3.210e-01  4.540e-01
 -4.950e-01  4.050e-01 -3.840e-01  4.150e-01  5.030e-01 -1.390e-01
 -2.590e-01 -1.340e-01 -7.320e-01 -2.700e-01 -1.260e-01  5.950e-01
  2.060e-01 -2.770e-01  6.900e-02 -1.018e+00 -2.200e-02  2.900e-02
 -2.990e-01  3.420e-01 -3.030e-01 -8.000e-02  7.420e-01 -3.800e-02
  1.460e-01 -3.710e-01 -7.460e-01 -4.520e-01 -1.200e-02  2.840e-01
  3.180e-01 -7.600e-01 -2.800e-01 -1.160e-01  6.600e-02  4.190e-01
 -2.280e-01  1.480e-01 -5.000e-02  3.200e-01 -9.700e-02 -4.520e-01
  7.450e-01 -9.400e-02  7.330e-01 -4.370e-01  4.890e-01 -3.090e-01
  2.210e-01 -3.140e-01 -2.210e-01 -7.700e-01  7.300e-02  5.160e-01
  7.950e-01 -4.280e-01  2.950e-01 -5.410e-01  5.650e-01 -3.180e-01
 -3.050e-01 -3.640e-01 -5.400e-02 -9.980e-01 -4.050e-01 -3.300e-01
 -2.520e-01 -4.550e-01 -1.160e-01  1.400e-02  6.800e-02 -6.900e-02
 -8.400e-02  2.220e-01  4.010e-01 -6.300e-02  1.850e-01  6.600e-01
  1.520e-01 -9.000e-03  6.190e-01 -3.460e-01  7.700e-02 -8.500e-02
  6.600e-02  5.580e-01  2.950e-01 -2.670e-01 -2.700e-01 -7.500e-02
  1.600e-01 -4.590e-01 -4.390e-01 -2.710e-01  4.490e-01  3.450e-01
 -2.730e-01 -4.570e-01  2.840e-01 -3.900e-02 -2.000e-03  8.700e-02] [-0.188  0.226  0.057  0.128 -0.315 -0.235  0.348 -0.117  0.223  0.061
 -0.357  0.132 -0.309 -0.154 -0.036 -0.102  0.177 -0.276 -0.023 -0.198
 -0.484  0.277  0.122  0.104  0.034 -0.084  0.251  0.105 -0.352  0.281
  0.047  0.256 -0.022 -0.002  0.063  0.25   0.021 -0.128 -0.119  0.083
 -0.004 -0.009 -0.516 -0.099 -0.21  -0.217  0.071 -0.218 -0.409 -0.139
 -0.003  0.215 -0.256 -0.041 -0.236  0.115  0.251 -0.11  -0.079  0.119
  0.321  0.092  0.276  0.071 -0.445 -0.141 -0.265 -0.307  0.093 -0.033
 -0.303 -0.13   0.053  0.438 -0.095 -0.06  -0.217  0.04   0.054 -0.112
  0.048 -0.284  0.281 -0.004  0.105  0.042 -0.277 -0.004 -0.068 -0.075
 -0.151  0.118 -0.313 -0.389 -0.006 -0.131  0.064  0.152 -0.363  0.039
  0.029 -0.201  0.009 -0.048  0.073 -0.062  0.1   -0.232 -0.194 -0.165
 -0.075 -0.032 -0.051  0.075  0.162 -0.127 -0.441 -0.062 -0.383 -0.212
 -0.401  0.255  0.046  0.013 -0.141 -0.221  0.021  0.098  0.184 -0.053
  0.026 -0.644  0.254  0.108  0.145 -0.137 -0.074 -0.299  0.449  0.113
 -0.341  0.145  0.2    0.108 -0.275 -0.25   0.298 -0.22  -0.239  0.03
 -0.705  0.234 -0.222 -0.085 -0.213  0.133  0.279  0.367 -0.301 -0.084
  0.388 -0.356 -0.222  0.161  0.237  0.137  0.077 -0.093 -0.24  -0.34
  0.31  -0.037 -0.248 -0.032 -0.003 -0.211 -0.381 -0.222  0.102  0.116
  0.279  0.003  0.158  0.123  0.085 -0.192 -0.047 -0.271 -0.08  -0.404
  0.018 -0.088 -0.105  0.213  0.161 -0.09   0.268  0.108  0.199  0.125
 -0.169  0.213 -0.118  0.037 -0.227 -0.114 -0.233  0.067  0.032  0.017
  0.168 -0.039 -0.114 -0.213  0.538 -0.254 -0.2    0.101  0.012  0.384
  0.14  -0.038 -0.065 -0.224 -0.091  0.074 -0.102 -0.201  0.067  0.267
  0.078 -0.005 -0.389  0.094  0.117 -0.164 -0.26   0.23  -0.095  0.094
  0.094 -0.006  0.142 -0.012  0.414 -0.414  0.023 -0.077  0.097 -0.202
  0.036  0.329  0.171  0.062 -0.036  0.162 -0.099 -0.013  0.215 -0.069
  0.054 -0.086 -0.121 -0.203 -0.332  0.081  0.201  0.131 -0.264  0.116
 -0.179 -0.018 -0.349 -0.104 -0.299 -0.28   0.424  0.043  0.149 -0.495
  0.086 -0.03   0.061  0.221  0.026  0.181 -0.146 -0.103 -0.238 -0.386
 -0.069  0.188 -0.265  0.087 -0.352 -0.118 -0.26   0.075  0.008  0.132] [-0.191 -0.147 -0.046 -0.3    0.18  -0.121  0.307 -0.023 -0.451 -0.054
 -0.272  0.051 -0.076  0.046 -0.329  0.077 -0.168  0.202  0.159 -0.045
 -0.253  0.18   0.214 -0.056  0.135 -0.265  0.252  0.485  0.029  0.157
  0.079 -0.201  0.202 -0.359  0.012  0.053  0.308  0.106  0.074 -0.603
 -0.329 -0.09   0.01  -0.027 -0.281 -0.049 -0.163  0.197 -0.186  0.153
  0.105  0.003 -0.408 -0.025 -0.102  0.041 -0.338 -0.115 -0.181 -0.148
 -0.114  0.002  0.101 -0.372 -0.211 -0.275 -0.292 -0.392 -0.009 -0.081
 -0.07  -0.314 -0.002  0.097  0.093 -0.242 -0.03   0.178  0.235  0.035
  0.14   0.212  0.172 -0.124 -0.174  0.09   0.101  0.149 -0.066  0.336
 -0.159 -0.022 -0.187 -0.147 -0.056  0.007  0.156 -0.006  0.112 -0.002
  0.096 -0.037  0.221 -0.064 -0.101  0.272 -0.222 -0.416 -0.114  0.227
 -0.133  0.302  0.044 -0.325  0.205 -0.051  0.181 -0.349 -0.137  0.134
 -0.039 -0.436 -0.145  0.019 -0.046 -0.022 -0.183  0.339 -0.169  0.092
 -0.252 -0.24   0.005  0.108  0.265  0.166 -0.179  0.221 -0.169 -0.026
  0.124  0.082  0.12   0.085  0.154  0.033 -0.212 -0.285 -0.141 -0.087
  0.176  0.046 -0.089 -0.062 -0.126 -0.097  0.499 -0.256 -0.207 -0.051
  0.367 -0.359 -0.458 -0.123  0.298  0.046  0.197  0.082  0.031 -0.107
  0.183 -0.232  0.03  -0.062  0.098  0.084 -0.556 -0.45  -0.718  0.087
  0.322 -0.128 -0.108  0.031  0.127  0.247 -0.089 -0.302  0.324  0.2
 -0.214 -0.17   0.015  0.206 -0.001 -0.077  0.081 -0.232  0.034  0.114
  0.429  0.168 -0.001 -0.133  0.055  0.13  -0.115  0.147  0.05  -0.371
  0.134  0.235 -0.271 -0.268  0.276 -0.274  0.254  0.075  0.479  0.431
 -0.185  0.012 -0.149 -0.118 -0.082  0.105 -0.072  0.224 -0.213 -0.044
 -0.096 -0.379 -0.451  0.018  0.229 -0.232 -0.12   0.205 -0.33   0.264
  0.043 -0.277 -0.136 -0.303  0.018 -0.293 -0.034  0.074 -0.079  0.091
  0.089  0.186  0.002 -0.226 -0.051 -0.02   0.23  -0.044  0.469  0.145
  0.109 -0.09  -0.032  0.246  0.131 -0.044  0.261  0.021  0.404 -0.049
 -0.416 -0.091 -0.258 -0.016 -0.41   0.023  0.257 -0.044 -0.078 -0.09
 -0.194 -0.039  0.202  0.088  0.13  -0.154 -0.064  0.135  0.038 -0.073
 -0.106  0.028  0.378 -0.016  0.014  0.084 -0.181  0.015  0.067 -0.069] [ 1.190e-01 -3.600e-02  4.260e-01  1.670e-01 -4.560e-01  9.120e-01
  4.560e-01  4.570e-01 -2.290e-01 -6.000e-01  5.300e-02  2.450e-01
  5.470e-01  3.000e-03 -2.830e-01  3.600e-01 -3.530e-01  2.210e-01
  1.000e-03  7.590e-01  2.920e-01 -8.700e-02  3.590e-01  3.780e-01
 -4.060e-01 -8.240e-01  4.610e-01  3.930e-01 -1.960e-01  2.710e-01
  4.740e-01 -1.390e-01  1.024e+00 -3.140e-01 -3.850e-01  9.200e-02
 -5.610e-01 -3.530e-01  1.660e-01 -1.250e-01 -1.940e-01  1.269e+00
 -4.430e-01 -9.900e-02 -6.960e-01  2.330e-01  3.490e-01 -4.220e-01
  3.110e-01  7.080e-01  1.730e-01  9.060e-01  1.500e-02 -3.180e-01
 -5.150e-01 -2.720e-01 -6.400e-01  1.000e-03  3.720e-01  3.370e-01
 -1.400e+00  1.000e-02 -3.710e-01 -8.500e-02 -6.140e-01 -5.000e-01
  3.390e-01  4.000e-02 -3.650e-01  7.770e-01  4.120e-01  2.020e-01
  1.770e-01 -2.840e-01 -3.290e-01  1.368e+00 -1.360e-01  1.690e-01
  1.170e-01 -3.100e-02  7.470e-01 -2.580e-01 -1.570e-01  4.620e-01
 -2.900e-02 -5.010e-01 -3.540e-01 -3.670e-01 -1.990e-01 -1.120e-01
  4.600e-02  5.070e-01 -2.260e-01  5.600e-02  4.700e-02 -4.150e-01
  4.010e-01  1.170e-01  4.550e-01  2.120e-01  3.450e-01  2.290e-01
  9.820e-01 -5.950e-01 -1.830e-01 -3.510e-01  6.360e-01  5.420e-01
 -6.650e-01  6.400e-01 -8.110e-01 -4.480e-01  1.690e-01  6.060e-01
  4.080e-01  6.260e-01  2.660e-01 -3.940e-01 -1.250e-01  3.200e-01
  3.660e-01 -3.640e-01  2.280e-01 -1.550e-01 -4.550e-01  4.680e-01
 -4.770e-01 -3.500e-02  4.460e-01 -3.730e-01 -5.650e-01 -6.030e-01
  8.380e-01  4.600e-01 -7.200e-02 -3.480e-01 -2.260e-01  4.000e-03
 -2.870e-01  3.300e-02 -2.890e-01 -3.730e-01  6.560e-01  1.600e-02
 -6.680e-01  1.200e-01 -8.900e-02 -1.310e-01 -2.730e-01 -6.600e-02
 -4.160e-01  6.760e-01 -4.670e-01  3.310e-01  3.060e-01  3.210e-01
  2.100e-01 -2.380e-01 -7.860e-01  4.940e-01 -2.170e-01  3.670e-01
 -1.260e-01 -2.040e-01  1.400e-02 -4.500e-02  8.610e-01  6.050e-01
 -5.100e-02  2.210e-01  1.120e-01 -2.930e-01 -6.300e-01 -2.690e-01
  3.920e-01  2.530e-01 -2.310e-01 -2.820e-01  3.830e-01  2.020e-01
  2.220e-01  1.010e+00  1.900e-01  8.400e-02  7.460e-01 -6.370e-01
 -3.620e-01 -6.040e-01 -7.680e-01  4.400e-02  3.820e-01 -1.570e-01
  4.670e-01 -3.590e-01  6.100e-01 -6.840e-01 -1.510e-01  3.250e-01
  1.970e-01 -2.410e-01  5.700e-02  1.840e-01 -2.520e-01  2.530e-01
  5.800e-01 -6.700e-02 -9.240e-01 -2.920e-01 -8.900e-02 -6.630e-01
 -4.140e-01 -4.360e-01  1.620e-01 -8.040e-01  3.830e-01 -2.800e-02
  3.670e-01 -2.050e-01 -5.430e-01  1.560e-01  9.310e-01 -1.310e-01
  5.950e-01  1.270e-01 -5.830e-01  6.540e-01 -1.480e-01  2.980e-01
  3.810e-01  1.340e-01  9.000e-02  1.730e-01  2.200e-01  1.890e-01
  4.510e-01 -9.320e-01 -4.300e-02  3.910e-01  2.490e-01  1.900e-01
 -2.470e-01  6.520e-01  7.200e-02  1.700e-01 -5.820e-01  4.410e-01
 -6.140e-01  6.500e-01  2.060e-01  3.020e-01  1.110e-01  3.310e-01
 -1.870e-01 -1.040e-01  1.240e-01 -4.760e-01  1.290e-01  2.870e-01
 -3.240e-01 -2.470e-01 -3.070e-01  4.500e-02  1.770e-01 -4.800e-02
  2.060e-01 -2.000e-01  3.720e-01 -4.870e-01 -1.140e-01 -7.350e-01
  4.000e-02 -1.720e-01  4.010e-01 -7.110e-01  4.900e-01  5.480e-01
  4.250e-01 -4.470e-01  6.780e-01  2.740e-01 -3.400e-02  2.330e-01
  6.600e-02 -5.230e-01  5.980e-01 -1.100e-02 -5.900e-02 -3.500e-02
  1.810e-01 -9.600e-02 -9.000e-03 -4.640e-01  1.670e-01  1.820e-01
  4.380e-01  2.890e-01  6.260e-01  4.080e-01 -4.030e-01 -4.440e-01] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
10/09/2021 09:17:24 - INFO - data_loader -   *** Example ***
10/09/2021 09:17:24 - INFO - data_loader -   guid: test-1
10/09/2021 09:17:24 - INFO - data_loader -   tokens: [CLS] how dare we go 0 - 2 feeder ##s bronze kids [SEP]
10/09/2021 09:17:24 - INFO - data_loader -   input_ids: 101 2129 8108 2057 2175 1014 1011 1016 21429 2015 4421 4268 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 09:17:24 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 09:17:24 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 09:17:24 - INFO - data_loader -   intent_label: 3 (id = 3)
10/09/2021 09:17:24 - INFO - data_loader -   slot_labels: 0 4 4 5 6 4 0 0 4 0 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 09:17:24 - INFO - data_loader -   ner_embeds: [ 1.920e-01  3.000e-02 -5.410e-01 -2.490e-01  8.700e-02 -4.460e-01
  3.700e-01  4.680e-01 -1.500e-02 -3.350e-01  8.400e-02  2.480e-01
 -1.150e-01 -2.240e-01 -1.040e-01 -2.340e-01 -4.870e-01  4.340e-01
 -1.940e-01 -4.700e-02  2.050e-01 -2.130e-01 -3.940e-01  4.730e-01
 -4.530e-01  3.110e-01 -1.390e-01  5.000e-01 -2.430e-01 -6.130e-01
  6.620e-01  5.020e-01 -1.150e-01 -6.000e-02 -5.620e-01  4.210e-01
  1.010e-01 -4.600e-02  4.170e-01 -1.920e-01 -4.670e-01  4.930e-01
  4.420e-01  1.300e-02 -2.280e-01 -2.030e-01 -1.410e-01  2.710e-01
  1.180e-01 -3.380e-01  3.520e-01  2.730e-01 -4.710e-01 -5.990e-01
 -4.630e-01 -2.470e-01  4.560e-01  1.350e-01  9.400e-02  1.007e+00
  6.660e-01 -8.600e-02 -1.050e-01 -1.010e+00  4.700e-02  7.100e-02
 -6.450e-01 -5.600e-02 -6.300e-02  1.000e-03  2.210e-01  1.970e-01
  2.000e-03  3.970e-01  5.380e-01  9.700e-02 -1.100e-01  6.210e-01
  3.560e-01  4.540e-01  1.090e-01 -1.180e-01  8.800e-02  1.500e-01
 -3.390e-01 -1.920e-01 -4.030e-01 -3.470e-01  2.930e-01  5.400e-02
  1.510e-01  3.640e-01  1.860e-01 -6.300e-01 -1.040e-01 -7.130e-01
  2.080e-01  4.060e-01 -3.940e-01  6.600e-02  2.450e-01  4.080e-01
  1.033e+00  2.930e-01  9.500e-02 -8.000e-03  4.320e-01 -3.220e-01
 -5.650e-01 -9.600e-02 -3.080e-01 -5.730e-01 -4.070e-01  2.750e-01
  1.480e-01 -1.800e-02  7.280e-01 -5.440e-01 -1.052e+00  1.100e-02
  5.480e-01 -1.490e-01  1.250e-01 -3.130e-01 -3.500e-02  3.750e-01
 -7.790e-01 -3.370e-01  2.200e-02 -4.770e-01 -6.280e-01  3.620e-01
  6.600e-02  1.410e-01 -2.860e-01  2.920e-01 -6.900e-02  1.100e-02
 -5.110e-01 -1.430e-01 -1.240e-01  5.520e-01 -2.400e-01 -1.520e-01
 -6.000e-03 -2.080e-01  8.300e-02 -1.270e-01 -1.990e-01 -1.500e-01
 -1.870e-01 -3.200e-02 -3.700e-02 -2.480e-01 -3.860e-01 -1.285e+00
  2.650e-01 -4.450e-01 -1.560e-01  3.110e-01  9.000e-03 -7.970e-01
 -2.300e-02 -1.270e-01 -5.870e-01  3.300e-01  4.850e-01  4.660e-01
 -6.440e-01 -3.770e-01 -2.550e-01  7.000e-03 -2.550e-01  6.240e-01
  2.890e-01 -1.080e-01 -3.260e-01  3.380e-01 -2.090e-01 -3.150e-01
  6.170e-01 -7.300e-02 -1.430e-01  3.330e-01 -1.950e-01  2.340e-01
  8.350e-01  1.350e-01 -2.530e-01  3.400e-02  5.290e-01 -2.620e-01
 -9.700e-02  2.980e-01  5.290e-01  2.400e-02 -3.210e-01  4.540e-01
 -4.950e-01  4.050e-01 -3.840e-01  4.150e-01  5.030e-01 -1.390e-01
 -2.590e-01 -1.340e-01 -7.320e-01 -2.700e-01 -1.260e-01  5.950e-01
  2.060e-01 -2.770e-01  6.900e-02 -1.018e+00 -2.200e-02  2.900e-02
 -2.990e-01  3.420e-01 -3.030e-01 -8.000e-02  7.420e-01 -3.800e-02
  1.460e-01 -3.710e-01 -7.460e-01 -4.520e-01 -1.200e-02  2.840e-01
  3.180e-01 -7.600e-01 -2.800e-01 -1.160e-01  6.600e-02  4.190e-01
 -2.280e-01  1.480e-01 -5.000e-02  3.200e-01 -9.700e-02 -4.520e-01
  7.450e-01 -9.400e-02  7.330e-01 -4.370e-01  4.890e-01 -3.090e-01
  2.210e-01 -3.140e-01 -2.210e-01 -7.700e-01  7.300e-02  5.160e-01
  7.950e-01 -4.280e-01  2.950e-01 -5.410e-01  5.650e-01 -3.180e-01
 -3.050e-01 -3.640e-01 -5.400e-02 -9.980e-01 -4.050e-01 -3.300e-01
 -2.520e-01 -4.550e-01 -1.160e-01  1.400e-02  6.800e-02 -6.900e-02
 -8.400e-02  2.220e-01  4.010e-01 -6.300e-02  1.850e-01  6.600e-01
  1.520e-01 -9.000e-03  6.190e-01 -3.460e-01  7.700e-02 -8.500e-02
  6.600e-02  5.580e-01  2.950e-01 -2.670e-01 -2.700e-01 -7.500e-02
  1.600e-01 -4.590e-01 -4.390e-01 -2.710e-01  4.490e-01  3.450e-01
 -2.730e-01 -4.570e-01  2.840e-01 -3.900e-02 -2.000e-03  8.700e-02] [-0.17   0.043 -0.414  0.205 -0.013  0.178 -0.067 -0.053 -0.069  0.236
 -0.246 -0.056 -0.073  0.019 -0.076  0.14  -0.153  0.018 -0.057  0.018
 -0.058  0.153 -0.061 -0.044 -0.129 -0.096  0.164 -0.049  0.119  0.098
 -0.154 -0.205  0.292 -0.008 -0.287  0.052  0.017 -0.082 -0.014  0.03
 -0.043  0.164 -0.451  0.157  0.06  -0.274  0.434 -0.142 -0.055 -0.012
 -0.278 -0.325  0.096 -0.134 -0.003 -0.018 -0.002 -0.234 -0.177  0.124
  0.198  0.155 -0.147 -0.453  0.069  0.292 -0.132  0.022  0.202 -0.276
 -0.326 -0.078 -0.01   0.464 -0.112 -0.002 -0.2    0.228 -0.051  0.069
 -0.247 -0.061  0.586  0.122 -0.16   0.138 -0.061 -0.402 -0.551 -0.065
 -0.245  0.135  0.067 -0.107 -0.327 -0.199 -0.019 -0.108 -0.466 -0.224
  0.017 -0.073  0.048 -0.097  0.035 -0.483  0.167 -0.133 -0.225 -0.125
 -0.182 -0.144 -0.134 -0.183  0.068 -0.195 -0.26  -0.202  0.077  0.105
 -0.073 -0.55   0.229  0.249 -0.118  0.128 -0.105  0.125  0.152 -0.116
 -0.053  0.32  -0.316  0.062  0.478 -0.114  0.21  -0.039  0.122  0.486
 -0.185  0.121  0.24  -0.323  0.201 -0.294  0.117 -0.228 -0.673 -0.139
 -0.207  0.091 -0.541 -0.013 -0.104 -0.02  -0.045  0.153 -0.388 -0.211
  0.63  -0.272 -0.096 -0.077  0.381  0.058  0.328 -0.145 -0.065  0.279
  0.103  0.303 -0.595  0.353 -0.048 -0.124 -0.34  -0.06   0.491  0.449
 -0.084  0.083  0.304  0.313 -0.328 -0.161  0.099  0.109 -0.097  0.17
 -0.297 -0.15   0.024  0.086  0.213 -0.41   0.535  0.486 -0.095  0.166
  0.623  0.024 -0.044  0.048 -0.231 -0.021 -0.23   0.043  0.026  0.103
  0.2   -0.069 -0.404  0.096  0.427 -0.349  0.003  0.256  0.118  0.402
  0.069 -0.015 -0.12  -0.078  0.254 -0.407 -0.127 -0.138  0.284  0.281
  0.237  0.307 -0.022  0.103  0.294  0.015 -0.277 -0.148 -0.138  0.076
  0.121  0.066  0.241  0.246 -0.001  0.123 -0.126 -0.259 -0.016  0.092
  0.098  0.018 -0.064  0.136 -0.137 -0.417  0.284 -0.051  0.198  0.086
  0.117 -0.076  0.258  0.407  0.066  0.124 -0.165 -0.194 -0.412  0.162
 -0.573 -0.226 -0.067  0.002 -0.145  0.183  0.171  0.006  0.211 -0.154
  0.2   -0.036 -0.368 -0.181  0.203 -0.314 -0.101  0.08  -0.139 -0.664
 -0.029  0.205 -0.275  0.035 -0.141  0.2   -0.011  0.025  0.139  0.166] [ 0.121  0.388 -0.389  0.014 -0.189  0.07  -0.078  0.02   0.095 -0.092
 -0.517 -0.198 -0.162  0.268  0.176  0.106  0.65   0.226 -0.169 -0.072
 -0.239  0.228 -0.06  -0.398 -0.485  0.128 -0.02  -0.014 -0.066 -0.069
  0.266  0.606 -0.01  -0.297  0.041  0.208  0.27   0.083  0.377 -0.197
 -0.062  0.302 -0.308 -0.196  0.096  0.241  0.115  0.115 -0.21  -0.054
  0.03   0.014 -0.383 -0.632  0.056  0.273 -0.55   0.166 -0.014  0.12
 -0.099  0.005 -0.216 -0.039  0.003  0.115  0.004 -0.23   0.156 -0.235
 -0.283  0.161  0.203  0.24   0.415 -0.056 -0.34   0.061  0.202 -0.017
 -0.252 -0.503 -0.136  0.097 -0.115 -0.366 -0.059  0.235 -0.321  0.335
 -0.421 -0.085 -0.3   -0.341 -0.188 -0.389 -0.007  0.376  0.006 -0.366
  0.249  0.377  0.222 -0.249  0.016 -0.602 -0.224  0.266 -0.219  0.143
  0.365  0.34  -0.208 -0.078 -0.112 -0.145  0.128 -0.361 -0.252  0.125
 -0.232  0.17   0.539 -0.641 -0.075 -0.277  0.186  0.226  0.196 -0.293
 -0.125 -0.427  0.085  0.093 -0.432 -0.038 -0.175 -0.259  0.073  0.102
 -0.256  0.35   0.128 -0.23   0.062 -0.199  0.2    0.2   -0.139 -0.003
 -0.385  0.176 -0.274 -0.069  0.07  -0.088 -0.061 -0.087 -0.221  0.318
  0.201  0.013  0.148  0.031  0.24  -0.211  0.136 -0.154 -0.074 -0.171
 -0.015 -0.094 -0.076  0.315  0.083 -0.105 -0.416 -0.239 -0.276  0.279
  0.459  0.186 -0.159 -0.335  0.154  0.004 -0.158 -0.024 -0.026 -0.151
 -0.176 -0.261  0.063 -0.032 -0.045  0.225 -0.295 -0.039  0.049 -0.13
 -0.035  0.219  0.124 -0.507 -0.18   0.234  0.179 -0.106 -0.27   0.209
  0.035 -0.418  0.267 -0.066  0.147  0.015  0.142 -0.258 -0.337  0.289
  0.742  0.176  0.124  0.236 -0.062 -0.169  0.157  0.063  0.23   0.24
 -0.238 -0.381 -0.231  0.143 -0.316 -0.185 -0.234  0.141  0.198  0.199
  0.017 -0.59  -0.092 -0.168 -0.134  0.015 -0.248  0.216 -0.343  0.001
  0.173 -0.097  0.424 -0.268 -0.088  0.159 -0.181 -0.064 -0.085 -0.104
  0.264 -0.371  0.053 -0.19  -0.275  0.106 -0.027 -0.027  0.262  0.005
 -0.158  0.058  0.148 -0.231  0.029 -0.374  0.03   0.245  0.026 -0.033
  0.235  0.234 -0.158  0.305  0.389 -0.178  0.092 -0.005 -0.062 -0.204
 -0.331 -0.12  -0.038  0.56  -0.328  0.226  0.086  0.172  0.015  0.369] [-9.60e-02  5.89e-01 -5.20e-02  8.40e-02  4.00e-03 -2.26e-01  1.05e-01
 -1.68e-01 -9.50e-02  6.00e-02 -8.70e-02  2.67e-01 -2.41e-01  1.92e-01
  2.71e-01 -1.30e-02 -2.26e-01  2.07e-01 -3.60e-01  1.92e-01 -1.84e-01
  3.84e-01  1.02e-01  1.46e-01  2.18e-01  1.68e-01  1.89e-01 -4.20e-02
 -2.39e-01 -1.50e-01  1.81e-01 -6.70e-02  2.70e-02  6.80e-02 -2.40e-02
  9.50e-02  2.28e-01  5.52e-01  2.00e-01  3.40e-01 -8.50e-02  1.02e-01
 -2.14e-01 -9.60e-02  4.20e-02  2.21e-01 -2.38e-01  3.51e-01  2.57e-01
 -1.32e-01  1.13e-01 -1.00e-03 -2.63e-01 -2.73e-01  2.20e-01  1.29e-01
 -3.03e-01  3.32e-01 -2.53e-01 -3.50e-02  1.52e-01  7.90e-02  9.50e-02
 -4.99e-01  6.20e-02  1.99e-01 -6.02e-01  1.43e-01 -2.25e-01  3.49e-01
 -2.27e-01  6.10e-02  3.20e-02  1.66e-01 -1.78e-01  2.00e-03 -6.00e-02
 -1.85e-01  1.09e-01 -9.80e-02  3.00e-01 -1.79e-01  3.17e-01 -8.50e-02
 -2.43e-01 -8.80e-02  3.30e-02 -9.40e-02 -4.46e-01  1.60e-02 -3.16e-01
 -1.00e-03  1.82e-01  8.60e-02 -7.00e-02 -2.87e-01  6.30e-02 -5.50e-02
  8.30e-02  2.91e-01 -1.31e-01 -2.20e-02 -2.60e-02  3.15e-01 -4.80e-02
 -2.60e-01 -6.00e-02 -2.96e-01 -1.28e-01 -5.06e-01 -1.27e-01 -2.19e-01
 -4.60e-02  4.90e-02 -2.29e-01 -1.30e-01 -1.32e-01 -1.41e-01 -2.18e-01
 -1.26e-01 -1.32e-01  7.20e-02  5.17e-01  7.20e-02  4.10e-02  1.24e-01
 -2.03e-01  4.70e-02  2.71e-01 -3.15e-01 -2.45e-01 -3.14e-01 -9.70e-02
  1.24e-01 -1.94e-01 -1.21e-01 -4.05e-01  2.60e-01  5.90e-02  4.00e-02
 -5.90e-02  3.45e-01  3.40e-02  1.30e-02  9.00e-02 -4.88e-01  2.14e-01
 -1.40e-01  2.01e-01  1.43e-01 -2.61e-01  3.42e-01 -1.85e-01 -1.90e-01
 -3.84e-01  7.00e-02  1.13e-01  3.40e-02  4.30e-02 -1.06e-01 -1.22e-01
 -3.10e-02 -2.37e-01 -4.90e-02 -1.07e-01 -6.40e-02 -3.29e-01 -3.10e-02
 -2.23e-01  1.41e-01  1.99e-01 -3.32e-01 -3.08e-01  1.79e-01  3.50e-02
 -2.38e-01 -4.25e-01 -3.73e-01  3.48e-01  1.65e-01  3.02e-01 -2.32e-01
  2.07e-01  3.00e-02  1.09e-01 -1.90e-01 -1.52e-01  1.72e-01  5.70e-02
  1.80e-02 -1.35e-01  1.31e-01 -5.52e-01 -1.39e-01  6.60e-02  2.91e-01
  2.57e-01 -1.67e-01  2.55e-01  2.67e-01  2.47e-01  3.77e-01  3.38e-01
 -8.90e-02  2.87e-01  1.16e-01  2.42e-01  1.25e-01  1.10e-01  1.50e-02
  5.06e-01 -1.67e-01  3.80e-02 -3.35e-01  1.05e+00 -5.97e-01 -4.60e-02
 -3.27e-01 -2.30e-02  1.18e-01  1.77e-01 -2.50e-02  1.52e-01 -4.00e-01
 -1.30e-02 -3.25e-01 -9.80e-02  1.70e-02  1.19e-01  2.20e-01  7.00e-03
 -1.58e-01 -4.01e-01 -1.73e-01  3.19e-01 -3.41e-01  2.40e-01  8.70e-02
 -1.34e-01 -3.15e-01 -1.78e-01 -5.40e-02 -1.09e-01 -8.20e-02  2.96e-01
  1.91e-01 -2.40e-02  1.00e-03  3.40e-01  1.38e-01 -1.38e-01 -4.70e-02
  2.35e-01 -4.50e-02  3.60e-02 -2.57e-01  4.29e-01 -1.21e-01  1.51e-01
  3.08e-01  4.53e-01 -3.49e-01  0.00e+00  3.63e-01 -4.00e-03  1.97e-01
  9.90e-02 -1.24e-01 -2.77e-01  5.60e-02 -5.89e-01 -3.17e-01  3.98e-01
  1.98e-01  8.70e-02 -3.27e-01  3.52e-01 -1.46e-01  8.70e-02 -3.61e-01
 -1.22e-01  2.10e-01 -5.10e-02  3.20e-02  2.45e-01  1.13e-01 -3.12e-01
 -1.87e-01 -1.66e-01 -3.48e-01 -1.83e-01  8.20e-02  4.39e-01  2.62e-01
 -3.63e-01  3.61e-01 -9.00e-03 -1.73e-01  2.58e-01 -2.74e-01] [ 0.304  0.41  -0.053  0.088 -0.216  0.481  0.262 -0.166 -0.631 -0.107
 -0.468  0.137  0.472 -0.172  0.259  0.336  0.408 -0.809 -0.465  0.347
  0.411  0.433  0.285 -0.073  0.214 -0.067  0.509  0.361 -0.192  0.133
  0.34  -0.052 -0.153  0.133  0.3    0.468 -0.435 -0.163  0.662  0.07
 -0.226 -0.1   -0.076  0.09   0.186  0.315  0.058  0.246 -0.264 -0.108
  0.352 -0.435 -0.365 -0.036 -0.075  0.14  -0.478 -0.142  0.021 -0.525
 -0.015  0.325  0.018 -0.148 -0.297 -0.319 -0.026  0.138 -0.042 -0.038
 -0.267  0.076  0.096  0.691 -0.389 -0.223 -0.224 -0.335  0.195  0.173
  0.255 -0.713  0.044 -0.162 -0.081 -0.401 -0.339  0.493 -0.328  0.212
 -0.245 -0.101 -0.308 -0.319 -0.27   0.117  0.481  0.023  0.604 -0.199
 -0.32  -0.463  0.428 -0.127  0.337 -0.435 -0.053 -0.52  -0.16  -0.527
  0.205 -0.14  -0.092  0.17   0.458  0.513  0.122 -0.348  0.166 -0.037
  0.62   0.65   0.176  0.184 -0.18   0.079  0.177  0.046 -0.674 -0.508
  0.116  0.248  0.355  0.093 -0.016  0.096  0.07   0.342 -0.163  0.121
 -0.311  0.231  0.095 -0.008  0.073  0.195 -0.359  0.047 -0.38  -0.14
 -0.292  0.415 -0.554 -0.101 -0.688  0.003  0.45  -0.083  0.113 -0.151
  0.561 -0.274 -0.078 -0.22  -0.401 -0.323  0.008 -0.022 -0.528 -0.232
 -0.433 -0.13  -0.002 -0.765 -0.014 -0.42  -0.372 -0.302 -0.031  0.033
  0.234  0.474 -0.036  0.138  0.442 -0.16  -0.507 -0.218  0.26   0.655
 -0.184 -0.345 -0.011 -0.122  0.169 -0.477 -0.361  0.39   0.039 -0.233
  0.362  0.123  0.311  0.126  0.364 -0.07  -0.182 -0.235 -0.069 -0.357
  0.276  0.031  0.158 -0.516  0.247  0.236 -0.184 -0.033  0.402  0.438
 -0.042 -0.054  0.53  -0.547  0.445 -0.206  0.029 -0.116  0.432 -0.187
 -0.19  -0.253 -0.808  0.038 -0.101 -0.38  -0.081  0.17   0.034  0.07
  0.392 -0.418  0.037 -0.281  0.591 -0.837 -0.06  -0.415 -0.231 -0.238
  0.037  0.433 -0.179 -0.398  0.11   0.422  0.14  -0.383  0.04  -0.256
  0.236 -0.457 -0.217 -0.543 -0.164  0.192 -0.645 -0.658  0.298 -0.384
 -0.198 -0.174 -0.011 -0.129 -0.027  0.152 -0.03   0.229 -0.475 -0.468
  0.45   0.302  0.024 -0.177  0.359 -0.36  -0.665 -0.09   0.133 -0.65
 -0.512  0.052  0.075  0.41  -0.015  0.541 -0.075  0.728  0.156  0.318] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [ 0.321 -0.135  0.294 -0.326 -0.179  0.248 -0.269  0.177 -0.092  0.103
  0.188 -0.768  0.387 -0.157 -0.772 -0.223  0.118  0.037  0.361 -0.235
 -0.227  0.571  0.605  0.114  0.135 -0.016 -0.161  0.357 -0.582 -0.142
 -0.247 -0.101 -0.55   0.052 -0.181 -0.048  0.187  0.019  0.257  0.355
 -0.002 -0.43   0.241  0.231 -0.035  0.493 -0.321 -0.138 -0.223 -0.035
  0.605  0.242  0.438 -0.286 -0.547 -0.075 -0.135  0.044  0.401  0.25
 -0.382  0.039 -0.023 -0.246  0.695 -0.507 -0.049 -0.275 -0.7   -0.549
  0.258  0.024  0.24  -0.043 -0.009  0.421  0.214  0.181 -0.073  0.15
  0.654 -0.25  -0.152 -0.234  0.025  0.037  0.102  0.446 -0.828  0.03
 -0.252 -0.032  0.121 -0.168 -0.791 -0.238  0.266  0.222 -0.608 -0.142
 -0.197 -0.063  0.13  -0.223  0.21  -0.274 -0.321 -0.052  0.513 -0.25
  0.189  0.138 -0.416 -0.158  0.961  0.132 -0.055 -0.17  -0.232 -0.398
  0.106 -0.074  0.372  0.446 -0.013  0.099  0.571 -0.064  0.057  0.424
  0.562  0.024 -0.277 -0.019  0.353 -0.337 -0.406  0.255  0.587  0.122
 -0.235 -0.111 -0.284  0.416 -0.205  0.153  0.704 -0.491 -0.044 -0.116
 -0.082  0.089 -0.072  0.151 -0.331 -0.244  0.037  0.258 -0.089 -0.895
 -0.016 -0.204  0.644  0.264 -0.337 -0.253  0.397  0.187 -0.338  0.105
  0.321 -0.484 -0.151  0.259  0.145  0.004 -0.033 -0.332  0.245  0.101
  0.137 -0.677  0.076  0.688  0.436  0.411 -0.336  0.019 -0.263  0.204
  0.047  0.186  0.042  0.236  0.567  0.157 -0.018 -0.105 -0.352 -0.174
  0.378  0.126 -0.068  0.246  0.496  0.069 -0.397 -0.409  0.417 -0.03
  0.135  0.065  0.815  0.005 -0.111 -0.483 -0.071  0.325  0.308  0.504
 -0.141 -0.599  0.146  0.322 -0.67   0.031 -0.285  0.073  0.003  0.29
  0.161 -0.233 -0.518 -0.396 -0.518 -0.165  0.414  0.566 -0.639 -0.464
  0.911 -0.335  0.898 -0.204 -0.23  -0.395 -0.466 -0.645  0.79  -0.337
  0.222  0.471  0.593 -0.286  0.18  -0.478 -0.163 -0.214 -0.139 -0.574
  0.177 -0.497  0.19   0.409 -0.244 -0.568  0.353 -0.293 -0.139 -0.262
 -0.03  -0.612  0.066 -0.084  0.171 -0.5   -0.201  0.184 -0.269 -0.376
  0.758 -0.086 -0.227 -0.018  0.55  -0.092 -0.999 -0.315 -0.22   0.608
  0.286 -0.021 -0.021 -0.544  0.055  0.035 -0.076  0.109 -0.002  0.042] [ 0.642 -0.27   0.588 -0.652 -0.358  0.496 -0.538  0.354 -0.184  0.206
  0.376 -1.536  0.774 -0.314 -1.544 -0.446  0.236  0.074  0.722 -0.47
 -0.454  1.142  1.21   0.228  0.27  -0.032 -0.322  0.714 -1.164 -0.284
 -0.494 -0.202 -1.1    0.104 -0.362 -0.096  0.374  0.038  0.514  0.71
 -0.004 -0.86   0.482  0.462 -0.07   0.986 -0.642 -0.276 -0.446 -0.07
  1.21   0.484  0.876 -0.572 -1.094 -0.15  -0.27   0.088  0.802  0.5
 -0.764  0.078 -0.046 -0.492  1.39  -1.014 -0.098 -0.55  -1.4   -1.098
  0.516  0.048  0.48  -0.086 -0.018  0.842  0.428  0.362 -0.146  0.3
  1.308 -0.5   -0.304 -0.468  0.05   0.074  0.204  0.892 -1.656  0.06
 -0.504 -0.064  0.242 -0.336 -1.582 -0.476  0.532  0.444 -1.216 -0.284
 -0.394 -0.126  0.26  -0.446  0.42  -0.548 -0.642 -0.104  1.026 -0.5
  0.378  0.276 -0.832 -0.316  1.922  0.264 -0.11  -0.34  -0.464 -0.796
  0.212 -0.148  0.744  0.892 -0.026  0.198  1.142 -0.128  0.114  0.848
  1.124  0.048 -0.554 -0.038  0.706 -0.674 -0.812  0.51   1.174  0.244
 -0.47  -0.222 -0.568  0.832 -0.41   0.306  1.408 -0.982 -0.088 -0.232
 -0.164  0.178 -0.144  0.302 -0.662 -0.488  0.074  0.516 -0.178 -1.79
 -0.032 -0.408  1.288  0.528 -0.674 -0.506  0.794  0.374 -0.676  0.21
  0.642 -0.968 -0.302  0.518  0.29   0.008 -0.066 -0.664  0.49   0.202
  0.274 -1.354  0.152  1.376  0.872  0.822 -0.672  0.038 -0.526  0.408
  0.094  0.372  0.084  0.472  1.134  0.314 -0.036 -0.21  -0.704 -0.348
  0.756  0.252 -0.136  0.492  0.992  0.138 -0.794 -0.818  0.834 -0.06
  0.27   0.13   1.63   0.01  -0.222 -0.966 -0.142  0.65   0.616  1.008
 -0.282 -1.198  0.292  0.644 -1.34   0.062 -0.57   0.146  0.006  0.58
  0.322 -0.466 -1.036 -0.792 -1.036 -0.33   0.828  1.132 -1.278 -0.928
  1.822 -0.67   1.796 -0.408 -0.46  -0.79  -0.932 -1.29   1.58  -0.674
  0.444  0.942  1.186 -0.572  0.36  -0.956 -0.326 -0.428 -0.278 -1.148
  0.354 -0.994  0.38   0.818 -0.488 -1.136  0.706 -0.586 -0.278 -0.524
 -0.06  -1.224  0.132 -0.168  0.342 -1.    -0.402  0.368 -0.538 -0.752
  1.516 -0.172 -0.454 -0.036  1.1   -0.184 -1.998 -0.63  -0.44   1.216
  0.572 -0.042 -0.042 -1.088  0.11   0.07  -0.152  0.218 -0.004  0.084] [ 0.357 -0.257  0.595 -0.295  0.09   0.218  0.013  0.138 -0.253  0.321
  0.397  0.336  0.035 -0.465  0.068 -0.05  -0.07   0.234  0.202  0.052
  0.238 -0.264  0.234  0.351 -0.426  0.023 -0.256  0.513 -0.106  0.481
  0.006  0.491 -0.164  0.236  0.088 -0.429 -0.149  0.123  0.41  -0.318
 -0.28   0.223  0.336 -0.054  0.535  0.342  0.173  0.255  0.142 -0.065
  0.118  0.251  0.346 -0.142 -0.349 -0.249 -0.216  0.047 -0.611 -0.131
  0.118  0.419  0.104  0.571 -0.49   0.024  0.079  0.389  0.047  0.011
 -0.177 -0.185 -0.554 -0.371 -0.196  0.305  0.434 -0.081  0.256 -0.425
 -0.183  0.113  0.041  0.347 -0.748  0.111 -0.304 -0.222 -0.377 -0.005
  0.348 -0.073 -0.277 -0.206 -0.21   0.216 -0.498 -0.079  0.061 -0.443
  0.233 -0.079  0.597  0.504  0.276 -0.062 -0.327 -0.099  0.129  0.053
 -0.306  0.614  0.146 -0.093  0.337 -0.543  0.822 -0.118  0.422  0.177
 -0.216  0.565  0.075 -0.394  0.179  0.025  0.129  0.302 -0.146 -0.123
 -0.175 -0.507 -0.013  0.302  0.187 -0.294 -0.168  0.104  0.054  0.022
 -0.241  0.258 -0.066  0.487  0.247  0.076  0.582 -0.033 -0.281 -0.296
 -0.574 -0.311 -0.078 -0.105 -0.246 -0.301  0.135  0.276  0.151 -0.373
  0.118  0.474  0.055  0.054 -0.223  0.378  0.374  0.256 -0.144  0.026
 -0.027  0.402 -0.017  0.527  0.208 -0.169 -0.45   0.304 -0.248  0.532
  0.509 -0.373 -0.02  -0.188 -0.346 -0.296 -0.246  0.066  0.115  0.21
  0.825  0.183 -0.206 -0.087  0.711 -0.114  0.274 -0.167 -0.108  0.321
  0.461  0.696  0.334  0.161 -0.059 -0.56   0.172  0.29   0.47  -0.274
  0.162 -0.26   0.202 -0.419  0.211 -0.552 -0.013  0.499  0.374 -0.359
  0.019 -0.085  0.157 -0.073 -0.598 -0.13   0.43   0.334  0.222  0.268
  0.424  0.039 -0.331 -0.297  0.099 -0.495 -0.106 -0.148  0.071  0.109
  0.388  0.09  -0.307 -0.218 -0.21  -0.089  0.328  0.186 -0.204 -0.427
 -0.127  0.305 -0.333 -0.414 -0.066  0.109 -0.095  0.356  0.08  -0.189
 -0.107 -0.491 -0.003  0.203  0.186  0.345 -0.061  0.208  0.089 -0.104
 -0.452 -0.133  0.327  0.208 -0.193 -0.126  0.315 -0.007  0.235 -0.652
 -0.373  0.264 -0.048  0.301  0.338  0.341 -0.022  0.097 -0.596 -0.148
  0.299  0.793 -0.506 -0.107  0.018 -0.026 -0.727 -0.324  0.035  0.416] [-0.217  0.063  0.183 -0.148 -0.186 -0.39   0.13   0.066 -0.087 -0.007
 -0.375 -0.085 -0.062 -0.314 -0.155 -0.129  0.379  0.206  0.006  0.096
 -0.071  0.409  0.374  0.099 -0.075  0.17  -0.28   0.032 -0.186  0.207
  0.126 -0.021  0.048 -0.065  0.175  0.156  0.117  0.102  0.068  0.126
 -0.036  0.375 -0.091 -0.202 -0.153  0.105 -0.125 -0.072 -0.024 -0.398
  0.282 -0.087 -0.092 -0.125 -0.238  0.066  0.246 -0.052 -0.091  0.154
 -0.243  0.088  0.359 -0.052  0.069  0.236 -0.107 -0.331 -0.047 -0.23
  0.026  0.024 -0.139  0.022 -0.284 -0.014 -0.171  0.196  0.132 -0.11
 -0.071 -0.262  0.526  0.338 -0.234 -0.231  0.029  0.005  0.006  0.032
 -0.336 -0.073 -0.168 -0.532 -0.248 -0.046 -0.132  0.483 -0.141 -0.517
 -0.073  0.272  0.274  0.018  0.083 -0.183  0.288  0.151 -0.112  0.072
  0.277  0.086  0.053 -0.214  0.477  0.053  0.077 -0.145 -0.239 -0.341
 -0.311  0.09  -0.001 -0.279 -0.096 -0.01   0.043  0.41   0.007 -0.25
 -0.048 -0.617  0.314  0.117 -0.236 -0.304 -0.134 -0.168  0.018 -0.39
 -0.386 -0.01  -0.299 -0.307 -0.19   0.188  0.242 -0.303 -0.152  0.027
 -0.605  0.041 -0.102 -0.193 -0.004 -0.046  0.356  0.254 -0.31  -0.136
  0.365 -0.098  0.061 -0.065  0.176  0.118 -0.075  0.036 -0.055 -0.035
 -0.013 -0.057 -0.234 -0.163 -0.115  0.089 -0.124 -0.235 -0.08   0.492
  0.071 -0.003  0.2    0.263  0.107 -0.075  0.142  0.057 -0.282 -0.054
 -0.073  0.112 -0.203 -0.158  0.451  0.031 -0.094 -0.081  0.183  0.254
  0.151  0.593  0.131  0.077  0.03  -0.194  0.029  0.249 -0.136  0.059
 -0.062  0.116 -0.276 -0.082  0.463 -0.386 -0.275 -0.123 -0.055  0.078
  0.135  0.194 -0.295  0.189 -0.116 -0.171 -0.001  0.239  0.384  0.129
 -0.    -0.212  0.098 -0.11   0.27  -0.186 -0.11   0.082 -0.315  0.011
  0.269 -0.169  0.203 -0.229 -0.025 -0.203 -0.034 -0.145  0.207 -0.246
  0.081  0.063  0.242  0.338 -0.256  0.056 -0.423 -0.292  0.047 -0.032
  0.182 -0.4    0.443 -0.017  0.035  0.093 -0.29   0.13  -0.346  0.172
  0.033 -0.07  -0.038 -0.053 -0.459 -0.362  0.248  0.08   0.05  -0.283
  0.036  0.169 -0.2    0.051  0.232  0.215  0.123  0.047  0.249 -0.292
 -0.149 -0.157  0.224 -0.062  0.033 -0.259  0.048  0.12   0.349 -0.03 ] [ 1.190e-01 -3.600e-02  4.260e-01  1.670e-01 -4.560e-01  9.120e-01
  4.560e-01  4.570e-01 -2.290e-01 -6.000e-01  5.300e-02  2.450e-01
  5.470e-01  3.000e-03 -2.830e-01  3.600e-01 -3.530e-01  2.210e-01
  1.000e-03  7.590e-01  2.920e-01 -8.700e-02  3.590e-01  3.780e-01
 -4.060e-01 -8.240e-01  4.610e-01  3.930e-01 -1.960e-01  2.710e-01
  4.740e-01 -1.390e-01  1.024e+00 -3.140e-01 -3.850e-01  9.200e-02
 -5.610e-01 -3.530e-01  1.660e-01 -1.250e-01 -1.940e-01  1.269e+00
 -4.430e-01 -9.900e-02 -6.960e-01  2.330e-01  3.490e-01 -4.220e-01
  3.110e-01  7.080e-01  1.730e-01  9.060e-01  1.500e-02 -3.180e-01
 -5.150e-01 -2.720e-01 -6.400e-01  1.000e-03  3.720e-01  3.370e-01
 -1.400e+00  1.000e-02 -3.710e-01 -8.500e-02 -6.140e-01 -5.000e-01
  3.390e-01  4.000e-02 -3.650e-01  7.770e-01  4.120e-01  2.020e-01
  1.770e-01 -2.840e-01 -3.290e-01  1.368e+00 -1.360e-01  1.690e-01
  1.170e-01 -3.100e-02  7.470e-01 -2.580e-01 -1.570e-01  4.620e-01
 -2.900e-02 -5.010e-01 -3.540e-01 -3.670e-01 -1.990e-01 -1.120e-01
  4.600e-02  5.070e-01 -2.260e-01  5.600e-02  4.700e-02 -4.150e-01
  4.010e-01  1.170e-01  4.550e-01  2.120e-01  3.450e-01  2.290e-01
  9.820e-01 -5.950e-01 -1.830e-01 -3.510e-01  6.360e-01  5.420e-01
 -6.650e-01  6.400e-01 -8.110e-01 -4.480e-01  1.690e-01  6.060e-01
  4.080e-01  6.260e-01  2.660e-01 -3.940e-01 -1.250e-01  3.200e-01
  3.660e-01 -3.640e-01  2.280e-01 -1.550e-01 -4.550e-01  4.680e-01
 -4.770e-01 -3.500e-02  4.460e-01 -3.730e-01 -5.650e-01 -6.030e-01
  8.380e-01  4.600e-01 -7.200e-02 -3.480e-01 -2.260e-01  4.000e-03
 -2.870e-01  3.300e-02 -2.890e-01 -3.730e-01  6.560e-01  1.600e-02
 -6.680e-01  1.200e-01 -8.900e-02 -1.310e-01 -2.730e-01 -6.600e-02
 -4.160e-01  6.760e-01 -4.670e-01  3.310e-01  3.060e-01  3.210e-01
  2.100e-01 -2.380e-01 -7.860e-01  4.940e-01 -2.170e-01  3.670e-01
 -1.260e-01 -2.040e-01  1.400e-02 -4.500e-02  8.610e-01  6.050e-01
 -5.100e-02  2.210e-01  1.120e-01 -2.930e-01 -6.300e-01 -2.690e-01
  3.920e-01  2.530e-01 -2.310e-01 -2.820e-01  3.830e-01  2.020e-01
  2.220e-01  1.010e+00  1.900e-01  8.400e-02  7.460e-01 -6.370e-01
 -3.620e-01 -6.040e-01 -7.680e-01  4.400e-02  3.820e-01 -1.570e-01
  4.670e-01 -3.590e-01  6.100e-01 -6.840e-01 -1.510e-01  3.250e-01
  1.970e-01 -2.410e-01  5.700e-02  1.840e-01 -2.520e-01  2.530e-01
  5.800e-01 -6.700e-02 -9.240e-01 -2.920e-01 -8.900e-02 -6.630e-01
 -4.140e-01 -4.360e-01  1.620e-01 -8.040e-01  3.830e-01 -2.800e-02
  3.670e-01 -2.050e-01 -5.430e-01  1.560e-01  9.310e-01 -1.310e-01
  5.950e-01  1.270e-01 -5.830e-01  6.540e-01 -1.480e-01  2.980e-01
  3.810e-01  1.340e-01  9.000e-02  1.730e-01  2.200e-01  1.890e-01
  4.510e-01 -9.320e-01 -4.300e-02  3.910e-01  2.490e-01  1.900e-01
 -2.470e-01  6.520e-01  7.200e-02  1.700e-01 -5.820e-01  4.410e-01
 -6.140e-01  6.500e-01  2.060e-01  3.020e-01  1.110e-01  3.310e-01
 -1.870e-01 -1.040e-01  1.240e-01 -4.760e-01  1.290e-01  2.870e-01
 -3.240e-01 -2.470e-01 -3.070e-01  4.500e-02  1.770e-01 -4.800e-02
  2.060e-01 -2.000e-01  3.720e-01 -4.870e-01 -1.140e-01 -7.350e-01
  4.000e-02 -1.720e-01  4.010e-01 -7.110e-01  4.900e-01  5.480e-01
  4.250e-01 -4.470e-01  6.780e-01  2.740e-01 -3.400e-02  2.330e-01
  6.600e-02 -5.230e-01  5.980e-01 -1.100e-02 -5.900e-02 -3.500e-02
  1.810e-01 -9.600e-02 -9.000e-03 -4.640e-01  1.670e-01  1.820e-01
  4.380e-01  2.890e-01  6.260e-01  4.080e-01 -4.030e-01 -4.440e-01] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
10/09/2021 09:17:24 - INFO - data_loader -   *** Example ***
10/09/2021 09:17:24 - INFO - data_loader -   guid: test-2
10/09/2021 09:17:24 - INFO - data_loader -   tokens: [CLS] g ##j re ##tar ##d [SEP]
10/09/2021 09:17:24 - INFO - data_loader -   input_ids: 101 1043 3501 2128 7559 2094 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 09:17:24 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 09:17:24 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 09:17:24 - INFO - data_loader -   intent_label: 2 (id = 2)
10/09/2021 09:17:24 - INFO - data_loader -   slot_labels: 0 6 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 09:17:24 - INFO - data_loader -   ner_embeds: [ 1.920e-01  3.000e-02 -5.410e-01 -2.490e-01  8.700e-02 -4.460e-01
  3.700e-01  4.680e-01 -1.500e-02 -3.350e-01  8.400e-02  2.480e-01
 -1.150e-01 -2.240e-01 -1.040e-01 -2.340e-01 -4.870e-01  4.340e-01
 -1.940e-01 -4.700e-02  2.050e-01 -2.130e-01 -3.940e-01  4.730e-01
 -4.530e-01  3.110e-01 -1.390e-01  5.000e-01 -2.430e-01 -6.130e-01
  6.620e-01  5.020e-01 -1.150e-01 -6.000e-02 -5.620e-01  4.210e-01
  1.010e-01 -4.600e-02  4.170e-01 -1.920e-01 -4.670e-01  4.930e-01
  4.420e-01  1.300e-02 -2.280e-01 -2.030e-01 -1.410e-01  2.710e-01
  1.180e-01 -3.380e-01  3.520e-01  2.730e-01 -4.710e-01 -5.990e-01
 -4.630e-01 -2.470e-01  4.560e-01  1.350e-01  9.400e-02  1.007e+00
  6.660e-01 -8.600e-02 -1.050e-01 -1.010e+00  4.700e-02  7.100e-02
 -6.450e-01 -5.600e-02 -6.300e-02  1.000e-03  2.210e-01  1.970e-01
  2.000e-03  3.970e-01  5.380e-01  9.700e-02 -1.100e-01  6.210e-01
  3.560e-01  4.540e-01  1.090e-01 -1.180e-01  8.800e-02  1.500e-01
 -3.390e-01 -1.920e-01 -4.030e-01 -3.470e-01  2.930e-01  5.400e-02
  1.510e-01  3.640e-01  1.860e-01 -6.300e-01 -1.040e-01 -7.130e-01
  2.080e-01  4.060e-01 -3.940e-01  6.600e-02  2.450e-01  4.080e-01
  1.033e+00  2.930e-01  9.500e-02 -8.000e-03  4.320e-01 -3.220e-01
 -5.650e-01 -9.600e-02 -3.080e-01 -5.730e-01 -4.070e-01  2.750e-01
  1.480e-01 -1.800e-02  7.280e-01 -5.440e-01 -1.052e+00  1.100e-02
  5.480e-01 -1.490e-01  1.250e-01 -3.130e-01 -3.500e-02  3.750e-01
 -7.790e-01 -3.370e-01  2.200e-02 -4.770e-01 -6.280e-01  3.620e-01
  6.600e-02  1.410e-01 -2.860e-01  2.920e-01 -6.900e-02  1.100e-02
 -5.110e-01 -1.430e-01 -1.240e-01  5.520e-01 -2.400e-01 -1.520e-01
 -6.000e-03 -2.080e-01  8.300e-02 -1.270e-01 -1.990e-01 -1.500e-01
 -1.870e-01 -3.200e-02 -3.700e-02 -2.480e-01 -3.860e-01 -1.285e+00
  2.650e-01 -4.450e-01 -1.560e-01  3.110e-01  9.000e-03 -7.970e-01
 -2.300e-02 -1.270e-01 -5.870e-01  3.300e-01  4.850e-01  4.660e-01
 -6.440e-01 -3.770e-01 -2.550e-01  7.000e-03 -2.550e-01  6.240e-01
  2.890e-01 -1.080e-01 -3.260e-01  3.380e-01 -2.090e-01 -3.150e-01
  6.170e-01 -7.300e-02 -1.430e-01  3.330e-01 -1.950e-01  2.340e-01
  8.350e-01  1.350e-01 -2.530e-01  3.400e-02  5.290e-01 -2.620e-01
 -9.700e-02  2.980e-01  5.290e-01  2.400e-02 -3.210e-01  4.540e-01
 -4.950e-01  4.050e-01 -3.840e-01  4.150e-01  5.030e-01 -1.390e-01
 -2.590e-01 -1.340e-01 -7.320e-01 -2.700e-01 -1.260e-01  5.950e-01
  2.060e-01 -2.770e-01  6.900e-02 -1.018e+00 -2.200e-02  2.900e-02
 -2.990e-01  3.420e-01 -3.030e-01 -8.000e-02  7.420e-01 -3.800e-02
  1.460e-01 -3.710e-01 -7.460e-01 -4.520e-01 -1.200e-02  2.840e-01
  3.180e-01 -7.600e-01 -2.800e-01 -1.160e-01  6.600e-02  4.190e-01
 -2.280e-01  1.480e-01 -5.000e-02  3.200e-01 -9.700e-02 -4.520e-01
  7.450e-01 -9.400e-02  7.330e-01 -4.370e-01  4.890e-01 -3.090e-01
  2.210e-01 -3.140e-01 -2.210e-01 -7.700e-01  7.300e-02  5.160e-01
  7.950e-01 -4.280e-01  2.950e-01 -5.410e-01  5.650e-01 -3.180e-01
 -3.050e-01 -3.640e-01 -5.400e-02 -9.980e-01 -4.050e-01 -3.300e-01
 -2.520e-01 -4.550e-01 -1.160e-01  1.400e-02  6.800e-02 -6.900e-02
 -8.400e-02  2.220e-01  4.010e-01 -6.300e-02  1.850e-01  6.600e-01
  1.520e-01 -9.000e-03  6.190e-01 -3.460e-01  7.700e-02 -8.500e-02
  6.600e-02  5.580e-01  2.950e-01 -2.670e-01 -2.700e-01 -7.500e-02
  1.600e-01 -4.590e-01 -4.390e-01 -2.710e-01  4.490e-01  3.450e-01
 -2.730e-01 -4.570e-01  2.840e-01 -3.900e-02 -2.000e-03  8.700e-02] [ 0.024  0.072 -0.091 -0.337 -0.393  0.222 -0.391 -0.447 -0.088 -0.022
  0.012  0.266  0.259 -0.076  0.293 -0.147 -0.048 -0.079 -0.092 -0.057
 -0.082  0.369  0.376  0.064  0.117 -0.004  0.039  0.442 -0.318 -0.133
 -0.305 -0.093 -0.014  0.448  0.199  0.01  -0.179 -0.134 -0.31   0.043
 -0.3   -0.089 -0.03   0.413  0.217 -0.294 -0.217  0.179  0.088 -0.339
 -0.124  0.346  0.183 -0.309  0.201  0.126 -0.205 -0.268  0.343  0.078
 -0.     0.116  0.084  0.116  0.081 -0.256 -0.093 -0.323 -0.194 -0.179
 -0.379  0.129 -0.125  0.342  0.212 -0.096  0.017 -0.006 -0.011 -0.104
  0.217  0.331 -0.184  0.443 -0.163  0.095 -0.398 -0.251 -0.04   0.376
 -0.146  0.215  0.035 -0.009  0.115 -0.272  0.162  0.15  -0.042 -0.255
 -0.188 -0.258  0.041  0.146 -0.253 -0.279  0.009 -0.19  -0.342  0.046
 -0.042 -0.147  0.059 -0.377  0.247 -0.006  0.038 -0.243  0.213  0.287
 -0.035 -0.008  0.379 -0.434 -0.001 -0.144 -0.087 -0.181  0.263  0.021
 -0.015 -0.241 -0.092  0.189 -0.005 -0.256 -0.    -0.064  0.375  0.281
  0.015  0.367 -0.147  0.245 -0.063 -0.257 -0.252  0.075  0.136 -0.093
  0.13   0.108  0.065 -0.039 -0.172  0.027  0.488  0.527  0.021  0.11
  0.048  0.03   0.132 -0.143 -0.008  0.07   0.349 -0.139 -0.003  0.005
  0.065 -0.131  0.194  0.181 -0.006 -0.098 -0.109 -0.126  0.217 -0.018
 -0.129  0.048  0.22   0.359 -0.381 -0.114  0.384  0.334 -0.138 -0.25
 -0.014  0.009 -0.003  0.294  0.058  0.417 -0.183 -0.166 -0.255 -0.234
 -0.005  0.215  0.322 -0.151 -0.004  0.113 -0.     0.012  0.256 -0.236
 -0.022 -0.017 -0.099 -0.093 -0.117 -0.605 -0.117 -0.072  0.444  0.288
 -0.002  0.116  0.242 -0.074 -0.235 -0.024 -0.235  0.181  0.053  0.372
  0.073 -0.01  -0.106  0.283 -0.06  -0.158 -0.098 -0.118  0.336 -0.441
  0.138 -0.185 -0.373 -0.003  0.103 -0.572 -0.388 -0.166 -0.223 -0.148
  0.068  0.434  0.018 -0.372  0.197 -0.085 -0.014 -0.048  0.097  0.196
 -0.038 -0.009 -0.164  0.222  0.031  0.061  0.332  0.033 -0.085 -0.288
 -0.183 -0.248  0.113 -0.109  0.064 -0.556  0.271  0.026  0.144  0.319
 -0.004  0.136 -0.127 -0.106  0.511  0.204  0.123  0.338  0.066 -0.085
 -0.091  0.041 -0.076 -0.159  0.097  0.442  0.076  0.123 -0.339  0.191] [ 0.048  0.144 -0.182 -0.674 -0.786  0.444 -0.782 -0.894 -0.176 -0.044
  0.024  0.532  0.518 -0.152  0.586 -0.294 -0.096 -0.158 -0.184 -0.114
 -0.164  0.738  0.752  0.128  0.234 -0.008  0.078  0.884 -0.636 -0.266
 -0.61  -0.186 -0.028  0.896  0.398  0.02  -0.358 -0.268 -0.62   0.086
 -0.6   -0.178 -0.06   0.826  0.434 -0.588 -0.434  0.358  0.176 -0.678
 -0.248  0.692  0.366 -0.618  0.402  0.252 -0.41  -0.536  0.686  0.156
 -0.     0.232  0.168  0.232  0.162 -0.512 -0.186 -0.646 -0.388 -0.358
 -0.758  0.258 -0.25   0.684  0.424 -0.192  0.034 -0.012 -0.022 -0.208
  0.434  0.662 -0.368  0.886 -0.326  0.19  -0.796 -0.502 -0.08   0.752
 -0.292  0.43   0.07  -0.018  0.23  -0.544  0.324  0.3   -0.084 -0.51
 -0.376 -0.516  0.082  0.292 -0.506 -0.558  0.018 -0.38  -0.684  0.092
 -0.084 -0.294  0.118 -0.754  0.494 -0.012  0.076 -0.486  0.426  0.574
 -0.07  -0.016  0.758 -0.868 -0.002 -0.288 -0.174 -0.362  0.526  0.042
 -0.03  -0.482 -0.184  0.378 -0.01  -0.512 -0.    -0.128  0.75   0.562
  0.03   0.734 -0.294  0.49  -0.126 -0.514 -0.504  0.15   0.272 -0.186
  0.26   0.216  0.13  -0.078 -0.344  0.054  0.976  1.054  0.042  0.22
  0.096  0.06   0.264 -0.286 -0.016  0.14   0.698 -0.278 -0.006  0.01
  0.13  -0.262  0.388  0.362 -0.012 -0.196 -0.218 -0.252  0.434 -0.036
 -0.258  0.096  0.44   0.718 -0.762 -0.228  0.768  0.668 -0.276 -0.5
 -0.028  0.018 -0.006  0.588  0.116  0.834 -0.366 -0.332 -0.51  -0.468
 -0.01   0.43   0.644 -0.302 -0.008  0.226 -0.     0.024  0.512 -0.472
 -0.044 -0.034 -0.198 -0.186 -0.234 -1.21  -0.234 -0.144  0.888  0.576
 -0.004  0.232  0.484 -0.148 -0.47  -0.048 -0.47   0.362  0.106  0.744
  0.146 -0.02  -0.212  0.566 -0.12  -0.316 -0.196 -0.236  0.672 -0.882
  0.276 -0.37  -0.746 -0.006  0.206 -1.144 -0.776 -0.332 -0.446 -0.296
  0.136  0.868  0.036 -0.744  0.394 -0.17  -0.028 -0.096  0.194  0.392
 -0.076 -0.018 -0.328  0.444  0.062  0.122  0.664  0.066 -0.17  -0.576
 -0.366 -0.496  0.226 -0.218  0.128 -1.112  0.542  0.052  0.288  0.638
 -0.008  0.272 -0.254 -0.212  1.022  0.408  0.246  0.676  0.132 -0.17
 -0.182  0.082 -0.152 -0.318  0.194  0.884  0.152  0.246 -0.678  0.382] [-0.218 -0.321 -0.051  0.072 -0.376  0.016 -0.311 -0.459 -0.2    0.031
 -0.306  0.105  0.125 -0.074 -0.016 -0.172 -0.167 -0.055 -0.019  0.377
  0.032  0.13   0.013  0.466  0.541 -0.165  0.217  0.008  0.274 -0.151
 -0.076  0.59   0.132 -0.165 -0.351  0.317 -0.186  0.186 -0.246  0.492
  0.296  0.008 -0.379  0.418 -0.307  0.188  0.056 -0.104 -0.066  0.031
 -0.122  0.254 -0.136 -0.415 -0.029  0.161 -0.487 -0.275  0.446  0.028
 -0.396  0.166  0.148 -0.389  0.109  0.473  0.037 -0.287 -0.089 -0.48
 -0.399 -0.349 -0.187 -0.08   0.208  0.044 -0.513  0.032  0.096  0.037
  0.455  0.189  0.209  0.276  0.006 -0.141  0.079 -0.079 -0.177  0.18
 -1.085 -0.101 -0.316  0.     0.077  0.084  0.251  0.044  0.063 -0.062
  0.084  0.006 -0.167 -0.455  0.15   0.022 -0.209 -0.331  0.056 -0.077
 -0.026 -0.578  0.097  0.109 -0.121 -0.363  0.413 -0.168  0.197 -0.517
 -0.138 -0.159  0.3   -0.438  0.126  0.161 -0.006  0.171 -0.063 -0.663
 -0.288  0.006  0.356  0.429  0.389  0.107 -0.496  0.069 -0.079  0.304
  0.201  0.181  0.296  0.028 -0.398 -0.078  0.132 -0.172 -0.025 -0.235
 -0.091  0.131  0.193  0.312  0.11  -0.009 -0.245  0.156  0.175 -0.48
  0.603 -0.05  -0.171 -0.092  0.076  0.344 -0.592  0.242  0.051  0.126
 -0.396 -0.044  0.604 -0.036  0.09   0.118 -0.083 -0.239  0.241 -0.04
  0.095  0.005  0.009  0.062 -0.139 -0.135  0.451  0.147  0.147 -0.093
  0.557  0.166 -0.064  0.036 -0.257  0.342  0.357  0.126  0.145  0.065
 -0.047 -0.083 -0.114 -0.058 -0.068 -0.164 -0.585 -0.098  0.118  0.047
 -0.272 -0.058  0.07  -0.344  0.598 -0.17  -0.298 -0.387  0.288  0.406
  0.348 -0.004 -0.53   0.159 -0.197 -0.191 -0.08   0.117  0.192  0.315
 -0.25  -0.349 -0.425  0.129 -0.08   0.037 -0.287  0.183  0.006 -0.055
  0.325 -0.111  0.383 -0.203 -0.152 -0.303 -0.018 -0.079 -0.082  0.024
 -0.143  0.05   0.045  0.155 -0.265  0.295  0.124 -0.083  0.31   0.032
  0.604 -0.678 -0.127 -0.351 -0.327 -0.129  0.093  0.08  -0.196  0.017
  0.267 -0.444  0.299 -0.002 -0.12   0.176 -0.151  0.422 -0.142 -0.355
  0.311  0.099  0.21   0.421  0.024  0.123 -0.038 -0.198 -0.177 -0.439
  0.103  0.219  0.07  -0.275  0.038 -0.179 -0.035  0.07  -0.131 -0.07 ] [-0.436 -0.642 -0.102  0.144 -0.752  0.032 -0.622 -0.918 -0.4    0.062
 -0.612  0.21   0.25  -0.148 -0.032 -0.344 -0.334 -0.11  -0.038  0.754
  0.064  0.26   0.026  0.932  1.082 -0.33   0.434  0.016  0.548 -0.302
 -0.152  1.18   0.264 -0.33  -0.702  0.634 -0.372  0.372 -0.492  0.984
  0.592  0.016 -0.758  0.836 -0.614  0.376  0.112 -0.208 -0.132  0.062
 -0.244  0.508 -0.272 -0.83  -0.058  0.322 -0.974 -0.55   0.892  0.056
 -0.792  0.332  0.296 -0.778  0.218  0.946  0.074 -0.574 -0.178 -0.96
 -0.798 -0.698 -0.374 -0.16   0.416  0.088 -1.026  0.064  0.192  0.074
  0.91   0.378  0.418  0.552  0.012 -0.282  0.158 -0.158 -0.354  0.36
 -2.17  -0.202 -0.632  0.     0.154  0.168  0.502  0.088  0.126 -0.124
  0.168  0.012 -0.334 -0.91   0.3    0.044 -0.418 -0.662  0.112 -0.154
 -0.052 -1.156  0.194  0.218 -0.242 -0.726  0.826 -0.336  0.394 -1.034
 -0.276 -0.318  0.6   -0.876  0.252  0.322 -0.012  0.342 -0.126 -1.326
 -0.576  0.012  0.712  0.858  0.778  0.214 -0.992  0.138 -0.158  0.608
  0.402  0.362  0.592  0.056 -0.796 -0.156  0.264 -0.344 -0.05  -0.47
 -0.182  0.262  0.386  0.624  0.22  -0.018 -0.49   0.312  0.35  -0.96
  1.206 -0.1   -0.342 -0.184  0.152  0.688 -1.184  0.484  0.102  0.252
 -0.792 -0.088  1.208 -0.072  0.18   0.236 -0.166 -0.478  0.482 -0.08
  0.19   0.01   0.018  0.124 -0.278 -0.27   0.902  0.294  0.294 -0.186
  1.114  0.332 -0.128  0.072 -0.514  0.684  0.714  0.252  0.29   0.13
 -0.094 -0.166 -0.228 -0.116 -0.136 -0.328 -1.17  -0.196  0.236  0.094
 -0.544 -0.116  0.14  -0.688  1.196 -0.34  -0.596 -0.774  0.576  0.812
  0.696 -0.008 -1.06   0.318 -0.394 -0.382 -0.16   0.234  0.384  0.63
 -0.5   -0.698 -0.85   0.258 -0.16   0.074 -0.574  0.366  0.012 -0.11
  0.65  -0.222  0.766 -0.406 -0.304 -0.606 -0.036 -0.158 -0.164  0.048
 -0.286  0.1    0.09   0.31  -0.53   0.59   0.248 -0.166  0.62   0.064
  1.208 -1.356 -0.254 -0.702 -0.654 -0.258  0.186  0.16  -0.392  0.034
  0.534 -0.888  0.598 -0.004 -0.24   0.352 -0.302  0.844 -0.284 -0.71
  0.622  0.198  0.42   0.842  0.048  0.246 -0.076 -0.396 -0.354 -0.878
  0.206  0.438  0.14  -0.55   0.076 -0.358 -0.07   0.14  -0.262 -0.14 ] [-0.654 -0.963 -0.153  0.216 -1.128  0.048 -0.933 -1.377 -0.6    0.093
 -0.918  0.315  0.375 -0.222 -0.048 -0.516 -0.501 -0.165 -0.057  1.131
  0.096  0.39   0.039  1.398  1.623 -0.495  0.651  0.024  0.822 -0.453
 -0.228  1.77   0.396 -0.495 -1.053  0.951 -0.558  0.558 -0.738  1.476
  0.888  0.024 -1.137  1.254 -0.921  0.564  0.168 -0.312 -0.198  0.093
 -0.366  0.762 -0.408 -1.245 -0.087  0.483 -1.461 -0.825  1.338  0.084
 -1.188  0.498  0.444 -1.167  0.327  1.419  0.111 -0.861 -0.267 -1.44
 -1.197 -1.047 -0.561 -0.24   0.624  0.132 -1.539  0.096  0.288  0.111
  1.365  0.567  0.627  0.828  0.018 -0.423  0.237 -0.237 -0.531  0.54
 -3.255 -0.303 -0.948  0.     0.231  0.252  0.753  0.132  0.189 -0.186
  0.252  0.018 -0.501 -1.365  0.45   0.066 -0.627 -0.993  0.168 -0.231
 -0.078 -1.734  0.291  0.327 -0.363 -1.089  1.239 -0.504  0.591 -1.551
 -0.414 -0.477  0.9   -1.314  0.378  0.483 -0.018  0.513 -0.189 -1.989
 -0.864  0.018  1.068  1.287  1.167  0.321 -1.488  0.207 -0.237  0.912
  0.603  0.543  0.888  0.084 -1.194 -0.234  0.396 -0.516 -0.075 -0.705
 -0.273  0.393  0.579  0.936  0.33  -0.027 -0.735  0.468  0.525 -1.44
  1.809 -0.15  -0.513 -0.276  0.228  1.032 -1.776  0.726  0.153  0.378
 -1.188 -0.132  1.812 -0.108  0.27   0.354 -0.249 -0.717  0.723 -0.12
  0.285  0.015  0.027  0.186 -0.417 -0.405  1.353  0.441  0.441 -0.279
  1.671  0.498 -0.192  0.108 -0.771  1.026  1.071  0.378  0.435  0.195
 -0.141 -0.249 -0.342 -0.174 -0.204 -0.492 -1.755 -0.294  0.354  0.141
 -0.816 -0.174  0.21  -1.032  1.794 -0.51  -0.894 -1.161  0.864  1.218
  1.044 -0.012 -1.59   0.477 -0.591 -0.573 -0.24   0.351  0.576  0.945
 -0.75  -1.047 -1.275  0.387 -0.24   0.111 -0.861  0.549  0.018 -0.165
  0.975 -0.333  1.149 -0.609 -0.456 -0.909 -0.054 -0.237 -0.246  0.072
 -0.429  0.15   0.135  0.465 -0.795  0.885  0.372 -0.249  0.93   0.096
  1.812 -2.034 -0.381 -1.053 -0.981 -0.387  0.279  0.24  -0.588  0.051
  0.801 -1.332  0.897 -0.006 -0.36   0.528 -0.453  1.266 -0.426 -1.065
  0.933  0.297  0.63   1.263  0.072  0.369 -0.114 -0.594 -0.531 -1.317
  0.309  0.657  0.21  -0.825  0.114 -0.537 -0.105  0.21  -0.393 -0.21 ] [ 1.190e-01 -3.600e-02  4.260e-01  1.670e-01 -4.560e-01  9.120e-01
  4.560e-01  4.570e-01 -2.290e-01 -6.000e-01  5.300e-02  2.450e-01
  5.470e-01  3.000e-03 -2.830e-01  3.600e-01 -3.530e-01  2.210e-01
  1.000e-03  7.590e-01  2.920e-01 -8.700e-02  3.590e-01  3.780e-01
 -4.060e-01 -8.240e-01  4.610e-01  3.930e-01 -1.960e-01  2.710e-01
  4.740e-01 -1.390e-01  1.024e+00 -3.140e-01 -3.850e-01  9.200e-02
 -5.610e-01 -3.530e-01  1.660e-01 -1.250e-01 -1.940e-01  1.269e+00
 -4.430e-01 -9.900e-02 -6.960e-01  2.330e-01  3.490e-01 -4.220e-01
  3.110e-01  7.080e-01  1.730e-01  9.060e-01  1.500e-02 -3.180e-01
 -5.150e-01 -2.720e-01 -6.400e-01  1.000e-03  3.720e-01  3.370e-01
 -1.400e+00  1.000e-02 -3.710e-01 -8.500e-02 -6.140e-01 -5.000e-01
  3.390e-01  4.000e-02 -3.650e-01  7.770e-01  4.120e-01  2.020e-01
  1.770e-01 -2.840e-01 -3.290e-01  1.368e+00 -1.360e-01  1.690e-01
  1.170e-01 -3.100e-02  7.470e-01 -2.580e-01 -1.570e-01  4.620e-01
 -2.900e-02 -5.010e-01 -3.540e-01 -3.670e-01 -1.990e-01 -1.120e-01
  4.600e-02  5.070e-01 -2.260e-01  5.600e-02  4.700e-02 -4.150e-01
  4.010e-01  1.170e-01  4.550e-01  2.120e-01  3.450e-01  2.290e-01
  9.820e-01 -5.950e-01 -1.830e-01 -3.510e-01  6.360e-01  5.420e-01
 -6.650e-01  6.400e-01 -8.110e-01 -4.480e-01  1.690e-01  6.060e-01
  4.080e-01  6.260e-01  2.660e-01 -3.940e-01 -1.250e-01  3.200e-01
  3.660e-01 -3.640e-01  2.280e-01 -1.550e-01 -4.550e-01  4.680e-01
 -4.770e-01 -3.500e-02  4.460e-01 -3.730e-01 -5.650e-01 -6.030e-01
  8.380e-01  4.600e-01 -7.200e-02 -3.480e-01 -2.260e-01  4.000e-03
 -2.870e-01  3.300e-02 -2.890e-01 -3.730e-01  6.560e-01  1.600e-02
 -6.680e-01  1.200e-01 -8.900e-02 -1.310e-01 -2.730e-01 -6.600e-02
 -4.160e-01  6.760e-01 -4.670e-01  3.310e-01  3.060e-01  3.210e-01
  2.100e-01 -2.380e-01 -7.860e-01  4.940e-01 -2.170e-01  3.670e-01
 -1.260e-01 -2.040e-01  1.400e-02 -4.500e-02  8.610e-01  6.050e-01
 -5.100e-02  2.210e-01  1.120e-01 -2.930e-01 -6.300e-01 -2.690e-01
  3.920e-01  2.530e-01 -2.310e-01 -2.820e-01  3.830e-01  2.020e-01
  2.220e-01  1.010e+00  1.900e-01  8.400e-02  7.460e-01 -6.370e-01
 -3.620e-01 -6.040e-01 -7.680e-01  4.400e-02  3.820e-01 -1.570e-01
  4.670e-01 -3.590e-01  6.100e-01 -6.840e-01 -1.510e-01  3.250e-01
  1.970e-01 -2.410e-01  5.700e-02  1.840e-01 -2.520e-01  2.530e-01
  5.800e-01 -6.700e-02 -9.240e-01 -2.920e-01 -8.900e-02 -6.630e-01
 -4.140e-01 -4.360e-01  1.620e-01 -8.040e-01  3.830e-01 -2.800e-02
  3.670e-01 -2.050e-01 -5.430e-01  1.560e-01  9.310e-01 -1.310e-01
  5.950e-01  1.270e-01 -5.830e-01  6.540e-01 -1.480e-01  2.980e-01
  3.810e-01  1.340e-01  9.000e-02  1.730e-01  2.200e-01  1.890e-01
  4.510e-01 -9.320e-01 -4.300e-02  3.910e-01  2.490e-01  1.900e-01
 -2.470e-01  6.520e-01  7.200e-02  1.700e-01 -5.820e-01  4.410e-01
 -6.140e-01  6.500e-01  2.060e-01  3.020e-01  1.110e-01  3.310e-01
 -1.870e-01 -1.040e-01  1.240e-01 -4.760e-01  1.290e-01  2.870e-01
 -3.240e-01 -2.470e-01 -3.070e-01  4.500e-02  1.770e-01 -4.800e-02
  2.060e-01 -2.000e-01  3.720e-01 -4.870e-01 -1.140e-01 -7.350e-01
  4.000e-02 -1.720e-01  4.010e-01 -7.110e-01  4.900e-01  5.480e-01
  4.250e-01 -4.470e-01  6.780e-01  2.740e-01 -3.400e-02  2.330e-01
  6.600e-02 -5.230e-01  5.980e-01 -1.100e-02 -5.900e-02 -3.500e-02
  1.810e-01 -9.600e-02 -9.000e-03 -4.640e-01  1.670e-01  1.820e-01
  4.380e-01  2.890e-01  6.260e-01  4.080e-01 -4.030e-01 -4.440e-01] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
10/09/2021 09:17:24 - INFO - data_loader -   *** Example ***
10/09/2021 09:17:24 - INFO - data_loader -   guid: test-3
10/09/2021 09:17:24 - INFO - data_loader -   tokens: [CLS] yu ##p ign ##ite to ks no ##ob act [SEP]
10/09/2021 09:17:24 - INFO - data_loader -   input_ids: 101 9805 2361 16270 4221 2000 29535 2053 16429 2552 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 09:17:24 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 09:17:24 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 09:17:24 - INFO - data_loader -   intent_label: 2 (id = 2)
10/09/2021 09:17:24 - INFO - data_loader -   slot_labels: 0 4 0 3 0 4 4 7 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 09:17:25 - INFO - data_loader -   ner_embeds: [ 1.920e-01  3.000e-02 -5.410e-01 -2.490e-01  8.700e-02 -4.460e-01
  3.700e-01  4.680e-01 -1.500e-02 -3.350e-01  8.400e-02  2.480e-01
 -1.150e-01 -2.240e-01 -1.040e-01 -2.340e-01 -4.870e-01  4.340e-01
 -1.940e-01 -4.700e-02  2.050e-01 -2.130e-01 -3.940e-01  4.730e-01
 -4.530e-01  3.110e-01 -1.390e-01  5.000e-01 -2.430e-01 -6.130e-01
  6.620e-01  5.020e-01 -1.150e-01 -6.000e-02 -5.620e-01  4.210e-01
  1.010e-01 -4.600e-02  4.170e-01 -1.920e-01 -4.670e-01  4.930e-01
  4.420e-01  1.300e-02 -2.280e-01 -2.030e-01 -1.410e-01  2.710e-01
  1.180e-01 -3.380e-01  3.520e-01  2.730e-01 -4.710e-01 -5.990e-01
 -4.630e-01 -2.470e-01  4.560e-01  1.350e-01  9.400e-02  1.007e+00
  6.660e-01 -8.600e-02 -1.050e-01 -1.010e+00  4.700e-02  7.100e-02
 -6.450e-01 -5.600e-02 -6.300e-02  1.000e-03  2.210e-01  1.970e-01
  2.000e-03  3.970e-01  5.380e-01  9.700e-02 -1.100e-01  6.210e-01
  3.560e-01  4.540e-01  1.090e-01 -1.180e-01  8.800e-02  1.500e-01
 -3.390e-01 -1.920e-01 -4.030e-01 -3.470e-01  2.930e-01  5.400e-02
  1.510e-01  3.640e-01  1.860e-01 -6.300e-01 -1.040e-01 -7.130e-01
  2.080e-01  4.060e-01 -3.940e-01  6.600e-02  2.450e-01  4.080e-01
  1.033e+00  2.930e-01  9.500e-02 -8.000e-03  4.320e-01 -3.220e-01
 -5.650e-01 -9.600e-02 -3.080e-01 -5.730e-01 -4.070e-01  2.750e-01
  1.480e-01 -1.800e-02  7.280e-01 -5.440e-01 -1.052e+00  1.100e-02
  5.480e-01 -1.490e-01  1.250e-01 -3.130e-01 -3.500e-02  3.750e-01
 -7.790e-01 -3.370e-01  2.200e-02 -4.770e-01 -6.280e-01  3.620e-01
  6.600e-02  1.410e-01 -2.860e-01  2.920e-01 -6.900e-02  1.100e-02
 -5.110e-01 -1.430e-01 -1.240e-01  5.520e-01 -2.400e-01 -1.520e-01
 -6.000e-03 -2.080e-01  8.300e-02 -1.270e-01 -1.990e-01 -1.500e-01
 -1.870e-01 -3.200e-02 -3.700e-02 -2.480e-01 -3.860e-01 -1.285e+00
  2.650e-01 -4.450e-01 -1.560e-01  3.110e-01  9.000e-03 -7.970e-01
 -2.300e-02 -1.270e-01 -5.870e-01  3.300e-01  4.850e-01  4.660e-01
 -6.440e-01 -3.770e-01 -2.550e-01  7.000e-03 -2.550e-01  6.240e-01
  2.890e-01 -1.080e-01 -3.260e-01  3.380e-01 -2.090e-01 -3.150e-01
  6.170e-01 -7.300e-02 -1.430e-01  3.330e-01 -1.950e-01  2.340e-01
  8.350e-01  1.350e-01 -2.530e-01  3.400e-02  5.290e-01 -2.620e-01
 -9.700e-02  2.980e-01  5.290e-01  2.400e-02 -3.210e-01  4.540e-01
 -4.950e-01  4.050e-01 -3.840e-01  4.150e-01  5.030e-01 -1.390e-01
 -2.590e-01 -1.340e-01 -7.320e-01 -2.700e-01 -1.260e-01  5.950e-01
  2.060e-01 -2.770e-01  6.900e-02 -1.018e+00 -2.200e-02  2.900e-02
 -2.990e-01  3.420e-01 -3.030e-01 -8.000e-02  7.420e-01 -3.800e-02
  1.460e-01 -3.710e-01 -7.460e-01 -4.520e-01 -1.200e-02  2.840e-01
  3.180e-01 -7.600e-01 -2.800e-01 -1.160e-01  6.600e-02  4.190e-01
 -2.280e-01  1.480e-01 -5.000e-02  3.200e-01 -9.700e-02 -4.520e-01
  7.450e-01 -9.400e-02  7.330e-01 -4.370e-01  4.890e-01 -3.090e-01
  2.210e-01 -3.140e-01 -2.210e-01 -7.700e-01  7.300e-02  5.160e-01
  7.950e-01 -4.280e-01  2.950e-01 -5.410e-01  5.650e-01 -3.180e-01
 -3.050e-01 -3.640e-01 -5.400e-02 -9.980e-01 -4.050e-01 -3.300e-01
 -2.520e-01 -4.550e-01 -1.160e-01  1.400e-02  6.800e-02 -6.900e-02
 -8.400e-02  2.220e-01  4.010e-01 -6.300e-02  1.850e-01  6.600e-01
  1.520e-01 -9.000e-03  6.190e-01 -3.460e-01  7.700e-02 -8.500e-02
  6.600e-02  5.580e-01  2.950e-01 -2.670e-01 -2.700e-01 -7.500e-02
  1.600e-01 -4.590e-01 -4.390e-01 -2.710e-01  4.490e-01  3.450e-01
 -2.730e-01 -4.570e-01  2.840e-01 -3.900e-02 -2.000e-03  8.700e-02] [-0.031  0.503 -0.021 -0.027 -0.386  0.086  0.245  0.001  0.027 -0.008
 -0.312  0.243 -0.01  -0.062  0.253 -0.041 -0.091  0.23   0.239  0.004
 -0.012  0.107  0.269  0.025  0.117  0.064 -0.019  0.173 -0.166  0.209
 -0.104 -0.073  0.21   0.164 -0.081  0.206 -0.022  0.216  0.052  0.222
 -0.104  0.037 -0.239 -0.159 -0.272  0.165  0.116  0.178  0.014 -0.17
 -0.113  0.07   0.059  0.2    0.02   0.183  0.026 -0.057 -0.269  0.153
  0.303 -0.067  0.021 -0.187 -0.125 -0.274  0.207 -0.247 -0.014  0.04
 -0.529  0.02  -0.376  0.386  0.069 -0.029 -0.338 -0.316  0.106 -0.073
  0.119 -0.171  0.227 -0.059 -0.325  0.175 -0.286  0.002 -0.114 -0.282
 -0.18  -0.057 -0.011  0.035  0.242 -0.024  0.259  0.074  0.102  0.078
  0.399  0.254  0.195  0.013  0.109 -0.292 -0.303 -0.013 -0.064  0.102
 -0.164  0.007  0.192 -0.246 -0.113  0.032 -0.035 -0.149  0.066  0.107
  0.023  0.018  0.174 -0.263 -0.038 -0.062 -0.     0.056  0.147 -0.16
  0.057 -0.491 -0.009  0.011  0.046 -0.215  0.083 -0.059  0.115  0.146
 -0.034  0.095 -0.282  0.076 -0.241 -0.136  0.041  0.079 -0.384 -0.234
 -0.269  0.082 -0.121 -0.207 -0.301  0.249 -0.193  0.009  0.057 -0.192
  0.406  0.042  0.105  0.038  0.39   0.085  0.657 -0.167 -0.085 -0.157
 -0.024  0.364 -0.371 -0.046 -0.095  0.053 -0.421 -0.267  0.105  0.052
  0.212  0.04   0.136 -0.135  0.171  0.087  0.113  0.203  0.269 -0.06
 -0.277  0.    -0.032 -0.16   0.074 -0.046  0.156 -0.078 -0.33   0.255
 -0.213  0.188  0.292 -0.069 -0.069 -0.334 -0.214 -0.148  0.403  0.093
  0.44  -0.218 -0.157  0.038  0.551 -0.189 -0.282  0.111  0.268  0.331
  0.106 -0.075 -0.086  0.034 -0.307 -0.266 -0.327 -0.257  0.274  0.021
 -0.102 -0.146 -0.258 -0.24   0.339 -0.182 -0.32  -0.031 -0.188  0.032
  0.139 -0.065 -0.045 -0.126  0.287 -0.367 -0.234  0.266 -0.061  0.089
 -0.049  0.311 -0.099 -0.208  0.027  0.107  0.014 -0.036  0.122  0.044
  0.265  0.163  0.059 -0.076 -0.005  0.02  -0.013  0.108 -0.247 -0.06
 -0.415  0.154  0.175 -0.03  -0.186 -0.195  0.048 -0.243  0.183  0.003
 -0.096  0.136  0.066  0.199  0.14   0.27   0.131 -0.172  0.051  0.087
 -0.161  0.289 -0.347 -0.212  0.137 -0.223 -0.341  0.004 -0.183  0.367] [-0.062  1.006 -0.042 -0.054 -0.772  0.172  0.49   0.002  0.054 -0.016
 -0.624  0.486 -0.02  -0.124  0.506 -0.082 -0.182  0.46   0.478  0.008
 -0.024  0.214  0.538  0.05   0.234  0.128 -0.038  0.346 -0.332  0.418
 -0.208 -0.146  0.42   0.328 -0.162  0.412 -0.044  0.432  0.104  0.444
 -0.208  0.074 -0.478 -0.318 -0.544  0.33   0.232  0.356  0.028 -0.34
 -0.226  0.14   0.118  0.4    0.04   0.366  0.052 -0.114 -0.538  0.306
  0.606 -0.134  0.042 -0.374 -0.25  -0.548  0.414 -0.494 -0.028  0.08
 -1.058  0.04  -0.752  0.772  0.138 -0.058 -0.676 -0.632  0.212 -0.146
  0.238 -0.342  0.454 -0.118 -0.65   0.35  -0.572  0.004 -0.228 -0.564
 -0.36  -0.114 -0.022  0.07   0.484 -0.048  0.518  0.148  0.204  0.156
  0.798  0.508  0.39   0.026  0.218 -0.584 -0.606 -0.026 -0.128  0.204
 -0.328  0.014  0.384 -0.492 -0.226  0.064 -0.07  -0.298  0.132  0.214
  0.046  0.036  0.348 -0.526 -0.076 -0.124 -0.     0.112  0.294 -0.32
  0.114 -0.982 -0.018  0.022  0.092 -0.43   0.166 -0.118  0.23   0.292
 -0.068  0.19  -0.564  0.152 -0.482 -0.272  0.082  0.158 -0.768 -0.468
 -0.538  0.164 -0.242 -0.414 -0.602  0.498 -0.386  0.018  0.114 -0.384
  0.812  0.084  0.21   0.076  0.78   0.17   1.314 -0.334 -0.17  -0.314
 -0.048  0.728 -0.742 -0.092 -0.19   0.106 -0.842 -0.534  0.21   0.104
  0.424  0.08   0.272 -0.27   0.342  0.174  0.226  0.406  0.538 -0.12
 -0.554  0.    -0.064 -0.32   0.148 -0.092  0.312 -0.156 -0.66   0.51
 -0.426  0.376  0.584 -0.138 -0.138 -0.668 -0.428 -0.296  0.806  0.186
  0.88  -0.436 -0.314  0.076  1.102 -0.378 -0.564  0.222  0.536  0.662
  0.212 -0.15  -0.172  0.068 -0.614 -0.532 -0.654 -0.514  0.548  0.042
 -0.204 -0.292 -0.516 -0.48   0.678 -0.364 -0.64  -0.062 -0.376  0.064
  0.278 -0.13  -0.09  -0.252  0.574 -0.734 -0.468  0.532 -0.122  0.178
 -0.098  0.622 -0.198 -0.416  0.054  0.214  0.028 -0.072  0.244  0.088
  0.53   0.326  0.118 -0.152 -0.01   0.04  -0.026  0.216 -0.494 -0.12
 -0.83   0.308  0.35  -0.06  -0.372 -0.39   0.096 -0.486  0.366  0.006
 -0.192  0.272  0.132  0.398  0.28   0.54   0.262 -0.344  0.102  0.174
 -0.322  0.578 -0.694 -0.424  0.274 -0.446 -0.682  0.008 -0.366  0.734] [-0.036 -0.27  -0.023  0.22  -0.332  0.129 -0.08  -0.079  0.326 -0.005
 -0.17  -0.322 -0.048  0.149  0.042  0.046 -0.252 -0.079  0.019  0.061
 -0.166  0.011  0.091 -0.009  0.131 -0.419 -0.478 -0.221  0.042 -0.036
 -0.219  0.215  0.582 -0.082  0.035 -0.124 -0.016 -0.472  0.181  0.374
  0.116  0.19   0.104 -0.027  0.208 -0.043 -0.003  0.266 -0.633 -0.353
  0.432  0.512  0.185 -0.149 -0.143  0.305  0.349 -0.118  0.195  0.018
 -0.309  0.241 -0.374 -0.503 -0.131  0.354  0.161 -0.416 -0.282  0.086
 -0.292 -0.212 -0.26  -0.152  0.107  0.156  0.327  0.355  0.034 -0.217
  0.443  0.237  0.095  0.224 -0.565 -0.256 -0.445 -0.224 -0.036  0.233
 -0.589  0.097  0.278 -0.343 -0.078 -0.056  0.104  0.379  0.492 -0.287
  0.21  -0.26   0.381 -0.001 -0.137 -0.227 -0.234 -0.164 -0.045  0.268
 -0.048 -0.426 -0.184 -0.195  0.107 -0.136  0.115 -0.124  0.113 -0.136
  0.112 -0.04   0.073 -0.067  0.064  0.098 -0.081  0.292 -0.024 -0.307
 -0.087  0.389  0.13   0.03   0.029  0.108 -0.223  0.025 -0.327 -0.164
 -0.043  0.324  0.199 -0.181 -0.301  0.173 -0.151  0.64  -0.317  0.202
 -0.028  0.219 -0.162 -0.236 -0.255 -0.218 -0.002  0.526 -0.069 -0.512
  0.189 -0.083 -0.044 -0.315  0.274  0.357 -0.05   0.178 -0.565  0.091
  0.406 -0.182  0.025  0.184  0.015  0.227 -0.42  -0.254 -0.459  0.142
  0.231  0.157 -0.131 -0.206 -0.241 -0.092  0.194  0.259  0.419 -0.16
  0.093 -0.37  -0.341 -0.009  0.066 -0.316  0.004  0.356  0.018  0.059
  0.237 -0.09  -0.064 -0.101  0.098  0.316 -0.061 -0.455 -0.244 -0.084
  0.051 -0.037 -0.662 -0.623  0.032 -0.265 -0.084  0.218  0.105 -0.117
  0.042 -0.115 -0.101  0.276  0.269  0.142 -0.483  0.406  0.302  0.055
  0.02  -0.088 -0.399 -0.277  0.017 -0.265 -0.033  0.448  0.077  0.228
  0.451 -0.02   0.003  0.33  -0.313 -0.37  -0.456 -0.228 -0.457 -0.051
  0.193  0.295  0.274 -0.178  0.086 -0.279 -0.063  0.069 -0.221 -0.259
 -0.199 -0.201  0.062 -0.156 -0.25   0.177  0.23   0.14  -0.003  0.057
 -0.216 -0.225  0.151  0.094 -0.493 -0.198  0.049  0.429  0.207 -0.214
  0.063 -0.136  0.192  0.167  0.034 -0.359 -0.348 -0.036 -0.121 -0.44
  0.187  0.222  0.09  -0.037  0.012 -0.007 -0.014 -0.043 -0.201  0.154] [-0.072 -0.54  -0.046  0.44  -0.664  0.258 -0.16  -0.158  0.652 -0.01
 -0.34  -0.644 -0.096  0.298  0.084  0.092 -0.504 -0.158  0.038  0.122
 -0.332  0.022  0.182 -0.018  0.262 -0.838 -0.956 -0.442  0.084 -0.072
 -0.438  0.43   1.164 -0.164  0.07  -0.248 -0.032 -0.944  0.362  0.748
  0.232  0.38   0.208 -0.054  0.416 -0.086 -0.006  0.532 -1.266 -0.706
  0.864  1.024  0.37  -0.298 -0.286  0.61   0.698 -0.236  0.39   0.036
 -0.618  0.482 -0.748 -1.006 -0.262  0.708  0.322 -0.832 -0.564  0.172
 -0.584 -0.424 -0.52  -0.304  0.214  0.312  0.654  0.71   0.068 -0.434
  0.886  0.474  0.19   0.448 -1.13  -0.512 -0.89  -0.448 -0.072  0.466
 -1.178  0.194  0.556 -0.686 -0.156 -0.112  0.208  0.758  0.984 -0.574
  0.42  -0.52   0.762 -0.002 -0.274 -0.454 -0.468 -0.328 -0.09   0.536
 -0.096 -0.852 -0.368 -0.39   0.214 -0.272  0.23  -0.248  0.226 -0.272
  0.224 -0.08   0.146 -0.134  0.128  0.196 -0.162  0.584 -0.048 -0.614
 -0.174  0.778  0.26   0.06   0.058  0.216 -0.446  0.05  -0.654 -0.328
 -0.086  0.648  0.398 -0.362 -0.602  0.346 -0.302  1.28  -0.634  0.404
 -0.056  0.438 -0.324 -0.472 -0.51  -0.436 -0.004  1.052 -0.138 -1.024
  0.378 -0.166 -0.088 -0.63   0.548  0.714 -0.1    0.356 -1.13   0.182
  0.812 -0.364  0.05   0.368  0.03   0.454 -0.84  -0.508 -0.918  0.284
  0.462  0.314 -0.262 -0.412 -0.482 -0.184  0.388  0.518  0.838 -0.32
  0.186 -0.74  -0.682 -0.018  0.132 -0.632  0.008  0.712  0.036  0.118
  0.474 -0.18  -0.128 -0.202  0.196  0.632 -0.122 -0.91  -0.488 -0.168
  0.102 -0.074 -1.324 -1.246  0.064 -0.53  -0.168  0.436  0.21  -0.234
  0.084 -0.23  -0.202  0.552  0.538  0.284 -0.966  0.812  0.604  0.11
  0.04  -0.176 -0.798 -0.554  0.034 -0.53  -0.066  0.896  0.154  0.456
  0.902 -0.04   0.006  0.66  -0.626 -0.74  -0.912 -0.456 -0.914 -0.102
  0.386  0.59   0.548 -0.356  0.172 -0.558 -0.126  0.138 -0.442 -0.518
 -0.398 -0.402  0.124 -0.312 -0.5    0.354  0.46   0.28  -0.006  0.114
 -0.432 -0.45   0.302  0.188 -0.986 -0.396  0.098  0.858  0.414 -0.428
  0.126 -0.272  0.384  0.334  0.068 -0.718 -0.696 -0.072 -0.242 -0.88
  0.374  0.444  0.18  -0.074  0.024 -0.014 -0.028 -0.086 -0.402  0.308] [ 0.214 -0.048 -0.045 -0.188  0.415 -0.082 -0.318 -0.329 -0.017  0.204
  0.29   0.016  0.338 -0.25  -0.104 -0.123  0.008  0.228  0.155  0.063
 -0.154 -0.056 -0.098  0.242 -0.069  0.069  0.348 -0.226 -0.062  0.148
  0.055  0.039  0.255  0.037 -0.349  0.133  0.013 -0.147  0.095  0.043
 -0.123  0.212  0.127  0.191  0.3   -0.45   0.315  0.327 -0.133 -0.304
  0.169  0.318 -0.501 -0.224  0.026 -0.204 -0.071  0.123  0.012 -0.048
  0.036  0.42  -0.119 -0.116 -0.298 -0.186  0.14   0.054  0.413 -0.05
 -0.348 -0.309 -0.047 -0.125 -0.08  -0.306 -0.002  0.152  0.061  0.298
  0.186  0.099  0.258  0.16  -0.272 -0.298  0.024  0.082 -0.102 -0.168
 -0.122  0.077 -0.069 -0.178 -0.189 -0.173  0.317  0.643 -0.135 -0.067
 -0.084  0.    -0.066 -0.12   0.141 -0.215 -0.125 -0.189  0.027  0.08
  0.108 -0.184 -0.361  0.047  0.329 -0.208 -0.097 -0.013 -0.09   0.133
  0.148  0.029  0.036 -0.245 -0.401  0.222 -0.066  0.087 -0.389  0.064
  0.141 -0.281  0.064 -0.326  0.376 -0.277 -0.302  0.244 -0.096 -0.104
 -0.122 -0.213 -0.085  0.136 -0.184 -0.146 -0.142 -0.592 -0.319  0.157
 -0.056 -0.246 -0.338 -0.193 -0.07   0.128  0.222 -0.048 -0.286  0.105
  0.566 -0.404  0.093 -0.519  0.171 -0.293 -0.011  0.205 -0.136  0.184
  0.348 -0.056  0.241  0.442 -0.013 -0.361  0.029 -0.068 -0.289  0.48
  0.182 -0.414 -0.58  -0.157  0.088 -0.36  -0.494  0.23   0.338  0.105
  0.509 -0.507 -0.209 -0.168  0.157 -0.284 -0.084  0.132  0.049 -0.309
  0.009 -0.258  0.449 -0.482  0.425  0.054 -0.017 -0.181 -0.147 -0.244
  0.182  0.293  0.34   0.303  0.271 -0.163 -0.13   0.032  0.056  0.132
  0.174  0.313  0.077 -0.274 -0.165 -0.285 -0.283  0.207  0.339  0.166
  0.084  0.181  0.015  0.072 -0.028 -0.296 -0.41   0.24  -0.254  0.123
  0.011 -0.021  0.232 -0.052  0.26  -0.005 -0.384 -0.316  0.13  -0.175
 -0.074  0.26   0.027 -0.177  0.283 -0.083 -0.382 -0.385  0.035  0.094
 -0.137 -0.136  0.06   0.253 -0.116 -0.201  0.007 -0.168 -0.091 -0.166
 -0.169 -0.216  0.069 -0.104  0.23   0.234 -0.187  0.377  0.111 -0.029
  0.444  0.365 -0.146 -0.147  0.095  0.038 -0.042  0.038 -0.02   0.073
 -0.328  0.275  0.113  0.184  0.015  0.56  -0.178  0.074  0.5    0.013] [ 0.245  0.328  0.026 -0.433 -0.139 -0.027 -0.323  0.087 -0.167 -0.274
 -0.298  0.153  0.041  0.155 -0.022  0.055 -0.358 -0.146  0.312  0.241
 -0.161  0.349  0.088  0.222  0.058  0.038  0.096  0.11   0.194 -0.136
 -0.299 -0.022 -0.257  0.078  0.317 -0.003 -0.17   0.22  -0.593  0.265
 -0.035  0.094 -0.129  0.288 -0.034  0.101 -0.422  0.039  0.166 -0.385
  0.033  0.037  0.016  0.364 -0.231  0.156 -0.298 -0.213 -0.128 -0.378
 -0.009  0.352 -0.076  0.141  0.016  0.004 -0.074 -0.659 -0.002  0.137
 -0.486  0.148  0.011 -0.075 -0.006  0.047  0.174 -0.171  0.18  -0.166
  0.69  -0.212 -0.195  0.651 -0.09  -0.125 -0.278  0.206  0.327 -0.257
  0.057 -0.275 -0.007 -0.036 -0.056 -0.408  0.428  0.081  0.134 -0.211
 -0.41  -0.293  0.031  0.332  0.403 -0.001 -0.31  -0.133 -0.225  0.205
 -0.077 -0.148 -0.082  0.02   0.277 -0.057 -0.144  0.256  0.389  0.023
  0.114  0.441 -0.035 -0.066 -0.058 -0.109  0.195 -0.157 -0.008 -0.216
  0.382 -0.337 -0.198 -0.374  0.09  -0.329 -0.015  0.061  0.45   0.469
  0.173  0.298 -0.082  0.448 -0.198  0.213  0.016 -0.085 -0.68  -0.006
 -0.25   0.37  -0.264  0.121 -0.383 -0.096  0.12   0.374 -0.149  0.308
  0.067 -0.649 -0.046  0.643  0.378 -0.257  0.374 -0.121  0.284 -0.072
  0.089 -0.308 -0.09   0.052  0.107 -0.216  0.261 -0.19   0.137  0.343
 -0.343  0.358  0.032  0.154 -0.253  0.053  0.546  0.069 -0.338 -0.398
  0.058 -0.215 -0.092  0.027  0.497 -0.156 -0.004  0.05  -0.297 -0.027
 -0.014  0.545  0.241  0.032  0.02  -0.051 -0.195  0.163 -0.202 -0.496
  0.387  0.091  0.001  0.127 -0.174  0.072  0.216 -0.29   0.655  0.451
  0.427  0.166  0.192 -0.052 -0.662  0.021 -0.058 -0.145  0.498  0.457
 -0.07  -0.234  0.064  0.448  0.159 -0.175  0.048 -0.035  0.008 -0.198
  0.061  0.001 -0.314 -0.003  0.037 -0.204 -0.232  0.586 -0.013  0.52
  0.599 -0.409 -0.285  0.127 -0.262  0.397 -0.044  0.081  0.19   0.352
  0.568  0.38   0.206 -0.204  0.426 -0.387  0.245  0.01  -0.041  0.064
 -0.212 -0.222  0.255 -0.377  0.511 -0.404  0.304 -0.004  0.175  0.469
  0.219  0.311  0.358  0.276  0.334  0.451  0.23   0.298 -0.031 -0.419
 -0.001 -0.13   0.247  0.097 -0.141  0.055 -0.019 -0.23  -0.403  0.184] [ 0.152  0.508  0.125  0.069 -0.497 -0.161  0.446 -0.629  0.386  0.075
 -0.202 -0.012  0.083 -0.144  0.123 -0.37   0.122  0.299  0.161 -0.211
 -0.036 -0.12   0.063  0.085 -0.043 -0.239 -0.239  0.117 -0.    -0.124
  0.083 -0.164 -0.164 -0.192  0.1    0.339 -0.135  0.236 -0.285  0.48
 -0.537  0.087 -0.311 -0.013  0.115 -0.493 -0.194 -0.237  0.245 -0.26
  0.074  0.318 -0.263  0.003 -0.539  0.566  0.075  0.125 -0.315  0.455
 -0.052  0.38   0.545 -0.091  0.106  0.424 -0.068 -0.49  -0.111  0.018
 -0.186 -0.433 -0.295  0.108 -0.099  0.205 -0.26  -0.337  0.146 -0.268
  0.198 -0.357  0.081  0.399 -0.089 -0.544 -0.27  -0.129  0.065 -0.059
 -0.256 -0.37  -0.269  0.261 -0.415  0.023  0.186  0.717 -0.071  0.284
  0.18  -0.192 -0.01  -0.161 -0.109 -0.418 -0.13   0.202 -0.316  0.149
 -0.149  0.38  -0.44  -0.096 -0.309 -0.096 -0.148  0.271 -0.041  0.08
 -0.403 -0.063  0.406 -0.424  0.079 -0.037  0.529  0.01   0.335 -0.085
 -0.382 -0.25  -0.213  0.349 -0.151  0.048  0.216  0.141  0.09   0.272
 -0.025  0.199 -0.085 -0.276 -0.187  0.207  0.268 -0.209 -0.332 -0.101
 -0.405  0.218 -0.444 -0.063  0.189  0.055  0.113 -0.011 -0.344 -0.135
  0.515 -0.405 -0.228  0.03  -0.213 -0.063 -0.062  0.167 -0.089 -0.07
 -0.396  0.35   0.553  0.17   0.23   0.112 -0.431 -0.357 -0.023  0.159
  0.5   -0.281 -0.141  0.421  0.027 -0.261  0.389 -0.286 -0.119  0.057
  0.023  0.14  -0.128 -0.016 -0.103  0.002  0.107  0.131 -0.322  0.452
 -0.38   0.247 -0.209 -0.144  0.125 -0.363  0.062 -0.153 -0.164  0.225
 -0.061 -0.418 -0.31  -0.385  0.499  0.328  0.065 -0.098  0.477  0.451
  0.051  0.18   0.343  0.237 -0.217 -0.025 -0.564 -0.31   0.119  0.04
  0.003  0.081 -0.676  0.199  0.095 -0.472 -0.271  0.484 -0.351 -0.119
  0.084 -0.188  0.341 -0.285  0.058 -0.003 -0.279 -0.186  0.279 -0.337
  0.071 -0.156  0.191 -0.424 -0.013 -0.183  0.447 -0.541 -0.219 -0.386
 -0.016  0.339  0.208 -0.105 -0.441  0.249 -0.321  0.295 -0.111 -0.343
 -0.041 -0.214  0.079 -0.165  0.228 -0.103  0.16  -0.308  0.354 -0.587
 -0.172 -0.375 -0.01   0.388  0.297  0.095 -0.169 -0.019 -0.21   0.09
 -0.311  0.19   0.152 -0.29   0.011  0.153  0.045  0.058 -0.108  0.362] [ 0.304  1.016  0.25   0.138 -0.994 -0.322  0.892 -1.258  0.772  0.15
 -0.404 -0.024  0.166 -0.288  0.246 -0.74   0.244  0.598  0.322 -0.422
 -0.072 -0.24   0.126  0.17  -0.086 -0.478 -0.478  0.234 -0.    -0.248
  0.166 -0.328 -0.328 -0.384  0.2    0.678 -0.27   0.472 -0.57   0.96
 -1.074  0.174 -0.622 -0.026  0.23  -0.986 -0.388 -0.474  0.49  -0.52
  0.148  0.636 -0.526  0.006 -1.078  1.132  0.15   0.25  -0.63   0.91
 -0.104  0.76   1.09  -0.182  0.212  0.848 -0.136 -0.98  -0.222  0.036
 -0.372 -0.866 -0.59   0.216 -0.198  0.41  -0.52  -0.674  0.292 -0.536
  0.396 -0.714  0.162  0.798 -0.178 -1.088 -0.54  -0.258  0.13  -0.118
 -0.512 -0.74  -0.538  0.522 -0.83   0.046  0.372  1.434 -0.142  0.568
  0.36  -0.384 -0.02  -0.322 -0.218 -0.836 -0.26   0.404 -0.632  0.298
 -0.298  0.76  -0.88  -0.192 -0.618 -0.192 -0.296  0.542 -0.082  0.16
 -0.806 -0.126  0.812 -0.848  0.158 -0.074  1.058  0.02   0.67  -0.17
 -0.764 -0.5   -0.426  0.698 -0.302  0.096  0.432  0.282  0.18   0.544
 -0.05   0.398 -0.17  -0.552 -0.374  0.414  0.536 -0.418 -0.664 -0.202
 -0.81   0.436 -0.888 -0.126  0.378  0.11   0.226 -0.022 -0.688 -0.27
  1.03  -0.81  -0.456  0.06  -0.426 -0.126 -0.124  0.334 -0.178 -0.14
 -0.792  0.7    1.106  0.34   0.46   0.224 -0.862 -0.714 -0.046  0.318
  1.    -0.562 -0.282  0.842  0.054 -0.522  0.778 -0.572 -0.238  0.114
  0.046  0.28  -0.256 -0.032 -0.206  0.004  0.214  0.262 -0.644  0.904
 -0.76   0.494 -0.418 -0.288  0.25  -0.726  0.124 -0.306 -0.328  0.45
 -0.122 -0.836 -0.62  -0.77   0.998  0.656  0.13  -0.196  0.954  0.902
  0.102  0.36   0.686  0.474 -0.434 -0.05  -1.128 -0.62   0.238  0.08
  0.006  0.162 -1.352  0.398  0.19  -0.944 -0.542  0.968 -0.702 -0.238
  0.168 -0.376  0.682 -0.57   0.116 -0.006 -0.558 -0.372  0.558 -0.674
  0.142 -0.312  0.382 -0.848 -0.026 -0.366  0.894 -1.082 -0.438 -0.772
 -0.032  0.678  0.416 -0.21  -0.882  0.498 -0.642  0.59  -0.222 -0.686
 -0.082 -0.428  0.158 -0.33   0.456 -0.206  0.32  -0.616  0.708 -1.174
 -0.344 -0.75  -0.02   0.776  0.594  0.19  -0.338 -0.038 -0.42   0.18
 -0.622  0.38   0.304 -0.58   0.022  0.306  0.09   0.116 -0.216  0.724] [ 2.210e-01 -2.830e-01  3.180e-01  1.000e-02 -6.470e-01  1.180e-01
 -1.077e+00  2.190e-01 -6.010e-01  1.180e-01  4.790e-01 -6.490e-01
 -4.580e-01  7.200e-01 -2.070e-01 -5.160e-01 -2.380e-01 -3.660e-01
  2.440e-01 -2.640e-01  2.320e-01 -2.010e-01  5.510e-01  8.860e-01
  9.980e-01 -5.780e-01  4.530e-01 -8.040e-01 -2.650e-01 -9.900e-02
  8.630e-01 -2.910e-01  4.150e-01 -3.770e-01  1.330e-01  8.130e-01
  8.700e-02  7.500e-01  4.470e-01 -1.810e-01 -6.610e-01  7.460e-01
  6.900e-02  1.078e+00 -6.600e-01 -9.300e-01 -9.500e-02 -1.430e-01
 -7.310e-01  7.400e-02  3.390e-01 -6.500e-01  2.960e-01  2.450e-01
 -8.200e-02  3.350e-01  7.900e-02 -1.290e-01  7.720e-01 -3.420e-01
  6.440e-01 -1.390e-01  3.750e-01  2.160e-01 -2.490e-01  5.310e-01
  4.980e-01  2.200e-02 -2.610e-01 -5.990e-01 -5.470e-01 -7.200e-02
 -1.080e-01  6.130e-01  3.880e-01  3.900e-01  6.380e-01  1.630e-01
 -3.830e-01  3.000e-03  1.130e-01 -2.970e-01  6.280e-01 -3.560e-01
 -3.090e-01  7.180e-01 -2.020e-01 -6.300e-02 -8.000e-02 -4.600e-02
  2.410e-01  7.270e-01 -2.740e-01 -6.450e-01  8.550e-01  1.990e-01
  3.350e-01  1.031e+00 -1.000e-01 -4.600e-02 -3.400e-01  1.460e-01
  2.040e-01  4.110e-01 -6.510e-01 -3.440e-01  3.350e-01 -5.240e-01
 -5.130e-01  5.960e-01 -4.050e-01  4.480e-01 -1.321e+00  1.690e-01
  2.420e-01  1.680e-01  6.960e-01  4.340e-01  5.140e-01 -4.950e-01
  1.235e+00 -7.770e-01  1.012e+00 -4.200e-01  2.580e-01  3.810e-01
 -1.046e+00  7.320e-01  2.240e-01  3.900e-02  6.790e-01 -1.400e-02
 -5.350e-01  6.800e-02  2.620e-01 -3.220e-01 -1.180e-01 -6.420e-01
 -3.560e-01  1.500e-01  5.640e-01 -1.940e-01  3.330e-01 -4.380e-01
 -3.040e-01  2.760e-01  4.090e-01 -4.760e-01 -1.000e-01 -1.350e-01
 -2.870e-01 -4.490e-01 -4.280e-01 -2.740e-01 -4.900e-02  1.040e-01
  1.030e-01 -5.600e-02 -9.990e-01  2.950e-01  6.100e-02  4.500e-02
 -5.300e-02 -6.440e-01  1.810e-01  5.090e-01 -2.990e-01  1.980e-01
  3.080e-01 -1.960e-01 -5.520e-01 -9.000e-02 -2.990e-01  3.190e-01
  3.170e-01  7.590e-01 -5.340e-01  3.980e-01 -7.460e-01  2.050e-01
  4.470e-01  2.720e-01  5.900e-02 -1.350e-01 -1.820e-01 -2.920e-01
  1.360e-01 -9.500e-02  3.050e-01  1.000e-03  4.580e-01  2.500e-02
 -1.850e-01  3.890e-01 -3.000e-03  7.300e-01  4.950e-01  4.350e-01
  5.640e-01 -3.340e-01 -4.920e-01  1.440e-01  7.410e-01 -3.020e-01
  4.000e-01 -4.670e-01  0.000e+00 -7.000e-02  1.950e-01  1.400e-02
  3.470e-01  3.820e-01  3.840e-01 -7.810e-01  2.930e-01 -5.830e-01
 -5.440e-01 -1.900e-01 -5.350e-01  3.680e-01  2.720e-01 -4.080e-01
  2.670e-01 -8.500e-02  4.400e-02  1.960e-01  7.800e-02  1.251e+00
 -1.260e-01 -6.800e-02  3.030e-01  1.770e-01  2.420e-01  4.180e-01
  2.140e-01  2.510e-01  3.310e-01  1.900e-02 -1.810e-01 -8.290e-01
  2.360e-01  1.600e-02  2.540e-01 -7.900e-02  6.000e-03  3.970e-01
  9.510e-01  6.050e-01 -6.070e-01  3.800e-02  4.920e-01 -6.290e-01
 -2.230e-01 -3.690e-01 -5.100e-02  6.250e-01 -4.000e-03 -5.520e-01
 -7.710e-01  5.100e-02  1.191e+00 -1.062e+00  1.860e-01  3.500e-02
 -5.320e-01 -1.010e-01 -6.560e-01  4.830e-01 -4.050e-01  2.020e-01
  4.710e-01  3.730e-01  9.300e-02 -6.100e-01 -2.720e-01  3.150e-01
 -5.050e-01 -1.060e-01  4.500e-02  6.900e-02 -6.800e-02  3.480e-01
  4.900e-02 -5.500e-02  5.880e-01 -5.370e-01 -3.010e-01  1.310e-01
  3.800e-02  3.590e-01 -3.990e-01  2.700e-01  4.910e-01  1.680e-01
  2.000e-01  2.780e-01 -8.200e-02 -1.450e-01  2.590e-01  4.720e-01] [ 1.190e-01 -3.600e-02  4.260e-01  1.670e-01 -4.560e-01  9.120e-01
  4.560e-01  4.570e-01 -2.290e-01 -6.000e-01  5.300e-02  2.450e-01
  5.470e-01  3.000e-03 -2.830e-01  3.600e-01 -3.530e-01  2.210e-01
  1.000e-03  7.590e-01  2.920e-01 -8.700e-02  3.590e-01  3.780e-01
 -4.060e-01 -8.240e-01  4.610e-01  3.930e-01 -1.960e-01  2.710e-01
  4.740e-01 -1.390e-01  1.024e+00 -3.140e-01 -3.850e-01  9.200e-02
 -5.610e-01 -3.530e-01  1.660e-01 -1.250e-01 -1.940e-01  1.269e+00
 -4.430e-01 -9.900e-02 -6.960e-01  2.330e-01  3.490e-01 -4.220e-01
  3.110e-01  7.080e-01  1.730e-01  9.060e-01  1.500e-02 -3.180e-01
 -5.150e-01 -2.720e-01 -6.400e-01  1.000e-03  3.720e-01  3.370e-01
 -1.400e+00  1.000e-02 -3.710e-01 -8.500e-02 -6.140e-01 -5.000e-01
  3.390e-01  4.000e-02 -3.650e-01  7.770e-01  4.120e-01  2.020e-01
  1.770e-01 -2.840e-01 -3.290e-01  1.368e+00 -1.360e-01  1.690e-01
  1.170e-01 -3.100e-02  7.470e-01 -2.580e-01 -1.570e-01  4.620e-01
 -2.900e-02 -5.010e-01 -3.540e-01 -3.670e-01 -1.990e-01 -1.120e-01
  4.600e-02  5.070e-01 -2.260e-01  5.600e-02  4.700e-02 -4.150e-01
  4.010e-01  1.170e-01  4.550e-01  2.120e-01  3.450e-01  2.290e-01
  9.820e-01 -5.950e-01 -1.830e-01 -3.510e-01  6.360e-01  5.420e-01
 -6.650e-01  6.400e-01 -8.110e-01 -4.480e-01  1.690e-01  6.060e-01
  4.080e-01  6.260e-01  2.660e-01 -3.940e-01 -1.250e-01  3.200e-01
  3.660e-01 -3.640e-01  2.280e-01 -1.550e-01 -4.550e-01  4.680e-01
 -4.770e-01 -3.500e-02  4.460e-01 -3.730e-01 -5.650e-01 -6.030e-01
  8.380e-01  4.600e-01 -7.200e-02 -3.480e-01 -2.260e-01  4.000e-03
 -2.870e-01  3.300e-02 -2.890e-01 -3.730e-01  6.560e-01  1.600e-02
 -6.680e-01  1.200e-01 -8.900e-02 -1.310e-01 -2.730e-01 -6.600e-02
 -4.160e-01  6.760e-01 -4.670e-01  3.310e-01  3.060e-01  3.210e-01
  2.100e-01 -2.380e-01 -7.860e-01  4.940e-01 -2.170e-01  3.670e-01
 -1.260e-01 -2.040e-01  1.400e-02 -4.500e-02  8.610e-01  6.050e-01
 -5.100e-02  2.210e-01  1.120e-01 -2.930e-01 -6.300e-01 -2.690e-01
  3.920e-01  2.530e-01 -2.310e-01 -2.820e-01  3.830e-01  2.020e-01
  2.220e-01  1.010e+00  1.900e-01  8.400e-02  7.460e-01 -6.370e-01
 -3.620e-01 -6.040e-01 -7.680e-01  4.400e-02  3.820e-01 -1.570e-01
  4.670e-01 -3.590e-01  6.100e-01 -6.840e-01 -1.510e-01  3.250e-01
  1.970e-01 -2.410e-01  5.700e-02  1.840e-01 -2.520e-01  2.530e-01
  5.800e-01 -6.700e-02 -9.240e-01 -2.920e-01 -8.900e-02 -6.630e-01
 -4.140e-01 -4.360e-01  1.620e-01 -8.040e-01  3.830e-01 -2.800e-02
  3.670e-01 -2.050e-01 -5.430e-01  1.560e-01  9.310e-01 -1.310e-01
  5.950e-01  1.270e-01 -5.830e-01  6.540e-01 -1.480e-01  2.980e-01
  3.810e-01  1.340e-01  9.000e-02  1.730e-01  2.200e-01  1.890e-01
  4.510e-01 -9.320e-01 -4.300e-02  3.910e-01  2.490e-01  1.900e-01
 -2.470e-01  6.520e-01  7.200e-02  1.700e-01 -5.820e-01  4.410e-01
 -6.140e-01  6.500e-01  2.060e-01  3.020e-01  1.110e-01  3.310e-01
 -1.870e-01 -1.040e-01  1.240e-01 -4.760e-01  1.290e-01  2.870e-01
 -3.240e-01 -2.470e-01 -3.070e-01  4.500e-02  1.770e-01 -4.800e-02
  2.060e-01 -2.000e-01  3.720e-01 -4.870e-01 -1.140e-01 -7.350e-01
  4.000e-02 -1.720e-01  4.010e-01 -7.110e-01  4.900e-01  5.480e-01
  4.250e-01 -4.470e-01  6.780e-01  2.740e-01 -3.400e-02  2.330e-01
  6.600e-02 -5.230e-01  5.980e-01 -1.100e-02 -5.900e-02 -3.500e-02
  1.810e-01 -9.600e-02 -9.000e-03 -4.640e-01  1.670e-01  1.820e-01
  4.380e-01  2.890e-01  6.260e-01  4.080e-01 -4.030e-01 -4.440e-01] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
10/09/2021 09:17:25 - INFO - data_loader -   *** Example ***
10/09/2021 09:17:25 - INFO - data_loader -   guid: test-4
10/09/2021 09:17:25 - INFO - data_loader -   tokens: [CLS] no flash th ##resh [SEP]
10/09/2021 09:17:25 - INFO - data_loader -   input_ids: 101 2053 5956 16215 21898 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 09:17:25 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 09:17:25 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 09:17:25 - INFO - data_loader -   intent_label: 4 (id = 4)
10/09/2021 09:17:25 - INFO - data_loader -   slot_labels: 0 4 6 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/09/2021 09:17:25 - INFO - data_loader -   ner_embeds: [ 1.920e-01  3.000e-02 -5.410e-01 -2.490e-01  8.700e-02 -4.460e-01
  3.700e-01  4.680e-01 -1.500e-02 -3.350e-01  8.400e-02  2.480e-01
 -1.150e-01 -2.240e-01 -1.040e-01 -2.340e-01 -4.870e-01  4.340e-01
 -1.940e-01 -4.700e-02  2.050e-01 -2.130e-01 -3.940e-01  4.730e-01
 -4.530e-01  3.110e-01 -1.390e-01  5.000e-01 -2.430e-01 -6.130e-01
  6.620e-01  5.020e-01 -1.150e-01 -6.000e-02 -5.620e-01  4.210e-01
  1.010e-01 -4.600e-02  4.170e-01 -1.920e-01 -4.670e-01  4.930e-01
  4.420e-01  1.300e-02 -2.280e-01 -2.030e-01 -1.410e-01  2.710e-01
  1.180e-01 -3.380e-01  3.520e-01  2.730e-01 -4.710e-01 -5.990e-01
 -4.630e-01 -2.470e-01  4.560e-01  1.350e-01  9.400e-02  1.007e+00
  6.660e-01 -8.600e-02 -1.050e-01 -1.010e+00  4.700e-02  7.100e-02
 -6.450e-01 -5.600e-02 -6.300e-02  1.000e-03  2.210e-01  1.970e-01
  2.000e-03  3.970e-01  5.380e-01  9.700e-02 -1.100e-01  6.210e-01
  3.560e-01  4.540e-01  1.090e-01 -1.180e-01  8.800e-02  1.500e-01
 -3.390e-01 -1.920e-01 -4.030e-01 -3.470e-01  2.930e-01  5.400e-02
  1.510e-01  3.640e-01  1.860e-01 -6.300e-01 -1.040e-01 -7.130e-01
  2.080e-01  4.060e-01 -3.940e-01  6.600e-02  2.450e-01  4.080e-01
  1.033e+00  2.930e-01  9.500e-02 -8.000e-03  4.320e-01 -3.220e-01
 -5.650e-01 -9.600e-02 -3.080e-01 -5.730e-01 -4.070e-01  2.750e-01
  1.480e-01 -1.800e-02  7.280e-01 -5.440e-01 -1.052e+00  1.100e-02
  5.480e-01 -1.490e-01  1.250e-01 -3.130e-01 -3.500e-02  3.750e-01
 -7.790e-01 -3.370e-01  2.200e-02 -4.770e-01 -6.280e-01  3.620e-01
  6.600e-02  1.410e-01 -2.860e-01  2.920e-01 -6.900e-02  1.100e-02
 -5.110e-01 -1.430e-01 -1.240e-01  5.520e-01 -2.400e-01 -1.520e-01
 -6.000e-03 -2.080e-01  8.300e-02 -1.270e-01 -1.990e-01 -1.500e-01
 -1.870e-01 -3.200e-02 -3.700e-02 -2.480e-01 -3.860e-01 -1.285e+00
  2.650e-01 -4.450e-01 -1.560e-01  3.110e-01  9.000e-03 -7.970e-01
 -2.300e-02 -1.270e-01 -5.870e-01  3.300e-01  4.850e-01  4.660e-01
 -6.440e-01 -3.770e-01 -2.550e-01  7.000e-03 -2.550e-01  6.240e-01
  2.890e-01 -1.080e-01 -3.260e-01  3.380e-01 -2.090e-01 -3.150e-01
  6.170e-01 -7.300e-02 -1.430e-01  3.330e-01 -1.950e-01  2.340e-01
  8.350e-01  1.350e-01 -2.530e-01  3.400e-02  5.290e-01 -2.620e-01
 -9.700e-02  2.980e-01  5.290e-01  2.400e-02 -3.210e-01  4.540e-01
 -4.950e-01  4.050e-01 -3.840e-01  4.150e-01  5.030e-01 -1.390e-01
 -2.590e-01 -1.340e-01 -7.320e-01 -2.700e-01 -1.260e-01  5.950e-01
  2.060e-01 -2.770e-01  6.900e-02 -1.018e+00 -2.200e-02  2.900e-02
 -2.990e-01  3.420e-01 -3.030e-01 -8.000e-02  7.420e-01 -3.800e-02
  1.460e-01 -3.710e-01 -7.460e-01 -4.520e-01 -1.200e-02  2.840e-01
  3.180e-01 -7.600e-01 -2.800e-01 -1.160e-01  6.600e-02  4.190e-01
 -2.280e-01  1.480e-01 -5.000e-02  3.200e-01 -9.700e-02 -4.520e-01
  7.450e-01 -9.400e-02  7.330e-01 -4.370e-01  4.890e-01 -3.090e-01
  2.210e-01 -3.140e-01 -2.210e-01 -7.700e-01  7.300e-02  5.160e-01
  7.950e-01 -4.280e-01  2.950e-01 -5.410e-01  5.650e-01 -3.180e-01
 -3.050e-01 -3.640e-01 -5.400e-02 -9.980e-01 -4.050e-01 -3.300e-01
 -2.520e-01 -4.550e-01 -1.160e-01  1.400e-02  6.800e-02 -6.900e-02
 -8.400e-02  2.220e-01  4.010e-01 -6.300e-02  1.850e-01  6.600e-01
  1.520e-01 -9.000e-03  6.190e-01 -3.460e-01  7.700e-02 -8.500e-02
  6.600e-02  5.580e-01  2.950e-01 -2.670e-01 -2.700e-01 -7.500e-02
  1.600e-01 -4.590e-01 -4.390e-01 -2.710e-01  4.490e-01  3.450e-01
 -2.730e-01 -4.570e-01  2.840e-01 -3.900e-02 -2.000e-03  8.700e-02] [ 0.006  0.114 -0.266  0.01  -0.121  0.148  0.175 -0.024 -0.091  0.202
 -0.056 -0.105  0.152 -0.097 -0.027  0.245 -0.214 -0.514 -0.061  0.158
 -0.163 -0.144 -0.064  0.01   0.275  0.394  0.46  -0.157 -0.1   -0.04
 -0.102 -0.107  0.162  0.119 -0.015 -0.026 -0.039  0.329  0.407  0.034
 -0.197  0.123 -0.252  0.048  0.095  0.145  0.133 -0.043 -0.002 -0.136
  0.315  0.212  0.09   0.072  0.102  0.102  0.002  0.345  0.041 -0.005
 -0.106  0.057 -0.045  0.315 -0.225  0.328  0.298  0.236  0.207  0.036
 -0.19   0.064 -0.049  0.4   -0.037  0.173  0.115 -0.038  0.111 -0.434
 -0.444 -0.208 -0.132  0.022 -0.401 -0.204 -0.121  0.212 -0.29   0.248
 -0.23  -0.003  0.07  -0.13  -0.044 -0.004  0.069  0.134 -0.457 -0.07
 -0.145  0.089  0.045  0.128  0.001  0.159 -0.04  -0.08  -0.252  0.114
 -0.097  0.396 -0.312 -0.052 -0.074 -0.045  0.143  0.096  0.1    0.008
  0.388  0.18   0.303 -0.289  0.159  0.395  0.257 -0.025 -0.039 -0.317
 -0.16  -0.183  0.098 -0.303  0.081 -0.391 -0.168 -0.186  0.354  0.084
 -0.242  0.136  0.4   -0.123  0.088  0.134  0.069  0.049  0.133  0.313
  0.27   0.146 -0.013  0.049 -0.209 -0.387  0.263 -0.007 -0.399  0.008
  0.132  0.031  0.1    0.107  0.323  0.082 -0.046 -0.478  0.111 -0.166
  0.173  0.042 -0.298 -0.003 -0.048 -0.112 -0.323 -0.107  0.071  0.188
 -0.234  0.312 -0.16   0.247 -0.03   0.036 -0.157  0.026 -0.126 -0.184
  0.261 -0.329  0.272  0.356  0.093 -0.16  -0.013 -0.178 -0.289  0.335
  0.276  0.084  0.27  -0.419 -0.052 -0.189 -0.253  0.192  0.079 -0.108
  0.028  0.188  0.036  0.354  0.368 -0.005 -0.181  0.06  -0.105  0.124
  0.487  0.005  0.099  0.052 -0.096 -0.537  0.073 -0.201  0.443  0.094
 -0.413  0.117 -0.267  0.108  0.204 -0.235 -0.366  0.198 -0.157 -0.629
 -0.202  0.067  0.042 -0.183 -0.069  0.129  0.008 -0.026  0.011 -0.099
  0.441  0.284 -0.051  0.011 -0.027 -0.099 -0.213 -0.061 -0.029 -0.099
  0.197 -0.095  0.224  0.086 -0.283  0.139 -0.227 -0.084 -0.337 -0.246
  0.055  0.034 -0.141 -0.45  -0.253  0.239 -0.178 -0.073 -0.031 -0.15
  0.236  0.238  0.039  0.111  0.171  0.14  -0.077  0.042 -0.406 -0.064
  0.02   0.246  0.087 -0.245 -0.15   0.29   0.228 -0.056  0.007  0.037] [ 0.251  0.132  0.483 -0.087 -0.362  0.364  0.066 -0.111  0.228 -0.012
 -0.112 -0.235  0.107 -0.296  0.219  0.032  0.145 -0.263  0.007 -0.179
  0.146  0.202 -0.411  0.308 -0.181 -0.608 -0.303  0.01  -0.508 -0.367
 -0.141 -0.022  0.154  0.432 -0.294  0.16  -0.234  0.201  0.168  0.518
 -0.199  0.058 -0.249  0.169 -0.296 -0.596  0.34  -0.29  -0.412  0.027
 -0.055  0.059  0.22   0.09   0.314  0.191  0.261 -0.065  0.298 -0.018
 -0.224  0.403 -0.015  0.016 -0.297  0.322  0.223 -0.545  0.103 -0.488
  0.258  0.089 -0.187  0.064  0.365 -0.005  0.422  0.086  0.079 -0.276
  0.054 -0.242 -0.102 -0.225 -0.336 -0.01  -0.527 -0.349 -0.347  0.24
 -0.253  0.377  0.379 -0.105 -0.551  0.319  0.171  0.178  0.146  0.298
 -0.381  0.218 -0.042 -0.481 -0.444 -0.283  0.109 -0.441 -0.088 -0.067
  0.205 -0.189 -0.208 -0.183  0.595 -0.146  0.72  -0.003  0.113 -0.215
 -0.541  0.214  0.034 -0.086 -0.083 -0.201 -0.026 -0.041 -0.005 -0.613
 -0.105  0.443  0.109 -0.068  0.058 -0.429 -0.502 -0.041  0.019  0.288
 -0.356 -0.027 -0.051  0.03  -0.391  0.253 -0.124  0.113 -0.441 -0.118
  0.153  0.033 -0.106  0.232 -0.057 -0.468 -0.088  0.002 -0.251 -0.213
  0.256  0.059 -0.375  0.132 -0.052  0.055 -0.404  0.172 -0.275  0.29
  0.204  0.128  0.246  0.353  0.433 -0.007 -0.427  0.395 -0.288  0.817
  0.321  0.474 -0.244 -0.033 -0.22  -0.282 -0.346 -0.355  0.412 -0.595
 -0.078  0.121 -0.323  0.201  0.014 -0.202 -0.244  0.208 -0.159  0.197
 -0.355  0.101 -0.108 -0.141  0.255  0.345  0.202 -0.313 -0.396  0.01
  0.223 -0.2   -0.222  0.093  0.498 -0.433  0.024  0.171  0.017  0.071
  0.059  0.35  -0.218  0.46   0.12  -0.098 -0.01   0.231  0.304  0.14
  0.035  0.065  0.027 -0.322  0.069 -0.623 -0.149  0.498 -0.484  0.201
  0.772  0.013  0.522 -0.085 -0.392  0.13  -0.26   0.068 -0.235 -0.561
  0.247  0.196  0.021 -0.076  0.486 -0.001  0.425 -0.25   0.49  -0.022
 -0.02   0.336 -0.003 -0.27  -0.511  0.157 -0.011 -0.224 -0.145 -0.138
  0.001 -0.094  0.031  0.215 -0.182 -0.174 -0.065  0.272  0.035 -0.206
 -0.418  0.62   0.053  0.481  0.07  -0.336  0.16   0.072 -0.18  -0.286
 -0.058  0.241 -0.077 -0.27   0.428  0.291  0.154 -0.212  0.27  -0.039] [-0.153  0.06  -0.283 -0.047 -0.245  0.433  0.068 -0.181 -0.205  0.086
  0.045  0.005 -0.156 -0.101  0.334  0.24   0.146  0.12  -0.11   0.165
  0.065  0.325  0.06  -0.197  0.311 -0.29   0.278  0.311 -0.251 -0.089
 -0.272  0.003  0.15   0.054 -0.453  0.105 -0.263  0.349 -0.148  0.113
 -0.381  0.37  -0.243 -0.519 -0.487 -0.456  0.502  0.25   0.069  0.202
 -0.186 -0.24   0.227 -0.581 -0.5    0.251  0.068 -0.096  0.094 -0.07
 -0.294 -0.132 -0.365 -0.359  0.062  0.082  0.215 -0.036 -0.593 -0.059
 -0.048  0.032 -0.744 -0.036  0.311 -0.001 -0.359  0.197  0.141 -0.049
  0.627 -0.435  0.517  0.297 -0.415 -0.164 -0.171  0.35  -0.38  -0.116
 -0.179 -0.211 -0.77  -0.214 -0.006 -0.637  0.397  0.536 -0.261  0.194
  0.122 -0.055  0.49  -0.432  0.202 -0.075 -0.443 -0.238  0.692  0.203
  0.357 -0.321 -0.355  0.016 -0.154 -0.409  0.128 -0.341 -0.524  0.118
  0.251  0.08   0.274 -0.117  0.175 -0.064  0.1    0.219  0.047 -0.082
 -0.102  0.196  0.307  0.003  0.223  0.147 -0.141 -0.505  0.167  0.018
 -0.062  0.065 -0.129  0.221  0.027 -0.159  0.225 -0.14  -0.371 -0.218
  0.069 -0.014  0.224  0.065  0.195 -0.17   0.187  0.11  -0.53  -0.326
  0.033 -0.012  0.227  0.238  0.532  0.231 -0.001  0.663 -0.139  0.038
  0.26   0.473 -0.27   0.059  0.013 -0.065 -0.26  -0.14  -0.074  0.153
 -0.403 -0.366 -0.623  0.123 -0.047  0.326  0.111  0.051  0.144 -0.032
  0.053 -0.145 -0.143  0.554 -0.08   0.217  0.635 -0.074  0.071  0.381
  0.323  0.227 -0.246 -0.022  0.188  0.539  0.219  0.159  0.197  0.011
  0.239 -0.098  0.109 -0.294  0.279 -0.125 -0.4    0.242  0.341  0.226
  0.225 -0.219  0.05   0.239 -0.499  0.249  0.016 -0.042  0.076  0.182
 -0.179  0.063 -0.309 -0.373  0.176  0.352  0.186  0.293  0.113 -0.173
  0.222 -0.05  -0.053 -0.204 -0.47   0.019  0.062 -0.2    0.232 -0.387
 -0.283  0.305  0.044 -0.065  0.086  0.121  0.31  -0.352 -0.472  0.034
 -0.057 -0.21  -0.039  0.471 -0.233 -0.164 -0.372  0.261  0.166  0.028
 -0.454 -0.433 -0.007  0.101 -0.005  0.128  0.406  0.179  0.041 -0.229
 -0.237  0.208  0.541  0.339  0.422 -0.309 -0.074  0.165 -0.58  -0.015
 -0.4    0.239 -0.605  0.015  0.554  0.23  -0.205 -0.255 -0.165 -0.085] [-0.306  0.12  -0.566 -0.094 -0.49   0.866  0.136 -0.362 -0.41   0.172
  0.09   0.01  -0.312 -0.202  0.668  0.48   0.292  0.24  -0.22   0.33
  0.13   0.65   0.12  -0.394  0.622 -0.58   0.556  0.622 -0.502 -0.178
 -0.544  0.006  0.3    0.108 -0.906  0.21  -0.526  0.698 -0.296  0.226
 -0.762  0.74  -0.486 -1.038 -0.974 -0.912  1.004  0.5    0.138  0.404
 -0.372 -0.48   0.454 -1.162 -1.     0.502  0.136 -0.192  0.188 -0.14
 -0.588 -0.264 -0.73  -0.718  0.124  0.164  0.43  -0.072 -1.186 -0.118
 -0.096  0.064 -1.488 -0.072  0.622 -0.002 -0.718  0.394  0.282 -0.098
  1.254 -0.87   1.034  0.594 -0.83  -0.328 -0.342  0.7   -0.76  -0.232
 -0.358 -0.422 -1.54  -0.428 -0.012 -1.274  0.794  1.072 -0.522  0.388
  0.244 -0.11   0.98  -0.864  0.404 -0.15  -0.886 -0.476  1.384  0.406
  0.714 -0.642 -0.71   0.032 -0.308 -0.818  0.256 -0.682 -1.048  0.236
  0.502  0.16   0.548 -0.234  0.35  -0.128  0.2    0.438  0.094 -0.164
 -0.204  0.392  0.614  0.006  0.446  0.294 -0.282 -1.01   0.334  0.036
 -0.124  0.13  -0.258  0.442  0.054 -0.318  0.45  -0.28  -0.742 -0.436
  0.138 -0.028  0.448  0.13   0.39  -0.34   0.374  0.22  -1.06  -0.652
  0.066 -0.024  0.454  0.476  1.064  0.462 -0.002  1.326 -0.278  0.076
  0.52   0.946 -0.54   0.118  0.026 -0.13  -0.52  -0.28  -0.148  0.306
 -0.806 -0.732 -1.246  0.246 -0.094  0.652  0.222  0.102  0.288 -0.064
  0.106 -0.29  -0.286  1.108 -0.16   0.434  1.27  -0.148  0.142  0.762
  0.646  0.454 -0.492 -0.044  0.376  1.078  0.438  0.318  0.394  0.022
  0.478 -0.196  0.218 -0.588  0.558 -0.25  -0.8    0.484  0.682  0.452
  0.45  -0.438  0.1    0.478 -0.998  0.498  0.032 -0.084  0.152  0.364
 -0.358  0.126 -0.618 -0.746  0.352  0.704  0.372  0.586  0.226 -0.346
  0.444 -0.1   -0.106 -0.408 -0.94   0.038  0.124 -0.4    0.464 -0.774
 -0.566  0.61   0.088 -0.13   0.172  0.242  0.62  -0.704 -0.944  0.068
 -0.114 -0.42  -0.078  0.942 -0.466 -0.328 -0.744  0.522  0.332  0.056
 -0.908 -0.866 -0.014  0.202 -0.01   0.256  0.812  0.358  0.082 -0.458
 -0.474  0.416  1.082  0.678  0.844 -0.618 -0.148  0.33  -1.16  -0.03
 -0.8    0.478 -1.21   0.03   1.108  0.46  -0.41  -0.51  -0.33  -0.17 ] [ 1.190e-01 -3.600e-02  4.260e-01  1.670e-01 -4.560e-01  9.120e-01
  4.560e-01  4.570e-01 -2.290e-01 -6.000e-01  5.300e-02  2.450e-01
  5.470e-01  3.000e-03 -2.830e-01  3.600e-01 -3.530e-01  2.210e-01
  1.000e-03  7.590e-01  2.920e-01 -8.700e-02  3.590e-01  3.780e-01
 -4.060e-01 -8.240e-01  4.610e-01  3.930e-01 -1.960e-01  2.710e-01
  4.740e-01 -1.390e-01  1.024e+00 -3.140e-01 -3.850e-01  9.200e-02
 -5.610e-01 -3.530e-01  1.660e-01 -1.250e-01 -1.940e-01  1.269e+00
 -4.430e-01 -9.900e-02 -6.960e-01  2.330e-01  3.490e-01 -4.220e-01
  3.110e-01  7.080e-01  1.730e-01  9.060e-01  1.500e-02 -3.180e-01
 -5.150e-01 -2.720e-01 -6.400e-01  1.000e-03  3.720e-01  3.370e-01
 -1.400e+00  1.000e-02 -3.710e-01 -8.500e-02 -6.140e-01 -5.000e-01
  3.390e-01  4.000e-02 -3.650e-01  7.770e-01  4.120e-01  2.020e-01
  1.770e-01 -2.840e-01 -3.290e-01  1.368e+00 -1.360e-01  1.690e-01
  1.170e-01 -3.100e-02  7.470e-01 -2.580e-01 -1.570e-01  4.620e-01
 -2.900e-02 -5.010e-01 -3.540e-01 -3.670e-01 -1.990e-01 -1.120e-01
  4.600e-02  5.070e-01 -2.260e-01  5.600e-02  4.700e-02 -4.150e-01
  4.010e-01  1.170e-01  4.550e-01  2.120e-01  3.450e-01  2.290e-01
  9.820e-01 -5.950e-01 -1.830e-01 -3.510e-01  6.360e-01  5.420e-01
 -6.650e-01  6.400e-01 -8.110e-01 -4.480e-01  1.690e-01  6.060e-01
  4.080e-01  6.260e-01  2.660e-01 -3.940e-01 -1.250e-01  3.200e-01
  3.660e-01 -3.640e-01  2.280e-01 -1.550e-01 -4.550e-01  4.680e-01
 -4.770e-01 -3.500e-02  4.460e-01 -3.730e-01 -5.650e-01 -6.030e-01
  8.380e-01  4.600e-01 -7.200e-02 -3.480e-01 -2.260e-01  4.000e-03
 -2.870e-01  3.300e-02 -2.890e-01 -3.730e-01  6.560e-01  1.600e-02
 -6.680e-01  1.200e-01 -8.900e-02 -1.310e-01 -2.730e-01 -6.600e-02
 -4.160e-01  6.760e-01 -4.670e-01  3.310e-01  3.060e-01  3.210e-01
  2.100e-01 -2.380e-01 -7.860e-01  4.940e-01 -2.170e-01  3.670e-01
 -1.260e-01 -2.040e-01  1.400e-02 -4.500e-02  8.610e-01  6.050e-01
 -5.100e-02  2.210e-01  1.120e-01 -2.930e-01 -6.300e-01 -2.690e-01
  3.920e-01  2.530e-01 -2.310e-01 -2.820e-01  3.830e-01  2.020e-01
  2.220e-01  1.010e+00  1.900e-01  8.400e-02  7.460e-01 -6.370e-01
 -3.620e-01 -6.040e-01 -7.680e-01  4.400e-02  3.820e-01 -1.570e-01
  4.670e-01 -3.590e-01  6.100e-01 -6.840e-01 -1.510e-01  3.250e-01
  1.970e-01 -2.410e-01  5.700e-02  1.840e-01 -2.520e-01  2.530e-01
  5.800e-01 -6.700e-02 -9.240e-01 -2.920e-01 -8.900e-02 -6.630e-01
 -4.140e-01 -4.360e-01  1.620e-01 -8.040e-01  3.830e-01 -2.800e-02
  3.670e-01 -2.050e-01 -5.430e-01  1.560e-01  9.310e-01 -1.310e-01
  5.950e-01  1.270e-01 -5.830e-01  6.540e-01 -1.480e-01  2.980e-01
  3.810e-01  1.340e-01  9.000e-02  1.730e-01  2.200e-01  1.890e-01
  4.510e-01 -9.320e-01 -4.300e-02  3.910e-01  2.490e-01  1.900e-01
 -2.470e-01  6.520e-01  7.200e-02  1.700e-01 -5.820e-01  4.410e-01
 -6.140e-01  6.500e-01  2.060e-01  3.020e-01  1.110e-01  3.310e-01
 -1.870e-01 -1.040e-01  1.240e-01 -4.760e-01  1.290e-01  2.870e-01
 -3.240e-01 -2.470e-01 -3.070e-01  4.500e-02  1.770e-01 -4.800e-02
  2.060e-01 -2.000e-01  3.720e-01 -4.870e-01 -1.140e-01 -7.350e-01
  4.000e-02 -1.720e-01  4.010e-01 -7.110e-01  4.900e-01  5.480e-01
  4.250e-01 -4.470e-01  6.780e-01  2.740e-01 -3.400e-02  2.330e-01
  6.600e-02 -5.230e-01  5.980e-01 -1.100e-02 -5.900e-02 -3.500e-02
  1.810e-01 -9.600e-02 -9.000e-03 -4.640e-01  1.670e-01  1.820e-01
  4.380e-01  2.890e-01  6.260e-01  4.080e-01 -4.030e-01 -4.440e-01] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
10/09/2021 09:17:27 - INFO - data_loader -   Saving features into cached file ./data\cached_test_low_distilbert-base-uncased_50
10/09/2021 09:17:37 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-config.json from cache at C:\Users\k3lan/.cache\torch\transformers\a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.8949e27aafafa845a18d98a0e3a88bc2d248bbc32a1b75947366664658f23b1c
10/09/2021 09:17:37 - INFO - transformers.configuration_utils -   Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "finetuning_task": "low",
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 30522
}

10/09/2021 09:17:38 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/distilbert-base-uncased-pytorch_model.bin from cache at C:\Users\k3lan/.cache\torch\transformers\ae9df7a8d658c4f3e1917a471a8a21cf678fa1d4cb91e7702dfe0598dbdcf354.c2015533705b9dff680ae707e205a35e2860e8d148b45d35085419d74fe57ac5
10/09/2021 09:17:39 - WARNING - transformers.modeling_utils -   Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing JointDistilBERT: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']
- This IS expected if you are initializing JointDistilBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing JointDistilBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
10/09/2021 09:17:39 - WARNING - transformers.modeling_utils -   Some weights of JointDistilBERT were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['intent_classifier.linear.weight', 'intent_classifier.linear.bias', 'slot_classifier.linear.weight', 'slot_classifier.linear.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
True
NVIDIA GeForce RTX 2070 Super with Max-Q Design
Using device: cuda
10/09/2021 09:17:42 - INFO - trainer -   ***** Running training *****
10/09/2021 09:17:42 - INFO - trainer -     Num examples = 29358
10/09/2021 09:17:42 - INFO - trainer -     Num Epochs = 20
10/09/2021 09:17:42 - INFO - trainer -     Total train batch size = 32
10/09/2021 09:17:42 - INFO - trainer -     Gradient Accumulation steps = 1
10/09/2021 09:17:42 - INFO - trainer -     Total optimization steps = 18360
10/09/2021 09:17:42 - INFO - trainer -     Logging steps = 200
10/09/2021 09:17:42 - INFO - trainer -     Save steps = 200
Epoch:   0%|                                                                                    | 0/20 [00:00<?, ?it/s]10/09/2021 09:18:24 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 199/918 [00:40<02:27,  4.88it/s]
10/09/2021 09:18:24 - INFO - trainer -     Num examples = 3258
10/09/2021 09:18:24 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:07<00:00,  7.28it/s]
C:\Users\k3lan\anaconda3\envs\jbert\lib\site-packages\sklearn\metrics\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\k3lan\anaconda3\envs\jbert\lib\site-packages\sklearn\metrics\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\k3lan\anaconda3\envs\jbert\lib\site-packages\sklearn\metrics\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
10/09/2021 09:18:31 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:18:31 - INFO - trainer -     T-F1 = 0.951029873141454
10/09/2021 09:18:31 - INFO - trainer -     T-F1(C) = 0.8776978417266187
10/09/2021 09:18:31 - INFO - trainer -     T-F1(L) = 0.8095238095238096
10/09/2021 09:18:31 - INFO - trainer -     T-F1(O) = 0.9832474925454052
10/09/2021 09:18:31 - INFO - trainer -     T-F1(P) = 0.9891463772367263
10/09/2021 09:18:31 - INFO - trainer -     T-F1(S) = 0.9544429409111412
10/09/2021 09:18:31 - INFO - trainer -     T-F1(T) = 0.888268156424581
10/09/2021 09:18:31 - INFO - trainer -     U-F1(A) = 0.778846153846154
10/09/2021 09:18:31 - INFO - trainer -     U-F1(E) = 0.759581881533101
10/09/2021 09:18:31 - INFO - trainer -     U-F1(I) = 0.0
10/09/2021 09:18:31 - INFO - trainer -     U-F1(O) = 0.9665323287191169
10/09/2021 09:18:31 - INFO - trainer -     intent_acc = 0.9383057090239411
10/09/2021 09:18:31 - INFO - trainer -     loss = 0.2815348356962204
10/09/2021 09:18:31 - INFO - trainer -     semantic_frame_acc = 0.8606507059545734
10/09/2021 09:18:31 - INFO - trainer -     slot_f1 = 0.9484708839547549
10/09/2021 09:18:31 - INFO - trainer -     slot_precision = 0.9486033519553073
10/09/2021 09:18:31 - INFO - trainer -     slot_recall = 0.9483384529461044

10/09/2021 09:18:31 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:18:31 - INFO - trainer -     T-F1 = 0.951029873141454
10/09/2021 09:18:31 - INFO - trainer -     T-F1(C) = 0.8776978417266187
10/09/2021 09:18:31 - INFO - trainer -     T-F1(L) = 0.8095238095238096
10/09/2021 09:18:31 - INFO - trainer -     T-F1(O) = 0.9832474925454052
10/09/2021 09:18:31 - INFO - trainer -     T-F1(P) = 0.9891463772367263
10/09/2021 09:18:31 - INFO - trainer -     T-F1(S) = 0.9544429409111412
10/09/2021 09:18:31 - INFO - trainer -     T-F1(T) = 0.888268156424581
10/09/2021 09:18:31 - INFO - trainer -     U-F1(A) = 0.778846153846154
10/09/2021 09:18:31 - INFO - trainer -     U-F1(E) = 0.759581881533101
10/09/2021 09:18:31 - INFO - trainer -     U-F1(I) = 0.0
10/09/2021 09:18:31 - INFO - trainer -     U-F1(O) = 0.9665323287191169
10/09/2021 09:18:31 - INFO - trainer -     intent_acc = 0.9383057090239411
10/09/2021 09:18:31 - INFO - trainer -     semantic_frame_acc = 0.8606507059545734
10/09/2021 09:18:31 - INFO - trainer -     slot_f1 = 0.9484708839547549
10/09/2021 09:18:31 - INFO - trainer -     slot_precision = 0.9486033519553073
10/09/2021 09:18:31 - INFO - trainer -     slot_recall = 0.9483384529461044
10/09/2021 09:18:31 - INFO - transformers.configuration_utils -   Configuration saved in final_low_distilbert_e_model\config.json
10/09/2021 09:18:32 - INFO - transformers.modeling_utils -   Model weights saved in final_low_distilbert_e_model\pytorch_model.bin
10/09/2021 09:18:32 - INFO - trainer -   Saving model checkpoint to final_low_distilbert_e_model
Best model saved
                                                                                                                       10/09/2021 09:19:14 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 399/918 [01:31<01:51,  4.67it/s]
10/09/2021 09:19:14 - INFO - trainer -     Num examples = 3258
10/09/2021 09:19:14 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:07<00:00,  6.98it/s]
C:\Users\k3lan\anaconda3\envs\jbert\lib\site-packages\sklearn\metrics\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\k3lan\anaconda3\envs\jbert\lib\site-packages\sklearn\metrics\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\k3lan\anaconda3\envs\jbert\lib\site-packages\sklearn\metrics\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
10/09/2021 09:19:21 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:19:21 - INFO - trainer -     T-F1 = 0.9733912571273419
10/09/2021 09:19:21 - INFO - trainer -     T-F1(C) = 0.9245541838134431
10/09/2021 09:19:21 - INFO - trainer -     T-F1(L) = 0.9506172839506173
10/09/2021 09:19:21 - INFO - trainer -     T-F1(O) = 0.9898967952199891
10/09/2021 09:19:21 - INFO - trainer -     T-F1(P) = 0.9927092446777486
10/09/2021 09:19:21 - INFO - trainer -     T-F1(S) = 0.9774297558728697
10/09/2021 09:19:21 - INFO - trainer -     T-F1(T) = 0.9284712482468445
10/09/2021 09:19:21 - INFO - trainer -     U-F1(A) = 0.7562189054726368
10/09/2021 09:19:21 - INFO - trainer -     U-F1(E) = 0.7681660899653979
10/09/2021 09:19:21 - INFO - trainer -     U-F1(I) = 0.0
10/09/2021 09:19:21 - INFO - trainer -     U-F1(O) = 0.9663747810858144
10/09/2021 09:19:21 - INFO - trainer -     intent_acc = 0.9383057090239411
10/09/2021 09:19:21 - INFO - trainer -     loss = 0.23085283648733998
10/09/2021 09:19:21 - INFO - trainer -     semantic_frame_acc = 0.8950276243093923
10/09/2021 09:19:21 - INFO - trainer -     slot_f1 = 0.9717938029734612
10/09/2021 09:19:21 - INFO - trainer -     slot_precision = 0.9670907079646017
10/09/2021 09:19:21 - INFO - trainer -     slot_recall = 0.9765428651214745

10/09/2021 09:19:21 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:19:21 - INFO - trainer -     T-F1 = 0.951029873141454
10/09/2021 09:19:21 - INFO - trainer -     T-F1(C) = 0.8776978417266187
10/09/2021 09:19:21 - INFO - trainer -     T-F1(L) = 0.8095238095238096
10/09/2021 09:19:21 - INFO - trainer -     T-F1(O) = 0.9832474925454052
10/09/2021 09:19:21 - INFO - trainer -     T-F1(P) = 0.9891463772367263
10/09/2021 09:19:21 - INFO - trainer -     T-F1(S) = 0.9544429409111412
10/09/2021 09:19:21 - INFO - trainer -     T-F1(T) = 0.888268156424581
10/09/2021 09:19:21 - INFO - trainer -     U-F1(A) = 0.778846153846154
10/09/2021 09:19:21 - INFO - trainer -     U-F1(E) = 0.759581881533101
10/09/2021 09:19:21 - INFO - trainer -     U-F1(I) = 0.0
10/09/2021 09:19:21 - INFO - trainer -     U-F1(O) = 0.9665323287191169
10/09/2021 09:19:21 - INFO - trainer -     intent_acc = 0.9383057090239411
10/09/2021 09:19:21 - INFO - trainer -     semantic_frame_acc = 0.8606507059545734
10/09/2021 09:19:21 - INFO - trainer -     slot_f1 = 0.9484708839547549
10/09/2021 09:19:21 - INFO - trainer -     slot_precision = 0.9486033519553073
10/09/2021 09:19:21 - INFO - trainer -     slot_recall = 0.9483384529461044
                                                                                                                       10/09/2021 09:20:05 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 599/918 [02:21<01:08,  4.66it/s]
10/09/2021 09:20:05 - INFO - trainer -     Num examples = 3258
10/09/2021 09:20:05 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:07<00:00,  6.82it/s]
10/09/2021 09:20:12 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:20:12 - INFO - trainer -     T-F1 = 0.9817289337332971███████████████████| 51/51 [00:07<00:00,  6.96it/s]
10/09/2021 09:20:12 - INFO - trainer -     T-F1(C) = 0.9681159420289855
10/09/2021 09:20:12 - INFO - trainer -     T-F1(L) = 0.9757575757575757
10/09/2021 09:20:12 - INFO - trainer -     T-F1(O) = 0.9927339767921048
10/09/2021 09:20:12 - INFO - trainer -     T-F1(P) = 0.9947368421052633
10/09/2021 09:20:12 - INFO - trainer -     T-F1(S) = 0.9856014862981887
10/09/2021 09:20:12 - INFO - trainer -     T-F1(T) = 0.9257759784075573
10/09/2021 09:20:12 - INFO - trainer -     U-F1(A) = 0.7720930232558139
10/09/2021 09:20:12 - INFO - trainer -     U-F1(E) = 0.7831932773109244
10/09/2021 09:20:12 - INFO - trainer -     U-F1(I) = 0.10256410256410256
10/09/2021 09:20:12 - INFO - trainer -     U-F1(O) = 0.9662961002293983
10/09/2021 09:20:12 - INFO - trainer -     intent_acc = 0.937998772252916
10/09/2021 09:20:12 - INFO - trainer -     loss = 0.20262067151420257
10/09/2021 09:20:12 - INFO - trainer -     semantic_frame_acc = 0.9069981583793738
10/09/2021 09:20:12 - INFO - trainer -     slot_f1 = 0.9806055532300822
10/09/2021 09:20:12 - INFO - trainer -     slot_precision = 0.9799219185722253
10/09/2021 09:20:12 - INFO - trainer -     slot_recall = 0.9812901424183189

10/09/2021 09:20:12 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:20:12 - INFO - trainer -     T-F1 = 0.9817289337332971
10/09/2021 09:20:12 - INFO - trainer -     T-F1(C) = 0.9681159420289855
10/09/2021 09:20:12 - INFO - trainer -     T-F1(L) = 0.9757575757575757
10/09/2021 09:20:12 - INFO - trainer -     T-F1(O) = 0.9927339767921048
10/09/2021 09:20:12 - INFO - trainer -     T-F1(P) = 0.9947368421052633
10/09/2021 09:20:12 - INFO - trainer -     T-F1(S) = 0.9856014862981887
10/09/2021 09:20:12 - INFO - trainer -     T-F1(T) = 0.9257759784075573
10/09/2021 09:20:12 - INFO - trainer -     U-F1(A) = 0.7720930232558139
10/09/2021 09:20:12 - INFO - trainer -     U-F1(E) = 0.7831932773109244
10/09/2021 09:20:12 - INFO - trainer -     U-F1(I) = 0.10256410256410256
10/09/2021 09:20:12 - INFO - trainer -     U-F1(O) = 0.9662961002293983
10/09/2021 09:20:12 - INFO - trainer -     intent_acc = 0.937998772252916
10/09/2021 09:20:12 - INFO - trainer -     semantic_frame_acc = 0.9069981583793738
10/09/2021 09:20:12 - INFO - trainer -     slot_f1 = 0.9806055532300822
10/09/2021 09:20:12 - INFO - trainer -     slot_precision = 0.9799219185722253
10/09/2021 09:20:12 - INFO - trainer -     slot_recall = 0.9812901424183189
10/09/2021 09:20:12 - INFO - transformers.configuration_utils -   Configuration saved in final_low_distilbert_e_model\config.json
10/09/2021 09:20:13 - INFO - transformers.modeling_utils -   Model weights saved in final_low_distilbert_e_model\pytorch_model.bin
10/09/2021 09:20:13 - INFO - trainer -   Saving model checkpoint to final_low_distilbert_e_model
Best model saved
                                                                                                                       10/09/2021 09:20:56 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 799/918 [03:13<00:25,  4.67it/s]
10/09/2021 09:20:56 - INFO - trainer -     Num examples = 3258
10/09/2021 09:20:56 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:07<00:00,  6.93it/s]
C:\Users\k3lan\anaconda3\envs\jbert\lib\site-packages\sklearn\metrics\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\k3lan\anaconda3\envs\jbert\lib\site-packages\sklearn\metrics\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\k3lan\anaconda3\envs\jbert\lib\site-packages\sklearn\metrics\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
10/09/2021 09:21:04 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:21:04 - INFO - trainer -     T-F1 = 0.9806049098060491
10/09/2021 09:21:04 - INFO - trainer -     T-F1(C) = 0.9560283687943263
10/09/2021 09:21:04 - INFO - trainer -     T-F1(L) = 0.9791044776119404
10/09/2021 09:21:04 - INFO - trainer -     T-F1(O) = 0.9922295277943813
10/09/2021 09:21:04 - INFO - trainer -     T-F1(P) = 0.9947306791569086
10/09/2021 09:21:04 - INFO - trainer -     T-F1(S) = 0.9834710743801653
10/09/2021 09:21:04 - INFO - trainer -     T-F1(T) = 0.9309878213802435
10/09/2021 09:21:04 - INFO - trainer -     U-F1(A) = 0.7661691542288557
10/09/2021 09:21:04 - INFO - trainer -     U-F1(E) = 0.7715736040609137
10/09/2021 09:21:04 - INFO - trainer -     U-F1(I) = 0.0
10/09/2021 09:21:04 - INFO - trainer -     U-F1(O) = 0.9668246445497629
10/09/2021 09:21:04 - INFO - trainer -     intent_acc = 0.9389195825659914
10/09/2021 09:21:04 - INFO - trainer -     loss = 0.2065849670154207
10/09/2021 09:21:04 - INFO - trainer -     semantic_frame_acc = 0.9066912216083487
10/09/2021 09:21:04 - INFO - trainer -     slot_f1 = 0.9797222222222222
10/09/2021 09:21:04 - INFO - trainer -     slot_precision = 0.9745786128764852
10/09/2021 09:21:04 - INFO - trainer -     slot_recall = 0.9849204132923765

10/09/2021 09:21:04 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:21:04 - INFO - trainer -     T-F1 = 0.9817289337332971
10/09/2021 09:21:04 - INFO - trainer -     T-F1(C) = 0.9681159420289855
10/09/2021 09:21:04 - INFO - trainer -     T-F1(L) = 0.9757575757575757
10/09/2021 09:21:04 - INFO - trainer -     T-F1(O) = 0.9927339767921048
10/09/2021 09:21:04 - INFO - trainer -     T-F1(P) = 0.9947368421052633
10/09/2021 09:21:04 - INFO - trainer -     T-F1(S) = 0.9856014862981887
10/09/2021 09:21:04 - INFO - trainer -     T-F1(T) = 0.9257759784075573
10/09/2021 09:21:04 - INFO - trainer -     U-F1(A) = 0.7720930232558139
10/09/2021 09:21:04 - INFO - trainer -     U-F1(E) = 0.7831932773109244
10/09/2021 09:21:04 - INFO - trainer -     U-F1(I) = 0.10256410256410256
10/09/2021 09:21:04 - INFO - trainer -     U-F1(O) = 0.9662961002293983
10/09/2021 09:21:04 - INFO - trainer -     intent_acc = 0.937998772252916
10/09/2021 09:21:04 - INFO - trainer -     semantic_frame_acc = 0.9069981583793738
10/09/2021 09:21:04 - INFO - trainer -     slot_f1 = 0.9806055532300822
10/09/2021 09:21:04 - INFO - trainer -     slot_precision = 0.9799219185722253
10/09/2021 09:21:04 - INFO - trainer -     slot_recall = 0.9812901424183189
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 918/918 [03:46<00:00,  4.05it/s]
Epoch:   5%|███▋                                                                     | 1/20 [03:46<1:11:43, 226.48s/it]10/09/2021 09:21:47 - INFO - trainer -   ***** Running evaluation on dev dataset ***** | 81/918 [00:17<03:01,  4.62it/s]
10/09/2021 09:21:47 - INFO - trainer -     Num examples = 3258
10/09/2021 09:21:47 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:07<00:00,  6.83it/s]
10/09/2021 09:21:55 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:21:55 - INFO - trainer -     T-F1 = 0.9856850715746421███████████████████| 51/51 [00:07<00:00,  6.93it/s]
10/09/2021 09:21:55 - INFO - trainer -     T-F1(C) = 0.9630681818181818
10/09/2021 09:21:55 - INFO - trainer -     T-F1(L) = 0.9760479041916169
10/09/2021 09:21:55 - INFO - trainer -     T-F1(O) = 0.9943061656092402
10/09/2021 09:21:55 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:21:55 - INFO - trainer -     T-F1(S) = 0.9875747814081914
10/09/2021 09:21:55 - INFO - trainer -     T-F1(T) = 0.9575070821529744
10/09/2021 09:21:55 - INFO - trainer -     U-F1(A) = 0.7549019607843138
10/09/2021 09:21:55 - INFO - trainer -     U-F1(E) = 0.7441860465116279
10/09/2021 09:21:55 - INFO - trainer -     U-F1(I) = 0.0
10/09/2021 09:21:55 - INFO - trainer -     U-F1(O) = 0.9654088050314464
10/09/2021 09:21:55 - INFO - trainer -     intent_acc = 0.9355432780847146
10/09/2021 09:21:55 - INFO - trainer -     loss = 0.1982005332030502
10/09/2021 09:21:55 - INFO - trainer -     semantic_frame_acc = 0.9094536525475752
10/09/2021 09:21:55 - INFO - trainer -     slot_f1 = 0.9850829499512059
10/09/2021 09:21:55 - INFO - trainer -     slot_precision = 0.9835746102449888
10/09/2021 09:21:55 - INFO - trainer -     slot_recall = 0.9865959229265568

10/09/2021 09:21:55 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:21:55 - INFO - trainer -     T-F1 = 0.9817289337332971
10/09/2021 09:21:55 - INFO - trainer -     T-F1(C) = 0.9681159420289855
10/09/2021 09:21:55 - INFO - trainer -     T-F1(L) = 0.9757575757575757
10/09/2021 09:21:55 - INFO - trainer -     T-F1(O) = 0.9927339767921048
10/09/2021 09:21:55 - INFO - trainer -     T-F1(P) = 0.9947368421052633
10/09/2021 09:21:55 - INFO - trainer -     T-F1(S) = 0.9856014862981887
10/09/2021 09:21:55 - INFO - trainer -     T-F1(T) = 0.9257759784075573
10/09/2021 09:21:55 - INFO - trainer -     U-F1(A) = 0.7720930232558139
10/09/2021 09:21:55 - INFO - trainer -     U-F1(E) = 0.7831932773109244
10/09/2021 09:21:55 - INFO - trainer -     U-F1(I) = 0.10256410256410256
10/09/2021 09:21:55 - INFO - trainer -     U-F1(O) = 0.9662961002293983
10/09/2021 09:21:55 - INFO - trainer -     intent_acc = 0.937998772252916
10/09/2021 09:21:55 - INFO - trainer -     semantic_frame_acc = 0.9069981583793738
10/09/2021 09:21:55 - INFO - trainer -     slot_f1 = 0.9806055532300822
10/09/2021 09:21:55 - INFO - trainer -     slot_precision = 0.9799219185722253
10/09/2021 09:21:55 - INFO - trainer -     slot_recall = 0.9812901424183189
                                                                                                                       10/09/2021 09:22:38 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 281/918 [01:08<02:16,  4.68it/s]
10/09/2021 09:22:38 - INFO - trainer -     Num examples = 3258
10/09/2021 09:22:38 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:07<00:00,  6.84it/s]
C:\Users\k3lan\anaconda3\envs\jbert\lib\site-packages\sklearn\metrics\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\k3lan\anaconda3\envs\jbert\lib\site-packages\sklearn\metrics\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\k3lan\anaconda3\envs\jbert\lib\site-packages\sklearn\metrics\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
10/09/2021 09:22:46 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:22:46 - INFO - trainer -     T-F1 = 0.9844474761255116
10/09/2021 09:22:46 - INFO - trainer -     T-F1(C) = 0.9684813753581661
10/09/2021 09:22:46 - INFO - trainer -     T-F1(L) = 0.9734513274336283
10/09/2021 09:22:46 - INFO - trainer -     T-F1(O) = 0.9944703458744444
10/09/2021 09:22:46 - INFO - trainer -     T-F1(P) = 0.9953134153485649
10/09/2021 09:22:46 - INFO - trainer -     T-F1(S) = 0.9866543948458352
10/09/2021 09:22:46 - INFO - trainer -     T-F1(T) = 0.9461756373937676
10/09/2021 09:22:46 - INFO - trainer -     U-F1(A) = 0.7980295566502463
10/09/2021 09:22:46 - INFO - trainer -     U-F1(E) = 0.7165354330708661
10/09/2021 09:22:46 - INFO - trainer -     U-F1(I) = 0.0
10/09/2021 09:22:46 - INFO - trainer -     U-F1(O) = 0.9657320872274142
10/09/2021 09:22:46 - INFO - trainer -     intent_acc = 0.9370779619398404
10/09/2021 09:22:46 - INFO - trainer -     loss = 0.19882825382199942
10/09/2021 09:22:46 - INFO - trainer -     semantic_frame_acc = 0.9146715776550031
10/09/2021 09:22:46 - INFO - trainer -     slot_f1 = 0.9842244869468101
10/09/2021 09:22:46 - INFO - trainer -     slot_precision = 0.9840871021775545
10/09/2021 09:22:46 - INFO - trainer -     slot_recall = 0.984361910080983

10/09/2021 09:22:46 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:22:46 - INFO - trainer -     T-F1 = 0.9817289337332971
10/09/2021 09:22:46 - INFO - trainer -     T-F1(C) = 0.9681159420289855
10/09/2021 09:22:46 - INFO - trainer -     T-F1(L) = 0.9757575757575757
10/09/2021 09:22:46 - INFO - trainer -     T-F1(O) = 0.9927339767921048
10/09/2021 09:22:46 - INFO - trainer -     T-F1(P) = 0.9947368421052633
10/09/2021 09:22:46 - INFO - trainer -     T-F1(S) = 0.9856014862981887
10/09/2021 09:22:46 - INFO - trainer -     T-F1(T) = 0.9257759784075573
10/09/2021 09:22:46 - INFO - trainer -     U-F1(A) = 0.7720930232558139
10/09/2021 09:22:46 - INFO - trainer -     U-F1(E) = 0.7831932773109244
10/09/2021 09:22:46 - INFO - trainer -     U-F1(I) = 0.10256410256410256
10/09/2021 09:22:46 - INFO - trainer -     U-F1(O) = 0.9662961002293983
10/09/2021 09:22:46 - INFO - trainer -     intent_acc = 0.937998772252916
10/09/2021 09:22:46 - INFO - trainer -     semantic_frame_acc = 0.9069981583793738
10/09/2021 09:22:46 - INFO - trainer -     slot_f1 = 0.9806055532300822
10/09/2021 09:22:46 - INFO - trainer -     slot_precision = 0.9799219185722253
10/09/2021 09:22:46 - INFO - trainer -     slot_recall = 0.9812901424183189
                                                                                                                       10/09/2021 09:23:29 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 481/918 [01:59<01:35,  4.58it/s]
10/09/2021 09:23:29 - INFO - trainer -     Num examples = 3258
10/09/2021 09:23:29 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:07<00:00,  6.84it/s]
10/09/2021 09:23:37 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:23:37 - INFO - trainer -     T-F1 = 0.9908030199039122███████████████████| 51/51 [00:07<00:00,  7.01it/s]
10/09/2021 09:23:37 - INFO - trainer -     T-F1(C) = 0.9778434268833087
10/09/2021 09:23:37 - INFO - trainer -     T-F1(L) = 0.978978978978979
10/09/2021 09:23:37 - INFO - trainer -     T-F1(O) = 0.9963766156508571
10/09/2021 09:23:37 - INFO - trainer -     T-F1(P) = 0.9953106682297773
10/09/2021 09:23:37 - INFO - trainer -     T-F1(S) = 0.9949003245248029
10/09/2021 09:23:37 - INFO - trainer -     T-F1(T) = 0.9745042492917847
10/09/2021 09:23:37 - INFO - trainer -     U-F1(A) = 0.776255707762557
10/09/2021 09:23:37 - INFO - trainer -     U-F1(E) = 0.7737478411053541
10/09/2021 09:23:37 - INFO - trainer -     U-F1(I) = 0.36111111111111105
10/09/2021 09:23:37 - INFO - trainer -     U-F1(O) = 0.9645766914629826
10/09/2021 09:23:37 - INFO - trainer -     intent_acc = 0.934622467771639
10/09/2021 09:23:37 - INFO - trainer -     loss = 0.18734079226851463
10/09/2021 09:23:37 - INFO - trainer -     semantic_frame_acc = 0.9195825659914058
10/09/2021 09:23:37 - INFO - trainer -     slot_f1 = 0.9904521201909576
10/09/2021 09:23:37 - INFO - trainer -     slot_precision = 0.9960463146003954
10/09/2021 09:23:37 - INFO - trainer -     slot_recall = 0.9849204132923765

10/09/2021 09:23:37 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:23:37 - INFO - trainer -     T-F1 = 0.9908030199039122
10/09/2021 09:23:37 - INFO - trainer -     T-F1(C) = 0.9778434268833087
10/09/2021 09:23:37 - INFO - trainer -     T-F1(L) = 0.978978978978979
10/09/2021 09:23:37 - INFO - trainer -     T-F1(O) = 0.9963766156508571
10/09/2021 09:23:37 - INFO - trainer -     T-F1(P) = 0.9953106682297773
10/09/2021 09:23:37 - INFO - trainer -     T-F1(S) = 0.9949003245248029
10/09/2021 09:23:37 - INFO - trainer -     T-F1(T) = 0.9745042492917847
10/09/2021 09:23:37 - INFO - trainer -     U-F1(A) = 0.776255707762557
10/09/2021 09:23:37 - INFO - trainer -     U-F1(E) = 0.7737478411053541
10/09/2021 09:23:37 - INFO - trainer -     U-F1(I) = 0.36111111111111105
10/09/2021 09:23:37 - INFO - trainer -     U-F1(O) = 0.9645766914629826
10/09/2021 09:23:37 - INFO - trainer -     intent_acc = 0.934622467771639
10/09/2021 09:23:37 - INFO - trainer -     semantic_frame_acc = 0.9195825659914058
10/09/2021 09:23:37 - INFO - trainer -     slot_f1 = 0.9904521201909576
10/09/2021 09:23:37 - INFO - trainer -     slot_precision = 0.9960463146003954
10/09/2021 09:23:37 - INFO - trainer -     slot_recall = 0.9849204132923765
10/09/2021 09:23:37 - INFO - transformers.configuration_utils -   Configuration saved in final_low_distilbert_e_model\config.json
10/09/2021 09:23:37 - INFO - transformers.modeling_utils -   Model weights saved in final_low_distilbert_e_model\pytorch_model.bin
10/09/2021 09:23:37 - INFO - trainer -   Saving model checkpoint to final_low_distilbert_e_model
Best model saved
                                                                                                                       10/09/2021 09:24:20 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 681/918 [02:50<00:51,  4.59it/s]
10/09/2021 09:24:20 - INFO - trainer -     Num examples = 3258
10/09/2021 09:24:20 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:07<00:00,  6.82it/s]
10/09/2021 09:24:28 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:24:28 - INFO - trainer -     T-F1 = 0.9890590809628009███████████████████| 51/51 [00:07<00:00,  6.83it/s]
10/09/2021 09:24:28 - INFO - trainer -     T-F1(C) = 0.9711815561959655
10/09/2021 09:24:28 - INFO - trainer -     T-F1(L) = 0.978978978978979
10/09/2021 09:24:28 - INFO - trainer -     T-F1(O) = 0.9956672443674177
10/09/2021 09:24:28 - INFO - trainer -     T-F1(P) = 0.9947275922671353
10/09/2021 09:24:28 - INFO - trainer -     T-F1(S) = 0.9925857275254866
10/09/2021 09:24:28 - INFO - trainer -     T-F1(T) = 0.9733520336605891
10/09/2021 09:24:28 - INFO - trainer -     U-F1(A) = 0.7720930232558139
10/09/2021 09:24:28 - INFO - trainer -     U-F1(E) = 0.7584973166368515
10/09/2021 09:24:28 - INFO - trainer -     U-F1(I) = 0.0
10/09/2021 09:24:28 - INFO - trainer -     U-F1(O) = 0.9667483374168709
10/09/2021 09:24:28 - INFO - trainer -     intent_acc = 0.9383057090239411
10/09/2021 09:24:28 - INFO - trainer -     loss = 0.19849049928141574
10/09/2021 09:24:28 - INFO - trainer -     semantic_frame_acc = 0.9195825659914058
10/09/2021 09:24:28 - INFO - trainer -     slot_f1 = 0.9885282596530498
10/09/2021 09:24:28 - INFO - trainer -     slot_precision = 0.9904681805438744
10/09/2021 09:24:28 - INFO - trainer -     slot_recall = 0.9865959229265568

10/09/2021 09:24:28 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:24:28 - INFO - trainer -     T-F1 = 0.9908030199039122
10/09/2021 09:24:28 - INFO - trainer -     T-F1(C) = 0.9778434268833087
10/09/2021 09:24:28 - INFO - trainer -     T-F1(L) = 0.978978978978979
10/09/2021 09:24:28 - INFO - trainer -     T-F1(O) = 0.9963766156508571
10/09/2021 09:24:28 - INFO - trainer -     T-F1(P) = 0.9953106682297773
10/09/2021 09:24:28 - INFO - trainer -     T-F1(S) = 0.9949003245248029
10/09/2021 09:24:28 - INFO - trainer -     T-F1(T) = 0.9745042492917847
10/09/2021 09:24:28 - INFO - trainer -     U-F1(A) = 0.776255707762557
10/09/2021 09:24:28 - INFO - trainer -     U-F1(E) = 0.7737478411053541
10/09/2021 09:24:28 - INFO - trainer -     U-F1(I) = 0.36111111111111105
10/09/2021 09:24:28 - INFO - trainer -     U-F1(O) = 0.9645766914629826
10/09/2021 09:24:28 - INFO - trainer -     intent_acc = 0.934622467771639
10/09/2021 09:24:28 - INFO - trainer -     semantic_frame_acc = 0.9195825659914058
10/09/2021 09:24:28 - INFO - trainer -     slot_f1 = 0.9904521201909576
10/09/2021 09:24:28 - INFO - trainer -     slot_precision = 0.9960463146003954
10/09/2021 09:24:28 - INFO - trainer -     slot_recall = 0.9849204132923765
                                                                                                                       10/09/2021 09:25:11 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 881/918 [03:41<00:07,  4.69it/s]
10/09/2021 09:25:11 - INFO - trainer -     Num examples = 3258
10/09/2021 09:25:11 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:07<00:00,  6.83it/s]
C:\Users\k3lan\anaconda3\envs\jbert\lib\site-packages\sklearn\metrics\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\k3lan\anaconda3\envs\jbert\lib\site-packages\sklearn\metrics\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\k3lan\anaconda3\envs\jbert\lib\site-packages\sklearn\metrics\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
10/09/2021 09:25:19 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:25:19 - INFO - trainer -     T-F1 = 0.9890380926281173
10/09/2021 09:25:19 - INFO - trainer -     T-F1(C) = 0.9767441860465117
10/09/2021 09:25:19 - INFO - trainer -     T-F1(L) = 0.9788519637462235
10/09/2021 09:25:19 - INFO - trainer -     T-F1(O) = 0.995670527113324
10/09/2021 09:25:19 - INFO - trainer -     T-F1(P) = 0.9953106682297773
10/09/2021 09:25:19 - INFO - trainer -     T-F1(S) = 0.9916434540389971
10/09/2021 09:25:19 - INFO - trainer -     T-F1(T) = 0.9677419354838709
10/09/2021 09:25:19 - INFO - trainer -     U-F1(A) = 0.7777777777777778
10/09/2021 09:25:19 - INFO - trainer -     U-F1(E) = 0.7684563758389261
10/09/2021 09:25:19 - INFO - trainer -     U-F1(I) = 0.0
10/09/2021 09:25:19 - INFO - trainer -     U-F1(O) = 0.9660031706887441
10/09/2021 09:25:19 - INFO - trainer -     intent_acc = 0.9376918354818907
10/09/2021 09:25:19 - INFO - trainer -     loss = 0.1920644430553212
10/09/2021 09:25:19 - INFO - trainer -     semantic_frame_acc = 0.9186617556783303
10/09/2021 09:25:19 - INFO - trainer -     slot_f1 = 0.9887892376681614
10/09/2021 09:25:19 - INFO - trainer -     slot_precision = 0.9924050632911392
10/09/2021 09:25:19 - INFO - trainer -     slot_recall = 0.9851996648980732

10/09/2021 09:25:19 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:25:19 - INFO - trainer -     T-F1 = 0.9908030199039122
10/09/2021 09:25:19 - INFO - trainer -     T-F1(C) = 0.9778434268833087
10/09/2021 09:25:19 - INFO - trainer -     T-F1(L) = 0.978978978978979
10/09/2021 09:25:19 - INFO - trainer -     T-F1(O) = 0.9963766156508571
10/09/2021 09:25:19 - INFO - trainer -     T-F1(P) = 0.9953106682297773
10/09/2021 09:25:19 - INFO - trainer -     T-F1(S) = 0.9949003245248029
10/09/2021 09:25:19 - INFO - trainer -     T-F1(T) = 0.9745042492917847
10/09/2021 09:25:19 - INFO - trainer -     U-F1(A) = 0.776255707762557
10/09/2021 09:25:19 - INFO - trainer -     U-F1(E) = 0.7737478411053541
10/09/2021 09:25:19 - INFO - trainer -     U-F1(I) = 0.36111111111111105
10/09/2021 09:25:19 - INFO - trainer -     U-F1(O) = 0.9645766914629826
10/09/2021 09:25:19 - INFO - trainer -     intent_acc = 0.934622467771639
10/09/2021 09:25:19 - INFO - trainer -     semantic_frame_acc = 0.9195825659914058
10/09/2021 09:25:19 - INFO - trainer -     slot_f1 = 0.9904521201909576
10/09/2021 09:25:19 - INFO - trainer -     slot_precision = 0.9960463146003954
10/09/2021 09:25:19 - INFO - trainer -     slot_recall = 0.9849204132923765
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 918/918 [03:57<00:00,  3.86it/s]
Epoch:  10%|███████▎                                                                 | 2/20 [07:44<1:09:54, 233.02s/it]10/09/2021 09:26:02 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 163/918 [00:35<02:39,  4.72it/s]
10/09/2021 09:26:02 - INFO - trainer -     Num examples = 3258
10/09/2021 09:26:02 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:07<00:00,  6.78it/s]
C:\Users\k3lan\anaconda3\envs\jbert\lib\site-packages\sklearn\metrics\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\k3lan\anaconda3\envs\jbert\lib\site-packages\sklearn\metrics\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\k3lan\anaconda3\envs\jbert\lib\site-packages\sklearn\metrics\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
10/09/2021 09:26:10 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:26:10 - INFO - trainer -     T-F1 = 0.9900286846059281
10/09/2021 09:26:10 - INFO - trainer -     T-F1(C) = 0.978540772532189
10/09/2021 09:26:10 - INFO - trainer -     T-F1(L) = 0.9851632047477745
10/09/2021 09:26:10 - INFO - trainer -     T-F1(O) = 0.9961528041181251
10/09/2021 09:26:10 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:26:10 - INFO - trainer -     T-F1(S) = 0.9916434540389971
10/09/2021 09:26:10 - INFO - trainer -     T-F1(T) = 0.97054698457223
10/09/2021 09:26:10 - INFO - trainer -     U-F1(A) = 0.7813953488372093
10/09/2021 09:26:10 - INFO - trainer -     U-F1(E) = 0.7728813559322034
10/09/2021 09:26:10 - INFO - trainer -     U-F1(I) = 0.0
10/09/2021 09:26:10 - INFO - trainer -     U-F1(O) = 0.9669247009148487
10/09/2021 09:26:10 - INFO - trainer -     intent_acc = 0.9392265193370166
10/09/2021 09:26:10 - INFO - trainer -     loss = 0.19362555122842975
10/09/2021 09:26:10 - INFO - trainer -     semantic_frame_acc = 0.9220380601596071
10/09/2021 09:26:10 - INFO - trainer -     slot_f1 = 0.9896619167365185
10/09/2021 09:26:10 - INFO - trainer -     slot_precision = 0.9902152641878669
10/09/2021 09:26:10 - INFO - trainer -     slot_recall = 0.9891091873778274

10/09/2021 09:26:10 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:26:10 - INFO - trainer -     T-F1 = 0.9908030199039122
10/09/2021 09:26:10 - INFO - trainer -     T-F1(C) = 0.9778434268833087
10/09/2021 09:26:10 - INFO - trainer -     T-F1(L) = 0.978978978978979
10/09/2021 09:26:10 - INFO - trainer -     T-F1(O) = 0.9963766156508571
10/09/2021 09:26:10 - INFO - trainer -     T-F1(P) = 0.9953106682297773
10/09/2021 09:26:10 - INFO - trainer -     T-F1(S) = 0.9949003245248029
10/09/2021 09:26:10 - INFO - trainer -     T-F1(T) = 0.9745042492917847
10/09/2021 09:26:10 - INFO - trainer -     U-F1(A) = 0.776255707762557
10/09/2021 09:26:10 - INFO - trainer -     U-F1(E) = 0.7737478411053541
10/09/2021 09:26:10 - INFO - trainer -     U-F1(I) = 0.36111111111111105
10/09/2021 09:26:10 - INFO - trainer -     U-F1(O) = 0.9645766914629826
10/09/2021 09:26:10 - INFO - trainer -     intent_acc = 0.934622467771639
10/09/2021 09:26:10 - INFO - trainer -     semantic_frame_acc = 0.9195825659914058
10/09/2021 09:26:10 - INFO - trainer -     slot_f1 = 0.9904521201909576
10/09/2021 09:26:10 - INFO - trainer -     slot_precision = 0.9960463146003954
10/09/2021 09:26:10 - INFO - trainer -     slot_recall = 0.9849204132923765
                                                                                                                       10/09/2021 09:26:53 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 363/918 [01:26<02:01,  4.57it/s]
10/09/2021 09:26:53 - INFO - trainer -     Num examples = 3258
10/09/2021 09:26:53 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:07<00:00,  6.69it/s]
10/09/2021 09:27:02 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:27:02 - INFO - trainer -     T-F1 = 0.9887151597552685███████████████████| 51/51 [00:07<00:00,  6.87it/s]
10/09/2021 09:27:02 - INFO - trainer -     T-F1(C) = 0.9740634005763689
10/09/2021 09:27:02 - INFO - trainer -     T-F1(L) = 0.9821428571428571
10/09/2021 09:27:02 - INFO - trainer -     T-F1(O) = 0.9954942728407795
10/09/2021 09:27:02 - INFO - trainer -     T-F1(P) = 0.9967883211678833
10/09/2021 09:27:02 - INFO - trainer -     T-F1(S) = 0.9898710865561694
10/09/2021 09:27:02 - INFO - trainer -     T-F1(T) = 0.9642857142857143
10/09/2021 09:27:02 - INFO - trainer -     U-F1(A) = 0.7793427230046949
10/09/2021 09:27:02 - INFO - trainer -     U-F1(E) = 0.7617449664429531
10/09/2021 09:27:02 - INFO - trainer -     U-F1(I) = 0.2
10/09/2021 09:27:02 - INFO - trainer -     U-F1(O) = 0.9645314981471679
10/09/2021 09:27:02 - INFO - trainer -     intent_acc = 0.9352363413136894
10/09/2021 09:27:02 - INFO - trainer -     loss = 0.19528634890037425
10/09/2021 09:27:02 - INFO - trainer -     semantic_frame_acc = 0.9146715776550031
10/09/2021 09:27:02 - INFO - trainer -     slot_f1 = 0.9883171070931849
10/09/2021 09:27:02 - INFO - trainer -     slot_precision = 0.9844832363535605
10/09/2021 09:27:02 - INFO - trainer -     slot_recall = 0.9921809550404915

10/09/2021 09:27:02 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:27:02 - INFO - trainer -     T-F1 = 0.9908030199039122
10/09/2021 09:27:02 - INFO - trainer -     T-F1(C) = 0.9778434268833087
10/09/2021 09:27:02 - INFO - trainer -     T-F1(L) = 0.978978978978979
10/09/2021 09:27:02 - INFO - trainer -     T-F1(O) = 0.9963766156508571
10/09/2021 09:27:02 - INFO - trainer -     T-F1(P) = 0.9953106682297773
10/09/2021 09:27:02 - INFO - trainer -     T-F1(S) = 0.9949003245248029
10/09/2021 09:27:02 - INFO - trainer -     T-F1(T) = 0.9745042492917847
10/09/2021 09:27:02 - INFO - trainer -     U-F1(A) = 0.776255707762557
10/09/2021 09:27:02 - INFO - trainer -     U-F1(E) = 0.7737478411053541
10/09/2021 09:27:02 - INFO - trainer -     U-F1(I) = 0.36111111111111105
10/09/2021 09:27:02 - INFO - trainer -     U-F1(O) = 0.9645766914629826
10/09/2021 09:27:02 - INFO - trainer -     intent_acc = 0.934622467771639
10/09/2021 09:27:02 - INFO - trainer -     semantic_frame_acc = 0.9195825659914058
10/09/2021 09:27:02 - INFO - trainer -     slot_f1 = 0.9904521201909576
10/09/2021 09:27:02 - INFO - trainer -     slot_precision = 0.9960463146003954
10/09/2021 09:27:02 - INFO - trainer -     slot_recall = 0.9849204132923765
                                                                                                                       10/09/2021 09:27:45 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 563/918 [02:18<01:17,  4.56it/s]
10/09/2021 09:27:45 - INFO - trainer -     Num examples = 3258
10/09/2021 09:27:45 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:07<00:00,  6.76it/s]
10/09/2021 09:27:53 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:27:53 - INFO - trainer -     T-F1 = 0.9901315789473684███████████████████| 51/51 [00:07<00:00,  6.91it/s]
10/09/2021 09:27:53 - INFO - trainer -     T-F1(C) = 0.9753979739507959
10/09/2021 09:27:53 - INFO - trainer -     T-F1(L) = 0.984984984984985
10/09/2021 09:27:53 - INFO - trainer -     T-F1(O) = 0.996103896103896
10/09/2021 09:27:53 - INFO - trainer -     T-F1(P) = 0.995307917888563
10/09/2021 09:27:53 - INFO - trainer -     T-F1(S) = 0.9935004642525535
10/09/2021 09:27:53 - INFO - trainer -     T-F1(T) = 0.9717514124293786
10/09/2021 09:27:53 - INFO - trainer -     U-F1(A) = 0.7722772277227723
10/09/2021 09:27:53 - INFO - trainer -     U-F1(E) = 0.773851590106007
10/09/2021 09:27:53 - INFO - trainer -     U-F1(I) = 0.06666666666666667
10/09/2021 09:27:53 - INFO - trainer -     U-F1(O) = 0.9674711437565583
10/09/2021 09:27:53 - INFO - trainer -     intent_acc = 0.9404542664211173
10/09/2021 09:27:53 - INFO - trainer -     loss = 0.19457456520667263
10/09/2021 09:27:53 - INFO - trainer -     semantic_frame_acc = 0.9226519337016574
10/09/2021 09:27:53 - INFO - trainer -     slot_f1 = 0.989485489976167
10/09/2021 09:27:53 - INFO - trainer -     slot_precision = 0.9935247747747747
10/09/2021 09:27:53 - INFO - trainer -     slot_recall = 0.9854789165037698

10/09/2021 09:27:53 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:27:53 - INFO - trainer -     T-F1 = 0.9908030199039122
10/09/2021 09:27:53 - INFO - trainer -     T-F1(C) = 0.9778434268833087
10/09/2021 09:27:53 - INFO - trainer -     T-F1(L) = 0.978978978978979
10/09/2021 09:27:53 - INFO - trainer -     T-F1(O) = 0.9963766156508571
10/09/2021 09:27:53 - INFO - trainer -     T-F1(P) = 0.9953106682297773
10/09/2021 09:27:53 - INFO - trainer -     T-F1(S) = 0.9949003245248029
10/09/2021 09:27:53 - INFO - trainer -     T-F1(T) = 0.9745042492917847
10/09/2021 09:27:53 - INFO - trainer -     U-F1(A) = 0.776255707762557
10/09/2021 09:27:53 - INFO - trainer -     U-F1(E) = 0.7737478411053541
10/09/2021 09:27:53 - INFO - trainer -     U-F1(I) = 0.36111111111111105
10/09/2021 09:27:53 - INFO - trainer -     U-F1(O) = 0.9645766914629826
10/09/2021 09:27:53 - INFO - trainer -     intent_acc = 0.934622467771639
10/09/2021 09:27:53 - INFO - trainer -     semantic_frame_acc = 0.9195825659914058
10/09/2021 09:27:53 - INFO - trainer -     slot_f1 = 0.9904521201909576
10/09/2021 09:27:53 - INFO - trainer -     slot_precision = 0.9960463146003954
10/09/2021 09:27:53 - INFO - trainer -     slot_recall = 0.9849204132923765
                                                                                                                       10/09/2021 09:28:36 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 763/918 [03:09<00:33,  4.67it/s]
10/09/2021 09:28:36 - INFO - trainer -     Num examples = 3258
10/09/2021 09:28:36 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:07<00:00,  6.71it/s]
10/09/2021 09:28:44 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:28:44 - INFO - trainer -     T-F1 = 0.9872108843537415███████████████████| 51/51 [00:07<00:00,  6.79it/s]
10/09/2021 09:28:44 - INFO - trainer -     T-F1(C) = 0.9727403156384504
10/09/2021 09:28:44 - INFO - trainer -     T-F1(L) = 0.9761904761904762
10/09/2021 09:28:44 - INFO - trainer -     T-F1(O) = 0.9948985129708021
10/09/2021 09:28:44 - INFO - trainer -     T-F1(P) = 0.9958968347010552
10/09/2021 09:28:44 - INFO - trainer -     T-F1(S) = 0.9867033470884916
10/09/2021 09:28:44 - INFO - trainer -     T-F1(T) = 0.9668508287292817
10/09/2021 09:28:44 - INFO - trainer -     U-F1(A) = 0.7813953488372093
10/09/2021 09:28:44 - INFO - trainer -     U-F1(E) = 0.7684021543985639
10/09/2021 09:28:44 - INFO - trainer -     U-F1(I) = 0.18750000000000003
10/09/2021 09:28:44 - INFO - trainer -     U-F1(O) = 0.9677871148459384
10/09/2021 09:28:44 - INFO - trainer -     intent_acc = 0.9407612031921424
10/09/2021 09:28:44 - INFO - trainer -     loss = 0.1877930509109123
10/09/2021 09:28:44 - INFO - trainer -     semantic_frame_acc = 0.9168201350521793
10/09/2021 09:28:44 - INFO - trainer -     slot_f1 = 0.9867780097425192
10/09/2021 09:28:44 - INFO - trainer -     slot_precision = 0.9836293007769146
10/09/2021 09:28:44 - INFO - trainer -     slot_recall = 0.9899469421949176

10/09/2021 09:28:44 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:28:44 - INFO - trainer -     T-F1 = 0.9908030199039122
10/09/2021 09:28:44 - INFO - trainer -     T-F1(C) = 0.9778434268833087
10/09/2021 09:28:44 - INFO - trainer -     T-F1(L) = 0.978978978978979
10/09/2021 09:28:44 - INFO - trainer -     T-F1(O) = 0.9963766156508571
10/09/2021 09:28:44 - INFO - trainer -     T-F1(P) = 0.9953106682297773
10/09/2021 09:28:44 - INFO - trainer -     T-F1(S) = 0.9949003245248029
10/09/2021 09:28:44 - INFO - trainer -     T-F1(T) = 0.9745042492917847
10/09/2021 09:28:44 - INFO - trainer -     U-F1(A) = 0.776255707762557
10/09/2021 09:28:44 - INFO - trainer -     U-F1(E) = 0.7737478411053541
10/09/2021 09:28:44 - INFO - trainer -     U-F1(I) = 0.36111111111111105
10/09/2021 09:28:44 - INFO - trainer -     U-F1(O) = 0.9645766914629826
10/09/2021 09:28:44 - INFO - trainer -     intent_acc = 0.934622467771639
10/09/2021 09:28:44 - INFO - trainer -     semantic_frame_acc = 0.9195825659914058
10/09/2021 09:28:44 - INFO - trainer -     slot_f1 = 0.9904521201909576
10/09/2021 09:28:44 - INFO - trainer -     slot_precision = 0.9960463146003954
10/09/2021 09:28:44 - INFO - trainer -     slot_recall = 0.9849204132923765
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 918/918 [03:50<00:00,  3.98it/s]
Epoch:  15%|██████████▉                                                              | 3/20 [11:34<1:05:44, 232.01s/it]10/09/2021 09:29:27 - INFO - trainer -   ***** Running evaluation on dev dataset ***** | 45/918 [00:09<03:09,  4.61it/s]
10/09/2021 09:29:27 - INFO - trainer -     Num examples = 3258
10/09/2021 09:29:27 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:07<00:00,  6.73it/s]
10/09/2021 09:29:36 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:29:36 - INFO - trainer -     T-F1 = 0.9885807504078303███████████████████| 51/51 [00:07<00:00,  6.81it/s]
10/09/2021 09:29:36 - INFO - trainer -     T-F1(C) = 0.9701280227596016
10/09/2021 09:29:36 - INFO - trainer -     T-F1(L) = 0.9823529411764705
10/09/2021 09:29:36 - INFO - trainer -     T-F1(O) = 0.9954397394136807
10/09/2021 09:29:36 - INFO - trainer -     T-F1(P) = 0.9976608187134504
10/09/2021 09:29:36 - INFO - trainer -     T-F1(S) = 0.9908003679852806
10/09/2021 09:29:36 - INFO - trainer -     T-F1(T) = 0.9596662030598052
10/09/2021 09:29:36 - INFO - trainer -     U-F1(A) = 0.7924528301886793
10/09/2021 09:29:36 - INFO - trainer -     U-F1(E) = 0.7742998352553542
10/09/2021 09:29:36 - INFO - trainer -     U-F1(I) = 0.3414634146341463
10/09/2021 09:29:36 - INFO - trainer -     U-F1(O) = 0.966053748231966
10/09/2021 09:29:36 - INFO - trainer -     intent_acc = 0.9386126457949663
10/09/2021 09:29:36 - INFO - trainer -     loss = 0.19781337415470795
10/09/2021 09:29:36 - INFO - trainer -     semantic_frame_acc = 0.91804788213628
10/09/2021 09:29:36 - INFO - trainer -     slot_f1 = 0.9880422691879867
10/09/2021 09:29:36 - INFO - trainer -     slot_precision = 0.9839379673220714
10/09/2021 09:29:36 - INFO - trainer -     slot_recall = 0.9921809550404915

10/09/2021 09:29:36 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:29:36 - INFO - trainer -     T-F1 = 0.9908030199039122
10/09/2021 09:29:36 - INFO - trainer -     T-F1(C) = 0.9778434268833087
10/09/2021 09:29:36 - INFO - trainer -     T-F1(L) = 0.978978978978979
10/09/2021 09:29:36 - INFO - trainer -     T-F1(O) = 0.9963766156508571
10/09/2021 09:29:36 - INFO - trainer -     T-F1(P) = 0.9953106682297773
10/09/2021 09:29:36 - INFO - trainer -     T-F1(S) = 0.9949003245248029
10/09/2021 09:29:36 - INFO - trainer -     T-F1(T) = 0.9745042492917847
10/09/2021 09:29:36 - INFO - trainer -     U-F1(A) = 0.776255707762557
10/09/2021 09:29:36 - INFO - trainer -     U-F1(E) = 0.7737478411053541
10/09/2021 09:29:36 - INFO - trainer -     U-F1(I) = 0.36111111111111105
10/09/2021 09:29:36 - INFO - trainer -     U-F1(O) = 0.9645766914629826
10/09/2021 09:29:36 - INFO - trainer -     intent_acc = 0.934622467771639
10/09/2021 09:29:36 - INFO - trainer -     semantic_frame_acc = 0.9195825659914058
10/09/2021 09:29:36 - INFO - trainer -     slot_f1 = 0.9904521201909576
10/09/2021 09:29:36 - INFO - trainer -     slot_precision = 0.9960463146003954
10/09/2021 09:29:36 - INFO - trainer -     slot_recall = 0.9849204132923765
                                                                                                                       10/09/2021 09:30:19 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 245/918 [01:01<02:26,  4.59it/s]
10/09/2021 09:30:19 - INFO - trainer -     Num examples = 3258
10/09/2021 09:30:19 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:07<00:00,  6.63it/s]
10/09/2021 09:30:27 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:30:27 - INFO - trainer -     T-F1 = 0.9894794370815685███████████████████| 51/51 [00:07<00:00,  6.93it/s]
10/09/2021 09:30:27 - INFO - trainer -     T-F1(C) = 0.9727403156384504
10/09/2021 09:30:27 - INFO - trainer -     T-F1(L) = 0.9737609329446065
10/09/2021 09:30:27 - INFO - trainer -     T-F1(O) = 0.9958281410846832
10/09/2021 09:30:27 - INFO - trainer -     T-F1(P) = 0.994718309859155
10/09/2021 09:30:27 - INFO - trainer -     T-F1(S) = 0.9935185185185186
10/09/2021 09:30:27 - INFO - trainer -     T-F1(T) = 0.9760900140646976
10/09/2021 09:30:27 - INFO - trainer -     U-F1(A) = 0.7777777777777778
10/09/2021 09:30:27 - INFO - trainer -     U-F1(E) = 0.7781569965870306
10/09/2021 09:30:27 - INFO - trainer -     U-F1(I) = 0.2564102564102564
10/09/2021 09:30:27 - INFO - trainer -     U-F1(O) = 0.9670484581497797
10/09/2021 09:30:27 - INFO - trainer -     intent_acc = 0.9395334561080417
10/09/2021 09:30:27 - INFO - trainer -     loss = 0.20089196523322778
10/09/2021 09:30:27 - INFO - trainer -     semantic_frame_acc = 0.9208103130755064
10/09/2021 09:30:27 - INFO - trainer -     slot_f1 = 0.9889618555260583
10/09/2021 09:30:27 - INFO - trainer -     slot_precision = 0.9896532438478747
10/09/2021 09:30:27 - INFO - trainer -     slot_recall = 0.9882714325607372

10/09/2021 09:30:27 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:30:27 - INFO - trainer -     T-F1 = 0.9908030199039122
10/09/2021 09:30:27 - INFO - trainer -     T-F1(C) = 0.9778434268833087
10/09/2021 09:30:27 - INFO - trainer -     T-F1(L) = 0.978978978978979
10/09/2021 09:30:27 - INFO - trainer -     T-F1(O) = 0.9963766156508571
10/09/2021 09:30:27 - INFO - trainer -     T-F1(P) = 0.9953106682297773
10/09/2021 09:30:27 - INFO - trainer -     T-F1(S) = 0.9949003245248029
10/09/2021 09:30:27 - INFO - trainer -     T-F1(T) = 0.9745042492917847
10/09/2021 09:30:27 - INFO - trainer -     U-F1(A) = 0.776255707762557
10/09/2021 09:30:27 - INFO - trainer -     U-F1(E) = 0.7737478411053541
10/09/2021 09:30:27 - INFO - trainer -     U-F1(I) = 0.36111111111111105
10/09/2021 09:30:27 - INFO - trainer -     U-F1(O) = 0.9645766914629826
10/09/2021 09:30:27 - INFO - trainer -     intent_acc = 0.934622467771639
10/09/2021 09:30:27 - INFO - trainer -     semantic_frame_acc = 0.9195825659914058
10/09/2021 09:30:27 - INFO - trainer -     slot_f1 = 0.9904521201909576
10/09/2021 09:30:27 - INFO - trainer -     slot_precision = 0.9960463146003954
10/09/2021 09:30:27 - INFO - trainer -     slot_recall = 0.9849204132923765
                                                                                                                       10/09/2021 09:31:12 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 445/918 [01:54<01:42,  4.61it/s]
10/09/2021 09:31:12 - INFO - trainer -     Num examples = 3258
10/09/2021 09:31:12 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:07<00:00,  6.73it/s]
10/09/2021 09:31:20 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:31:20 - INFO - trainer -     T-F1 = 0.9896711062788801███████████████████| 51/51 [00:07<00:00,  6.73it/s]
10/09/2021 09:31:20 - INFO - trainer -     T-F1(C) = 0.9798850574712643
10/09/2021 09:31:20 - INFO - trainer -     T-F1(L) = 0.9794721407624633
10/09/2021 09:31:20 - INFO - trainer -     T-F1(O) = 0.9958736019111738
10/09/2021 09:31:20 - INFO - trainer -     T-F1(P) = 0.9967939376275139
10/09/2021 09:31:20 - INFO - trainer -     T-F1(S) = 0.9921550530687586
10/09/2021 09:31:20 - INFO - trainer -     T-F1(T) = 0.9626556016597512
10/09/2021 09:31:20 - INFO - trainer -     U-F1(A) = 0.7663551401869159
10/09/2021 09:31:20 - INFO - trainer -     U-F1(E) = 0.7321772639691716
10/09/2021 09:31:20 - INFO - trainer -     U-F1(I) = 0.2222222222222222
10/09/2021 09:31:20 - INFO - trainer -     U-F1(O) = 0.9657212458674089
10/09/2021 09:31:20 - INFO - trainer -     intent_acc = 0.93646408839779
10/09/2021 09:31:20 - INFO - trainer -     loss = 0.20359829411494965
10/09/2021 09:31:20 - INFO - trainer -     semantic_frame_acc = 0.9183548189073051
10/09/2021 09:31:20 - INFO - trainer -     slot_f1 = 0.9894356408117876
10/09/2021 09:31:20 - INFO - trainer -     slot_precision = 0.9850539717686133
10/09/2021 09:31:20 - INFO - trainer -     slot_recall = 0.9938564646746719

10/09/2021 09:31:20 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:31:20 - INFO - trainer -     T-F1 = 0.9908030199039122
10/09/2021 09:31:20 - INFO - trainer -     T-F1(C) = 0.9778434268833087
10/09/2021 09:31:20 - INFO - trainer -     T-F1(L) = 0.978978978978979
10/09/2021 09:31:20 - INFO - trainer -     T-F1(O) = 0.9963766156508571
10/09/2021 09:31:20 - INFO - trainer -     T-F1(P) = 0.9953106682297773
10/09/2021 09:31:20 - INFO - trainer -     T-F1(S) = 0.9949003245248029
10/09/2021 09:31:20 - INFO - trainer -     T-F1(T) = 0.9745042492917847
10/09/2021 09:31:20 - INFO - trainer -     U-F1(A) = 0.776255707762557
10/09/2021 09:31:20 - INFO - trainer -     U-F1(E) = 0.7737478411053541
10/09/2021 09:31:20 - INFO - trainer -     U-F1(I) = 0.36111111111111105
10/09/2021 09:31:20 - INFO - trainer -     U-F1(O) = 0.9645766914629826
10/09/2021 09:31:20 - INFO - trainer -     intent_acc = 0.934622467771639
10/09/2021 09:31:20 - INFO - trainer -     semantic_frame_acc = 0.9195825659914058
10/09/2021 09:31:20 - INFO - trainer -     slot_f1 = 0.9904521201909576
10/09/2021 09:31:20 - INFO - trainer -     slot_precision = 0.9960463146003954
10/09/2021 09:31:20 - INFO - trainer -     slot_recall = 0.9849204132923765
                                                                                                                       10/09/2021 09:31:47 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 645/918 [02:29<00:32,  8.37it/s]
10/09/2021 09:31:47 - INFO - trainer -     Num examples = 3258
10/09/2021 09:31:47 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.46it/s]
10/09/2021 09:31:50 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:31:50 - INFO - trainer -     T-F1 = 0.9912830291473712█████████████████▋ | 50/51 [00:03<00:00, 14.47it/s]
10/09/2021 09:31:50 - INFO - trainer -     T-F1(C) = 0.9771428571428572
10/09/2021 09:31:50 - INFO - trainer -     T-F1(L) = 0.9910979228486648
10/09/2021 09:31:50 - INFO - trainer -     T-F1(O) = 0.9965281544971248
10/09/2021 09:31:50 - INFO - trainer -     T-F1(P) = 0.997953814674072
10/09/2021 09:31:50 - INFO - trainer -     T-F1(S) = 0.9903359410952601
10/09/2021 09:31:50 - INFO - trainer -     T-F1(T) = 0.9760900140646976
10/09/2021 09:31:50 - INFO - trainer -     U-F1(A) = 0.7751196172248804
10/09/2021 09:31:50 - INFO - trainer -     U-F1(E) = 0.7743119266055047
10/09/2021 09:31:50 - INFO - trainer -     U-F1(I) = 0.12121212121212122
10/09/2021 09:31:50 - INFO - trainer -     U-F1(O) = 0.9698027578984115
10/09/2021 09:31:50 - INFO - trainer -     intent_acc = 0.9429097605893186
10/09/2021 09:31:50 - INFO - trainer -     loss = 0.2183922614683123
10/09/2021 09:31:50 - INFO - trainer -     semantic_frame_acc = 0.9278698588090853
10/09/2021 09:31:50 - INFO - trainer -     slot_f1 = 0.990945814180248
10/09/2021 09:31:50 - INFO - trainer -     slot_precision = 0.9886047804335742
10/09/2021 09:31:50 - INFO - trainer -     slot_recall = 0.9932979614632784

10/09/2021 09:31:50 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:31:50 - INFO - trainer -     T-F1 = 0.9908030199039122
10/09/2021 09:31:50 - INFO - trainer -     T-F1(C) = 0.9778434268833087
10/09/2021 09:31:50 - INFO - trainer -     T-F1(L) = 0.978978978978979
10/09/2021 09:31:50 - INFO - trainer -     T-F1(O) = 0.9963766156508571
10/09/2021 09:31:50 - INFO - trainer -     T-F1(P) = 0.9953106682297773
10/09/2021 09:31:50 - INFO - trainer -     T-F1(S) = 0.9949003245248029
10/09/2021 09:31:50 - INFO - trainer -     T-F1(T) = 0.9745042492917847
10/09/2021 09:31:50 - INFO - trainer -     U-F1(A) = 0.776255707762557
10/09/2021 09:31:50 - INFO - trainer -     U-F1(E) = 0.7737478411053541
10/09/2021 09:31:50 - INFO - trainer -     U-F1(I) = 0.36111111111111105
10/09/2021 09:31:50 - INFO - trainer -     U-F1(O) = 0.9645766914629826
10/09/2021 09:31:50 - INFO - trainer -     intent_acc = 0.934622467771639
10/09/2021 09:31:50 - INFO - trainer -     semantic_frame_acc = 0.9195825659914058
10/09/2021 09:31:50 - INFO - trainer -     slot_f1 = 0.9904521201909576
10/09/2021 09:31:50 - INFO - trainer -     slot_precision = 0.9960463146003954
10/09/2021 09:31:50 - INFO - trainer -     slot_recall = 0.9849204132923765
                                                                                                                       10/09/2021 09:32:14 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 845/918 [02:56<00:08,  8.33it/s]
10/09/2021 09:32:14 - INFO - trainer -     Num examples = 3258
10/09/2021 09:32:14 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.28it/s]
10/09/2021 09:32:18 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:32:18 - INFO - trainer -     T-F1 = 0.9902965696323629█████████████████▋ | 50/51 [00:03<00:00, 14.33it/s]
10/09/2021 09:32:18 - INFO - trainer -     T-F1(C) = 0.982608695652174
10/09/2021 09:32:18 - INFO - trainer -     T-F1(L) = 0.9757575757575757
10/09/2021 09:32:18 - INFO - trainer -     T-F1(O) = 0.9962619860230781
10/09/2021 09:32:18 - INFO - trainer -     T-F1(P) = 0.9961910342806914
10/09/2021 09:32:18 - INFO - trainer -     T-F1(S) = 0.992633517495396
10/09/2021 09:32:18 - INFO - trainer -     T-F1(T) = 0.9691011235955057
10/09/2021 09:32:18 - INFO - trainer -     U-F1(A) = 0.7772511848341231
10/09/2021 09:32:18 - INFO - trainer -     U-F1(E) = 0.7703435804701628
10/09/2021 09:32:18 - INFO - trainer -     U-F1(I) = 0.24390243902439024
10/09/2021 09:32:18 - INFO - trainer -     U-F1(O) = 0.9672561722990719
10/09/2021 09:32:18 - INFO - trainer -     intent_acc = 0.939840392879067
10/09/2021 09:32:18 - INFO - trainer -     loss = 0.19521220912243806
10/09/2021 09:32:18 - INFO - trainer -     semantic_frame_acc = 0.9229588704726827
10/09/2021 09:32:18 - INFO - trainer -     slot_f1 = 0.9897973445143257
10/09/2021 09:32:18 - INFO - trainer -     slot_precision = 0.9907666480134303
10/09/2021 09:32:18 - INFO - trainer -     slot_recall = 0.9888299357721307

10/09/2021 09:32:18 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:32:18 - INFO - trainer -     T-F1 = 0.9908030199039122
10/09/2021 09:32:18 - INFO - trainer -     T-F1(C) = 0.9778434268833087
10/09/2021 09:32:18 - INFO - trainer -     T-F1(L) = 0.978978978978979
10/09/2021 09:32:18 - INFO - trainer -     T-F1(O) = 0.9963766156508571
10/09/2021 09:32:18 - INFO - trainer -     T-F1(P) = 0.9953106682297773
10/09/2021 09:32:18 - INFO - trainer -     T-F1(S) = 0.9949003245248029
10/09/2021 09:32:18 - INFO - trainer -     T-F1(T) = 0.9745042492917847
10/09/2021 09:32:18 - INFO - trainer -     U-F1(A) = 0.776255707762557
10/09/2021 09:32:18 - INFO - trainer -     U-F1(E) = 0.7737478411053541
10/09/2021 09:32:18 - INFO - trainer -     U-F1(I) = 0.36111111111111105
10/09/2021 09:32:18 - INFO - trainer -     U-F1(O) = 0.9645766914629826
10/09/2021 09:32:18 - INFO - trainer -     intent_acc = 0.934622467771639
10/09/2021 09:32:18 - INFO - trainer -     semantic_frame_acc = 0.9195825659914058
10/09/2021 09:32:18 - INFO - trainer -     slot_f1 = 0.9904521201909576
10/09/2021 09:32:18 - INFO - trainer -     slot_precision = 0.9960463146003954
10/09/2021 09:32:18 - INFO - trainer -     slot_recall = 0.9849204132923765
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 918/918 [03:09<00:00,  4.85it/s]
Epoch:  20%|███████████████                                                            | 4/20 [14:44<57:22, 215.15s/it]10/09/2021 09:32:42 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 127/918 [00:15<01:33,  8.42it/s]
10/09/2021 09:32:42 - INFO - trainer -     Num examples = 3258
10/09/2021 09:32:42 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.35it/s]
10/09/2021 09:32:46 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:32:46 - INFO - trainer -     T-F1 = 0.9897778383535505█████████████████▋ | 50/51 [00:03<00:00, 14.25it/s]
10/09/2021 09:32:46 - INFO - trainer -     T-F1(C) = 0.9729729729729729
10/09/2021 09:32:46 - INFO - trainer -     T-F1(L) = 0.9819277108433735
10/09/2021 09:32:46 - INFO - trainer -     T-F1(O) = 0.9960410000542329
10/09/2021 09:32:46 - INFO - trainer -     T-F1(P) = 0.9976594499707432
10/09/2021 09:32:46 - INFO - trainer -     T-F1(S) = 0.9898336414048059
10/09/2021 09:32:46 - INFO - trainer -     T-F1(T) = 0.9722222222222221
10/09/2021 09:32:46 - INFO - trainer -     U-F1(A) = 0.7941176470588236
10/09/2021 09:32:46 - INFO - trainer -     U-F1(E) = 0.7490774907749077
10/09/2021 09:32:46 - INFO - trainer -     U-F1(I) = 0.2857142857142857
10/09/2021 09:32:46 - INFO - trainer -     U-F1(O) = 0.9664804469273743
10/09/2021 09:32:46 - INFO - trainer -     intent_acc = 0.9386126457949663
10/09/2021 09:32:46 - INFO - trainer -     loss = 0.21298669877589918
10/09/2021 09:32:46 - INFO - trainer -     semantic_frame_acc = 0.9201964395334561
10/09/2021 09:32:46 - INFO - trainer -     slot_f1 = 0.9892653004321762
10/09/2021 09:32:46 - INFO - trainer -     slot_precision = 0.987750556792873
10/09/2021 09:32:46 - INFO - trainer -     slot_recall = 0.9907846970120078

10/09/2021 09:32:46 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:32:46 - INFO - trainer -     T-F1 = 0.9908030199039122
10/09/2021 09:32:46 - INFO - trainer -     T-F1(C) = 0.9778434268833087
10/09/2021 09:32:46 - INFO - trainer -     T-F1(L) = 0.978978978978979
10/09/2021 09:32:46 - INFO - trainer -     T-F1(O) = 0.9963766156508571
10/09/2021 09:32:46 - INFO - trainer -     T-F1(P) = 0.9953106682297773
10/09/2021 09:32:46 - INFO - trainer -     T-F1(S) = 0.9949003245248029
10/09/2021 09:32:46 - INFO - trainer -     T-F1(T) = 0.9745042492917847
10/09/2021 09:32:46 - INFO - trainer -     U-F1(A) = 0.776255707762557
10/09/2021 09:32:46 - INFO - trainer -     U-F1(E) = 0.7737478411053541
10/09/2021 09:32:46 - INFO - trainer -     U-F1(I) = 0.36111111111111105
10/09/2021 09:32:46 - INFO - trainer -     U-F1(O) = 0.9645766914629826
10/09/2021 09:32:46 - INFO - trainer -     intent_acc = 0.934622467771639
10/09/2021 09:32:46 - INFO - trainer -     semantic_frame_acc = 0.9195825659914058
10/09/2021 09:32:46 - INFO - trainer -     slot_f1 = 0.9904521201909576
10/09/2021 09:32:46 - INFO - trainer -     slot_precision = 0.9960463146003954
10/09/2021 09:32:46 - INFO - trainer -     slot_recall = 0.9849204132923765
                                                                                                                       10/09/2021 09:33:10 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 327/918 [00:43<01:11,  8.27it/s]
10/09/2021 09:33:10 - INFO - trainer -     Num examples = 3258
10/09/2021 09:33:10 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.30it/s]
10/09/2021 09:33:14 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:33:14 - INFO - trainer -     T-F1 = 0.9912520503007108█████████████████▋ | 50/51 [00:03<00:00, 14.23it/s]
10/09/2021 09:33:14 - INFO - trainer -     T-F1(C) = 0.9742857142857144
10/09/2021 09:33:14 - INFO - trainer -     T-F1(L) = 0.9819277108433735
10/09/2021 09:33:14 - INFO - trainer -     T-F1(O) = 0.9965330444203684
10/09/2021 09:33:14 - INFO - trainer -     T-F1(P) = 0.9964850615114235
10/09/2021 09:33:14 - INFO - trainer -     T-F1(S) = 0.9939898289412854
10/09/2021 09:33:14 - INFO - trainer -     T-F1(T) = 0.9787835926449788
10/09/2021 09:33:14 - INFO - trainer -     U-F1(A) = 0.7783251231527094
10/09/2021 09:33:14 - INFO - trainer -     U-F1(E) = 0.7190569744597249
10/09/2021 09:33:14 - INFO - trainer -     U-F1(I) = 0.06666666666666667
10/09/2021 09:33:14 - INFO - trainer -     U-F1(O) = 0.965015587114652
10/09/2021 09:33:14 - INFO - trainer -     intent_acc = 0.9358502148557397
10/09/2021 09:33:14 - INFO - trainer -     loss = 0.23638692454380147
10/09/2021 09:33:14 - INFO - trainer -     semantic_frame_acc = 0.9211172498465316
10/09/2021 09:33:14 - INFO - trainer -     slot_f1 = 0.9907718120805369
10/09/2021 09:33:14 - INFO - trainer -     slot_precision = 0.9921590590870905
10/09/2021 09:33:14 - INFO - trainer -     slot_recall = 0.9893884389835241

10/09/2021 09:33:14 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:33:14 - INFO - trainer -     T-F1 = 0.9908030199039122
10/09/2021 09:33:14 - INFO - trainer -     T-F1(C) = 0.9778434268833087
10/09/2021 09:33:14 - INFO - trainer -     T-F1(L) = 0.978978978978979
10/09/2021 09:33:14 - INFO - trainer -     T-F1(O) = 0.9963766156508571
10/09/2021 09:33:14 - INFO - trainer -     T-F1(P) = 0.9953106682297773
10/09/2021 09:33:14 - INFO - trainer -     T-F1(S) = 0.9949003245248029
10/09/2021 09:33:14 - INFO - trainer -     T-F1(T) = 0.9745042492917847
10/09/2021 09:33:14 - INFO - trainer -     U-F1(A) = 0.776255707762557
10/09/2021 09:33:14 - INFO - trainer -     U-F1(E) = 0.7737478411053541
10/09/2021 09:33:14 - INFO - trainer -     U-F1(I) = 0.36111111111111105
10/09/2021 09:33:14 - INFO - trainer -     U-F1(O) = 0.9645766914629826
10/09/2021 09:33:14 - INFO - trainer -     intent_acc = 0.934622467771639
10/09/2021 09:33:14 - INFO - trainer -     semantic_frame_acc = 0.9195825659914058
10/09/2021 09:33:14 - INFO - trainer -     slot_f1 = 0.9904521201909576
10/09/2021 09:33:14 - INFO - trainer -     slot_precision = 0.9960463146003954
10/09/2021 09:33:14 - INFO - trainer -     slot_recall = 0.9849204132923765
                                                                                                                       10/09/2021 09:33:38 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 527/918 [01:11<00:47,  8.32it/s]
10/09/2021 09:33:38 - INFO - trainer -     Num examples = 3258
10/09/2021 09:33:38 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.20it/s]
10/09/2021 09:33:42 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:33:42 - INFO - trainer -     T-F1 = 0.9891333876663951█████████████████▋ | 50/51 [00:03<00:00, 14.06it/s]
10/09/2021 09:33:42 - INFO - trainer -     T-F1(C) = 0.9757489300998574
10/09/2021 09:33:42 - INFO - trainer -     T-F1(L) = 0.9761904761904762
10/09/2021 09:33:42 - INFO - trainer -     T-F1(O) = 0.995764092538286
10/09/2021 09:33:42 - INFO - trainer -     T-F1(P) = 0.9964973730297724
10/09/2021 09:33:42 - INFO - trainer -     T-F1(S) = 0.9876316994961062
10/09/2021 09:33:42 - INFO - trainer -     T-F1(T) = 0.9776536312849162
10/09/2021 09:33:42 - INFO - trainer -     U-F1(A) = 0.7777777777777778
10/09/2021 09:33:42 - INFO - trainer -     U-F1(E) = 0.7728813559322034
10/09/2021 09:33:42 - INFO - trainer -     U-F1(I) = 0.30769230769230765
10/09/2021 09:33:42 - INFO - trainer -     U-F1(O) = 0.9666725445247751
10/09/2021 09:33:42 - INFO - trainer -     intent_acc = 0.9389195825659914
10/09/2021 09:33:42 - INFO - trainer -     loss = 0.22407673679146112
10/09/2021 09:33:42 - INFO - trainer -     semantic_frame_acc = 0.91804788213628
10/09/2021 09:33:42 - INFO - trainer -     slot_f1 = 0.9887453105460609
10/09/2021 09:33:42 - INFO - trainer -     slot_precision = 0.9839601769911505
10/09/2021 09:33:42 - INFO - trainer -     slot_recall = 0.9935772130689752

10/09/2021 09:33:42 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:33:42 - INFO - trainer -     T-F1 = 0.9908030199039122
10/09/2021 09:33:42 - INFO - trainer -     T-F1(C) = 0.9778434268833087
10/09/2021 09:33:42 - INFO - trainer -     T-F1(L) = 0.978978978978979
10/09/2021 09:33:42 - INFO - trainer -     T-F1(O) = 0.9963766156508571
10/09/2021 09:33:42 - INFO - trainer -     T-F1(P) = 0.9953106682297773
10/09/2021 09:33:42 - INFO - trainer -     T-F1(S) = 0.9949003245248029
10/09/2021 09:33:42 - INFO - trainer -     T-F1(T) = 0.9745042492917847
10/09/2021 09:33:42 - INFO - trainer -     U-F1(A) = 0.776255707762557
10/09/2021 09:33:42 - INFO - trainer -     U-F1(E) = 0.7737478411053541
10/09/2021 09:33:42 - INFO - trainer -     U-F1(I) = 0.36111111111111105
10/09/2021 09:33:42 - INFO - trainer -     U-F1(O) = 0.9645766914629826
10/09/2021 09:33:42 - INFO - trainer -     intent_acc = 0.934622467771639
10/09/2021 09:33:42 - INFO - trainer -     semantic_frame_acc = 0.9195825659914058
10/09/2021 09:33:42 - INFO - trainer -     slot_f1 = 0.9904521201909576
10/09/2021 09:33:42 - INFO - trainer -     slot_precision = 0.9960463146003954
10/09/2021 09:33:42 - INFO - trainer -     slot_recall = 0.9849204132923765
                                                                                                                       10/09/2021 09:34:06 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 727/918 [01:38<00:22,  8.34it/s]
10/09/2021 09:34:06 - INFO - trainer -     Num examples = 3258
10/09/2021 09:34:06 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.20it/s]
10/09/2021 09:34:10 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:34:10 - INFO - trainer -     T-F1 = 0.9912711402073106█████████████████▋ | 50/51 [00:03<00:00, 14.06it/s]
10/09/2021 09:34:10 - INFO - trainer -     T-F1(C) = 0.976878612716763
10/09/2021 09:34:10 - INFO - trainer -     T-F1(L) = 0.9910979228486648
10/09/2021 09:34:10 - INFO - trainer -     T-F1(O) = 0.9965300368683582
10/09/2021 09:34:10 - INFO - trainer -     T-F1(P) = 0.9970743124634289
10/09/2021 09:34:10 - INFO - trainer -     T-F1(S) = 0.9926131117266852
10/09/2021 09:34:10 - INFO - trainer -     T-F1(T) = 0.9735744089012518
10/09/2021 09:34:10 - INFO - trainer -     U-F1(A) = 0.7227722772277227
10/09/2021 09:34:10 - INFO - trainer -     U-F1(E) = 0.7536764705882353
10/09/2021 09:34:10 - INFO - trainer -     U-F1(I) = 0.2222222222222222
10/09/2021 09:34:10 - INFO - trainer -     U-F1(O) = 0.9647715381932332
10/09/2021 09:34:10 - INFO - trainer -     intent_acc = 0.9355432780847146
10/09/2021 09:34:10 - INFO - trainer -     loss = 0.22381478694139742
10/09/2021 09:34:10 - INFO - trainer -     semantic_frame_acc = 0.919889502762431
10/09/2021 09:34:10 - INFO - trainer -     slot_f1 = 0.9910714285714286
10/09/2021 09:34:10 - INFO - trainer -     slot_precision = 0.9902425425146362
10/09/2021 09:34:10 - INFO - trainer -     slot_recall = 0.9919017034347948

10/09/2021 09:34:10 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:34:10 - INFO - trainer -     T-F1 = 0.9908030199039122
10/09/2021 09:34:10 - INFO - trainer -     T-F1(C) = 0.9778434268833087
10/09/2021 09:34:10 - INFO - trainer -     T-F1(L) = 0.978978978978979
10/09/2021 09:34:10 - INFO - trainer -     T-F1(O) = 0.9963766156508571
10/09/2021 09:34:10 - INFO - trainer -     T-F1(P) = 0.9953106682297773
10/09/2021 09:34:10 - INFO - trainer -     T-F1(S) = 0.9949003245248029
10/09/2021 09:34:10 - INFO - trainer -     T-F1(T) = 0.9745042492917847
10/09/2021 09:34:10 - INFO - trainer -     U-F1(A) = 0.776255707762557
10/09/2021 09:34:10 - INFO - trainer -     U-F1(E) = 0.7737478411053541
10/09/2021 09:34:10 - INFO - trainer -     U-F1(I) = 0.36111111111111105
10/09/2021 09:34:10 - INFO - trainer -     U-F1(O) = 0.9645766914629826
10/09/2021 09:34:10 - INFO - trainer -     intent_acc = 0.934622467771639
10/09/2021 09:34:10 - INFO - trainer -     semantic_frame_acc = 0.9195825659914058
10/09/2021 09:34:10 - INFO - trainer -     slot_f1 = 0.9904521201909576
10/09/2021 09:34:10 - INFO - trainer -     slot_precision = 0.9960463146003954
10/09/2021 09:34:10 - INFO - trainer -     slot_recall = 0.9849204132923765
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 918/918 [02:05<00:00,  7.30it/s]
Epoch:  25%|██████████████████▊                                                        | 5/20 [16:49<45:43, 182.93s/it]10/09/2021 09:34:34 - INFO - trainer -   ***** Running evaluation on dev dataset *****  | 9/918 [00:01<01:48,  8.35it/s]
10/09/2021 09:34:34 - INFO - trainer -     Num examples = 3258
10/09/2021 09:34:34 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.20it/s]
10/09/2021 09:34:38 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:34:38 - INFO - trainer -     T-F1 = 0.9918256130790191█████████████████▋ | 50/51 [00:03<00:00, 14.17it/s]
10/09/2021 09:34:38 - INFO - trainer -     T-F1(C) = 0.9784791965566715
10/09/2021 09:34:38 - INFO - trainer -     T-F1(L) = 0.9851632047477745
10/09/2021 09:34:38 - INFO - trainer -     T-F1(O) = 0.9967454979388153
10/09/2021 09:34:38 - INFO - trainer -     T-F1(P) = 0.9973661106233538
10/09/2021 09:34:38 - INFO - trainer -     T-F1(S) = 0.9944598337950139
10/09/2021 09:34:38 - INFO - trainer -     T-F1(T) = 0.9737206085753805
10/09/2021 09:34:38 - INFO - trainer -     U-F1(A) = 0.6888888888888889
10/09/2021 09:34:38 - INFO - trainer -     U-F1(E) = 0.7672727272727273
10/09/2021 09:34:38 - INFO - trainer -     U-F1(I) = 0.30769230769230765
10/09/2021 09:34:38 - INFO - trainer -     U-F1(O) = 0.9637251482385769
10/09/2021 09:34:38 - INFO - trainer -     intent_acc = 0.9343155310006138
10/09/2021 09:34:38 - INFO - trainer -     loss = 0.22273406663946077
10/09/2021 09:34:38 - INFO - trainer -     semantic_frame_acc = 0.9195825659914058
10/09/2021 09:34:38 - INFO - trainer -     slot_f1 = 0.9914982578397212
10/09/2021 09:34:38 - INFO - trainer -     slot_precision = 0.9897050639955481
10/09/2021 09:34:38 - INFO - trainer -     slot_recall = 0.9932979614632784

10/09/2021 09:34:38 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:34:38 - INFO - trainer -     T-F1 = 0.9908030199039122
10/09/2021 09:34:38 - INFO - trainer -     T-F1(C) = 0.9778434268833087
10/09/2021 09:34:38 - INFO - trainer -     T-F1(L) = 0.978978978978979
10/09/2021 09:34:38 - INFO - trainer -     T-F1(O) = 0.9963766156508571
10/09/2021 09:34:38 - INFO - trainer -     T-F1(P) = 0.9953106682297773
10/09/2021 09:34:38 - INFO - trainer -     T-F1(S) = 0.9949003245248029
10/09/2021 09:34:38 - INFO - trainer -     T-F1(T) = 0.9745042492917847
10/09/2021 09:34:38 - INFO - trainer -     U-F1(A) = 0.776255707762557
10/09/2021 09:34:38 - INFO - trainer -     U-F1(E) = 0.7737478411053541
10/09/2021 09:34:38 - INFO - trainer -     U-F1(I) = 0.36111111111111105
10/09/2021 09:34:38 - INFO - trainer -     U-F1(O) = 0.9645766914629826
10/09/2021 09:34:38 - INFO - trainer -     intent_acc = 0.934622467771639
10/09/2021 09:34:38 - INFO - trainer -     semantic_frame_acc = 0.9195825659914058
10/09/2021 09:34:38 - INFO - trainer -     slot_f1 = 0.9904521201909576
10/09/2021 09:34:38 - INFO - trainer -     slot_precision = 0.9960463146003954
10/09/2021 09:34:38 - INFO - trainer -     slot_recall = 0.9849204132923765
                                                                                                                       10/09/2021 09:35:02 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 209/918 [00:28<01:24,  8.34it/s]
10/09/2021 09:35:02 - INFO - trainer -     Num examples = 3258
10/09/2021 09:35:02 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.25it/s]
10/09/2021 09:35:05 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:35:05 - INFO - trainer -     T-F1 = 0.9917943107221007█████████████████▋ | 50/51 [00:03<00:00, 14.15it/s]
10/09/2021 09:35:05 - INFO - trainer -     T-F1(C) = 0.9810771470160116
10/09/2021 09:35:05 - INFO - trainer -     T-F1(L) = 0.9880239520958084
10/09/2021 09:35:05 - INFO - trainer -     T-F1(O) = 0.9967504332755633
10/09/2021 09:35:05 - INFO - trainer -     T-F1(P) = 0.9959016393442623
10/09/2021 09:35:05 - INFO - trainer -     T-F1(S) = 0.9944444444444444
10/09/2021 09:35:05 - INFO - trainer -     T-F1(T) = 0.9762237762237763
10/09/2021 09:35:05 - INFO - trainer -     U-F1(A) = 0.696969696969697
10/09/2021 09:35:05 - INFO - trainer -     U-F1(E) = 0.7887323943661972
10/09/2021 09:35:05 - INFO - trainer -     U-F1(I) = 0.3333333333333333
10/09/2021 09:35:05 - INFO - trainer -     U-F1(O) = 0.9659410112359551
10/09/2021 09:35:05 - INFO - trainer -     intent_acc = 0.9370779619398404
10/09/2021 09:35:05 - INFO - trainer -     loss = 0.23642564842513963
10/09/2021 09:35:05 - INFO - trainer -     semantic_frame_acc = 0.9232658072437078
10/09/2021 09:35:05 - INFO - trainer -     slot_f1 = 0.9914673380892433
10/09/2021 09:35:05 - INFO - trainer -     slot_precision = 0.9932735426008968
10/09/2021 09:35:05 - INFO - trainer -     slot_recall = 0.9896676905892209

10/09/2021 09:35:05 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:35:05 - INFO - trainer -     T-F1 = 0.9908030199039122
10/09/2021 09:35:05 - INFO - trainer -     T-F1(C) = 0.9778434268833087
10/09/2021 09:35:05 - INFO - trainer -     T-F1(L) = 0.978978978978979
10/09/2021 09:35:05 - INFO - trainer -     T-F1(O) = 0.9963766156508571
10/09/2021 09:35:05 - INFO - trainer -     T-F1(P) = 0.9953106682297773
10/09/2021 09:35:05 - INFO - trainer -     T-F1(S) = 0.9949003245248029
10/09/2021 09:35:05 - INFO - trainer -     T-F1(T) = 0.9745042492917847
10/09/2021 09:35:05 - INFO - trainer -     U-F1(A) = 0.776255707762557
10/09/2021 09:35:05 - INFO - trainer -     U-F1(E) = 0.7737478411053541
10/09/2021 09:35:05 - INFO - trainer -     U-F1(I) = 0.36111111111111105
10/09/2021 09:35:05 - INFO - trainer -     U-F1(O) = 0.9645766914629826
10/09/2021 09:35:05 - INFO - trainer -     intent_acc = 0.934622467771639
10/09/2021 09:35:05 - INFO - trainer -     semantic_frame_acc = 0.9195825659914058
10/09/2021 09:35:05 - INFO - trainer -     slot_f1 = 0.9904521201909576
10/09/2021 09:35:05 - INFO - trainer -     slot_precision = 0.9960463146003954
10/09/2021 09:35:05 - INFO - trainer -     slot_recall = 0.9849204132923765
                                                                                                                       10/09/2021 09:35:29 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 409/918 [00:56<01:01,  8.29it/s]
10/09/2021 09:35:29 - INFO - trainer -     Num examples = 3258
10/09/2021 09:35:29 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.22it/s]
10/09/2021 09:35:33 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:35:33 - INFO - trainer -     T-F1 = 0.9916882409047554█████████████████▋ | 50/51 [00:03<00:00, 14.09it/s]
10/09/2021 09:35:33 - INFO - trainer -     T-F1(C) = 0.9742857142857144
10/09/2021 09:35:33 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:35:33 - INFO - trainer -     T-F1(O) = 0.9966914356999512
10/09/2021 09:35:33 - INFO - trainer -     T-F1(P) = 0.9976621858562245
10/09/2021 09:35:33 - INFO - trainer -     T-F1(S) = 0.995366079703429
10/09/2021 09:35:33 - INFO - trainer -     T-F1(T) = 0.9696132596685083
10/09/2021 09:35:33 - INFO - trainer -     U-F1(A) = 0.6127167630057804
10/09/2021 09:35:33 - INFO - trainer -     U-F1(E) = 0.7293666026871402
10/09/2021 09:35:33 - INFO - trainer -     U-F1(I) = 0.18604651162790697
10/09/2021 09:35:33 - INFO - trainer -     U-F1(O) = 0.9596816058141546
10/09/2021 09:35:33 - INFO - trainer -     intent_acc = 0.9269490484960098
10/09/2021 09:35:33 - INFO - trainer -     loss = 0.24815322970058404
10/09/2021 09:35:33 - INFO - trainer -     semantic_frame_acc = 0.9119091467157765
10/09/2021 09:35:33 - INFO - trainer -     slot_f1 = 0.9914982578397212
10/09/2021 09:35:33 - INFO - trainer -     slot_precision = 0.9897050639955481
10/09/2021 09:35:33 - INFO - trainer -     slot_recall = 0.9932979614632784

10/09/2021 09:35:33 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:35:33 - INFO - trainer -     T-F1 = 0.9908030199039122
10/09/2021 09:35:33 - INFO - trainer -     T-F1(C) = 0.9778434268833087
10/09/2021 09:35:33 - INFO - trainer -     T-F1(L) = 0.978978978978979
10/09/2021 09:35:33 - INFO - trainer -     T-F1(O) = 0.9963766156508571
10/09/2021 09:35:33 - INFO - trainer -     T-F1(P) = 0.9953106682297773
10/09/2021 09:35:33 - INFO - trainer -     T-F1(S) = 0.9949003245248029
10/09/2021 09:35:33 - INFO - trainer -     T-F1(T) = 0.9745042492917847
10/09/2021 09:35:33 - INFO - trainer -     U-F1(A) = 0.776255707762557
10/09/2021 09:35:33 - INFO - trainer -     U-F1(E) = 0.7737478411053541
10/09/2021 09:35:33 - INFO - trainer -     U-F1(I) = 0.36111111111111105
10/09/2021 09:35:33 - INFO - trainer -     U-F1(O) = 0.9645766914629826
10/09/2021 09:35:33 - INFO - trainer -     intent_acc = 0.934622467771639
10/09/2021 09:35:33 - INFO - trainer -     semantic_frame_acc = 0.9195825659914058
10/09/2021 09:35:33 - INFO - trainer -     slot_f1 = 0.9904521201909576
10/09/2021 09:35:33 - INFO - trainer -     slot_precision = 0.9960463146003954
10/09/2021 09:35:33 - INFO - trainer -     slot_recall = 0.9849204132923765
                                                                                                                       10/09/2021 09:35:57 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 609/918 [01:24<00:37,  8.32it/s]
10/09/2021 09:35:57 - INFO - trainer -     Num examples = 3258
10/09/2021 09:35:57 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.16it/s]
10/09/2021 09:36:01 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:36:01 - INFO - trainer -     T-F1 = 0.9908756638975895█████████████████▋ | 50/51 [00:03<00:00, 14.02it/s]
10/09/2021 09:36:01 - INFO - trainer -     T-F1(C) = 0.9728958630527819
10/09/2021 09:36:01 - INFO - trainer -     T-F1(L) = 0.9821428571428571
10/09/2021 09:36:01 - INFO - trainer -     T-F1(O) = 0.9963652145608419
10/09/2021 09:36:01 - INFO - trainer -     T-F1(P) = 0.9964932787843368
10/09/2021 09:36:01 - INFO - trainer -     T-F1(S) = 0.9944649446494466
10/09/2021 09:36:01 - INFO - trainer -     T-F1(T) = 0.9748603351955307
10/09/2021 09:36:01 - INFO - trainer -     U-F1(A) = 0.6432748538011696
10/09/2021 09:36:01 - INFO - trainer -     U-F1(E) = 0.7567567567567568
10/09/2021 09:36:01 - INFO - trainer -     U-F1(I) = 0.3111111111111111
10/09/2021 09:36:01 - INFO - trainer -     U-F1(O) = 0.9625761531766753
10/09/2021 09:36:01 - INFO - trainer -     intent_acc = 0.9321669736034377
10/09/2021 09:36:01 - INFO - trainer -     loss = 0.2569703966671345
10/09/2021 09:36:01 - INFO - trainer -     semantic_frame_acc = 0.9152854511970534
10/09/2021 09:36:01 - INFO - trainer -     slot_f1 = 0.9905292479108635
10/09/2021 09:36:01 - INFO - trainer -     slot_precision = 0.9880522367324257
10/09/2021 09:36:01 - INFO - trainer -     slot_recall = 0.9930187098575817

10/09/2021 09:36:01 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:36:01 - INFO - trainer -     T-F1 = 0.9908030199039122
10/09/2021 09:36:01 - INFO - trainer -     T-F1(C) = 0.9778434268833087
10/09/2021 09:36:01 - INFO - trainer -     T-F1(L) = 0.978978978978979
10/09/2021 09:36:01 - INFO - trainer -     T-F1(O) = 0.9963766156508571
10/09/2021 09:36:01 - INFO - trainer -     T-F1(P) = 0.9953106682297773
10/09/2021 09:36:01 - INFO - trainer -     T-F1(S) = 0.9949003245248029
10/09/2021 09:36:01 - INFO - trainer -     T-F1(T) = 0.9745042492917847
10/09/2021 09:36:01 - INFO - trainer -     U-F1(A) = 0.776255707762557
10/09/2021 09:36:01 - INFO - trainer -     U-F1(E) = 0.7737478411053541
10/09/2021 09:36:01 - INFO - trainer -     U-F1(I) = 0.36111111111111105
10/09/2021 09:36:01 - INFO - trainer -     U-F1(O) = 0.9645766914629826
10/09/2021 09:36:01 - INFO - trainer -     intent_acc = 0.934622467771639
10/09/2021 09:36:01 - INFO - trainer -     semantic_frame_acc = 0.9195825659914058
10/09/2021 09:36:01 - INFO - trainer -     slot_f1 = 0.9904521201909576
10/09/2021 09:36:01 - INFO - trainer -     slot_precision = 0.9960463146003954
10/09/2021 09:36:01 - INFO - trainer -     slot_recall = 0.9849204132923765
                                                                                                                       10/09/2021 09:36:25 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 809/918 [01:52<00:13,  8.33it/s]
10/09/2021 09:36:25 - INFO - trainer -     Num examples = 3258
10/09/2021 09:36:25 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.16it/s]
10/09/2021 09:36:29 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:36:29 - INFO - trainer -     T-F1 = 0.9912639912639912█████████████████▋ | 50/51 [00:03<00:00, 14.08it/s]
10/09/2021 09:36:29 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:36:29 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:36:29 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:36:29 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:36:29 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:36:29 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:36:29 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:36:29 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:36:29 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:36:29 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:36:29 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:36:29 - INFO - trainer -     loss = 0.2510740045165899
10/09/2021 09:36:29 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:36:29 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:36:29 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:36:29 - INFO - trainer -     slot_recall = 0.9910639486177045

10/09/2021 09:36:29 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:36:29 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:36:29 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:36:29 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:36:29 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:36:29 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:36:29 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:36:29 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:36:29 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:36:29 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:36:29 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:36:29 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:36:29 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:36:29 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:36:29 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:36:29 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:36:29 - INFO - trainer -     slot_recall = 0.9910639486177045
10/09/2021 09:36:29 - INFO - transformers.configuration_utils -   Configuration saved in final_low_distilbert_e_model\config.json
10/09/2021 09:36:30 - INFO - transformers.modeling_utils -   Model weights saved in final_low_distilbert_e_model\pytorch_model.bin
10/09/2021 09:36:30 - INFO - trainer -   Saving model checkpoint to final_low_distilbert_e_model
Best model saved
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 918/918 [02:10<00:00,  7.05it/s]
Epoch:  30%|██████████████████████▌                                                    | 6/20 [19:00<38:30, 165.01s/it]10/09/2021 09:36:54 - INFO - trainer -   ***** Running evaluation on dev dataset ***** | 91/918 [00:10<01:40,  8.23it/s]
10/09/2021 09:36:54 - INFO - trainer -     Num examples = 3258
10/09/2021 09:36:54 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.18it/s]
10/09/2021 09:36:58 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:36:58 - INFO - trainer -     T-F1 = 0.990450204638472██████████████████▋ | 50/51 [00:03<00:00, 14.08it/s]
10/09/2021 09:36:58 - INFO - trainer -     T-F1(C) = 0.9754689754689755
10/09/2021 09:36:58 - INFO - trainer -     T-F1(L) = 0.9880952380952381
10/09/2021 09:36:58 - INFO - trainer -     T-F1(O) = 0.996205139325599
10/09/2021 09:36:58 - INFO - trainer -     T-F1(P) = 0.9961954931226222
10/09/2021 09:36:58 - INFO - trainer -     T-F1(S) = 0.993984266543267
10/09/2021 09:36:58 - INFO - trainer -     T-F1(T) = 0.9681881051175656
10/09/2021 09:36:58 - INFO - trainer -     U-F1(A) = 0.7083333333333334
10/09/2021 09:36:58 - INFO - trainer -     U-F1(E) = 0.6910569105691057
10/09/2021 09:36:58 - INFO - trainer -     U-F1(I) = 0.2702702702702703
10/09/2021 09:36:58 - INFO - trainer -     U-F1(O) = 0.961518550474547
10/09/2021 09:36:58 - INFO - trainer -     intent_acc = 0.9297114794352364
10/09/2021 09:36:58 - INFO - trainer -     loss = 0.3091435802041316
10/09/2021 09:36:58 - INFO - trainer -     semantic_frame_acc = 0.9140577041129527
10/09/2021 09:36:58 - INFO - trainer -     slot_f1 = 0.9900934840239988
10/09/2021 09:36:58 - INFO - trainer -     slot_precision = 0.9894032348020078
10/09/2021 09:36:58 - INFO - trainer -     slot_recall = 0.9907846970120078

10/09/2021 09:36:58 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:36:58 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:36:58 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:36:58 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:36:58 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:36:58 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:36:58 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:36:58 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:36:58 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:36:58 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:36:58 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:36:58 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:36:58 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:36:58 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:36:58 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:36:58 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:36:58 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:37:22 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 291/918 [00:38<01:15,  8.34it/s]
10/09/2021 09:37:22 - INFO - trainer -     Num examples = 3258
10/09/2021 09:37:22 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.14it/s]
10/09/2021 09:37:26 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:37:26 - INFO - trainer -     T-F1 = 0.9915531335149864█████████████████▋ | 50/51 [00:03<00:00, 14.08it/s]
10/09/2021 09:37:26 - INFO - trainer -     T-F1(C) = 0.9742857142857144
10/09/2021 09:37:26 - INFO - trainer -     T-F1(L) = 0.9881656804733727
10/09/2021 09:37:26 - INFO - trainer -     T-F1(O) = 0.9966370145367759
10/09/2021 09:37:26 - INFO - trainer -     T-F1(P) = 0.9976608187134504
10/09/2021 09:37:26 - INFO - trainer -     T-F1(S) = 0.9958314034275128
10/09/2021 09:37:26 - INFO - trainer -     T-F1(T) = 0.9681881051175656
10/09/2021 09:37:26 - INFO - trainer -     U-F1(A) = 0.7559808612440191
10/09/2021 09:37:26 - INFO - trainer -     U-F1(E) = 0.7570621468926554
10/09/2021 09:37:26 - INFO - trainer -     U-F1(I) = 0.35714285714285715
10/09/2021 09:37:26 - INFO - trainer -     U-F1(O) = 0.9657342657342657
10/09/2021 09:37:26 - INFO - trainer -     intent_acc = 0.9367710251688153
10/09/2021 09:37:26 - INFO - trainer -     loss = 0.27304762587243436
10/09/2021 09:37:26 - INFO - trainer -     semantic_frame_acc = 0.9229588704726827
10/09/2021 09:37:26 - INFO - trainer -     slot_f1 = 0.991221959035809
10/09/2021 09:37:26 - INFO - trainer -     slot_precision = 0.989154616240267
10/09/2021 09:37:26 - INFO - trainer -     slot_recall = 0.9932979614632784

10/09/2021 09:37:26 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:37:26 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:37:26 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:37:26 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:37:26 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:37:26 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:37:26 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:37:26 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:37:26 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:37:26 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:37:26 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:37:26 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:37:26 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:37:26 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:37:26 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:37:26 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:37:26 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:37:50 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 491/918 [01:06<00:51,  8.33it/s]
10/09/2021 09:37:50 - INFO - trainer -     Num examples = 3258
10/09/2021 09:37:50 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.13it/s]
10/09/2021 09:37:54 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:37:54 - INFO - trainer -     T-F1 = 0.9907356948228884█████████████████▋ | 50/51 [00:03<00:00, 14.06it/s]
10/09/2021 09:37:54 - INFO - trainer -     T-F1(C) = 0.9715909090909091
10/09/2021 09:37:54 - INFO - trainer -     T-F1(L) = 0.9880239520958084
10/09/2021 09:37:54 - INFO - trainer -     T-F1(O) = 0.9963115643306574
10/09/2021 09:37:54 - INFO - trainer -     T-F1(P) = 0.9959088252483926
10/09/2021 09:37:54 - INFO - trainer -     T-F1(S) = 0.9958391123439667
10/09/2021 09:37:54 - INFO - trainer -     T-F1(T) = 0.9707112970711297
10/09/2021 09:37:54 - INFO - trainer -     U-F1(A) = 0.7032967032967034
10/09/2021 09:37:54 - INFO - trainer -     U-F1(E) = 0.7751371115173674
10/09/2021 09:37:54 - INFO - trainer -     U-F1(I) = 0.2916666666666667
10/09/2021 09:37:54 - INFO - trainer -     U-F1(O) = 0.9653249695068827
10/09/2021 09:37:54 - INFO - trainer -     intent_acc = 0.9370779619398404
10/09/2021 09:37:54 - INFO - trainer -     loss = 0.2673587235165577
10/09/2021 09:37:54 - INFO - trainer -     semantic_frame_acc = 0.9208103130755064
10/09/2021 09:37:54 - INFO - trainer -     slot_f1 = 0.9903859551344572
10/09/2021 09:37:54 - INFO - trainer -     slot_precision = 0.9883203559510567
10/09/2021 09:37:54 - INFO - trainer -     slot_recall = 0.9924602066461882

10/09/2021 09:37:54 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:37:54 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:37:54 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:37:54 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:37:54 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:37:54 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:37:54 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:37:54 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:37:54 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:37:54 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:37:54 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:37:54 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:37:54 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:37:54 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:37:54 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:37:54 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:37:54 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:38:18 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 691/918 [01:35<00:27,  8.36it/s]
10/09/2021 09:38:18 - INFO - trainer -     Num examples = 3258
10/09/2021 09:38:18 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.11it/s]
10/09/2021 09:38:22 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:38:22 - INFO - trainer -     T-F1 = 0.9907508161044613█████████████████▋ | 50/51 [00:03<00:00, 14.03it/s]
10/09/2021 09:38:22 - INFO - trainer -     T-F1(C) = 0.972818311874106
10/09/2021 09:38:22 - INFO - trainer -     T-F1(L) = 0.9793510324483775
10/09/2021 09:38:22 - INFO - trainer -     T-F1(O) = 0.9963091619626575
10/09/2021 09:38:22 - INFO - trainer -     T-F1(P) = 0.9979550102249489
10/09/2021 09:38:22 - INFO - trainer -     T-F1(S) = 0.994919168591224
10/09/2021 09:38:22 - INFO - trainer -     T-F1(T) = 0.9669421487603306
10/09/2021 09:38:22 - INFO - trainer -     U-F1(A) = 0.7623762376237623
10/09/2021 09:38:22 - INFO - trainer -     U-F1(E) = 0.770949720670391
10/09/2021 09:38:22 - INFO - trainer -     U-F1(I) = 0.2916666666666667
10/09/2021 09:38:22 - INFO - trainer -     U-F1(O) = 0.9666608483155874
10/09/2021 09:38:22 - INFO - trainer -     intent_acc = 0.9392265193370166
10/09/2021 09:38:22 - INFO - trainer -     loss = 0.25538092771289395
10/09/2021 09:38:22 - INFO - trainer -     semantic_frame_acc = 0.9220380601596071
10/09/2021 09:38:22 - INFO - trainer -     slot_f1 = 0.9904020030602309
10/09/2021 09:38:22 - INFO - trainer -     slot_precision = 0.9866962305986696
10/09/2021 09:38:22 - INFO - trainer -     slot_recall = 0.9941357162803686

10/09/2021 09:38:22 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:38:22 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:38:22 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:38:22 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:38:22 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:38:22 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:38:22 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:38:22 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:38:22 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:38:22 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:38:22 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:38:22 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:38:22 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:38:22 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:38:22 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:38:22 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:38:22 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:38:46 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 891/918 [02:03<00:03,  8.32it/s]
10/09/2021 09:38:46 - INFO - trainer -     Num examples = 3258
10/09/2021 09:38:46 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.14it/s]
10/09/2021 09:38:50 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:38:50 - INFO - trainer -     T-F1 = 0.990598174138166██████████████████▋ | 50/51 [00:03<00:00, 14.06it/s]
10/09/2021 09:38:50 - INFO - trainer -     T-F1(C) = 0.9688385269121813
10/09/2021 09:38:50 - INFO - trainer -     T-F1(L) = 0.9909909909909909
10/09/2021 09:38:50 - INFO - trainer -     T-F1(O) = 0.9962575256278136
10/09/2021 09:38:50 - INFO - trainer -     T-F1(P) = 0.997081144191477
10/09/2021 09:38:50 - INFO - trainer -     T-F1(S) = 0.995366079703429
10/09/2021 09:38:50 - INFO - trainer -     T-F1(T) = 0.9664804469273743
10/09/2021 09:38:50 - INFO - trainer -     U-F1(A) = 0.7572815533980582
10/09/2021 09:38:50 - INFO - trainer -     U-F1(E) = 0.7103174603174603
10/09/2021 09:38:50 - INFO - trainer -     U-F1(I) = 0.2916666666666667
10/09/2021 09:38:50 - INFO - trainer -     U-F1(O) = 0.9628343174713442
10/09/2021 09:38:50 - INFO - trainer -     intent_acc = 0.9318600368324125
10/09/2021 09:38:50 - INFO - trainer -     loss = 0.2797260350164245
10/09/2021 09:38:50 - INFO - trainer -     semantic_frame_acc = 0.916206261510129
10/09/2021 09:38:50 - INFO - trainer -     slot_f1 = 0.9902452619843924
10/09/2021 09:38:50 - INFO - trainer -     slot_precision = 0.988317107093185
10/09/2021 09:38:50 - INFO - trainer -     slot_recall = 0.9921809550404915

10/09/2021 09:38:50 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:38:50 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:38:50 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:38:50 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:38:50 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:38:50 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:38:50 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:38:50 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:38:50 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:38:50 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:38:50 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:38:50 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:38:50 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:38:50 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:38:50 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:38:50 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:38:50 - INFO - trainer -     slot_recall = 0.9910639486177045
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 918/918 [02:10<00:00,  7.05it/s]
Epoch:  35%|██████████████████████████▎                                                | 7/20 [21:10<33:17, 153.65s/it]10/09/2021 09:39:14 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 173/918 [00:20<01:29,  8.34it/s]
10/09/2021 09:39:14 - INFO - trainer -     Num examples = 3258
10/09/2021 09:39:14 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.14it/s]
10/09/2021 09:39:18 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:39:18 - INFO - trainer -     T-F1 = 0.9891422366992398█████████████████▋ | 50/51 [00:03<00:00, 14.05it/s]
10/09/2021 09:39:18 - INFO - trainer -     T-F1(C) = 0.9701280227596016
10/09/2021 09:39:18 - INFO - trainer -     T-F1(L) = 0.9881656804733727
10/09/2021 09:39:18 - INFO - trainer -     T-F1(O) = 0.9956540634506735
10/09/2021 09:39:18 - INFO - trainer -     T-F1(P) = 0.9964953271028038
10/09/2021 09:39:18 - INFO - trainer -     T-F1(S) = 0.9908172635445363
10/09/2021 09:39:18 - INFO - trainer -     T-F1(T) = 0.9682758620689655
10/09/2021 09:39:18 - INFO - trainer -     U-F1(A) = 0.736318407960199
10/09/2021 09:39:18 - INFO - trainer -     U-F1(E) = 0.7325581395348838
10/09/2021 09:39:18 - INFO - trainer -     U-F1(I) = 0.27906976744186046
10/09/2021 09:39:18 - INFO - trainer -     U-F1(O) = 0.96455872133426
10/09/2021 09:39:18 - INFO - trainer -     intent_acc = 0.934622467771639
10/09/2021 09:39:18 - INFO - trainer -     loss = 0.3283203182121118
10/09/2021 09:39:18 - INFO - trainer -     semantic_frame_acc = 0.9146715776550031
10/09/2021 09:39:18 - INFO - trainer -     slot_f1 = 0.9888950583009439
10/09/2021 09:39:18 - INFO - trainer -     slot_precision = 0.9831631244824731
10/09/2021 09:39:18 - INFO - trainer -     slot_recall = 0.9946942194917621

10/09/2021 09:39:18 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:39:18 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:39:18 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:39:18 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:39:18 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:39:18 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:39:18 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:39:18 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:39:18 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:39:18 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:39:18 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:39:18 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:39:18 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:39:18 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:39:18 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:39:18 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:39:18 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:39:42 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 373/918 [00:48<01:05,  8.35it/s]
10/09/2021 09:39:42 - INFO - trainer -     Num examples = 3258
10/09/2021 09:39:42 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.13it/s]
10/09/2021 09:39:46 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:39:46 - INFO - trainer -     T-F1 = 0.9899072558647027█████████████████▋ | 50/51 [00:03<00:00, 14.03it/s]
10/09/2021 09:39:46 - INFO - trainer -     T-F1(C) = 0.9754689754689755
10/09/2021 09:39:46 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:39:46 - INFO - trainer -     T-F1(O) = 0.9959878551290392
10/09/2021 09:39:46 - INFO - trainer -     T-F1(P) = 0.9964891749561146
10/09/2021 09:39:46 - INFO - trainer -     T-F1(S) = 0.992169507139567
10/09/2021 09:39:46 - INFO - trainer -     T-F1(T) = 0.9650349650349651
10/09/2021 09:39:46 - INFO - trainer -     U-F1(A) = 0.7216494845360824
10/09/2021 09:39:46 - INFO - trainer -     U-F1(E) = 0.7448015122873347
10/09/2021 09:39:46 - INFO - trainer -     U-F1(I) = 0.2857142857142857
10/09/2021 09:39:46 - INFO - trainer -     U-F1(O) = 0.9628725814885829
10/09/2021 09:39:46 - INFO - trainer -     intent_acc = 0.9321669736034377
10/09/2021 09:39:46 - INFO - trainer -     loss = 0.33449997212372573
10/09/2021 09:39:46 - INFO - trainer -     semantic_frame_acc = 0.9146715776550031
10/09/2021 09:39:46 - INFO - trainer -     slot_f1 = 0.9895382898591156
10/09/2021 09:39:46 - INFO - trainer -     slot_precision = 0.9885730211817169
10/09/2021 09:39:46 - INFO - trainer -     slot_recall = 0.9905054454063111

10/09/2021 09:39:46 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:39:46 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:39:46 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:39:46 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:39:46 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:39:46 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:39:46 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:39:46 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:39:46 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:39:46 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:39:46 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:39:46 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:39:46 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:39:46 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:39:46 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:39:46 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:39:46 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:40:10 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 573/918 [01:16<00:42,  8.04it/s]
10/09/2021 09:40:10 - INFO - trainer -     Num examples = 3258
10/09/2021 09:40:10 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 13.76it/s]
10/09/2021 09:40:14 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:40:14 - INFO - trainer -     T-F1 = 0.9903335602450646█████████████████▋ | 50/51 [00:03<00:00, 13.85it/s]
10/09/2021 09:40:14 - INFO - trainer -     T-F1(C) = 0.9715909090909091
10/09/2021 09:40:14 - INFO - trainer -     T-F1(L) = 0.9910979228486648
10/09/2021 09:40:14 - INFO - trainer -     T-F1(O) = 0.9961477944766968
10/09/2021 09:40:14 - INFO - trainer -     T-F1(P) = 0.9970794392523364
10/09/2021 09:40:14 - INFO - trainer -     T-F1(S) = 0.9916820702402956
10/09/2021 09:40:14 - INFO - trainer -     T-F1(T) = 0.9720670391061452
10/09/2021 09:40:14 - INFO - trainer -     U-F1(A) = 0.6553672316384181
10/09/2021 09:40:14 - INFO - trainer -     U-F1(E) = 0.7589928057553957
10/09/2021 09:40:14 - INFO - trainer -     U-F1(I) = 0.3
10/09/2021 09:40:14 - INFO - trainer -     U-F1(O) = 0.9632596204074525
10/09/2021 09:40:14 - INFO - trainer -     intent_acc = 0.9333947206875384
10/09/2021 09:40:14 - INFO - trainer -     loss = 0.3524543221893848
10/09/2021 09:40:14 - INFO - trainer -     semantic_frame_acc = 0.9158993247391037
10/09/2021 09:40:14 - INFO - trainer -     slot_f1 = 0.9899749373433584
10/09/2021 09:40:14 - INFO - trainer -     slot_precision = 0.9872257706192724
10/09/2021 09:40:14 - INFO - trainer -     slot_recall = 0.9927394582518849

10/09/2021 09:40:14 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:40:14 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:40:14 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:40:14 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:40:14 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:40:14 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:40:14 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:40:14 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:40:14 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:40:14 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:40:14 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:40:14 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:40:14 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:40:14 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:40:14 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:40:14 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:40:14 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:40:38 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 773/918 [01:45<00:17,  8.20it/s]
10/09/2021 09:40:38 - INFO - trainer -     Num examples = 3258
10/09/2021 09:40:38 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 13.87it/s]
10/09/2021 09:40:43 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:40:43 - INFO - trainer -     T-F1 = 0.9876576698765767█████████████████▋ | 50/51 [00:03<00:00, 13.64it/s]
10/09/2021 09:40:43 - INFO - trainer -     T-F1(C) = 0.9728958630527819
10/09/2021 09:40:43 - INFO - trainer -     T-F1(L) = 0.9545454545454545
10/09/2021 09:40:43 - INFO - trainer -     T-F1(O) = 0.9950551540509699
10/09/2021 09:40:43 - INFO - trainer -     T-F1(P) = 0.9967864446392054
10/09/2021 09:40:43 - INFO - trainer -     T-F1(S) = 0.9912482726853985
10/09/2021 09:40:43 - INFO - trainer -     T-F1(T) = 0.9641873278236915
10/09/2021 09:40:43 - INFO - trainer -     U-F1(A) = 0.711340206185567
10/09/2021 09:40:43 - INFO - trainer -     U-F1(E) = 0.7509293680297398
10/09/2021 09:40:43 - INFO - trainer -     U-F1(I) = 0.27906976744186046
10/09/2021 09:40:43 - INFO - trainer -     U-F1(O) = 0.9635951924751786
10/09/2021 09:40:43 - INFO - trainer -     intent_acc = 0.9340085942295887
10/09/2021 09:40:43 - INFO - trainer -     loss = 0.30585517076885
10/09/2021 09:40:43 - INFO - trainer -     semantic_frame_acc = 0.9116022099447514
10/09/2021 09:40:43 - INFO - trainer -     slot_f1 = 0.987239944521498
10/09/2021 09:40:43 - INFO - trainer -     slot_precision = 0.9807109396527969
10/09/2021 09:40:43 - INFO - trainer -     slot_recall = 0.9938564646746719

10/09/2021 09:40:43 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:40:43 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:40:43 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:40:43 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:40:43 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:40:43 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:40:43 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:40:43 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:40:43 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:40:43 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:40:43 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:40:43 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:40:43 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:40:43 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:40:43 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:40:43 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:40:43 - INFO - trainer -     slot_recall = 0.9910639486177045
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 918/918 [02:06<00:00,  7.23it/s]
Epoch:  40%|██████████████████████████████                                             | 8/20 [23:17<29:01, 145.14s/it]10/09/2021 09:41:07 - INFO - trainer -   ***** Running evaluation on dev dataset ***** | 55/918 [00:06<01:43,  8.37it/s]
10/09/2021 09:41:07 - INFO - trainer -     Num examples = 3258
10/09/2021 09:41:07 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.06it/s]
10/09/2021 09:41:11 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:41:11 - INFO - trainer -     T-F1 = 0.9889900774772327█████████████████▋ | 50/51 [00:03<00:00, 13.96it/s]
10/09/2021 09:41:11 - INFO - trainer -     T-F1(C) = 0.9742857142857144
10/09/2021 09:41:11 - INFO - trainer -     T-F1(L) = 0.9739130434782608
10/09/2021 09:41:11 - INFO - trainer -     T-F1(O) = 0.9956023671209078
10/09/2021 09:41:11 - INFO - trainer -     T-F1(P) = 0.9964932787843368
10/09/2021 09:41:11 - INFO - trainer -     T-F1(S) = 0.9921622867680959
10/09/2021 09:41:11 - INFO - trainer -     T-F1(T) = 0.9653259361997226
10/09/2021 09:41:11 - INFO - trainer -     U-F1(A) = 0.751269035532995
10/09/2021 09:41:11 - INFO - trainer -     U-F1(E) = 0.7390476190476191
10/09/2021 09:41:11 - INFO - trainer -     U-F1(I) = 0.27272727272727276
10/09/2021 09:41:11 - INFO - trainer -     U-F1(O) = 0.9638260869565217
10/09/2021 09:41:11 - INFO - trainer -     intent_acc = 0.934622467771639
10/09/2021 09:41:11 - INFO - trainer -     loss = 0.3571871573141977
10/09/2021 09:41:11 - INFO - trainer -     semantic_frame_acc = 0.9158993247391037
10/09/2021 09:41:11 - INFO - trainer -     slot_f1 = 0.9884642112578179
10/09/2021 09:41:11 - INFO - trainer -     slot_precision = 0.9839513004980631
10/09/2021 09:41:11 - INFO - trainer -     slot_recall = 0.9930187098575817

10/09/2021 09:41:11 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:41:11 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:41:11 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:41:11 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:41:11 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:41:11 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:41:11 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:41:11 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:41:11 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:41:11 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:41:11 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:41:11 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:41:11 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:41:11 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:41:11 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:41:11 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:41:11 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:41:35 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 255/918 [00:34<01:20,  8.28it/s]
10/09/2021 09:41:35 - INFO - trainer -     Num examples = 3258
10/09/2021 09:41:35 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.03it/s]
10/09/2021 09:41:39 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:41:39 - INFO - trainer -     T-F1 = 0.9903309274138635█████████████████▋ | 50/51 [00:03<00:00, 13.87it/s]
10/09/2021 09:41:39 - INFO - trainer -     T-F1(C) = 0.9769452449567723
10/09/2021 09:41:39 - INFO - trainer -     T-F1(L) = 0.9851632047477745
10/09/2021 09:41:39 - INFO - trainer -     T-F1(O) = 0.9961482124450713
10/09/2021 09:41:39 - INFO - trainer -     T-F1(P) = 0.9967864446392054
10/09/2021 09:41:39 - INFO - trainer -     T-F1(S) = 0.9926131117266852
10/09/2021 09:41:39 - INFO - trainer -     T-F1(T) = 0.9681881051175656
10/09/2021 09:41:39 - INFO - trainer -     U-F1(A) = 0.6740331491712707
10/09/2021 09:41:39 - INFO - trainer -     U-F1(E) = 0.7269230769230769
10/09/2021 09:41:39 - INFO - trainer -     U-F1(I) = 0.2857142857142857
10/09/2021 09:41:39 - INFO - trainer -     U-F1(O) = 0.9617183440152434
10/09/2021 09:41:39 - INFO - trainer -     intent_acc = 0.9306322897483118
10/09/2021 09:41:39 - INFO - trainer -     loss = 0.40919454592992277
10/09/2021 09:41:39 - INFO - trainer -     semantic_frame_acc = 0.914364640883978
10/09/2021 09:41:39 - INFO - trainer -     slot_f1 = 0.9898314528485862
10/09/2021 09:41:39 - INFO - trainer -     slot_precision = 0.9874930516953864
10/09/2021 09:41:39 - INFO - trainer -     slot_recall = 0.9921809550404915

10/09/2021 09:41:39 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:41:39 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:41:39 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:41:39 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:41:39 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:41:39 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:41:39 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:41:39 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:41:39 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:41:39 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:41:39 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:41:39 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:41:39 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:41:39 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:41:39 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:41:39 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:41:39 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:42:03 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 455/918 [01:02<00:55,  8.30it/s]
10/09/2021 09:42:03 - INFO - trainer -     Num examples = 3258
10/09/2021 09:42:03 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.08it/s]
10/09/2021 09:42:07 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:42:07 - INFO - trainer -     T-F1 = 0.9893964110929854█████████████████▋ | 50/51 [00:03<00:00, 13.96it/s]
10/09/2021 09:42:07 - INFO - trainer -     T-F1(C) = 0.9702970297029703
10/09/2021 09:42:07 - INFO - trainer -     T-F1(L) = 0.9852507374631269
10/09/2021 09:42:07 - INFO - trainer -     T-F1(O) = 0.9957654723127036
10/09/2021 09:42:07 - INFO - trainer -     T-F1(P) = 0.9976635514018691
10/09/2021 09:42:07 - INFO - trainer -     T-F1(S) = 0.9903091832025841
10/09/2021 09:42:07 - INFO - trainer -     T-F1(T) = 0.9680111265646731
10/09/2021 09:42:07 - INFO - trainer -     U-F1(A) = 0.7021276595744681
10/09/2021 09:42:07 - INFO - trainer -     U-F1(E) = 0.7442748091603053
10/09/2021 09:42:07 - INFO - trainer -     U-F1(I) = 0.25
10/09/2021 09:42:07 - INFO - trainer -     U-F1(O) = 0.9624739402362752
10/09/2021 09:42:07 - INFO - trainer -     intent_acc = 0.9321669736034377
10/09/2021 09:42:07 - INFO - trainer -     loss = 0.3572171899471797
10/09/2021 09:42:07 - INFO - trainer -     semantic_frame_acc = 0.9134438305709024
10/09/2021 09:42:07 - INFO - trainer -     slot_f1 = 0.9890170999582929
10/09/2021 09:42:07 - INFO - trainer -     slot_precision = 0.9847729789590255
10/09/2021 09:42:07 - INFO - trainer -     slot_recall = 0.9932979614632784

10/09/2021 09:42:07 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:42:07 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:42:07 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:42:07 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:42:07 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:42:07 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:42:07 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:42:07 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:42:07 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:42:07 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:42:07 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:42:07 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:42:07 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:42:07 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:42:07 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:42:07 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:42:07 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:42:31 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 655/918 [01:30<00:31,  8.37it/s]
10/09/2021 09:42:31 - INFO - trainer -     Num examples = 3258
10/09/2021 09:42:31 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.07it/s]
10/09/2021 09:42:35 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:42:35 - INFO - trainer -     T-F1 = 0.9897917517354021█████████████████▋ | 50/51 [00:03<00:00, 14.01it/s]
10/09/2021 09:42:35 - INFO - trainer -     T-F1(C) = 0.9647390691114246
10/09/2021 09:42:35 - INFO - trainer -     T-F1(L) = 0.9880239520958084
10/09/2021 09:42:35 - INFO - trainer -     T-F1(O) = 0.9959303272016929
10/09/2021 09:42:35 - INFO - trainer -     T-F1(P) = 0.9976608187134504
10/09/2021 09:42:35 - INFO - trainer -     T-F1(S) = 0.9912240184757506
10/09/2021 09:42:35 - INFO - trainer -     T-F1(T) = 0.9735744089012518
10/09/2021 09:42:35 - INFO - trainer -     U-F1(A) = 0.7448979591836734
10/09/2021 09:42:35 - INFO - trainer -     U-F1(E) = 0.7145631067961166
10/09/2021 09:42:35 - INFO - trainer -     U-F1(I) = 0.20512820512820512
10/09/2021 09:42:35 - INFO - trainer -     U-F1(O) = 0.9621921609434616
10/09/2021 09:42:35 - INFO - trainer -     intent_acc = 0.9315531000613874
10/09/2021 09:42:35 - INFO - trainer -     loss = 0.38475952007095604
10/09/2021 09:42:35 - INFO - trainer -     semantic_frame_acc = 0.9134438305709024
10/09/2021 09:42:35 - INFO - trainer -     slot_f1 = 0.9894209354120267
10/09/2021 09:42:35 - INFO - trainer -     slot_precision = 0.9864002220371912
10/09/2021 09:42:35 - INFO - trainer -     slot_recall = 0.9924602066461882

10/09/2021 09:42:35 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:42:35 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:42:35 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:42:35 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:42:35 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:42:35 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:42:35 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:42:35 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:42:35 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:42:35 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:42:35 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:42:35 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:42:35 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:42:35 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:42:35 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:42:35 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:42:35 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:42:59 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 855/918 [01:58<00:07,  8.33it/s]
10/09/2021 09:42:59 - INFO - trainer -     Num examples = 3258
10/09/2021 09:42:59 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.09it/s]
10/09/2021 09:43:03 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:43:03 - INFO - trainer -     T-F1 = 0.9900612661674608█████████████████▋ | 50/51 [00:03<00:00, 13.98it/s]
10/09/2021 09:43:03 - INFO - trainer -     T-F1(C) = 0.9701280227596016
10/09/2021 09:43:03 - INFO - trainer -     T-F1(L) = 0.9940119760479043
10/09/2021 09:43:03 - INFO - trainer -     T-F1(O) = 0.9960392816450545
10/09/2021 09:43:03 - INFO - trainer -     T-F1(P) = 0.9961977186311787
10/09/2021 09:43:03 - INFO - trainer -     T-F1(S) = 0.993077988001846
10/09/2021 09:43:03 - INFO - trainer -     T-F1(T) = 0.9695290858725762
10/09/2021 09:43:03 - INFO - trainer -     U-F1(A) = 0.6265060240963856
10/09/2021 09:43:03 - INFO - trainer -     U-F1(E) = 0.7419962335216573
10/09/2021 09:43:03 - INFO - trainer -     U-F1(I) = 0.24390243902439024
10/09/2021 09:43:03 - INFO - trainer -     U-F1(O) = 0.9622706818968502
10/09/2021 09:43:03 - INFO - trainer -     intent_acc = 0.9312461632903621
10/09/2021 09:43:03 - INFO - trainer -     loss = 0.4030814539714187
10/09/2021 09:43:03 - INFO - trainer -     semantic_frame_acc = 0.9137507673419276
10/09/2021 09:43:03 - INFO - trainer -     slot_f1 = 0.9896964633806739
10/09/2021 09:43:03 - INFO - trainer -     slot_precision = 0.986948069980561
10/09/2021 09:43:03 - INFO - trainer -     slot_recall = 0.9924602066461882

10/09/2021 09:43:03 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:43:03 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:43:03 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:43:03 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:43:03 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:43:03 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:43:03 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:43:03 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:43:03 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:43:03 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:43:03 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:43:03 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:43:03 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:43:03 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:43:03 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:43:03 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:43:03 - INFO - trainer -     slot_recall = 0.9910639486177045
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 918/918 [02:10<00:00,  7.05it/s]
Epoch:  45%|█████████████████████████████████▊                                         | 9/20 [25:27<25:45, 140.49s/it]10/09/2021 09:43:27 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 137/918 [00:16<01:34,  8.31it/s]
10/09/2021 09:43:27 - INFO - trainer -     Num examples = 3258
10/09/2021 09:43:27 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.11it/s]
10/09/2021 09:43:31 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:43:31 - INFO - trainer -     T-F1 = 0.9910008181074448█████████████████▋ | 50/51 [00:03<00:00, 13.99it/s]
10/09/2021 09:43:31 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:43:31 - INFO - trainer -     T-F1(L) = 0.9764705882352942
10/09/2021 09:43:31 - INFO - trainer -     T-F1(O) = 0.9964212124498428
10/09/2021 09:43:31 - INFO - trainer -     T-F1(P) = 0.9967826849956127
10/09/2021 09:43:31 - INFO - trainer -     T-F1(S) = 0.994914470642626
10/09/2021 09:43:31 - INFO - trainer -     T-F1(T) = 0.970873786407767
10/09/2021 09:43:31 - INFO - trainer -     U-F1(A) = 0.717948717948718
10/09/2021 09:43:31 - INFO - trainer -     U-F1(E) = 0.7049504950495049
10/09/2021 09:43:31 - INFO - trainer -     U-F1(I) = 0.2777777777777778
10/09/2021 09:43:31 - INFO - trainer -     U-F1(O) = 0.9629757785467128
10/09/2021 09:43:31 - INFO - trainer -     intent_acc = 0.9318600368324125
10/09/2021 09:43:31 - INFO - trainer -     loss = 0.38735268495100383
10/09/2021 09:43:31 - INFO - trainer -     semantic_frame_acc = 0.9168201350521793
10/09/2021 09:43:31 - INFO - trainer -     slot_f1 = 0.9906568121600893
10/09/2021 09:43:31 - INFO - trainer -     slot_precision = 0.9894150417827298
10/09/2021 09:43:31 - INFO - trainer -     slot_recall = 0.9919017034347948

10/09/2021 09:43:31 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:43:31 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:43:31 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:43:31 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:43:31 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:43:31 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:43:31 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:43:31 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:43:31 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:43:31 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:43:31 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:43:31 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:43:31 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:43:31 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:43:31 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:43:31 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:43:31 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:43:55 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 337/918 [00:44<01:10,  8.24it/s]
10/09/2021 09:43:55 - INFO - trainer -     Num examples = 3258
10/09/2021 09:43:55 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.08it/s]
10/09/2021 09:43:59 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:43:59 - INFO - trainer -     T-F1 = 0.9915416098226466█████████████████▋ | 50/51 [00:03<00:00, 13.99it/s]
10/09/2021 09:43:59 - INFO - trainer -     T-F1(C) = 0.9770114942528736
10/09/2021 09:43:59 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:43:59 - INFO - trainer -     T-F1(O) = 0.9966388376883878
10/09/2021 09:43:59 - INFO - trainer -     T-F1(P) = 0.9970777323202805
10/09/2021 09:43:59 - INFO - trainer -     T-F1(S) = 0.9926062846580406
10/09/2021 09:43:59 - INFO - trainer -     T-F1(T) = 0.9761570827489481
10/09/2021 09:43:59 - INFO - trainer -     U-F1(A) = 0.7309644670050761
10/09/2021 09:43:59 - INFO - trainer -     U-F1(E) = 0.7177570093457945
10/09/2021 09:43:59 - INFO - trainer -     U-F1(I) = 0.3508771929824561
10/09/2021 09:43:59 - INFO - trainer -     U-F1(O) = 0.960712414876899
10/09/2021 09:43:59 - INFO - trainer -     intent_acc = 0.9284837323511357
10/09/2021 09:43:59 - INFO - trainer -     loss = 0.3875403882679986
10/09/2021 09:43:59 - INFO - trainer -     semantic_frame_acc = 0.9131368937998773
10/09/2021 09:43:59 - INFO - trainer -     slot_f1 = 0.9912097111762244
10/09/2021 09:43:59 - INFO - trainer -     slot_precision = 0.9905186837702176
10/09/2021 09:43:59 - INFO - trainer -     slot_recall = 0.9919017034347948

10/09/2021 09:43:59 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:43:59 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:43:59 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:43:59 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:43:59 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:43:59 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:43:59 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:43:59 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:43:59 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:43:59 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:43:59 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:43:59 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:43:59 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:43:59 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:43:59 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:43:59 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:43:59 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:44:23 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 537/918 [01:12<00:45,  8.39it/s]
10/09/2021 09:44:23 - INFO - trainer -     Num examples = 3258
10/09/2021 09:44:23 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.12it/s]
10/09/2021 09:44:27 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:44:27 - INFO - trainer -     T-F1 = 0.9898000815993471█████████████████▋ | 50/51 [00:03<00:00, 14.04it/s]
10/09/2021 09:44:27 - INFO - trainer -     T-F1(C) = 0.9702127659574468
10/09/2021 09:44:27 - INFO - trainer -     T-F1(L) = 0.9850746268656716
10/09/2021 09:44:27 - INFO - trainer -     T-F1(O) = 0.9959290017912393
10/09/2021 09:44:27 - INFO - trainer -     T-F1(P) = 0.9973707274320772
10/09/2021 09:44:27 - INFO - trainer -     T-F1(S) = 0.9935364727608494
10/09/2021 09:44:27 - INFO - trainer -     T-F1(T) = 0.9640883977900552
10/09/2021 09:44:27 - INFO - trainer -     U-F1(A) = 0.7103825136612022
10/09/2021 09:44:27 - INFO - trainer -     U-F1(E) = 0.7329650092081031
10/09/2021 09:44:27 - INFO - trainer -     U-F1(I) = 0.25
10/09/2021 09:44:27 - INFO - trainer -     U-F1(O) = 0.962086956521739
10/09/2021 09:44:27 - INFO - trainer -     intent_acc = 0.9315531000613874
10/09/2021 09:44:27 - INFO - trainer -     loss = 0.38741874362469886
10/09/2021 09:44:27 - INFO - trainer -     semantic_frame_acc = 0.9146715776550031
10/09/2021 09:44:27 - INFO - trainer -     slot_f1 = 0.9894297635605008
10/09/2021 09:44:27 - INFO - trainer -     slot_precision = 0.9855915766140205
10/09/2021 09:44:27 - INFO - trainer -     slot_recall = 0.9932979614632784

10/09/2021 09:44:27 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:44:27 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:44:27 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:44:27 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:44:27 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:44:27 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:44:27 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:44:27 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:44:27 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:44:27 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:44:27 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:44:27 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:44:27 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:44:27 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:44:27 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:44:27 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:44:27 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:44:51 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 737/918 [01:40<00:21,  8.33it/s]
10/09/2021 09:44:51 - INFO - trainer -     Num examples = 3258
10/09/2021 09:44:51 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.07it/s]
10/09/2021 09:44:55 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:44:55 - INFO - trainer -     T-F1 = 0.9908706908298134█████████████████▋ | 50/51 [00:03<00:00, 13.95it/s]
10/09/2021 09:44:55 - INFO - trainer -     T-F1(C) = 0.9742857142857144
10/09/2021 09:44:55 - INFO - trainer -     T-F1(L) = 0.9880239520958084
10/09/2021 09:44:55 - INFO - trainer -     T-F1(O) = 0.9963660031458481
10/09/2021 09:44:55 - INFO - trainer -     T-F1(P) = 0.9967826849956127
10/09/2021 09:44:55 - INFO - trainer -     T-F1(S) = 0.9944598337950139
10/09/2021 09:44:55 - INFO - trainer -     T-F1(T) = 0.9694444444444444
10/09/2021 09:44:55 - INFO - trainer -     U-F1(A) = 0.6666666666666666
10/09/2021 09:44:55 - INFO - trainer -     U-F1(E) = 0.7386363636363638
10/09/2021 09:44:55 - INFO - trainer -     U-F1(I) = 0.23809523809523808
10/09/2021 09:44:55 - INFO - trainer -     U-F1(O) = 0.961771319840858
10/09/2021 09:44:55 - INFO - trainer -     intent_acc = 0.9315531000613874
10/09/2021 09:44:55 - INFO - trainer -     loss = 0.4419428638602589
10/09/2021 09:44:55 - INFO - trainer -     semantic_frame_acc = 0.9165131982811541
10/09/2021 09:44:55 - INFO - trainer -     slot_f1 = 0.9905239687848383
10/09/2021 09:44:55 - INFO - trainer -     slot_precision = 0.9885952712100139
10/09/2021 09:44:55 - INFO - trainer -     slot_recall = 0.9924602066461882

10/09/2021 09:44:55 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:44:55 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:44:55 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:44:55 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:44:55 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:44:55 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:44:55 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:44:55 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:44:55 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:44:55 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:44:55 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:44:55 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:44:55 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:44:55 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:44:55 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:44:55 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:44:55 - INFO - trainer -     slot_recall = 0.9910639486177045
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 918/918 [02:06<00:00,  7.28it/s]
Epoch:  50%|█████████████████████████████████████                                     | 10/20 [27:33<22:40, 136.04s/it]10/09/2021 09:45:19 - INFO - trainer -   ***** Running evaluation on dev dataset ***** | 19/918 [00:02<01:48,  8.29it/s]
10/09/2021 09:45:19 - INFO - trainer -     Num examples = 3258
10/09/2021 09:45:19 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.08it/s]
10/09/2021 09:45:23 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:45:23 - INFO - trainer -     T-F1 = 0.9907407407407407█████████████████▋ | 50/51 [00:03<00:00, 13.87it/s]
10/09/2021 09:45:23 - INFO - trainer -     T-F1(C) = 0.9756795422031473
10/09/2021 09:45:23 - INFO - trainer -     T-F1(L) = 0.9880239520958084
10/09/2021 09:45:23 - INFO - trainer -     T-F1(O) = 0.9963107638888888
10/09/2021 09:45:23 - INFO - trainer -     T-F1(P) = 0.9959207459207459
10/09/2021 09:45:23 - INFO - trainer -     T-F1(S) = 0.9944598337950139
10/09/2021 09:45:23 - INFO - trainer -     T-F1(T) = 0.97054698457223
10/09/2021 09:45:23 - INFO - trainer -     U-F1(A) = 0.7
10/09/2021 09:45:23 - INFO - trainer -     U-F1(E) = 0.7461538461538462
10/09/2021 09:45:23 - INFO - trainer -     U-F1(I) = 0.22222222222222224
10/09/2021 09:45:23 - INFO - trainer -     U-F1(O) = 0.9630913186622769
10/09/2021 09:45:23 - INFO - trainer -     intent_acc = 0.9333947206875384
10/09/2021 09:45:23 - INFO - trainer -     loss = 0.42351916826823177
10/09/2021 09:45:23 - INFO - trainer -     semantic_frame_acc = 0.9168201350521793
10/09/2021 09:45:23 - INFO - trainer -     slot_f1 = 0.9899721448467967
10/09/2021 09:45:23 - INFO - trainer -     slot_precision = 0.9874965268130036
10/09/2021 09:45:23 - INFO - trainer -     slot_recall = 0.9924602066461882

10/09/2021 09:45:23 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:45:23 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:45:23 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:45:23 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:45:23 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:45:23 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:45:23 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:45:23 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:45:23 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:45:23 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:45:23 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:45:23 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:45:23 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:45:23 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:45:23 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:45:23 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:45:23 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:45:47 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 219/918 [00:30<01:23,  8.34it/s]
10/09/2021 09:45:47 - INFO - trainer -     Num examples = 3258
10/09/2021 09:45:47 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.10it/s]
10/09/2021 09:45:51 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:45:51 - INFO - trainer -     T-F1 = 0.9901987476177511█████████████████▋ | 50/51 [00:03<00:00, 13.99it/s]
10/09/2021 09:45:51 - INFO - trainer -     T-F1(C) = 0.9715909090909091
10/09/2021 09:45:51 - INFO - trainer -     T-F1(L) = 0.9851632047477745
10/09/2021 09:45:51 - INFO - trainer -     T-F1(O) = 0.9960933260987519
10/09/2021 09:45:51 - INFO - trainer -     T-F1(P) = 0.9961977186311787
10/09/2021 09:45:51 - INFO - trainer -     T-F1(S) = 0.9930843706777317
10/09/2021 09:45:51 - INFO - trainer -     T-F1(T) = 0.9735006973500697
10/09/2021 09:45:51 - INFO - trainer -     U-F1(A) = 0.6815642458100559
10/09/2021 09:45:51 - INFO - trainer -     U-F1(E) = 0.7392120075046904
10/09/2021 09:45:51 - INFO - trainer -     U-F1(I) = 0.22727272727272727
10/09/2021 09:45:51 - INFO - trainer -     U-F1(O) = 0.9635416666666666
10/09/2021 09:45:51 - INFO - trainer -     intent_acc = 0.9324739103744628
10/09/2021 09:45:51 - INFO - trainer -     loss = 0.43102934635153006
10/09/2021 09:45:51 - INFO - trainer -     semantic_frame_acc = 0.9158993247391037
10/09/2021 09:45:51 - INFO - trainer -     slot_f1 = 0.9896993318485524
10/09/2021 09:45:51 - INFO - trainer -     slot_precision = 0.9866777685262281
10/09/2021 09:45:51 - INFO - trainer -     slot_recall = 0.9927394582518849

10/09/2021 09:45:51 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:45:51 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:45:51 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:45:51 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:45:51 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:45:51 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:45:51 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:45:51 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:45:51 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:45:51 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:45:51 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:45:51 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:45:51 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:45:51 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:45:51 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:45:51 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:45:51 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:46:15 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 419/918 [00:58<00:59,  8.35it/s]
10/09/2021 09:46:15 - INFO - trainer -     Num examples = 3258
10/09/2021 09:46:15 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.05it/s]
10/09/2021 09:46:19 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:46:19 - INFO - trainer -     T-F1 = 0.9911432075214607█████████████████▋ | 50/51 [00:03<00:00, 14.00it/s]
10/09/2021 09:46:19 - INFO - trainer -     T-F1(C) = 0.978540772532189
10/09/2021 09:46:19 - INFO - trainer -     T-F1(L) = 0.9909909909909909
10/09/2021 09:46:19 - INFO - trainer -     T-F1(O) = 0.9964744806638824
10/09/2021 09:46:19 - INFO - trainer -     T-F1(P) = 0.9970760233918129
10/09/2021 09:46:19 - INFO - trainer -     T-F1(S) = 0.9921550530687586
10/09/2021 09:46:19 - INFO - trainer -     T-F1(T) = 0.9722222222222221
10/09/2021 09:46:19 - INFO - trainer -     U-F1(A) = 0.7243243243243243
10/09/2021 09:46:19 - INFO - trainer -     U-F1(E) = 0.7265625
10/09/2021 09:46:19 - INFO - trainer -     U-F1(I) = 0.22222222222222224
10/09/2021 09:46:19 - INFO - trainer -     U-F1(O) = 0.9622445445098718
10/09/2021 09:46:19 - INFO - trainer -     intent_acc = 0.9318600368324125
10/09/2021 09:46:19 - INFO - trainer -     loss = 0.45289560827408354
10/09/2021 09:46:19 - INFO - trainer -     semantic_frame_acc = 0.9165131982811541
10/09/2021 09:46:19 - INFO - trainer -     slot_f1 = 0.9908026755852843
10/09/2021 09:46:19 - INFO - trainer -     slot_precision = 0.9888734353268428
10/09/2021 09:46:19 - INFO - trainer -     slot_recall = 0.9927394582518849

10/09/2021 09:46:19 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:46:19 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:46:19 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:46:19 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:46:19 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:46:19 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:46:19 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:46:19 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:46:19 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:46:19 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:46:19 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:46:19 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:46:19 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:46:19 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:46:19 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:46:19 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:46:19 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:46:43 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 619/918 [01:26<00:35,  8.34it/s]
10/09/2021 09:46:43 - INFO - trainer -     Num examples = 3258
10/09/2021 09:46:43 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.07it/s]
10/09/2021 09:46:47 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:46:47 - INFO - trainer -     T-F1 = 0.9914133842169823█████████████████▋ | 50/51 [00:03<00:00, 13.95it/s]
10/09/2021 09:46:47 - INFO - trainer -     T-F1(C) = 0.9784172661870504
10/09/2021 09:46:47 - INFO - trainer -     T-F1(L) = 0.9850746268656716
10/09/2021 09:46:47 - INFO - trainer -     T-F1(O) = 0.996583328813927
10/09/2021 09:46:47 - INFO - trainer -     T-F1(P) = 0.9970760233918129
10/09/2021 09:46:47 - INFO - trainer -     T-F1(S) = 0.9930843706777317
10/09/2021 09:46:47 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:46:47 - INFO - trainer -     U-F1(A) = 0.5526315789473685
10/09/2021 09:46:47 - INFO - trainer -     U-F1(E) = 0.7592592592592594
10/09/2021 09:46:47 - INFO - trainer -     U-F1(I) = 0.2564102564102564
10/09/2021 09:46:47 - INFO - trainer -     U-F1(O) = 0.9614520311149525
10/09/2021 09:46:47 - INFO - trainer -     intent_acc = 0.930939226519337
10/09/2021 09:46:47 - INFO - trainer -     loss = 0.43852954124118765
10/09/2021 09:46:47 - INFO - trainer -     semantic_frame_acc = 0.9158993247391037
10/09/2021 09:46:47 - INFO - trainer -     slot_f1 = 0.9910788960133816
10/09/2021 09:46:47 - INFO - trainer -     slot_precision = 0.989423879766212
10/09/2021 09:46:47 - INFO - trainer -     slot_recall = 0.9927394582518849

10/09/2021 09:46:47 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:46:47 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:46:47 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:46:47 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:46:47 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:46:47 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:46:47 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:46:47 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:46:47 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:46:47 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:46:47 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:46:47 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:46:47 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:46:47 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:46:47 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:46:47 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:46:47 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:47:10 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 819/918 [01:54<00:12,  8.24it/s]
10/09/2021 09:47:10 - INFO - trainer -     Num examples = 3258
10/09/2021 09:47:10 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.08it/s]
10/09/2021 09:47:14 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:47:14 - INFO - trainer -     T-F1 = 0.9902147322642022█████████████████▋ | 50/51 [00:03<00:00, 14.01it/s]
10/09/2021 09:47:14 - INFO - trainer -     T-F1(C) = 0.9784791965566715
10/09/2021 09:47:14 - INFO - trainer -     T-F1(L) = 0.9824561403508771
10/09/2021 09:47:14 - INFO - trainer -     T-F1(O) = 0.9960907807579542
10/09/2021 09:47:14 - INFO - trainer -     T-F1(P) = 0.9967845659163987
10/09/2021 09:47:14 - INFO - trainer -     T-F1(S) = 0.9917127071823204
10/09/2021 09:47:14 - INFO - trainer -     T-F1(T) = 0.9696969696969696
10/09/2021 09:47:14 - INFO - trainer -     U-F1(A) = 0.7474747474747474
10/09/2021 09:47:14 - INFO - trainer -     U-F1(E) = 0.7090558766859344
10/09/2021 09:47:14 - INFO - trainer -     U-F1(I) = 0.3414634146341463
10/09/2021 09:47:14 - INFO - trainer -     U-F1(O) = 0.9624869746439737
10/09/2021 09:47:14 - INFO - trainer -     intent_acc = 0.9318600368324125
10/09/2021 09:47:14 - INFO - trainer -     loss = 0.42621336208985133
10/09/2021 09:47:14 - INFO - trainer -     semantic_frame_acc = 0.9152854511970534
10/09/2021 09:47:14 - INFO - trainer -     slot_f1 = 0.989854065323141
10/09/2021 09:47:14 - INFO - trainer -     slot_precision = 0.9853348090758163
10/09/2021 09:47:14 - INFO - trainer -     slot_recall = 0.9944149678860653

10/09/2021 09:47:14 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:47:14 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:47:14 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:47:14 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:47:14 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:47:14 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:47:14 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:47:14 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:47:14 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:47:14 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:47:14 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:47:14 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:47:14 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:47:14 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:47:14 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:47:14 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:47:14 - INFO - trainer -     slot_recall = 0.9910639486177045
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 918/918 [02:09<00:00,  7.06it/s]
Epoch:  55%|████████████████████████████████████████▋                                 | 11/20 [29:43<20:07, 134.18s/it]10/09/2021 09:47:38 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 101/918 [00:12<01:38,  8.29it/s]
10/09/2021 09:47:38 - INFO - trainer -     Num examples = 3258
10/09/2021 09:47:38 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.02it/s]
10/09/2021 09:47:42 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:47:42 - INFO - trainer -     T-F1 = 0.9911504424778762█████████████████▋ | 50/51 [00:03<00:00, 13.97it/s]
10/09/2021 09:47:42 - INFO - trainer -     T-F1(C) = 0.978540772532189
10/09/2021 09:47:42 - INFO - trainer -     T-F1(L) = 0.9822485207100591
10/09/2021 09:47:42 - INFO - trainer -     T-F1(O) = 0.996473332971624
10/09/2021 09:47:42 - INFO - trainer -     T-F1(P) = 0.9967845659163987
10/09/2021 09:47:42 - INFO - trainer -     T-F1(S) = 0.9939953810623556
10/09/2021 09:47:42 - INFO - trainer -     T-F1(T) = 0.9722991689750693
10/09/2021 09:47:42 - INFO - trainer -     U-F1(A) = 0.7204301075268817
10/09/2021 09:47:42 - INFO - trainer -     U-F1(E) = 0.72265625
10/09/2021 09:47:42 - INFO - trainer -     U-F1(I) = 0.20512820512820512
10/09/2021 09:47:42 - INFO - trainer -     U-F1(O) = 0.9624502509084617
10/09/2021 09:47:42 - INFO - trainer -     intent_acc = 0.9321669736034377
10/09/2021 09:47:42 - INFO - trainer -     loss = 0.4562725552229905
10/09/2021 09:47:42 - INFO - trainer -     semantic_frame_acc = 0.9177409453652547
10/09/2021 09:47:42 - INFO - trainer -     slot_f1 = 0.9908103592314118
10/09/2021 09:47:42 - INFO - trainer -     slot_precision = 0.9880588725354068
10/09/2021 09:47:42 - INFO - trainer -     slot_recall = 0.9935772130689752

10/09/2021 09:47:42 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:47:42 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:47:42 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:47:42 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:47:42 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:47:42 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:47:42 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:47:42 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:47:42 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:47:42 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:47:42 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:47:42 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:47:42 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:47:42 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:47:42 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:47:42 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:47:42 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:48:06 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 301/918 [00:40<01:14,  8.34it/s]
10/09/2021 09:48:06 - INFO - trainer -     Num examples = 3258
10/09/2021 09:48:06 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.04it/s]
10/09/2021 09:48:10 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:48:10 - INFO - trainer -     T-F1 = 0.9904554131442597█████████████████▋ | 50/51 [00:03<00:00, 13.85it/s]
10/09/2021 09:48:10 - INFO - trainer -     T-F1(C) = 0.9683908045977011
10/09/2021 09:48:10 - INFO - trainer -     T-F1(L) = 0.9879518072289156
10/09/2021 09:48:10 - INFO - trainer -     T-F1(O) = 0.9962043162346818
10/09/2021 09:48:10 - INFO - trainer -     T-F1(P) = 0.9962043795620438
10/09/2021 09:48:10 - INFO - trainer -     T-F1(S) = 0.9935364727608494
10/09/2021 09:48:10 - INFO - trainer -     T-F1(T) = 0.9762237762237763
10/09/2021 09:48:10 - INFO - trainer -     U-F1(A) = 0.6742857142857143
10/09/2021 09:48:10 - INFO - trainer -     U-F1(E) = 0.7504488330341114
10/09/2021 09:48:10 - INFO - trainer -     U-F1(I) = 0.27272727272727276
10/09/2021 09:48:10 - INFO - trainer -     U-F1(O) = 0.9623693379790941
10/09/2021 09:48:10 - INFO - trainer -     intent_acc = 0.9318600368324125
10/09/2021 09:48:10 - INFO - trainer -     loss = 0.47065383831367774
10/09/2021 09:48:10 - INFO - trainer -     semantic_frame_acc = 0.9149785144260283
10/09/2021 09:48:10 - INFO - trainer -     slot_f1 = 0.9899609592861127
10/09/2021 09:48:10 - INFO - trainer -     slot_precision = 0.9885825675299359
10/09/2021 09:48:10 - INFO - trainer -     slot_recall = 0.9913432002234013

10/09/2021 09:48:10 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:48:10 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:48:10 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:48:10 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:48:10 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:48:10 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:48:10 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:48:10 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:48:10 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:48:10 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:48:10 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:48:10 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:48:10 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:48:10 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:48:10 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:48:10 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:48:10 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:48:34 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 501/918 [01:08<00:50,  8.26it/s]
10/09/2021 09:48:34 - INFO - trainer -     Num examples = 3258
10/09/2021 09:48:34 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.04it/s]
10/09/2021 09:48:38 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:48:38 - INFO - trainer -     T-F1 = 0.9911335424907926█████████████████▋ | 50/51 [00:03<00:00, 13.92it/s]
10/09/2021 09:48:38 - INFO - trainer -     T-F1(C) = 0.9727403156384504
10/09/2021 09:48:38 - INFO - trainer -     T-F1(L) = 0.9909909909909909
10/09/2021 09:48:38 - INFO - trainer -     T-F1(O) = 0.9964760097587422
10/09/2021 09:48:38 - INFO - trainer -     T-F1(P) = 0.997072599531616
10/09/2021 09:48:38 - INFO - trainer -     T-F1(S) = 0.9935424354243543
10/09/2021 09:48:38 - INFO - trainer -     T-F1(T) = 0.9735006973500697
10/09/2021 09:48:38 - INFO - trainer -     U-F1(A) = 0.6918918918918919
10/09/2021 09:48:38 - INFO - trainer -     U-F1(E) = 0.7240704500978473
10/09/2021 09:48:38 - INFO - trainer -     U-F1(I) = 0.1818181818181818
10/09/2021 09:48:38 - INFO - trainer -     U-F1(O) = 0.9628477622256782
10/09/2021 09:48:38 - INFO - trainer -     intent_acc = 0.9324739103744628
10/09/2021 09:48:38 - INFO - trainer -     loss = 0.4667284452520749
10/09/2021 09:48:38 - INFO - trainer -     semantic_frame_acc = 0.9177409453652547
10/09/2021 09:48:38 - INFO - trainer -     slot_f1 = 0.9907924107142857
10/09/2021 09:48:38 - INFO - trainer -     slot_precision = 0.9899637580150543
10/09/2021 09:48:38 - INFO - trainer -     slot_recall = 0.991622451829098

10/09/2021 09:48:38 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:48:38 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:48:38 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:48:38 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:48:38 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:48:38 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:48:38 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:48:38 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:48:38 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:48:38 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:48:38 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:48:38 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:48:38 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:48:38 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:48:38 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:48:38 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:48:38 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:49:02 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 701/918 [01:36<00:26,  8.29it/s]
10/09/2021 09:49:02 - INFO - trainer -     Num examples = 3258
10/09/2021 09:49:02 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.04it/s]
10/09/2021 09:49:06 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:49:06 - INFO - trainer -     T-F1 = 0.9912711402073106█████████████████▋ | 50/51 [00:03<00:00, 13.91it/s]
10/09/2021 09:49:06 - INFO - trainer -     T-F1(C) = 0.9784172661870504
10/09/2021 09:49:06 - INFO - trainer -     T-F1(L) = 0.9880239520958084
10/09/2021 09:49:06 - INFO - trainer -     T-F1(O) = 0.9965300368683582
10/09/2021 09:49:06 - INFO - trainer -     T-F1(P) = 0.9967845659163987
10/09/2021 09:49:06 - INFO - trainer -     T-F1(S) = 0.993077988001846
10/09/2021 09:49:06 - INFO - trainer -     T-F1(T) = 0.9734265734265735
10/09/2021 09:49:06 - INFO - trainer -     U-F1(A) = 0.6815642458100559
10/09/2021 09:49:06 - INFO - trainer -     U-F1(E) = 0.7551401869158879
10/09/2021 09:49:06 - INFO - trainer -     U-F1(I) = 0.2857142857142857
10/09/2021 09:49:06 - INFO - trainer -     U-F1(O) = 0.9649305555555555
10/09/2021 09:49:06 - INFO - trainer -     intent_acc = 0.9355432780847146
10/09/2021 09:49:06 - INFO - trainer -     loss = 0.4258861812744655
10/09/2021 09:49:06 - INFO - trainer -     semantic_frame_acc = 0.919889502762431
10/09/2021 09:49:06 - INFO - trainer -     slot_f1 = 0.990794979079498
10/09/2021 09:49:06 - INFO - trainer -     slot_precision = 0.9896907216494846
10/09/2021 09:49:06 - INFO - trainer -     slot_recall = 0.9919017034347948

10/09/2021 09:49:06 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:49:06 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:49:06 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:49:06 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:49:06 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:49:06 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:49:06 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:49:06 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:49:06 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:49:06 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:49:06 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:49:06 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:49:06 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:49:06 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:49:06 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:49:06 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:49:06 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:49:30 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 901/918 [02:04<00:02,  8.34it/s]
10/09/2021 09:49:30 - INFO - trainer -     Num examples = 3258
10/09/2021 09:49:30 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.10it/s]
10/09/2021 09:49:34 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:49:34 - INFO - trainer -     T-F1 = 0.9915462230706299█████████████████▋ | 50/51 [00:03<00:00, 13.95it/s]
10/09/2021 09:49:34 - INFO - trainer -     T-F1(C) = 0.9742857142857144
10/09/2021 09:49:34 - INFO - trainer -     T-F1(L) = 0.9940476190476191
10/09/2021 09:49:34 - INFO - trainer -     T-F1(O) = 0.9966381086650037
10/09/2021 09:49:34 - INFO - trainer -     T-F1(P) = 0.9970760233918129
10/09/2021 09:49:34 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:49:34 - INFO - trainer -     T-F1(T) = 0.9747899159663864
10/09/2021 09:49:34 - INFO - trainer -     U-F1(A) = 0.7241379310344828
10/09/2021 09:49:34 - INFO - trainer -     U-F1(E) = 0.7329434697855751
10/09/2021 09:49:34 - INFO - trainer -     U-F1(I) = 0.25
10/09/2021 09:49:34 - INFO - trainer -     U-F1(O) = 0.9642425289341854
10/09/2021 09:49:34 - INFO - trainer -     intent_acc = 0.9352363413136894
10/09/2021 09:49:34 - INFO - trainer -     loss = 0.4578125717337517
10/09/2021 09:49:34 - INFO - trainer -     semantic_frame_acc = 0.9205033763044813
10/09/2021 09:49:34 - INFO - trainer -     slot_f1 = 0.9910764082543223
10/09/2021 09:49:34 - INFO - trainer -     slot_precision = 0.9896964633806739
10/09/2021 09:49:34 - INFO - trainer -     slot_recall = 0.9924602066461882

10/09/2021 09:49:34 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:49:34 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:49:34 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:49:34 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:49:34 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:49:34 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:49:34 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:49:34 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:49:34 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:49:34 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:49:34 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:49:34 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:49:34 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:49:34 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:49:34 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:49:34 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:49:34 - INFO - trainer -     slot_recall = 0.9910639486177045
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 918/918 [02:10<00:00,  7.06it/s]
Epoch:  60%|████████████████████████████████████████████▍                             | 12/20 [31:53<17:43, 132.93s/it]10/09/2021 09:49:58 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 183/918 [00:21<01:29,  8.22it/s]
10/09/2021 09:49:58 - INFO - trainer -     Num examples = 3258
10/09/2021 09:49:58 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 13.96it/s]
10/09/2021 09:50:02 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:50:02 - INFO - trainer -     T-F1 = 0.991145620487672██████████████████▋ | 50/51 [00:03<00:00, 13.93it/s]
10/09/2021 09:50:02 - INFO - trainer -     T-F1(C) = 0.9756795422031473
10/09/2021 09:50:02 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:50:02 - INFO - trainer -     T-F1(O) = 0.9964740981828044
10/09/2021 09:50:02 - INFO - trainer -     T-F1(P) = 0.9964912280701754
10/09/2021 09:50:02 - INFO - trainer -     T-F1(S) = 0.9935364727608494
10/09/2021 09:50:02 - INFO - trainer -     T-F1(T) = 0.9736477115117893
10/09/2021 09:50:02 - INFO - trainer -     U-F1(A) = 0.7199999999999999
10/09/2021 09:50:02 - INFO - trainer -     U-F1(E) = 0.7289719626168224
10/09/2021 09:50:02 - INFO - trainer -     U-F1(I) = 0.2
10/09/2021 09:50:02 - INFO - trainer -     U-F1(O) = 0.9614984391259105
10/09/2021 09:50:02 - INFO - trainer -     intent_acc = 0.9312461632903621
10/09/2021 09:50:02 - INFO - trainer -     loss = 0.49045431287046154
10/09/2021 09:50:02 - INFO - trainer -     semantic_frame_acc = 0.9158993247391037
10/09/2021 09:50:02 - INFO - trainer -     slot_f1 = 0.9908052382279187
10/09/2021 09:50:02 - INFO - trainer -     slot_precision = 0.9886016124548235
10/09/2021 09:50:02 - INFO - trainer -     slot_recall = 0.9930187098575817

10/09/2021 09:50:02 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:50:02 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:50:02 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:50:02 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:50:02 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:50:02 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:50:02 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:50:02 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:50:02 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:50:02 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:50:02 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:50:02 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:50:02 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:50:02 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:50:02 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:50:02 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:50:02 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:50:26 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 383/918 [00:49<01:03,  8.36it/s]
10/09/2021 09:50:26 - INFO - trainer -     Num examples = 3258
10/09/2021 09:50:26 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.06it/s]
10/09/2021 09:50:30 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:50:30 - INFO - trainer -     T-F1 = 0.9914133842169823█████████████████▋ | 50/51 [00:03<00:00, 13.97it/s]
10/09/2021 09:50:30 - INFO - trainer -     T-F1(C) = 0.9742857142857144
10/09/2021 09:50:30 - INFO - trainer -     T-F1(L) = 0.9940476190476191
10/09/2021 09:50:30 - INFO - trainer -     T-F1(O) = 0.996583328813927
10/09/2021 09:50:30 - INFO - trainer -     T-F1(P) = 0.9959088252483926
10/09/2021 09:50:30 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:50:30 - INFO - trainer -     T-F1(T) = 0.9790209790209791
10/09/2021 09:50:30 - INFO - trainer -     U-F1(A) = 0.7
10/09/2021 09:50:30 - INFO - trainer -     U-F1(E) = 0.7490494296577946
10/09/2021 09:50:30 - INFO - trainer -     U-F1(I) = 0.3
10/09/2021 09:50:30 - INFO - trainer -     U-F1(O) = 0.9646447140381282
10/09/2021 09:50:30 - INFO - trainer -     intent_acc = 0.9358502148557397
10/09/2021 09:50:30 - INFO - trainer -     loss = 0.459586666549976
10/09/2021 09:50:30 - INFO - trainer -     semantic_frame_acc = 0.9208103130755064
10/09/2021 09:50:30 - INFO - trainer -     slot_f1 = 0.9910788960133816
10/09/2021 09:50:30 - INFO - trainer -     slot_precision = 0.989423879766212
10/09/2021 09:50:30 - INFO - trainer -     slot_recall = 0.9927394582518849

10/09/2021 09:50:30 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:50:30 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:50:30 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:50:30 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:50:30 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:50:30 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:50:30 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:50:30 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:50:30 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:50:30 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:50:30 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:50:30 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:50:30 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:50:30 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:50:30 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:50:30 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:50:30 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:50:54 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 583/918 [01:17<00:39,  8.41it/s]
10/09/2021 09:50:54 - INFO - trainer -     Num examples = 3258
10/09/2021 09:50:54 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.04it/s]
10/09/2021 09:50:58 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:50:58 - INFO - trainer -     T-F1 = 0.9926330150068213█████████████████▋ | 50/51 [00:03<00:00, 13.95it/s]
10/09/2021 09:50:58 - INFO - trainer -     T-F1(C) = 0.9784172661870504
10/09/2021 09:50:58 - INFO - trainer -     T-F1(L) = 0.9940119760479043
10/09/2021 09:50:58 - INFO - trainer -     T-F1(O) = 0.9970725360511763
10/09/2021 09:50:58 - INFO - trainer -     T-F1(P) = 0.9967864446392054
10/09/2021 09:50:58 - INFO - trainer -     T-F1(S) = 0.994914470642626
10/09/2021 09:50:58 - INFO - trainer -     T-F1(T) = 0.9790209790209791
10/09/2021 09:50:58 - INFO - trainer -     U-F1(A) = 0.6547619047619047
10/09/2021 09:50:58 - INFO - trainer -     U-F1(E) = 0.7251461988304094
10/09/2021 09:50:58 - INFO - trainer -     U-F1(I) = 0.22727272727272727
10/09/2021 09:50:58 - INFO - trainer -     U-F1(O) = 0.9604558798135037
10/09/2021 09:50:58 - INFO - trainer -     intent_acc = 0.929097605893186
10/09/2021 09:50:58 - INFO - trainer -     loss = 0.5028910438219706
10/09/2021 09:50:58 - INFO - trainer -     semantic_frame_acc = 0.9155923879680786
10/09/2021 09:50:58 - INFO - trainer -     slot_f1 = 0.9923259383284497
10/09/2021 09:50:58 - INFO - trainer -     slot_precision = 0.9916341327384273
10/09/2021 09:50:58 - INFO - trainer -     slot_recall = 0.9930187098575817

10/09/2021 09:50:58 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:50:58 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:50:58 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:50:58 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:50:58 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:50:58 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:50:58 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:50:58 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:50:58 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:50:58 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:50:58 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:50:58 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:50:58 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:50:58 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:50:58 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:50:58 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:50:58 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:51:22 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 783/918 [01:45<00:16,  8.39it/s]
10/09/2021 09:51:22 - INFO - trainer -     Num examples = 3258
10/09/2021 09:51:22 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.02it/s]
10/09/2021 09:51:26 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:51:26 - INFO - trainer -     T-F1 = 0.9915416098226466█████████████████▋ | 50/51 [00:03<00:00, 13.92it/s]
10/09/2021 09:51:26 - INFO - trainer -     T-F1(C) = 0.9784172661870504
10/09/2021 09:51:26 - INFO - trainer -     T-F1(L) = 0.9909909909909909
10/09/2021 09:51:26 - INFO - trainer -     T-F1(O) = 0.9966388376883878
10/09/2021 09:51:26 - INFO - trainer -     T-F1(P) = 0.9964912280701754
10/09/2021 09:51:26 - INFO - trainer -     T-F1(S) = 0.9935424354243543
10/09/2021 09:51:26 - INFO - trainer -     T-F1(T) = 0.9747899159663864
10/09/2021 09:51:26 - INFO - trainer -     U-F1(A) = 0.7096774193548387
10/09/2021 09:51:26 - INFO - trainer -     U-F1(E) = 0.7317073170731707
10/09/2021 09:51:26 - INFO - trainer -     U-F1(I) = 0.27906976744186046
10/09/2021 09:51:26 - INFO - trainer -     U-F1(O) = 0.9621133124782759
10/09/2021 09:51:26 - INFO - trainer -     intent_acc = 0.9315531000613874
10/09/2021 09:51:26 - INFO - trainer -     loss = 0.4970500253177449
10/09/2021 09:51:26 - INFO - trainer -     semantic_frame_acc = 0.9177409453652547
10/09/2021 09:51:26 - INFO - trainer -     slot_f1 = 0.9912097111762244
10/09/2021 09:51:26 - INFO - trainer -     slot_precision = 0.9905186837702176
10/09/2021 09:51:26 - INFO - trainer -     slot_recall = 0.9919017034347948

10/09/2021 09:51:26 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:51:26 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:51:26 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:51:26 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:51:26 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:51:26 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:51:26 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:51:26 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:51:26 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:51:26 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:51:26 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:51:26 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:51:26 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:51:26 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:51:26 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:51:26 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:51:26 - INFO - trainer -     slot_recall = 0.9910639486177045
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 918/918 [02:05<00:00,  7.29it/s]
Epoch:  65%|████████████████████████████████████████████████                          | 13/20 [33:59<15:15, 130.81s/it]10/09/2021 09:51:50 - INFO - trainer -   ***** Running evaluation on dev dataset ***** | 65/918 [00:07<01:42,  8.35it/s]
10/09/2021 09:51:50 - INFO - trainer -     Num examples = 3258
10/09/2021 09:51:50 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.06it/s]
10/09/2021 09:51:54 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:51:54 - INFO - trainer -     T-F1 = 0.9915508312891796█████████████████▋ | 50/51 [00:03<00:00, 13.98it/s]
10/09/2021 09:51:54 - INFO - trainer -     T-F1(C) = 0.9743589743589743
10/09/2021 09:51:54 - INFO - trainer -     T-F1(L) = 0.9940119760479043
10/09/2021 09:51:54 - INFO - trainer -     T-F1(O) = 0.9966373793253064
10/09/2021 09:51:54 - INFO - trainer -     T-F1(P) = 0.9964932787843368
10/09/2021 09:51:54 - INFO - trainer -     T-F1(S) = 0.9930843706777317
10/09/2021 09:51:54 - INFO - trainer -     T-F1(T) = 0.9789029535864979
10/09/2021 09:51:54 - INFO - trainer -     U-F1(A) = 0.6703296703296703
10/09/2021 09:51:54 - INFO - trainer -     U-F1(E) = 0.7339805825242718
10/09/2021 09:51:54 - INFO - trainer -     U-F1(I) = 0.27906976744186046
10/09/2021 09:51:54 - INFO - trainer -     U-F1(O) = 0.9622576177285318
10/09/2021 09:51:54 - INFO - trainer -     intent_acc = 0.9315531000613874
10/09/2021 09:51:54 - INFO - trainer -     loss = 0.49174457543766964
10/09/2021 09:51:54 - INFO - trainer -     semantic_frame_acc = 0.9155923879680786
10/09/2021 09:51:54 - INFO - trainer -     slot_f1 = 0.9912195121951219
10/09/2021 09:51:54 - INFO - trainer -     slot_precision = 0.9894268224819143
10/09/2021 09:51:54 - INFO - trainer -     slot_recall = 0.9930187098575817

10/09/2021 09:51:54 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:51:54 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:51:54 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:51:54 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:51:54 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:51:54 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:51:54 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:51:54 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:51:54 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:51:54 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:51:54 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:51:54 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:51:54 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:51:54 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:51:54 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:51:54 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:51:54 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:52:18 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 265/918 [00:35<01:18,  8.35it/s]
10/09/2021 09:52:18 - INFO - trainer -     Num examples = 3258
10/09/2021 09:52:18 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.07it/s]
10/09/2021 09:52:22 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:52:22 - INFO - trainer -     T-F1 = 0.991268758526603██████████████████▋ | 50/51 [00:03<00:00, 14.01it/s]
10/09/2021 09:52:22 - INFO - trainer -     T-F1(C) = 0.9756097560975611
10/09/2021 09:52:22 - INFO - trainer -     T-F1(L) = 0.9940119760479043
10/09/2021 09:52:22 - INFO - trainer -     T-F1(O) = 0.9965304130976905
10/09/2021 09:52:22 - INFO - trainer -     T-F1(P) = 0.9961954931226222
10/09/2021 09:52:22 - INFO - trainer -     T-F1(S) = 0.9940009229349331
10/09/2021 09:52:22 - INFO - trainer -     T-F1(T) = 0.9734265734265735
10/09/2021 09:52:22 - INFO - trainer -     U-F1(A) = 0.6508875739644969
10/09/2021 09:52:22 - INFO - trainer -     U-F1(E) = 0.7438330170777988
10/09/2021 09:52:22 - INFO - trainer -     U-F1(I) = 0.27272727272727276
10/09/2021 09:52:22 - INFO - trainer -     U-F1(O) = 0.9619113573407202
10/09/2021 09:52:22 - INFO - trainer -     intent_acc = 0.9315531000613874
10/09/2021 09:52:22 - INFO - trainer -     loss = 0.5191057578879682
10/09/2021 09:52:22 - INFO - trainer -     semantic_frame_acc = 0.9165131982811541
10/09/2021 09:52:22 - INFO - trainer -     slot_f1 = 0.990930654388168
10/09/2021 09:52:22 - INFO - trainer -     slot_precision = 0.990239821528165
10/09/2021 09:52:22 - INFO - trainer -     slot_recall = 0.991622451829098

10/09/2021 09:52:22 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:52:22 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:52:22 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:52:22 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:52:22 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:52:22 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:52:22 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:52:22 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:52:22 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:52:22 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:52:22 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:52:22 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:52:22 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:52:22 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:52:22 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:52:22 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:52:22 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:52:46 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 465/918 [01:03<00:54,  8.37it/s]
10/09/2021 09:52:46 - INFO - trainer -     Num examples = 3258
10/09/2021 09:52:46 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.05it/s]
10/09/2021 09:52:50 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:52:50 - INFO - trainer -     T-F1 = 0.9926289926289926█████████████████▋ | 50/51 [00:03<00:00, 13.94it/s]
10/09/2021 09:52:50 - INFO - trainer -     T-F1(C) = 0.9798850574712643
10/09/2021 09:52:50 - INFO - trainer -     T-F1(L) = 0.9940119760479043
10/09/2021 09:52:50 - INFO - trainer -     T-F1(O) = 0.9970731707317073
10/09/2021 09:52:50 - INFO - trainer -     T-F1(P) = 0.9970743124634289
10/09/2021 09:52:50 - INFO - trainer -     T-F1(S) = 0.994914470642626
10/09/2021 09:52:50 - INFO - trainer -     T-F1(T) = 0.9762237762237763
10/09/2021 09:52:50 - INFO - trainer -     U-F1(A) = 0.6956521739130435
10/09/2021 09:52:50 - INFO - trainer -     U-F1(E) = 0.7417475728155339
10/09/2021 09:52:50 - INFO - trainer -     U-F1(I) = 0.2608695652173913
10/09/2021 09:52:50 - INFO - trainer -     U-F1(O) = 0.9637844394385722
10/09/2021 09:52:50 - INFO - trainer -     intent_acc = 0.9337016574585635
10/09/2021 09:52:50 - INFO - trainer -     loss = 0.46491403618425714
10/09/2021 09:52:50 - INFO - trainer -     semantic_frame_acc = 0.9211172498465316
10/09/2021 09:52:50 - INFO - trainer -     slot_f1 = 0.9923216529387128
10/09/2021 09:52:50 - INFO - trainer -     slot_precision = 0.9921831379117811
10/09/2021 09:52:50 - INFO - trainer -     slot_recall = 0.9924602066461882

10/09/2021 09:52:50 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:52:50 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:52:50 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:52:50 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:52:50 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:52:50 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:52:50 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:52:50 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:52:50 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:52:50 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:52:50 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:52:50 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:52:50 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:52:50 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:52:50 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:52:50 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:52:50 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:53:14 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 665/918 [01:31<00:30,  8.26it/s]
10/09/2021 09:53:14 - INFO - trainer -     Num examples = 3258
10/09/2021 09:53:14 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.08it/s]
10/09/2021 09:53:18 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:53:18 - INFO - trainer -     T-F1 = 0.9924976128768245█████████████████▋ | 50/51 [00:03<00:00, 14.01it/s]
10/09/2021 09:53:18 - INFO - trainer -     T-F1(C) = 0.9798850574712643
10/09/2021 09:53:18 - INFO - trainer -     T-F1(L) = 0.9940119760479043
10/09/2021 09:53:18 - INFO - trainer -     T-F1(O) = 0.9970181621035511
10/09/2021 09:53:18 - INFO - trainer -     T-F1(P) = 0.9970743124634289
10/09/2021 09:53:18 - INFO - trainer -     T-F1(S) = 0.9940009229349331
10/09/2021 09:53:18 - INFO - trainer -     T-F1(T) = 0.9776536312849162
10/09/2021 09:53:18 - INFO - trainer -     U-F1(A) = 0.7173913043478262
10/09/2021 09:53:18 - INFO - trainer -     U-F1(E) = 0.7485822306238186
10/09/2021 09:53:18 - INFO - trainer -     U-F1(I) = 0.2857142857142857
10/09/2021 09:53:18 - INFO - trainer -     U-F1(O) = 0.9635036496350365
10/09/2021 09:53:18 - INFO - trainer -     intent_acc = 0.9340085942295887
10/09/2021 09:53:18 - INFO - trainer -     loss = 0.46857496497093465
10/09/2021 09:53:18 - INFO - trainer -     semantic_frame_acc = 0.9205033763044813
10/09/2021 09:53:18 - INFO - trainer -     slot_f1 = 0.9921875
10/09/2021 09:53:18 - INFO - trainer -     slot_precision = 0.9913576805129635
10/09/2021 09:53:18 - INFO - trainer -     slot_recall = 0.9930187098575817

10/09/2021 09:53:18 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:53:18 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:53:18 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:53:18 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:53:18 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:53:18 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:53:18 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:53:18 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:53:18 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:53:18 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:53:18 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:53:18 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:53:18 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:53:18 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:53:18 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:53:18 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:53:18 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:53:42 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 865/918 [01:59<00:06,  8.37it/s]
10/09/2021 09:53:42 - INFO - trainer -     Num examples = 3258
10/09/2021 09:53:42 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.07it/s]
10/09/2021 09:53:46 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:53:46 - INFO - trainer -     T-F1 = 0.9916791706452053█████████████████▋ | 50/51 [00:03<00:00, 14.01it/s]
10/09/2021 09:53:46 - INFO - trainer -     T-F1(C) = 0.9770114942528736
10/09/2021 09:53:46 - INFO - trainer -     T-F1(L) = 0.9940119760479043
10/09/2021 09:53:46 - INFO - trainer -     T-F1(O) = 0.9966928706966658
10/09/2021 09:53:46 - INFO - trainer -     T-F1(P) = 0.9973661106233538
10/09/2021 09:53:46 - INFO - trainer -     T-F1(S) = 0.993077988001846
10/09/2021 09:53:46 - INFO - trainer -     T-F1(T) = 0.9735006973500697
10/09/2021 09:53:46 - INFO - trainer -     U-F1(A) = 0.6927374301675977
10/09/2021 09:53:46 - INFO - trainer -     U-F1(E) = 0.7251461988304094
10/09/2021 09:53:46 - INFO - trainer -     U-F1(I) = 0.26666666666666666
10/09/2021 09:53:46 - INFO - trainer -     U-F1(O) = 0.9624502509084617
10/09/2021 09:53:46 - INFO - trainer -     intent_acc = 0.9315531000613874
10/09/2021 09:53:46 - INFO - trainer -     loss = 0.5126197880827913
10/09/2021 09:53:46 - INFO - trainer -     semantic_frame_acc = 0.9174340085942296
10/09/2021 09:53:46 - INFO - trainer -     slot_f1 = 0.9913504464285714
10/09/2021 09:53:46 - INFO - trainer -     slot_precision = 0.990521327014218
10/09/2021 09:53:46 - INFO - trainer -     slot_recall = 0.9921809550404915

10/09/2021 09:53:46 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:53:46 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:53:46 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:53:46 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:53:46 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:53:46 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:53:46 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:53:46 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:53:46 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:53:46 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:53:46 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:53:46 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:53:46 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:53:46 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:53:46 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:53:46 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:53:46 - INFO - trainer -     slot_recall = 0.9910639486177045
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 918/918 [02:09<00:00,  7.07it/s]
Epoch:  70%|███████████████████████████████████████████████████▊                      | 14/20 [36:09<13:02, 130.50s/it]10/09/2021 09:54:10 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 147/918 [00:17<01:33,  8.22it/s]
10/09/2021 09:54:10 - INFO - trainer -     Num examples = 3258
10/09/2021 09:54:10 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.04it/s]
10/09/2021 09:54:14 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:54:14 - INFO - trainer -     T-F1 = 0.9914157242131081█████████████████▋ | 50/51 [00:03<00:00, 13.92it/s]
10/09/2021 09:54:14 - INFO - trainer -     T-F1(C) = 0.9742857142857144
10/09/2021 09:54:14 - INFO - trainer -     T-F1(L) = 0.9940119760479043
10/09/2021 09:54:14 - INFO - trainer -     T-F1(O) = 0.9965829581819167
10/09/2021 09:54:14 - INFO - trainer -     T-F1(P) = 0.9970760233918129
10/09/2021 09:54:14 - INFO - trainer -     T-F1(S) = 0.993077988001846
10/09/2021 09:54:14 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:54:14 - INFO - trainer -     U-F1(A) = 0.6551724137931035
10/09/2021 09:54:14 - INFO - trainer -     U-F1(E) = 0.761029411764706
10/09/2021 09:54:14 - INFO - trainer -     U-F1(I) = 0.27272727272727276
10/09/2021 09:54:14 - INFO - trainer -     U-F1(O) = 0.9631560653458465
10/09/2021 09:54:14 - INFO - trainer -     intent_acc = 0.9333947206875384
10/09/2021 09:54:14 - INFO - trainer -     loss = 0.528614959040401
10/09/2021 09:54:14 - INFO - trainer -     semantic_frame_acc = 0.9177409453652547
10/09/2021 09:54:14 - INFO - trainer -     slot_f1 = 0.9910813823857303
10/09/2021 09:54:14 - INFO - trainer -     slot_precision = 0.9891515994436718
10/09/2021 09:54:14 - INFO - trainer -     slot_recall = 0.9930187098575817

10/09/2021 09:54:14 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:54:14 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:54:14 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:54:14 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:54:14 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:54:14 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:54:14 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:54:14 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:54:14 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:54:14 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:54:14 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:54:14 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:54:14 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:54:14 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:54:14 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:54:14 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:54:14 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:54:38 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 347/918 [00:45<01:08,  8.37it/s]
10/09/2021 09:54:38 - INFO - trainer -     Num examples = 3258
10/09/2021 09:54:38 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.03it/s]
10/09/2021 09:54:42 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:54:42 - INFO - trainer -     T-F1 = 0.9915531335149864█████████████████▋ | 50/51 [00:03<00:00, 14.03it/s]
10/09/2021 09:54:42 - INFO - trainer -     T-F1(C) = 0.9756795422031473
10/09/2021 09:54:42 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:54:42 - INFO - trainer -     T-F1(O) = 0.9966370145367759
10/09/2021 09:54:42 - INFO - trainer -     T-F1(P) = 0.9973676513600468
10/09/2021 09:54:42 - INFO - trainer -     T-F1(S) = 0.9930907415937356
10/09/2021 09:54:42 - INFO - trainer -     T-F1(T) = 0.9748603351955307
10/09/2021 09:54:42 - INFO - trainer -     U-F1(A) = 0.7111111111111111
10/09/2021 09:54:42 - INFO - trainer -     U-F1(E) = 0.708910891089109
10/09/2021 09:54:42 - INFO - trainer -     U-F1(I) = 0.25531914893617025
10/09/2021 09:54:42 - INFO - trainer -     U-F1(O) = 0.9616182572614108
10/09/2021 09:54:42 - INFO - trainer -     intent_acc = 0.9300184162062615
10/09/2021 09:54:42 - INFO - trainer -     loss = 0.5558708879147091
10/09/2021 09:54:42 - INFO - trainer -     semantic_frame_acc = 0.9155923879680786
10/09/2021 09:54:42 - INFO - trainer -     slot_f1 = 0.991221959035809
10/09/2021 09:54:42 - INFO - trainer -     slot_precision = 0.989154616240267
10/09/2021 09:54:42 - INFO - trainer -     slot_recall = 0.9932979614632784

10/09/2021 09:54:42 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:54:42 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:54:42 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:54:42 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:54:42 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:54:42 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:54:42 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:54:42 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:54:42 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:54:42 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:54:42 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:54:42 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:54:42 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:54:42 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:54:42 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:54:42 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:54:42 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:55:06 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 547/918 [01:13<00:44,  8.27it/s]
10/09/2021 09:55:06 - INFO - trainer -     Num examples = 3258
10/09/2021 09:55:06 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.03it/s]
10/09/2021 09:55:10 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:55:10 - INFO - trainer -     T-F1 = 0.992224798799618██████████████████▋ | 50/51 [00:03<00:00, 13.96it/s]
10/09/2021 09:55:10 - INFO - trainer -     T-F1(C) = 0.9784791965566715
10/09/2021 09:55:10 - INFO - trainer -     T-F1(L) = 0.9940119760479043
10/09/2021 09:55:10 - INFO - trainer -     T-F1(O) = 0.9969097316345893
10/09/2021 09:55:10 - INFO - trainer -     T-F1(P) = 0.9962021618463338
10/09/2021 09:55:10 - INFO - trainer -     T-F1(S) = 0.994914470642626
10/09/2021 09:55:10 - INFO - trainer -     T-F1(T) = 0.9775910364145658
10/09/2021 09:55:10 - INFO - trainer -     U-F1(A) = 0.6927374301675977
10/09/2021 09:55:10 - INFO - trainer -     U-F1(E) = 0.7094188376753506
10/09/2021 09:55:10 - INFO - trainer -     U-F1(I) = 0.2608695652173913
10/09/2021 09:55:10 - INFO - trainer -     U-F1(O) = 0.9613259668508287
10/09/2021 09:55:10 - INFO - trainer -     intent_acc = 0.9297114794352364
10/09/2021 09:55:10 - INFO - trainer -     loss = 0.5283252677935011
10/09/2021 09:55:10 - INFO - trainer -     semantic_frame_acc = 0.9155923879680786
10/09/2021 09:55:10 - INFO - trainer -     slot_f1 = 0.9919084821428571
10/09/2021 09:55:10 - INFO - trainer -     slot_precision = 0.9910788960133816
10/09/2021 09:55:10 - INFO - trainer -     slot_recall = 0.9927394582518849

10/09/2021 09:55:10 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:55:10 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:55:10 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:55:10 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:55:10 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:55:10 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:55:10 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:55:10 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:55:10 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:55:10 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:55:10 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:55:10 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:55:10 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:55:10 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:55:10 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:55:10 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:55:10 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:55:34 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 747/918 [01:41<00:20,  8.39it/s]
10/09/2021 09:55:34 - INFO - trainer -     Num examples = 3258
10/09/2021 09:55:34 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.02it/s]
10/09/2021 09:55:38 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:55:38 - INFO - trainer -     T-F1 = 0.9923559923559924█████████████████▋ | 50/51 [00:03<00:00, 13.90it/s]
10/09/2021 09:55:38 - INFO - trainer -     T-F1(C) = 0.9784791965566715
10/09/2021 09:55:38 - INFO - trainer -     T-F1(L) = 0.9940119760479043
10/09/2021 09:55:38 - INFO - trainer -     T-F1(O) = 0.9969647696476964
10/09/2021 09:55:38 - INFO - trainer -     T-F1(P) = 0.9967845659163987
10/09/2021 09:55:38 - INFO - trainer -     T-F1(S) = 0.9944547134935305
10/09/2021 09:55:38 - INFO - trainer -     T-F1(T) = 0.9774647887323944
10/09/2021 09:55:38 - INFO - trainer -     U-F1(A) = 0.7111111111111111
10/09/2021 09:55:38 - INFO - trainer -     U-F1(E) = 0.7527272727272727
10/09/2021 09:55:38 - INFO - trainer -     U-F1(I) = 0.27906976744186046
10/09/2021 09:55:38 - INFO - trainer -     U-F1(O) = 0.9632596204074525
10/09/2021 09:55:38 - INFO - trainer -     intent_acc = 0.9340085942295887
10/09/2021 09:55:38 - INFO - trainer -     loss = 0.506670762620428
10/09/2021 09:55:38 - INFO - trainer -     semantic_frame_acc = 0.9201964395334561
10/09/2021 09:55:38 - INFO - trainer -     slot_f1 = 0.9919039642657732
10/09/2021 09:55:38 - INFO - trainer -     slot_precision = 0.99162712810494
10/09/2021 09:55:38 - INFO - trainer -     slot_recall = 0.9921809550404915

10/09/2021 09:55:38 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:55:38 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:55:38 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:55:38 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:55:38 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:55:38 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:55:38 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:55:38 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:55:38 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:55:38 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:55:38 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:55:38 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:55:38 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:55:38 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:55:38 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:55:38 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:55:38 - INFO - trainer -     slot_recall = 0.9910639486177045
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 918/918 [02:06<00:00,  7.27it/s]
Epoch:  75%|███████████████████████████████████████████████████████▌                  | 15/20 [38:15<10:46, 129.23s/it]10/09/2021 09:56:02 - INFO - trainer -   ***** Running evaluation on dev dataset ***** | 29/918 [00:03<01:46,  8.33it/s]
10/09/2021 09:56:02 - INFO - trainer -     Num examples = 3258
10/09/2021 09:56:02 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.01it/s]
10/09/2021 09:56:06 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:56:06 - INFO - trainer -     T-F1 = 0.9919519847224116█████████████████▋ | 50/51 [00:03<00:00, 13.95it/s]
10/09/2021 09:56:06 - INFO - trainer -     T-F1(C) = 0.9770773638968482
10/09/2021 09:56:06 - INFO - trainer -     T-F1(L) = 0.9909909909909909
10/09/2021 09:56:06 - INFO - trainer -     T-F1(O) = 0.9968013011656275
10/09/2021 09:56:06 - INFO - trainer -     T-F1(P) = 0.9964932787843368
10/09/2021 09:56:06 - INFO - trainer -     T-F1(S) = 0.9953746530989824
10/09/2021 09:56:06 - INFO - trainer -     T-F1(T) = 0.9748603351955307
10/09/2021 09:56:06 - INFO - trainer -     U-F1(A) = 0.6885245901639344
10/09/2021 09:56:06 - INFO - trainer -     U-F1(E) = 0.7438330170777988
10/09/2021 09:56:06 - INFO - trainer -     U-F1(I) = 0.27906976744186046
10/09/2021 09:56:06 - INFO - trainer -     U-F1(O) = 0.963387124761409
10/09/2021 09:56:06 - INFO - trainer -     intent_acc = 0.9333947206875384
10/09/2021 09:56:06 - INFO - trainer -     loss = 0.49591971203392626
10/09/2021 09:56:06 - INFO - trainer -     semantic_frame_acc = 0.9192756292203806
10/09/2021 09:56:06 - INFO - trainer -     slot_f1 = 0.9916294642857143
10/09/2021 09:56:06 - INFO - trainer -     slot_precision = 0.9908001115137999
10/09/2021 09:56:06 - INFO - trainer -     slot_recall = 0.9924602066461882

10/09/2021 09:56:06 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:56:06 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:56:06 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:56:06 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:56:06 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:56:06 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:56:06 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:56:06 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:56:06 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:56:06 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:56:06 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:56:06 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:56:06 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:56:06 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:56:06 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:56:06 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:56:06 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:56:30 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 229/918 [00:31<01:23,  8.23it/s]
10/09/2021 09:56:30 - INFO - trainer -     Num examples = 3258
10/09/2021 09:56:30 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 13.90it/s]
10/09/2021 09:56:34 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:56:34 - INFO - trainer -     T-F1 = 0.9915485278080698█████████████████▋ | 50/51 [00:03<00:00, 13.87it/s]
10/09/2021 09:56:34 - INFO - trainer -     T-F1(C) = 0.9744318181818182
10/09/2021 09:56:34 - INFO - trainer -     T-F1(L) = 0.9940119760479043
10/09/2021 09:56:34 - INFO - trainer -     T-F1(O) = 0.9966377440347072
10/09/2021 09:56:34 - INFO - trainer -     T-F1(P) = 0.9973661106233538
10/09/2021 09:56:34 - INFO - trainer -     T-F1(S) = 0.9935364727608494
10/09/2021 09:56:34 - INFO - trainer -     T-F1(T) = 0.9734265734265735
10/09/2021 09:56:34 - INFO - trainer -     U-F1(A) = 0.6857142857142857
10/09/2021 09:56:34 - INFO - trainer -     U-F1(E) = 0.7495291902071562
10/09/2021 09:56:34 - INFO - trainer -     U-F1(I) = 0.2631578947368421
10/09/2021 09:56:34 - INFO - trainer -     U-F1(O) = 0.9643104643104643
10/09/2021 09:56:34 - INFO - trainer -     intent_acc = 0.9352363413136894
10/09/2021 09:56:34 - INFO - trainer -     loss = 0.5046255435502413
10/09/2021 09:56:34 - INFO - trainer -     semantic_frame_acc = 0.9195825659914058
10/09/2021 09:56:34 - INFO - trainer -     slot_f1 = 0.9910788960133816
10/09/2021 09:56:34 - INFO - trainer -     slot_precision = 0.989423879766212
10/09/2021 09:56:34 - INFO - trainer -     slot_recall = 0.9927394582518849

10/09/2021 09:56:34 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:56:34 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:56:34 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:56:34 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:56:34 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:56:34 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:56:34 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:56:34 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:56:34 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:56:34 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:56:34 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:56:34 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:56:34 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:56:34 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:56:34 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:56:34 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:56:34 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:56:58 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 429/918 [00:59<00:58,  8.37it/s]
10/09/2021 09:56:58 - INFO - trainer -     Num examples = 3258
10/09/2021 09:56:58 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.01it/s]
10/09/2021 09:57:02 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:57:02 - INFO - trainer -     T-F1 = 0.9916723549488055█████████████████▋ | 50/51 [00:03<00:00, 13.94it/s]
10/09/2021 09:57:02 - INFO - trainer -     T-F1(C) = 0.9784172661870504
10/09/2021 09:57:02 - INFO - trainer -     T-F1(L) = 0.9909909909909909
10/09/2021 09:57:02 - INFO - trainer -     T-F1(O) = 0.9966939461275811
10/09/2021 09:57:02 - INFO - trainer -     T-F1(P) = 0.997072599531616
10/09/2021 09:57:02 - INFO - trainer -     T-F1(S) = 0.9935364727608494
10/09/2021 09:57:02 - INFO - trainer -     T-F1(T) = 0.9734265734265735
10/09/2021 09:57:02 - INFO - trainer -     U-F1(A) = 0.6847826086956521
10/09/2021 09:57:02 - INFO - trainer -     U-F1(E) = 0.7509578544061303
10/09/2021 09:57:02 - INFO - trainer -     U-F1(I) = 0.2608695652173913
10/09/2021 09:57:02 - INFO - trainer -     U-F1(O) = 0.963913948646773
10/09/2021 09:57:02 - INFO - trainer -     intent_acc = 0.9340085942295887
10/09/2021 09:57:02 - INFO - trainer -     loss = 0.5054409730010757
10/09/2021 09:57:02 - INFO - trainer -     semantic_frame_acc = 0.9192756292203806
10/09/2021 09:57:02 - INFO - trainer -     slot_f1 = 0.9912048024570711
10/09/2021 09:57:02 - INFO - trainer -     slot_precision = 0.9910664433277498
10/09/2021 09:57:02 - INFO - trainer -     slot_recall = 0.9913432002234013

10/09/2021 09:57:02 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:57:02 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:57:02 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:57:02 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:57:02 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:57:02 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:57:02 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:57:02 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:57:02 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:57:02 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:57:02 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:57:02 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:57:02 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:57:02 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:57:02 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:57:02 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:57:02 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:57:26 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 629/918 [01:27<00:34,  8.35it/s]
10/09/2021 09:57:26 - INFO - trainer -     Num examples = 3258
10/09/2021 09:57:26 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.08it/s]
10/09/2021 09:57:30 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:57:30 - INFO - trainer -     T-F1 = 0.9912806539509538█████████████████▋ | 50/51 [00:03<00:00, 13.96it/s]
10/09/2021 09:57:30 - INFO - trainer -     T-F1(C) = 0.9799426934097422
10/09/2021 09:57:30 - INFO - trainer -     T-F1(L) = 0.9909909909909909
10/09/2021 09:57:30 - INFO - trainer -     T-F1(O) = 0.9965285311347365
10/09/2021 09:57:30 - INFO - trainer -     T-F1(P) = 0.9967826849956127
10/09/2021 09:57:30 - INFO - trainer -     T-F1(S) = 0.9921622867680959
10/09/2021 09:57:30 - INFO - trainer -     T-F1(T) = 0.9736477115117893
10/09/2021 09:57:30 - INFO - trainer -     U-F1(A) = 0.6892655367231639
10/09/2021 09:57:30 - INFO - trainer -     U-F1(E) = 0.7523629489603024
10/09/2021 09:57:30 - INFO - trainer -     U-F1(I) = 0.29268292682926833
10/09/2021 09:57:30 - INFO - trainer -     U-F1(O) = 0.9648119258103658
10/09/2021 09:57:30 - INFO - trainer -     intent_acc = 0.9358502148557397
10/09/2021 09:57:30 - INFO - trainer -     loss = 0.4874792705819595
10/09/2021 09:57:30 - INFO - trainer -     semantic_frame_acc = 0.9201964395334561
10/09/2021 09:57:30 - INFO - trainer -     slot_f1 = 0.9909432910686917
10/09/2021 09:57:30 - INFO - trainer -     slot_precision = 0.9888765294771968
10/09/2021 09:57:30 - INFO - trainer -     slot_recall = 0.9930187098575817

10/09/2021 09:57:30 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:57:30 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:57:30 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:57:30 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:57:30 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:57:30 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:57:30 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:57:30 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:57:30 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:57:30 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:57:30 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:57:30 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:57:30 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:57:30 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:57:30 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:57:30 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:57:30 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:57:54 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 829/918 [01:55<00:10,  8.39it/s]
10/09/2021 09:57:54 - INFO - trainer -     Num examples = 3258
10/09/2021 09:57:54 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.03it/s]
10/09/2021 09:57:58 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:57:58 - INFO - trainer -     T-F1 = 0.9919431926805953█████████████████▋ | 50/51 [00:03<00:00, 13.92it/s]
10/09/2021 09:57:58 - INFO - trainer -     T-F1(C) = 0.9784791965566715
10/09/2021 09:57:58 - INFO - trainer -     T-F1(L) = 0.9909909909909909
10/09/2021 09:57:58 - INFO - trainer -     T-F1(O) = 0.996802687909825
10/09/2021 09:57:58 - INFO - trainer -     T-F1(P) = 0.9970743124634289
10/09/2021 09:57:58 - INFO - trainer -     T-F1(S) = 0.9939953810623556
10/09/2021 09:57:58 - INFO - trainer -     T-F1(T) = 0.9746478873239436
10/09/2021 09:57:58 - INFO - trainer -     U-F1(A) = 0.6951871657754011
10/09/2021 09:57:58 - INFO - trainer -     U-F1(E) = 0.7269155206286837
10/09/2021 09:57:58 - INFO - trainer -     U-F1(I) = 0.2631578947368421
10/09/2021 09:57:58 - INFO - trainer -     U-F1(O) = 0.963680387409201
10/09/2021 09:57:58 - INFO - trainer -     intent_acc = 0.9333947206875384
10/09/2021 09:57:58 - INFO - trainer -     loss = 0.5201365410523745
10/09/2021 09:57:58 - INFO - trainer -     semantic_frame_acc = 0.919889502762431
10/09/2021 09:57:58 - INFO - trainer -     slot_f1 = 0.9914816366429269
10/09/2021 09:57:58 - INFO - trainer -     slot_precision = 0.9916201117318436
10/09/2021 09:57:58 - INFO - trainer -     slot_recall = 0.9913432002234013

10/09/2021 09:57:58 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:57:58 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:57:58 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:57:58 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:57:58 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:57:58 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:57:58 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:57:58 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:57:58 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:57:58 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:57:58 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:57:58 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:57:58 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:57:58 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:57:58 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:57:58 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:57:58 - INFO - trainer -     slot_recall = 0.9910639486177045
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 918/918 [02:10<00:00,  7.05it/s]
Epoch:  80%|███████████████████████████████████████████████████████████▏              | 16/20 [40:25<08:37, 129.50s/it]10/09/2021 09:58:22 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 111/918 [00:13<01:37,  8.24it/s]
10/09/2021 09:58:22 - INFO - trainer -     Num examples = 3258
10/09/2021 09:58:22 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.02it/s]
10/09/2021 09:58:26 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:58:26 - INFO - trainer -     T-F1 = 0.9918211559432935█████████████████▋ | 50/51 [00:03<00:00, 13.97it/s]
10/09/2021 09:58:26 - INFO - trainer -     T-F1(C) = 0.9743589743589743
10/09/2021 09:58:26 - INFO - trainer -     T-F1(L) = 0.9940119760479043
10/09/2021 09:58:26 - INFO - trainer -     T-F1(O) = 0.9967462039045554
10/09/2021 09:58:26 - INFO - trainer -     T-F1(P) = 0.9970743124634289
10/09/2021 09:58:26 - INFO - trainer -     T-F1(S) = 0.9939953810623556
10/09/2021 09:58:26 - INFO - trainer -     T-F1(T) = 0.9762900976290098
10/09/2021 09:58:26 - INFO - trainer -     U-F1(A) = 0.6627218934911242
10/09/2021 09:58:26 - INFO - trainer -     U-F1(E) = 0.7432950191570882
10/09/2021 09:58:26 - INFO - trainer -     U-F1(I) = 0.27272727272727276
10/09/2021 09:58:26 - INFO - trainer -     U-F1(O) = 0.9635011243729459
10/09/2021 09:58:26 - INFO - trainer -     intent_acc = 0.9333947206875384
10/09/2021 09:58:26 - INFO - trainer -     loss = 0.5195518599129191
10/09/2021 09:58:26 - INFO - trainer -     semantic_frame_acc = 0.9186617556783303
10/09/2021 09:58:26 - INFO - trainer -     slot_f1 = 0.9914958873553604
10/09/2021 09:58:26 - INFO - trainer -     slot_precision = 0.9899777282850779
10/09/2021 09:58:26 - INFO - trainer -     slot_recall = 0.9930187098575817

10/09/2021 09:58:26 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:58:26 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:58:26 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:58:26 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:58:26 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:58:26 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:58:26 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:58:26 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:58:26 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:58:26 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:58:26 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:58:26 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:58:26 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:58:26 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:58:26 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:58:26 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:58:26 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:58:50 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 311/918 [00:41<01:12,  8.38it/s]
10/09/2021 09:58:50 - INFO - trainer -     Num examples = 3258
10/09/2021 09:58:50 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.02it/s]
10/09/2021 09:58:54 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:58:54 - INFO - trainer -     T-F1 = 0.991685975194221██████████████████▋ | 50/51 [00:03<00:00, 13.94it/s]
10/09/2021 09:58:54 - INFO - trainer -     T-F1(C) = 0.9757489300998574
10/09/2021 09:58:54 - INFO - trainer -     T-F1(L) = 0.9940119760479043
10/09/2021 09:58:54 - INFO - trainer -     T-F1(O) = 0.9966917945658659
10/09/2021 09:58:54 - INFO - trainer -     T-F1(P) = 0.9970743124634289
10/09/2021 09:58:54 - INFO - trainer -     T-F1(S) = 0.9944598337950139
10/09/2021 09:58:54 - INFO - trainer -     T-F1(T) = 0.9721448467966575
10/09/2021 09:58:54 - INFO - trainer -     U-F1(A) = 0.6885245901639344
10/09/2021 09:58:54 - INFO - trainer -     U-F1(E) = 0.7640449438202248
10/09/2021 09:58:54 - INFO - trainer -     U-F1(I) = 0.27272727272727276
10/09/2021 09:58:54 - INFO - trainer -     U-F1(O) = 0.9643788010425718
10/09/2021 09:58:54 - INFO - trainer -     intent_acc = 0.9355432780847146
10/09/2021 09:58:54 - INFO - trainer -     loss = 0.515433840636237
10/09/2021 09:58:54 - INFO - trainer -     semantic_frame_acc = 0.9208103130755064
10/09/2021 09:58:54 - INFO - trainer -     slot_f1 = 0.9913576805129635
10/09/2021 09:58:54 - INFO - trainer -     slot_precision = 0.9897021987197329
10/09/2021 09:58:54 - INFO - trainer -     slot_recall = 0.9930187098575817

10/09/2021 09:58:54 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:58:54 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:58:54 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:58:54 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:58:54 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:58:54 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:58:54 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:58:54 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:58:54 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:58:54 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:58:54 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:58:54 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:58:54 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:58:54 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:58:54 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:58:54 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:58:54 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:59:18 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 511/918 [01:09<00:48,  8.37it/s]
10/09/2021 09:59:18 - INFO - trainer -     Num examples = 3258
10/09/2021 09:59:18 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.03it/s]
10/09/2021 09:59:22 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:59:22 - INFO - trainer -     T-F1 = 0.9915485278080698█████████████████▋ | 50/51 [00:03<00:00, 13.97it/s]
10/09/2021 09:59:22 - INFO - trainer -     T-F1(C) = 0.9729729729729729
10/09/2021 09:59:22 - INFO - trainer -     T-F1(L) = 0.9940119760479043
10/09/2021 09:59:22 - INFO - trainer -     T-F1(O) = 0.9966377440347072
10/09/2021 09:59:22 - INFO - trainer -     T-F1(P) = 0.9967826849956127
10/09/2021 09:59:22 - INFO - trainer -     T-F1(S) = 0.9935364727608494
10/09/2021 09:59:22 - INFO - trainer -     T-F1(T) = 0.9775910364145658
10/09/2021 09:59:22 - INFO - trainer -     U-F1(A) = 0.6704545454545453
10/09/2021 09:59:22 - INFO - trainer -     U-F1(E) = 0.7283464566929134
10/09/2021 09:59:22 - INFO - trainer -     U-F1(I) = 0.25
10/09/2021 09:59:22 - INFO - trainer -     U-F1(O) = 0.9623618784530386
10/09/2021 09:59:22 - INFO - trainer -     intent_acc = 0.9318600368324125
10/09/2021 09:59:22 - INFO - trainer -     loss = 0.552426211006355
10/09/2021 09:59:22 - INFO - trainer -     semantic_frame_acc = 0.9174340085942296
10/09/2021 09:59:22 - INFO - trainer -     slot_f1 = 0.9912170639899623
10/09/2021 09:59:22 - INFO - trainer -     slot_precision = 0.9896993318485523
10/09/2021 09:59:22 - INFO - trainer -     slot_recall = 0.9927394582518849

10/09/2021 09:59:22 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:59:22 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:59:22 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:59:22 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:59:22 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:59:22 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:59:22 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:59:22 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:59:22 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:59:22 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:59:22 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:59:22 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:59:22 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:59:22 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:59:22 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:59:22 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:59:22 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 09:59:46 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 711/918 [01:37<00:24,  8.36it/s]
10/09/2021 09:59:46 - INFO - trainer -     Num examples = 3258
10/09/2021 09:59:46 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.05it/s]
10/09/2021 09:59:50 - INFO - trainer -   ***** Eval results *****
10/09/2021 09:59:50 - INFO - trainer -     T-F1 = 0.9911480321394526█████████████████▋ | 50/51 [00:03<00:00, 14.02it/s]
10/09/2021 09:59:50 - INFO - trainer -     T-F1(C) = 0.9729729729729729
10/09/2021 09:59:50 - INFO - trainer -     T-F1(L) = 0.9940119760479043
10/09/2021 09:59:50 - INFO - trainer -     T-F1(O) = 0.9964737156187272
10/09/2021 09:59:50 - INFO - trainer -     T-F1(P) = 0.9970743124634289
10/09/2021 09:59:50 - INFO - trainer -     T-F1(S) = 0.9930907415937356
10/09/2021 09:59:50 - INFO - trainer -     T-F1(T) = 0.9735006973500697
10/09/2021 09:59:50 - INFO - trainer -     U-F1(A) = 0.6742857142857143
10/09/2021 09:59:50 - INFO - trainer -     U-F1(E) = 0.73828125
10/09/2021 09:59:50 - INFO - trainer -     U-F1(I) = 0.25
10/09/2021 09:59:50 - INFO - trainer -     U-F1(O) = 0.9635515633097252
10/09/2021 09:59:50 - INFO - trainer -     intent_acc = 0.9337016574585635
10/09/2021 09:59:50 - INFO - trainer -     loss = 0.5392705937299658
10/09/2021 09:59:50 - INFO - trainer -     semantic_frame_acc = 0.9186617556783303
10/09/2021 09:59:50 - INFO - trainer -     slot_f1 = 0.990807799442897
10/09/2021 09:59:50 - INFO - trainer -     slot_precision = 0.9883300916921367
10/09/2021 09:59:50 - INFO - trainer -     slot_recall = 0.9932979614632784

10/09/2021 09:59:50 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 09:59:50 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 09:59:50 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 09:59:50 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 09:59:50 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 09:59:50 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 09:59:50 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 09:59:50 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 09:59:50 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 09:59:50 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 09:59:50 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 09:59:50 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 09:59:50 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 09:59:50 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 09:59:50 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 09:59:50 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 09:59:50 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 10:00:14 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 911/918 [02:05<00:00,  8.36it/s]
10/09/2021 10:00:14 - INFO - trainer -     Num examples = 3258
10/09/2021 10:00:14 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 13.97it/s]
10/09/2021 10:00:18 - INFO - trainer -   ***** Eval results *****
10/09/2021 10:00:18 - INFO - trainer -     T-F1 = 0.9912806539509538█████████████████▋ | 50/51 [00:03<00:00, 13.80it/s]
10/09/2021 10:00:18 - INFO - trainer -     T-F1(C) = 0.9756795422031473
10/09/2021 10:00:18 - INFO - trainer -     T-F1(L) = 0.9940119760479043
10/09/2021 10:00:18 - INFO - trainer -     T-F1(O) = 0.9965285311347365
10/09/2021 10:00:18 - INFO - trainer -     T-F1(P) = 0.9970743124634289
10/09/2021 10:00:18 - INFO - trainer -     T-F1(S) = 0.992633517495396
10/09/2021 10:00:18 - INFO - trainer -     T-F1(T) = 0.9735006973500697
10/09/2021 10:00:18 - INFO - trainer -     U-F1(A) = 0.6994535519125683
10/09/2021 10:00:18 - INFO - trainer -     U-F1(E) = 0.7556390977443609
10/09/2021 10:00:18 - INFO - trainer -     U-F1(I) = 0.29268292682926833
10/09/2021 10:00:18 - INFO - trainer -     U-F1(O) = 0.9645833333333333
10/09/2021 10:00:18 - INFO - trainer -     intent_acc = 0.9358502148557397
10/09/2021 10:00:18 - INFO - trainer -     loss = 0.5094686232178527
10/09/2021 10:00:18 - INFO - trainer -     semantic_frame_acc = 0.9208103130755064
10/09/2021 10:00:18 - INFO - trainer -     slot_f1 = 0.9909432910686917
10/09/2021 10:00:18 - INFO - trainer -     slot_precision = 0.9888765294771968
10/09/2021 10:00:18 - INFO - trainer -     slot_recall = 0.9930187098575817

10/09/2021 10:00:18 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 10:00:18 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 10:00:18 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 10:00:18 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 10:00:18 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 10:00:18 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 10:00:18 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 10:00:18 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 10:00:18 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 10:00:18 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 10:00:18 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 10:00:18 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 10:00:18 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 10:00:18 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 10:00:18 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 10:00:18 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 10:00:18 - INFO - trainer -     slot_recall = 0.9910639486177045
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 918/918 [02:10<00:00,  7.06it/s]
Epoch:  85%|██████████████████████████████████████████████████████████████▉           | 17/20 [42:35<06:28, 129.66s/it]10/09/2021 10:00:42 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 193/918 [00:23<01:26,  8.42it/s]
10/09/2021 10:00:42 - INFO - trainer -     Num examples = 3258
10/09/2021 10:00:42 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.02it/s]
10/09/2021 10:00:46 - INFO - trainer -   ***** Eval results *****
10/09/2021 10:00:46 - INFO - trainer -     T-F1 = 0.9918189255522225█████████████████▋ | 50/51 [00:03<00:00, 14.00it/s]
10/09/2021 10:00:46 - INFO - trainer -     T-F1(C) = 0.9756795422031473
10/09/2021 10:00:46 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 10:00:46 - INFO - trainer -     T-F1(O) = 0.9967465567725842
10/09/2021 10:00:46 - INFO - trainer -     T-F1(P) = 0.9970743124634289
10/09/2021 10:00:46 - INFO - trainer -     T-F1(S) = 0.9940009229349331
10/09/2021 10:00:46 - INFO - trainer -     T-F1(T) = 0.9762237762237763
10/09/2021 10:00:46 - INFO - trainer -     U-F1(A) = 0.6923076923076923
10/09/2021 10:00:46 - INFO - trainer -     U-F1(E) = 0.7533460803059274
10/09/2021 10:00:46 - INFO - trainer -     U-F1(I) = 0.3
10/09/2021 10:00:46 - INFO - trainer -     U-F1(O) = 0.9648241206030151
10/09/2021 10:00:46 - INFO - trainer -     intent_acc = 0.9361571516267649
10/09/2021 10:00:46 - INFO - trainer -     loss = 0.5311606765049053
10/09/2021 10:00:46 - INFO - trainer -     semantic_frame_acc = 0.9214241866175568
10/09/2021 10:00:46 - INFO - trainer -     slot_f1 = 0.9914935155487381
10/09/2021 10:00:46 - INFO - trainer -     slot_precision = 0.9902506963788301
10/09/2021 10:00:46 - INFO - trainer -     slot_recall = 0.9927394582518849

10/09/2021 10:00:46 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 10:00:46 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 10:00:46 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 10:00:46 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 10:00:46 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 10:00:46 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 10:00:46 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 10:00:46 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 10:00:46 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 10:00:46 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 10:00:46 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 10:00:46 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 10:00:46 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 10:00:46 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 10:00:46 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 10:00:46 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 10:00:46 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 10:01:10 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 393/918 [00:51<01:03,  8.26it/s]
10/09/2021 10:01:10 - INFO - trainer -     Num examples = 3258
10/09/2021 10:01:10 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.01it/s]
10/09/2021 10:01:14 - INFO - trainer -   ***** Eval results *****
10/09/2021 10:01:14 - INFO - trainer -     T-F1 = 0.9908706908298134█████████████████▋ | 50/51 [00:03<00:00, 13.96it/s]
10/09/2021 10:01:14 - INFO - trainer -     T-F1(C) = 0.9728958630527819
10/09/2021 10:01:14 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 10:01:14 - INFO - trainer -     T-F1(O) = 0.9963660031458481
10/09/2021 10:01:14 - INFO - trainer -     T-F1(P) = 0.9970743124634289
10/09/2021 10:01:14 - INFO - trainer -     T-F1(S) = 0.992169507139567
10/09/2021 10:01:14 - INFO - trainer -     T-F1(T) = 0.9747899159663864
10/09/2021 10:01:14 - INFO - trainer -     U-F1(A) = 0.6931818181818182
10/09/2021 10:01:14 - INFO - trainer -     U-F1(E) = 0.7495291902071562
10/09/2021 10:01:14 - INFO - trainer -     U-F1(I) = 0.2857142857142857
10/09/2021 10:01:14 - INFO - trainer -     U-F1(O) = 0.9644529217964279
10/09/2021 10:01:14 - INFO - trainer -     intent_acc = 0.9352363413136894
10/09/2021 10:01:14 - INFO - trainer -     loss = 0.5341050590333694
10/09/2021 10:01:14 - INFO - trainer -     semantic_frame_acc = 0.9192756292203806
10/09/2021 10:01:14 - INFO - trainer -     slot_f1 = 0.9905239687848383
10/09/2021 10:01:14 - INFO - trainer -     slot_precision = 0.9885952712100139
10/09/2021 10:01:14 - INFO - trainer -     slot_recall = 0.9924602066461882

10/09/2021 10:01:14 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 10:01:14 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 10:01:14 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 10:01:14 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 10:01:14 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 10:01:14 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 10:01:14 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 10:01:14 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 10:01:14 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 10:01:14 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 10:01:14 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 10:01:14 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 10:01:14 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 10:01:14 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 10:01:14 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 10:01:14 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 10:01:14 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 10:01:38 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 593/918 [01:19<00:39,  8.31it/s]
10/09/2021 10:01:38 - INFO - trainer -     Num examples = 3258
10/09/2021 10:01:38 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.00it/s]
10/09/2021 10:01:42 - INFO - trainer -   ***** Eval results *****
10/09/2021 10:01:42 - INFO - trainer -     T-F1 = 0.991008174386921██████████████████▋ | 50/51 [00:03<00:00, 13.85it/s]
10/09/2021 10:01:42 - INFO - trainer -     T-F1(C) = 0.9729729729729729
10/09/2021 10:01:42 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 10:01:42 - INFO - trainer -     T-F1(O) = 0.9964200477326969
10/09/2021 10:01:42 - INFO - trainer -     T-F1(P) = 0.9970743124634289
10/09/2021 10:01:42 - INFO - trainer -     T-F1(S) = 0.9930907415937356
10/09/2021 10:01:42 - INFO - trainer -     T-F1(T) = 0.9733520336605891
10/09/2021 10:01:42 - INFO - trainer -     U-F1(A) = 0.6779661016949152
10/09/2021 10:01:42 - INFO - trainer -     U-F1(E) = 0.7523629489603024
10/09/2021 10:01:42 - INFO - trainer -     U-F1(I) = 0.3
10/09/2021 10:01:42 - INFO - trainer -     U-F1(O) = 0.9646447140381282
10/09/2021 10:01:42 - INFO - trainer -     intent_acc = 0.9355432780847146
10/09/2021 10:01:42 - INFO - trainer -     loss = 0.5296373598314091
10/09/2021 10:01:42 - INFO - trainer -     semantic_frame_acc = 0.919889502762431
10/09/2021 10:01:42 - INFO - trainer -     slot_f1 = 0.9906646231015744
10/09/2021 10:01:42 - INFO - trainer -     slot_precision = 0.9885984427141268
10/09/2021 10:01:42 - INFO - trainer -     slot_recall = 0.9927394582518849

10/09/2021 10:01:42 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 10:01:42 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 10:01:42 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 10:01:42 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 10:01:42 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 10:01:42 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 10:01:42 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 10:01:42 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 10:01:42 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 10:01:42 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 10:01:42 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 10:01:42 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 10:01:42 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 10:01:42 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 10:01:42 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 10:01:42 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 10:01:42 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 10:02:06 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 793/918 [01:47<00:14,  8.40it/s]
10/09/2021 10:02:06 - INFO - trainer -     Num examples = 3258
10/09/2021 10:02:06 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.01it/s]
10/09/2021 10:02:10 - INFO - trainer -   ***** Eval results *****
10/09/2021 10:02:10 - INFO - trainer -     T-F1 = 0.9911407932397437█████████████████▋ | 50/51 [00:03<00:00, 13.87it/s]
10/09/2021 10:02:10 - INFO - trainer -     T-F1(C) = 0.9728958630527819
10/09/2021 10:02:10 - INFO - trainer -     T-F1(L) = 0.9940119760479043
10/09/2021 10:02:10 - INFO - trainer -     T-F1(O) = 0.9964748630619882
10/09/2021 10:02:10 - INFO - trainer -     T-F1(P) = 0.9970743124634289
10/09/2021 10:02:10 - INFO - trainer -     T-F1(S) = 0.9935424354243543
10/09/2021 10:02:10 - INFO - trainer -     T-F1(T) = 0.9720670391061452
10/09/2021 10:02:10 - INFO - trainer -     U-F1(A) = 0.6779661016949152
10/09/2021 10:02:10 - INFO - trainer -     U-F1(E) = 0.7437379576107901
10/09/2021 10:02:10 - INFO - trainer -     U-F1(I) = 0.3
10/09/2021 10:02:10 - INFO - trainer -     U-F1(O) = 0.9643598615916954
10/09/2021 10:02:10 - INFO - trainer -     intent_acc = 0.9349294045426643
10/09/2021 10:02:10 - INFO - trainer -     loss = 0.5306314542871334
10/09/2021 10:02:10 - INFO - trainer -     semantic_frame_acc = 0.919889502762431
10/09/2021 10:02:10 - INFO - trainer -     slot_f1 = 0.9908001115137998
10/09/2021 10:02:10 - INFO - trainer -     slot_precision = 0.9891455608126913
10/09/2021 10:02:10 - INFO - trainer -     slot_recall = 0.9924602066461882

10/09/2021 10:02:10 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 10:02:10 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 10:02:10 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 10:02:10 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 10:02:10 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 10:02:10 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 10:02:10 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 10:02:10 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 10:02:10 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 10:02:10 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 10:02:10 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 10:02:10 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 10:02:10 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 10:02:10 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 10:02:10 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 10:02:10 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 10:02:10 - INFO - trainer -     slot_recall = 0.9910639486177045
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 918/918 [02:06<00:00,  7.28it/s]
Epoch:  90%|██████████████████████████████████████████████████████████████████▌       | 18/20 [44:42<04:17, 128.60s/it]10/09/2021 10:02:34 - INFO - trainer -   ***** Running evaluation on dev dataset ***** | 75/918 [00:08<01:41,  8.33it/s]
10/09/2021 10:02:34 - INFO - trainer -     Num examples = 3258
10/09/2021 10:02:34 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.00it/s]
10/09/2021 10:02:38 - INFO - trainer -   ***** Eval results *****
10/09/2021 10:02:38 - INFO - trainer -     T-F1 = 0.9903335602450646█████████████████▋ | 50/51 [00:03<00:00, 13.90it/s]
10/09/2021 10:02:38 - INFO - trainer -     T-F1(C) = 0.9715909090909091
10/09/2021 10:02:38 - INFO - trainer -     T-F1(L) = 0.9940119760479043
10/09/2021 10:02:38 - INFO - trainer -     T-F1(O) = 0.9961477944766968
10/09/2021 10:02:38 - INFO - trainer -     T-F1(P) = 0.9964912280701754
10/09/2021 10:02:38 - INFO - trainer -     T-F1(S) = 0.992626728110599
10/09/2021 10:02:38 - INFO - trainer -     T-F1(T) = 0.9707112970711297
10/09/2021 10:02:38 - INFO - trainer -     U-F1(A) = 0.6857142857142857
10/09/2021 10:02:38 - INFO - trainer -     U-F1(E) = 0.7590132827324477
10/09/2021 10:02:38 - INFO - trainer -     U-F1(I) = 0.2857142857142857
10/09/2021 10:02:38 - INFO - trainer -     U-F1(O) = 0.9653499653499652
10/09/2021 10:02:38 - INFO - trainer -     intent_acc = 0.9367710251688153
10/09/2021 10:02:38 - INFO - trainer -     loss = 0.5244803957495034
10/09/2021 10:02:38 - INFO - trainer -     semantic_frame_acc = 0.9192756292203806
10/09/2021 10:02:38 - INFO - trainer -     slot_f1 = 0.9899749373433584
10/09/2021 10:02:38 - INFO - trainer -     slot_precision = 0.9872257706192724
10/09/2021 10:02:38 - INFO - trainer -     slot_recall = 0.9927394582518849

10/09/2021 10:02:38 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 10:02:38 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 10:02:38 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 10:02:38 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 10:02:38 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 10:02:38 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 10:02:38 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 10:02:38 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 10:02:38 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 10:02:38 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 10:02:38 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 10:02:38 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 10:02:38 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 10:02:38 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 10:02:38 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 10:02:38 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 10:02:38 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 10:03:02 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 275/918 [00:36<01:17,  8.29it/s]
10/09/2021 10:03:02 - INFO - trainer -     Num examples = 3258
10/09/2021 10:03:02 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.02it/s]
10/09/2021 10:03:06 - INFO - trainer -   ***** Eval results *****
10/09/2021 10:03:06 - INFO - trainer -     T-F1 = 0.9916791706452053█████████████████▋ | 50/51 [00:03<00:00, 13.96it/s]
10/09/2021 10:03:06 - INFO - trainer -     T-F1(C) = 0.9784791965566715
10/09/2021 10:03:06 - INFO - trainer -     T-F1(L) = 0.9940119760479043
10/09/2021 10:03:06 - INFO - trainer -     T-F1(O) = 0.9966928706966658
10/09/2021 10:03:06 - INFO - trainer -     T-F1(P) = 0.9970743124634289
10/09/2021 10:03:06 - INFO - trainer -     T-F1(S) = 0.9926199261992621
10/09/2021 10:03:06 - INFO - trainer -     T-F1(T) = 0.9747899159663864
10/09/2021 10:03:06 - INFO - trainer -     U-F1(A) = 0.6853932584269663
10/09/2021 10:03:06 - INFO - trainer -     U-F1(E) = 0.7480916030534351
10/09/2021 10:03:06 - INFO - trainer -     U-F1(I) = 0.3
10/09/2021 10:03:06 - INFO - trainer -     U-F1(O) = 0.9646692067890544
10/09/2021 10:03:06 - INFO - trainer -     intent_acc = 0.9355432780847146
10/09/2021 10:03:06 - INFO - trainer -     loss = 0.5321523315894107
10/09/2021 10:03:06 - INFO - trainer -     semantic_frame_acc = 0.921731123388582
10/09/2021 10:03:06 - INFO - trainer -     slot_f1 = 0.9913504464285714
10/09/2021 10:03:06 - INFO - trainer -     slot_precision = 0.990521327014218
10/09/2021 10:03:06 - INFO - trainer -     slot_recall = 0.9921809550404915

10/09/2021 10:03:06 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 10:03:06 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 10:03:06 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 10:03:06 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 10:03:06 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 10:03:06 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 10:03:06 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 10:03:06 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 10:03:06 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 10:03:06 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 10:03:06 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 10:03:06 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 10:03:06 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 10:03:06 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 10:03:06 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 10:03:06 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 10:03:06 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 10:03:30 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 475/918 [01:04<00:53,  8.27it/s]
10/09/2021 10:03:30 - INFO - trainer -     Num examples = 3258
10/09/2021 10:03:30 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 13.95it/s]
10/09/2021 10:03:34 - INFO - trainer -   ***** Eval results *****
10/09/2021 10:03:34 - INFO - trainer -     T-F1 = 0.9912782774597984█████████████████▋ | 50/51 [00:03<00:00, 13.81it/s]
10/09/2021 10:03:34 - INFO - trainer -     T-F1(C) = 0.978540772532189
10/09/2021 10:03:34 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 10:03:34 - INFO - trainer -     T-F1(O) = 0.996528907690639
10/09/2021 10:03:34 - INFO - trainer -     T-F1(P) = 0.9970743124634289
10/09/2021 10:03:34 - INFO - trainer -     T-F1(S) = 0.992626728110599
10/09/2021 10:03:34 - INFO - trainer -     T-F1(T) = 0.9720670391061452
10/09/2021 10:03:34 - INFO - trainer -     U-F1(A) = 0.6892655367231639
10/09/2021 10:03:34 - INFO - trainer -     U-F1(E) = 0.7490494296577946
10/09/2021 10:03:34 - INFO - trainer -     U-F1(I) = 0.27906976744186046
10/09/2021 10:03:34 - INFO - trainer -     U-F1(O) = 0.9642980935875216
10/09/2021 10:03:34 - INFO - trainer -     intent_acc = 0.9349294045426643
10/09/2021 10:03:34 - INFO - trainer -     loss = 0.538593859083074
10/09/2021 10:03:34 - INFO - trainer -     semantic_frame_acc = 0.919889502762431
10/09/2021 10:03:34 - INFO - trainer -     slot_f1 = 0.9909407665505227
10/09/2021 10:03:34 - INFO - trainer -     slot_precision = 0.9891485809682805
10/09/2021 10:03:34 - INFO - trainer -     slot_recall = 0.9927394582518849

10/09/2021 10:03:34 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 10:03:34 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 10:03:34 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 10:03:34 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 10:03:34 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 10:03:34 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 10:03:34 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 10:03:34 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 10:03:34 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 10:03:34 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 10:03:34 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 10:03:34 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 10:03:34 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 10:03:34 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 10:03:34 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 10:03:34 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 10:03:34 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 10:03:58 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 675/918 [01:32<00:29,  8.35it/s]
10/09/2021 10:03:58 - INFO - trainer -     Num examples = 3258
10/09/2021 10:03:58 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.02it/s]
10/09/2021 10:04:02 - INFO - trainer -   ***** Eval results *****
10/09/2021 10:04:02 - INFO - trainer -     T-F1 = 0.9912806539509538█████████████████▋ | 50/51 [00:03<00:00, 13.89it/s]
10/09/2021 10:04:02 - INFO - trainer -     T-F1(C) = 0.978540772532189
10/09/2021 10:04:02 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 10:04:02 - INFO - trainer -     T-F1(O) = 0.9965285311347365
10/09/2021 10:04:02 - INFO - trainer -     T-F1(P) = 0.9970743124634289
10/09/2021 10:04:02 - INFO - trainer -     T-F1(S) = 0.9930907415937356
10/09/2021 10:04:02 - INFO - trainer -     T-F1(T) = 0.9707112970711297
10/09/2021 10:04:02 - INFO - trainer -     U-F1(A) = 0.6892655367231639
10/09/2021 10:04:02 - INFO - trainer -     U-F1(E) = 0.7537878787878789
10/09/2021 10:04:02 - INFO - trainer -     U-F1(I) = 0.27906976744186046
10/09/2021 10:04:02 - INFO - trainer -     U-F1(O) = 0.9646324549237171
10/09/2021 10:04:02 - INFO - trainer -     intent_acc = 0.9355432780847146
10/09/2021 10:04:02 - INFO - trainer -     loss = 0.5412427542512032
10/09/2021 10:04:02 - INFO - trainer -     semantic_frame_acc = 0.9208103130755064
10/09/2021 10:04:02 - INFO - trainer -     slot_f1 = 0.9909432910686917
10/09/2021 10:04:02 - INFO - trainer -     slot_precision = 0.9888765294771968
10/09/2021 10:04:02 - INFO - trainer -     slot_recall = 0.9930187098575817

10/09/2021 10:04:02 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 10:04:02 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 10:04:02 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 10:04:02 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 10:04:02 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 10:04:02 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 10:04:02 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 10:04:02 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 10:04:02 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 10:04:02 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 10:04:02 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 10:04:02 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 10:04:02 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 10:04:02 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 10:04:02 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 10:04:02 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 10:04:02 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 10:04:26 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 875/918 [02:00<00:05,  8.23it/s]
10/09/2021 10:04:26 - INFO - trainer -     Num examples = 3258
10/09/2021 10:04:26 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 13.78it/s]
10/09/2021 10:04:30 - INFO - trainer -   ***** Eval results *****
10/09/2021 10:04:30 - INFO - trainer -     T-F1 = 0.9914110429447853█████████████████▋ | 50/51 [00:03<00:00, 13.86it/s]
10/09/2021 10:04:30 - INFO - trainer -     T-F1(C) = 0.9770114942528736
10/09/2021 10:04:30 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 10:04:30 - INFO - trainer -     T-F1(O) = 0.9965836993655441
10/09/2021 10:04:30 - INFO - trainer -     T-F1(P) = 0.9967826849956127
10/09/2021 10:04:30 - INFO - trainer -     T-F1(S) = 0.9935483870967743
10/09/2021 10:04:30 - INFO - trainer -     T-F1(T) = 0.9734265734265735
10/09/2021 10:04:30 - INFO - trainer -     U-F1(A) = 0.6818181818181819
10/09/2021 10:04:30 - INFO - trainer -     U-F1(E) = 0.7552182163187856
10/09/2021 10:04:30 - INFO - trainer -     U-F1(I) = 0.3
10/09/2021 10:04:30 - INFO - trainer -     U-F1(O) = 0.9651827472717824
10/09/2021 10:04:30 - INFO - trainer -     intent_acc = 0.93646408839779
10/09/2021 10:04:30 - INFO - trainer -     loss = 0.5381549539811471
10/09/2021 10:04:30 - INFO - trainer -     semantic_frame_acc = 0.9211172498465316
10/09/2021 10:04:30 - INFO - trainer -     slot_f1 = 0.9910764082543223
10/09/2021 10:04:30 - INFO - trainer -     slot_precision = 0.9896964633806739
10/09/2021 10:04:30 - INFO - trainer -     slot_recall = 0.9924602066461882

10/09/2021 10:04:30 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 10:04:30 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 10:04:30 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 10:04:30 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 10:04:30 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 10:04:30 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 10:04:30 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 10:04:30 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 10:04:30 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 10:04:30 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 10:04:30 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 10:04:30 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 10:04:30 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 10:04:30 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 10:04:30 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 10:04:30 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 10:04:30 - INFO - trainer -     slot_recall = 0.9910639486177045
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 918/918 [02:10<00:00,  7.05it/s]
Epoch:  95%|██████████████████████████████████████████████████████████████████████▎   | 19/20 [46:52<02:09, 129.07s/it]10/09/2021 10:04:54 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 157/918 [00:18<01:31,  8.35it/s]
10/09/2021 10:04:54 - INFO - trainer -     Num examples = 3258
10/09/2021 10:04:54 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 13.95it/s]
10/09/2021 10:04:58 - INFO - trainer -   ***** Eval results *****
10/09/2021 10:04:58 - INFO - trainer -     T-F1 = 0.9912711402073106█████████████████▋ | 50/51 [00:03<00:00, 13.86it/s]
10/09/2021 10:04:58 - INFO - trainer -     T-F1(C) = 0.9770114942528736
10/09/2021 10:04:58 - INFO - trainer -     T-F1(L) = 0.9940119760479043
10/09/2021 10:04:58 - INFO - trainer -     T-F1(O) = 0.9965300368683582
10/09/2021 10:04:58 - INFO - trainer -     T-F1(P) = 0.9970743124634289
10/09/2021 10:04:58 - INFO - trainer -     T-F1(S) = 0.9926199261992621
10/09/2021 10:04:58 - INFO - trainer -     T-F1(T) = 0.9720670391061452
10/09/2021 10:04:58 - INFO - trainer -     U-F1(A) = 0.6818181818181819
10/09/2021 10:04:58 - INFO - trainer -     U-F1(E) = 0.7533460803059274
10/09/2021 10:04:58 - INFO - trainer -     U-F1(I) = 0.29268292682926833
10/09/2021 10:04:58 - INFO - trainer -     U-F1(O) = 0.965027700831025
10/09/2021 10:04:58 - INFO - trainer -     intent_acc = 0.9361571516267649
10/09/2021 10:04:58 - INFO - trainer -     loss = 0.5452444030373704
10/09/2021 10:04:58 - INFO - trainer -     semantic_frame_acc = 0.9214241866175568
10/09/2021 10:04:58 - INFO - trainer -     slot_f1 = 0.9909331845445669
10/09/2021 10:04:58 - INFO - trainer -     slot_precision = 0.9899665551839465
10/09/2021 10:04:58 - INFO - trainer -     slot_recall = 0.9919017034347948

10/09/2021 10:04:58 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 10:04:58 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 10:04:58 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 10:04:58 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 10:04:58 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 10:04:58 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 10:04:58 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 10:04:58 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 10:04:58 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 10:04:58 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 10:04:58 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 10:04:58 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 10:04:58 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 10:04:58 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 10:04:58 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 10:04:58 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 10:04:58 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 10:05:22 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 357/918 [00:47<01:07,  8.34it/s]
10/09/2021 10:05:22 - INFO - trainer -     Num examples = 3258
10/09/2021 10:05:22 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 13.97it/s]
10/09/2021 10:05:26 - INFO - trainer -   ***** Eval results *****
10/09/2021 10:05:26 - INFO - trainer -     T-F1 = 0.9903309274138635█████████████████▋ | 50/51 [00:03<00:00, 13.95it/s]
10/09/2021 10:05:26 - INFO - trainer -     T-F1(C) = 0.9728958630527819
10/09/2021 10:05:26 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 10:05:26 - INFO - trainer -     T-F1(O) = 0.9961482124450713
10/09/2021 10:05:26 - INFO - trainer -     T-F1(P) = 0.9970743124634289
10/09/2021 10:05:26 - INFO - trainer -     T-F1(S) = 0.9926199261992621
10/09/2021 10:05:26 - INFO - trainer -     T-F1(T) = 0.9680998613037448
10/09/2021 10:05:26 - INFO - trainer -     U-F1(A) = 0.6779661016949152
10/09/2021 10:05:26 - INFO - trainer -     U-F1(E) = 0.7485604606525911
10/09/2021 10:05:26 - INFO - trainer -     U-F1(I) = 0.3
10/09/2021 10:05:26 - INFO - trainer -     U-F1(O) = 0.964693665628245
10/09/2021 10:05:26 - INFO - trainer -     intent_acc = 0.9355432780847146
10/09/2021 10:05:26 - INFO - trainer -     loss = 0.5452006501602191
10/09/2021 10:05:26 - INFO - trainer -     semantic_frame_acc = 0.9189686924493554
10/09/2021 10:05:26 - INFO - trainer -     slot_f1 = 0.9899721448467967
10/09/2021 10:05:26 - INFO - trainer -     slot_precision = 0.9874965268130036
10/09/2021 10:05:26 - INFO - trainer -     slot_recall = 0.9924602066461882

10/09/2021 10:05:26 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 10:05:26 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 10:05:26 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 10:05:26 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 10:05:26 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 10:05:26 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 10:05:26 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 10:05:26 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 10:05:26 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 10:05:26 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 10:05:26 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 10:05:26 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 10:05:26 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 10:05:26 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 10:05:26 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 10:05:26 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 10:05:26 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 10:05:50 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 557/918 [01:15<00:43,  8.34it/s]
10/09/2021 10:05:50 - INFO - trainer -     Num examples = 3258
10/09/2021 10:05:50 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.02it/s]
10/09/2021 10:05:54 - INFO - trainer -   ***** Eval results *****
10/09/2021 10:05:54 - INFO - trainer -     T-F1 = 0.9911383776414451█████████████████▋ | 50/51 [00:03<00:00, 13.96it/s]
10/09/2021 10:05:54 - INFO - trainer -     T-F1(C) = 0.9756795422031473
10/09/2021 10:05:54 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 10:05:54 - INFO - trainer -     T-F1(O) = 0.9964752453771487
10/09/2021 10:05:54 - INFO - trainer -     T-F1(P) = 0.9970743124634289
10/09/2021 10:05:54 - INFO - trainer -     T-F1(S) = 0.9926199261992621
10/09/2021 10:05:54 - INFO - trainer -     T-F1(T) = 0.9734265734265735
10/09/2021 10:05:54 - INFO - trainer -     U-F1(A) = 0.6779661016949152
10/09/2021 10:05:54 - INFO - trainer -     U-F1(E) = 0.7495219885277247
10/09/2021 10:05:54 - INFO - trainer -     U-F1(I) = 0.3
10/09/2021 10:05:54 - INFO - trainer -     U-F1(O) = 0.9646814404432132
10/09/2021 10:05:54 - INFO - trainer -     intent_acc = 0.9355432780847146
10/09/2021 10:05:54 - INFO - trainer -     loss = 0.5460452536924505
10/09/2021 10:05:54 - INFO - trainer -     semantic_frame_acc = 0.9208103130755064
10/09/2021 10:05:54 - INFO - trainer -     slot_f1 = 0.99079754601227
10/09/2021 10:05:54 - INFO - trainer -     slot_precision = 0.9894179894179894
10/09/2021 10:05:54 - INFO - trainer -     slot_recall = 0.9921809550404915

10/09/2021 10:05:54 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 10:05:54 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 10:05:54 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 10:05:54 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 10:05:54 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 10:05:54 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 10:05:54 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 10:05:54 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 10:05:54 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 10:05:54 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 10:05:54 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 10:05:54 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 10:05:54 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 10:05:54 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 10:05:54 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 10:05:54 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 10:05:54 - INFO - trainer -     slot_recall = 0.9910639486177045
                                                                                                                       10/09/2021 10:06:18 - INFO - trainer -   ***** Running evaluation on dev dataset *****| 757/918 [01:42<00:19,  8.36it/s]
10/09/2021 10:06:18 - INFO - trainer -     Num examples = 3258
10/09/2021 10:06:18 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 51/51 [00:03<00:00, 14.03it/s]
10/09/2021 10:06:22 - INFO - trainer -   ***** Eval results *****
10/09/2021 10:06:22 - INFO - trainer -     T-F1 = 0.9912711402073106█████████████████▋ | 50/51 [00:03<00:00, 13.93it/s]
10/09/2021 10:06:22 - INFO - trainer -     T-F1(C) = 0.9756097560975611
10/09/2021 10:06:22 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 10:06:22 - INFO - trainer -     T-F1(O) = 0.9965300368683582
10/09/2021 10:06:22 - INFO - trainer -     T-F1(P) = 0.9970743124634289
10/09/2021 10:06:22 - INFO - trainer -     T-F1(S) = 0.9926199261992621
10/09/2021 10:06:22 - INFO - trainer -     T-F1(T) = 0.9747899159663864
10/09/2021 10:06:22 - INFO - trainer -     U-F1(A) = 0.6779661016949152
10/09/2021 10:06:22 - INFO - trainer -     U-F1(E) = 0.7495219885277247
10/09/2021 10:06:22 - INFO - trainer -     U-F1(I) = 0.3
10/09/2021 10:06:22 - INFO - trainer -     U-F1(O) = 0.9646814404432132
10/09/2021 10:06:22 - INFO - trainer -     intent_acc = 0.9355432780847146
10/09/2021 10:06:22 - INFO - trainer -     loss = 0.5467163833844311
10/09/2021 10:06:22 - INFO - trainer -     semantic_frame_acc = 0.9205033763044813
10/09/2021 10:06:22 - INFO - trainer -     slot_f1 = 0.9909331845445669
10/09/2021 10:06:22 - INFO - trainer -     slot_precision = 0.9899665551839465
10/09/2021 10:06:22 - INFO - trainer -     slot_recall = 0.9919017034347948

10/09/2021 10:06:22 - INFO - trainer -   ***** Current best eval results based on U-F1(I) *****
10/09/2021 10:06:22 - INFO - trainer -     T-F1 = 0.9912639912639912
10/09/2021 10:06:22 - INFO - trainer -     T-F1(C) = 0.9782923299565845
10/09/2021 10:06:22 - INFO - trainer -     T-F1(L) = 0.991044776119403
10/09/2021 10:06:22 - INFO - trainer -     T-F1(O) = 0.9965311653116531
10/09/2021 10:06:22 - INFO - trainer -     T-F1(P) = 0.9959040374488005
10/09/2021 10:06:22 - INFO - trainer -     T-F1(S) = 0.9935304990757856
10/09/2021 10:06:22 - INFO - trainer -     T-F1(T) = 0.9749303621169918
10/09/2021 10:06:22 - INFO - trainer -     U-F1(A) = 0.7647058823529411
10/09/2021 10:06:22 - INFO - trainer -     U-F1(E) = 0.7773722627737225
10/09/2021 10:06:22 - INFO - trainer -     U-F1(I) = 0.37209302325581395
10/09/2021 10:06:22 - INFO - trainer -     U-F1(O) = 0.9683621744450271
10/09/2021 10:06:22 - INFO - trainer -     intent_acc = 0.9419889502762431
10/09/2021 10:06:22 - INFO - trainer -     semantic_frame_acc = 0.9257213014119091
10/09/2021 10:06:22 - INFO - trainer -     slot_f1 = 0.9909255898366607
10/09/2021 10:06:22 - INFO - trainer -     slot_precision = 0.990787269681742
10/09/2021 10:06:22 - INFO - trainer -     slot_recall = 0.9910639486177045
Iteration: 100%|█████████████████████████████████████████████████████████████████████| 918/918 [02:06<00:00,  7.27it/s]
Epoch: 100%|██████████████████████████████████████████████████████████████████████████| 20/20 [48:58<00:00, 146.92s/it]
10/09/2021 10:06:41 - INFO - transformers.configuration_utils -   loading configuration file final_low_distilbert_e_model\config.json
10/09/2021 10:06:41 - INFO - transformers.configuration_utils -   Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "JointDistilBERT"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "finetuning_task": "low",
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "vocab_size": 30522
}

10/09/2021 10:06:41 - INFO - transformers.modeling_utils -   loading weights file final_low_distilbert_e_model\pytorch_model.bin
10/09/2021 10:06:42 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing JointDistilBERT.

10/09/2021 10:06:42 - INFO - transformers.modeling_utils -   All the weights of JointDistilBERT were initialized from the model checkpoint at final_low_distilbert_e_model.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use JointDistilBERT for predictions without further training.
10/09/2021 10:06:42 - INFO - trainer -   ***** Model Loaded *****
10/09/2021 10:06:42 - INFO - trainer -   ***** Running evaluation on test dataset *****
10/09/2021 10:06:42 - INFO - trainer -     Num examples = 3628
10/09/2021 10:06:42 - INFO - trainer -     Batch size = 64
Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 57/57 [00:04<00:00, 13.78it/s]
10/09/2021 10:06:47 - INFO - trainer -   ***** Eval results *****
10/09/2021 10:06:47 - INFO - trainer -     T-F1 = 0.9898765432098765
10/09/2021 10:06:47 - INFO - trainer -     T-F1(C) = 0.9801699716713882
10/09/2021 10:06:47 - INFO - trainer -     T-F1(L) = 0.9771689497716893
10/09/2021 10:06:47 - INFO - trainer -     T-F1(O) = 0.9960374987919204
10/09/2021 10:06:47 - INFO - trainer -     T-F1(P) = 0.9968635650810246
10/09/2021 10:06:47 - INFO - trainer -     T-F1(S) = 0.988313856427379
10/09/2021 10:06:47 - INFO - trainer -     T-F1(T) = 0.9754768392370572
10/09/2021 10:06:47 - INFO - trainer -     U-F1(A) = 0.7788461538461539
10/09/2021 10:06:47 - INFO - trainer -     U-F1(E) = 0.7360308285163776
10/09/2021 10:06:47 - INFO - trainer -     U-F1(I) = 0.36363636363636365
10/09/2021 10:06:47 - INFO - trainer -     U-F1(O) = 0.9687982700030892
10/09/2021 10:06:47 - INFO - trainer -     intent_acc = 0.942116868798236
10/09/2021 10:06:47 - INFO - trainer -     loss = 0.26794809782714174
10/09/2021 10:06:47 - INFO - trainer -     semantic_frame_acc = 0.9230981256890849
10/09/2021 10:06:47 - INFO - trainer -     slot_f1 = 0.9895939086294416
10/09/2021 10:06:47 - INFO - trainer -     slot_precision = 0.9895939086294416
10/09/2021 10:06:47 - INFO - trainer -     slot_recall = 0.9895939086294416
